2025-06-01 02:44:21,028 - INFO - Starting test of 11 tasks: task_id_0, task_id_58, task_id_77, task_id_127, task_id_227, task_id_404, task_id_431, task_id_433, task_id_435, task_id_441, task_id_447
2025-06-01 02:44:21,028 - INFO - 
==================================================
2025-06-01 02:44:21,028 - INFO - Processing task task_id_0...
2025-06-01 02:44:21,028 - INFO - Reading problem description and code template from tasks/task_id_0...
2025-06-01 02:44:21,028 - INFO - Problem description length: 310 characters
2025-06-01 02:44:21,028 - INFO - Reading unit tests from tasks/task_id_0...
2025-06-01 02:44:21,028 - INFO - Unit tests length: 69 characters
2025-06-01 02:44:21,029 - INFO - Running main workflow to generate solution...
2025-06-01 02:44:21,029 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.

-----Input-----
The input consists of one natural number:
x: An natural number.

-----Output-----
The output is a natural number which the value equals to x.
2025-06-01 02:44:21,029 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def ident (x : Nat) : Nat :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


def ident_spec (x : Nat) (result: Nat) : Prop :=
  -- << SPEC START >>
  result = x
  -- << SPEC END >>

theorem ident_spec_satisfied (x : Nat) :
  ident_spec x (ident x) := by
  -- << PROOF START >>
  unfold ident ident_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:44:21,058 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x74e20422e8e0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:44:21,060 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:44:21,060 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:44:21,067 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e203e6e0f0>
2025-06-01 02:44:21,067 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e20473f250> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:44:21,074 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204738ad0>
2025-06-01 02:44:21,074 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:44:21,074 - DEBUG - send_request_headers.complete
2025-06-01 02:44:21,074 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:44:21,074 - DEBUG - send_request_body.complete
2025-06-01 02:44:21,075 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:44:21,598 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'59'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-78998c59cd-rjbtl'), (b'x-envoy-upstream-service-time', b'62'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999923'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'4ms'), (b'x-request-id', b'req_0fab1df6615b1892fcccd57d870ca7fc'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=XDedkRQ5Eswti.fVFrPYG614uFbaSnVOJz0b7IwdNa0-1748745861-1.0.1.1-qfq9xf9MbfLob.AwjsS8308W01YxfN4G5fBDCL6QznYN1u0YCfwFUm_xR9gOJSbghQDL3JXulgLAO8LykBsIPbgpFcLsGs8J9rOtLkQopcw; path=/; expires=Sun, 01-Jun-25 03:14:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=VADCq8BAchMxkRzUgymrwviXl7XiEDdGh_7dUqoEb0Y-1748745861611-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b5e5fddf53bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:44:21,599 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:44:21,599 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:44:21,599 - DEBUG - receive_response_body.complete
2025-06-01 02:44:21,599 - DEBUG - response_closed.started
2025-06-01 02:44:21,599 - DEBUG - response_closed.complete
2025-06-01 02:44:21,600 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:44:21 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '59'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-78998c59cd-rjbtl'), ('x-envoy-upstream-service-time', '62'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999923'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '4ms'), ('x-request-id', 'req_0fab1df6615b1892fcccd57d870ca7fc'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=XDedkRQ5Eswti.fVFrPYG614uFbaSnVOJz0b7IwdNa0-1748745861-1.0.1.1-qfq9xf9MbfLob.AwjsS8308W01YxfN4G5fBDCL6QznYN1u0YCfwFUm_xR9gOJSbghQDL3JXulgLAO8LykBsIPbgpFcLsGs8J9rOtLkQopcw; path=/; expires=Sun, 01-Jun-25 03:14:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=VADCq8BAchMxkRzUgymrwviXl7XiEDdGh_7dUqoEb0Y-1748745861611-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b5e5fddf53bfe-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:44:21,600 - DEBUG - request_id: req_0fab1df6615b1892fcccd57d870ca7fc
2025-06-01 02:44:21,608 - INFO - Retrieved context:  modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
 Lean failed to infer it. Named arguments also improve
the readability of your code by identifying what each argument represents.

    
    
    def sum (xs : List Nat) :=
      xs.foldl (init := 0) (·+·)
    
    #eval sum [1, 2, 3, 4]
    -- 10
    
    example {a b : Nat} {p : Nat → Nat → Nat → Prop} (h₁ : p a b b) (h₂ : b = a)
        : p a a b :=
      Eq.subst (motive := fun x => p a x b) h₂ h₁
    

In the following examples, we illustrate the interaction between named and
default arguments.

    
    
    def f (x : Nat) (y : Nat := 1) (w : Nat := 2) (z : Nat) :=
      x + y + w - z
    
    example (x z : Nat) : f (z := z) x = x + 1 + 2 - z := rfl
    
    example (x z : Nat) : f x (z := z) = x + 1 + 2 - z := rfl
    
    example (x y : Nat) : f x y = fun z => x + y + 2 - z := rfl
    
    example : f = (fun x z => x + 1 + 2 - z) := rfl
    
    example (x : Nat) : f x = fun z => x + 1 + 2 - z := rfl
    
    example (y : Nat) : f (y := 5) = fun x z => x + 5 + 2 - z := rfl
    
    def g {α} [Add α] (a : α) (b? : Option α := none) (c : α) : α :=
      match b? with
      | none   => a + c
      | some b => a + b + c
    
    variable {α} [Add α]
    
    example : g = fun (a c : α) => a + c := rfl
    
    example (x : α) : g (c := x) = fun (a : α) => a + x := rfl
    
    example (x : α) : g (b? := some x) = fun (a c : α) => a + x + c := rfl
    
    example (x : α) : g x = fun (c : α) => x + c := rfl
    
    example (x y : α) : g x y = fun (c : α) => x + y + c := rfl
    

You can use `..` to provide missing explicit arguments as `_`. This feature
combined with named arguments is useful for writing patterns. Here is an
example:

    
    
    inductive Term where
      | var    (name : String)
      | num    (val : Nat)
      | app    (fn : Term) (arg : Term)
      | lambda (name : String) (type : Term) (body : Term)
    
    def getBinderName : Term → Option String
      | Term.lambda (name := n) .. => some n
      | _ => none
    
    def getBinderType : Term → Option Term
      | Term.lambda (type := t) .. => some t
      | _ => none
    

Ellipses are also useful when explicit arguments can be automatically inferred
by Lean, and we want to avoid a sequence of `_`s.

    
    
    example (f : Nat → Nat) (a b c : Nat) : f (a + b + c) = f (a + (b + c)) :=
      congrArg f (Nat.add_assoc ..)
    

[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next
chapter")

[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next
chapter")
2025-06-01 02:44:21,621 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.'}], 'model': 'o3-mini'}}
2025-06-01 02:44:21,622 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:44:21,622 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:44:21,630 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204270d10>
2025-06-01 02:44:21,631 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:44:21,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204270fe0>
2025-06-01 02:44:21,639 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:44:21,639 - DEBUG - send_request_headers.complete
2025-06-01 02:44:21,640 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:44:21,640 - DEBUG - send_request_body.complete
2025-06-01 02:44:21,640 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:44:27,580 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:44:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5451'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5454'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199622'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'113ms'), (b'x-request-id', b'req_02ac3a1d3f302af5716d235d9d425b23'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=NWkdm_l9QdZiJ9Uq8fHW95HJ5vdZemUugqk4swtiOpg-1748745867-1.0.1.1-vXjyzkuzYf_1TTNl2ShxQ78.ZbXbbT6IBQKUvXbyqN0hY60mQZgMR8axAxoioJTIKxBWNEVUeToSSwdW3lKb8xvkfdWE_BhWiDZEscCDmHU; path=/; expires=Sun, 01-Jun-25 03:14:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=pJUpkJaMDgKj7jJTLNQ.KPPEMK82GCy6kmnFF9lYV8Q-1748745867598-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b5e636dbc4436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:44:27,581 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:44:27,581 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:44:27,581 - DEBUG - receive_response_body.complete
2025-06-01 02:44:27,581 - DEBUG - response_closed.started
2025-06-01 02:44:27,581 - DEBUG - response_closed.complete
2025-06-01 02:44:27,581 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:44:27 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '5451'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '5454'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '199622'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '113ms'), ('x-request-id', 'req_02ac3a1d3f302af5716d235d9d425b23'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=NWkdm_l9QdZiJ9Uq8fHW95HJ5vdZemUugqk4swtiOpg-1748745867-1.0.1.1-vXjyzkuzYf_1TTNl2ShxQ78.ZbXbbT6IBQKUvXbyqN0hY60mQZgMR8axAxoioJTIKxBWNEVUeToSSwdW3lKb8xvkfdWE_BhWiDZEscCDmHU; path=/; expires=Sun, 01-Jun-25 03:14:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=pJUpkJaMDgKj7jJTLNQ.KPPEMK82GCy6kmnFF9lYV8Q-1748745867598-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b5e636dbc4436-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:44:27,582 - DEBUG - request_id: req_02ac3a1d3f302af5716d235d9d425b23
2025-06-01 02:44:27,585 - INFO - Attempt 1/3
2025-06-01 02:44:27,585 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that simply returns its input natural number. The function is the identity function on natural numbers.",
  "steps": [
    "Define a function with the appropriate type signature (ℕ -> ℕ) using Lean 4 syntax.",
    "Make the function simply return the input argument without any modifications.",
    "Verify that the function meets the requirements: for any input x, the output is x."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "natural numbers",
    "identity function"
  ],
  "proof_keywords": [
    "definition by inspection",
    "reflexivity"
  ],
  "assumptions": [
    "The function should not perform any computation other than returning the input.",
    "The natural number type is represented as ℕ in Lean 4."
  ],
  "retry_guidance": "If any issues arise with the type signature or Lean 4 syntax, review Lean's function definition syntax and ensure that ℕ is properly imported or declared in the environment."
}
2025-06-01 02:44:27,586 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that simply returns its input natural number. The function is the identity function on natural numbers.",\n  "steps": [\n    "Define a function with the appropriate type signature (ℕ -> ℕ) using Lean 4 syntax.",\n    "Make the function simply return the input argument without any modifications.",\n    "Verify that the function meets the requirements: for any input x, the output is x."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "natural numbers",\n    "identity function"\n  ],\n  "proof_keywords": [\n    "definition by inspection",\n    "reflexivity"\n  ],\n  "assumptions": [\n    "The function should not perform any computation other than returning the input.",\n    "The natural number type is represented as ℕ in Lean 4."\n  ],\n  "retry_guidance": "If any issues arise with the type signature or Lean 4 syntax, review Lean\'s function definition syntax and ensure that ℕ is properly imported or declared in the environment."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef ident (x : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\ndef ident_spec (x : Nat) (result: Nat) : Prop :=\n  -- << SPEC START >>\n  result = x\n  -- << SPEC END >>\n\ntheorem ident_spec_satisfied (x : Nat) :\n  ident_spec x (ident x) := by\n  -- << PROOF START >>\n  unfold ident ident_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n Lean failed to infer it. Named arguments also improve\nthe readability of your code by identifying what each argument represents.\n\n    \n    \n    def sum (xs : List Nat) :=\n      xs.foldl (init := 0) (·+·)\n    \n    #eval sum [1, 2, 3, 4]\n    -- 10\n    \n    example {a b : Nat} {p : Nat → Nat → Nat → Prop} (h₁ : p a b b) (h₂ : b = a)\n        : p a a b :=\n      Eq.subst (motive := fun x => p a x b) h₂ h₁\n    \n\nIn the following examples, we illustrate the interaction between named and\ndefault arguments.\n\n    \n    \n    def f (x : Nat) (y : Nat := 1) (w : Nat := 2) (z : Nat) :=\n      x + y + w - z\n    \n    example (x z : Nat) : f (z := z) x = x + 1 + 2 - z := rfl\n    \n    example (x z : Nat) : f x (z := z) = x + 1 + 2 - z := rfl\n    \n    example (x y : Nat) : f x y = fun z => x + y + 2 - z := rfl\n    \n    example : f = (fun x z => x + 1 + 2 - z) := rfl\n    \n    example (x : Nat) : f x = fun z => x + 1 + 2 - z := rfl\n    \n    example (y : Nat) : f (y := 5) = fun x z => x + 5 + 2 - z := rfl\n    \n    def g {α} [Add α] (a : α) (b? : Option α := none) (c : α) : α :=\n      match b? with\n      | none   => a + c\n      | some b => a + b + c\n    \n    variable {α} [Add α]\n    \n    example : g = fun (a c : α) => a + c := rfl\n    \n    example (x : α) : g (c := x) = fun (a : α) => a + x := rfl\n    \n    example (x : α) : g (b? := some x) = fun (a c : α) => a + x + c := rfl\n    \n    example (x : α) : g x = fun (c : α) => x + c := rfl\n    \n    example (x y : α) : g x y = fun (c : α) => x + y + c := rfl\n    \n\nYou can use `..` to provide missing explicit arguments as `_`. This feature\ncombined with named arguments is useful for writing patterns. Here is an\nexample:\n\n    \n    \n    inductive Term where\n      | var    (name : String)\n      | num    (val : Nat)\n      | app    (fn : Term) (arg : Term)\n      | lambda (name : String) (type : Term) (body : Term)\n    \n    def getBinderName : Term → Option String\n      | Term.lambda (name := n) .. => some n\n      | _ => none\n    \n    def getBinderType : Term → Option Term\n      | Term.lambda (type := t) .. => some t\n      | _ => none\n    \n\nEllipses are also useful when explicit arguments can be automatically inferred\nby Lean, and we want to avoid a sequence of `_`s.\n\n    \n    \n    example (f : Nat → Nat) (a b c : Nat) : f (a + b + c) = f (a + (b + c)) :=\n      congrArg f (Nat.add_assoc ..)\n    \n\n[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next\nchapter")\n\n[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next\nchapter")'}], 'model': 'gpt-4o'}}
2025-06-01 02:44:27,587 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:44:27,588 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:44:27,588 - DEBUG - send_request_headers.complete
2025-06-01 02:44:27,588 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:44:27,593 - DEBUG - send_request_body.complete
2025-06-01 02:44:27,593 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:44:31,738 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:44:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'3488'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'3492'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'13976'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'32.048s'), (b'x-request-id', b'req_a69f560f0f233cb9c5fa6ccc61012b0b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b5e889bdd4436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:44:31,738 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:44:31,738 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:44:31,741 - DEBUG - receive_response_body.complete
2025-06-01 02:44:31,741 - DEBUG - response_closed.started
2025-06-01 02:44:31,741 - DEBUG - response_closed.complete
2025-06-01 02:44:31,742 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:44:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '3488', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '3492', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '13976', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '32.048s', 'x-request-id': 'req_a69f560f0f233cb9c5fa6ccc61012b0b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b5e889bdd4436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:44:31,742 - DEBUG - request_id: req_a69f560f0f233cb9c5fa6ccc61012b0b
2025-06-01 02:44:31,742 - INFO - Raw solution received: ```json
{
  "code": "x",
  "proof": "rfl"
}
```
2025-06-01 02:44:31,742 - INFO - <class 'str'>
2025-06-01 02:44:31,742 - INFO - Generated solution: {'code': 'x', 'proof': 'rfl'}
2025-06-01 02:44:37,146 - INFO - Lean execution result: Lean code executed successfully.
2025-06-01 02:44:37,146 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef ident (x : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\ndef ident_spec (x : Nat) (result: Nat) : Prop :=\n  -- << SPEC START >>\n  result = x\n  -- << SPEC END >>\n\ntheorem ident_spec_satisfied (x : Nat) :\n  ident_spec x (ident x) := by\n  -- << PROOF START >>\n  unfold ident ident_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nx\n\nGenerated Proof:\nrfl\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean code executed successfully.'}], 'model': 'o3-mini'}}
2025-06-01 02:44:37,147 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:44:37,147 - DEBUG - close.started
2025-06-01 02:44:37,147 - DEBUG - close.complete
2025-06-01 02:44:37,147 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:44:37,154 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204290260>
2025-06-01 02:44:37,154 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:44:37,163 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204273ef0>
2025-06-01 02:44:37,163 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:44:37,164 - DEBUG - send_request_headers.complete
2025-06-01 02:44:37,164 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:44:37,164 - DEBUG - send_request_body.complete
2025-06-01 02:44:37,164 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:44:41,287 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:44:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'3893'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'3901'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199425'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'172ms'), (b'x-request-id', b'req_40713ecd59c8f6addc71ca31f54ae9fe'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b5ec46b368fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:44:41,287 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:44:41,287 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:44:41,288 - DEBUG - receive_response_body.complete
2025-06-01 02:44:41,288 - DEBUG - response_closed.started
2025-06-01 02:44:41,288 - DEBUG - response_closed.complete
2025-06-01 02:44:41,288 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:44:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '3893', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '3901', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199425', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '172ms', 'x-request-id': 'req_40713ecd59c8f6addc71ca31f54ae9fe', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b5ec46b368fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:44:41,288 - DEBUG - request_id: req_40713ecd59c8f6addc71ca31f54ae9fe
2025-06-01 02:44:41,288 - INFO - Feedback received: {'verdict': 'pass', 'error_summary': "The code and proof have executed without errors. The function 'ident' correctly returns its input, and the proof 'ident_spec_satisfied' using 'rfl' completes the verification.", 'error_type': '', 'suggested_fix': 'No modifications are necessary.', 'retry_strategy': 'No retry required.'}
2025-06-01 02:44:41,288 - INFO - Solution generated in 20.26 seconds
2025-06-01 02:44:41,288 - INFO - Generated code length: 1 characters
2025-06-01 02:44:41,288 - INFO - Generated proof length: 3 characters
2025-06-01 02:44:41,289 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:44:41,289 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:44:46,479 - INFO - Implementation test result: PASS
2025-06-01 02:44:46,479 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:44:51,720 - INFO - Full solution test result: PASS
2025-06-01 02:44:51,720 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:44:51,721 - INFO - ✅ Proof is correct
2025-06-01 02:44:51,721 - INFO - 
==================================================
2025-06-01 02:44:51,721 - INFO - Processing task task_id_58...
2025-06-01 02:44:51,721 - INFO - Reading problem description and code template from tasks/task_id_58...
2025-06-01 02:44:51,721 - INFO - Problem description length: 700 characters
2025-06-01 02:44:51,721 - INFO - Reading unit tests from tasks/task_id_58...
2025-06-01 02:44:51,721 - INFO - Unit tests length: 462 characters
2025-06-01 02:44:51,721 - INFO - Running main workflow to generate solution...
2025-06-01 02:44:51,721 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.

-----Input-----
The input consists of two integers:
a: An integer.
b: An integer.

-----Output-----
The output is a Boolean value:
Returns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).
Returns false if both integers are either non-negative or non-positive, or if one (or both) is zero.
2025-06-01 02:44:51,721 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def hasOppositeSign (a : Int) (b : Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result is true if a and b have opposite signs
def hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=
  -- << SPEC START >>
  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result
  -- << SPEC END >>

theorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :
  hasOppositeSign_spec a b (hasOppositeSign a b) := by
  -- << PROOF START >>
  unfold hasOppositeSign hasOppositeSign_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:44:51,751 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x74e20422f1a0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:44:51,752 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:44:51,752 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:44:51,759 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204273680>
2025-06-01 02:44:51,759 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e20448fdd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:44:51,768 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204273b60>
2025-06-01 02:44:51,768 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:44:51,768 - DEBUG - send_request_headers.complete
2025-06-01 02:44:51,768 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:44:51,768 - DEBUG - send_request_body.complete
2025-06-01 02:44:51,768 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:44:52,322 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:44:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'72'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5c589d798-z5tjt'), (b'x-envoy-upstream-service-time', b'74'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999825'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_b802fbbe2e761f79855dae43334e8652'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=M2SI370ZiY_DpG7aP.Ha8POs2.Ng2f8tClL1GjArEXE-1748745892-1.0.1.1-7Y4xtaqS7DpQIJ5bA.I1mrSqK9qpr0Olz1mG1AWK9hk5Hns1Zq8_QgGoSNWxfIV0kt0D5AA1sejuv0TYetDt0W_sXSynjV.NRWVLw0AZ7ag; path=/; expires=Sun, 01-Jun-25 03:14:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=o3VLH25rARcl_Cmq3XlQhww0pWnUNJXw4ehVgALjFqE-1748745892341-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b5f1fbf564436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:44:52,323 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:44:52,323 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:44:52,323 - DEBUG - receive_response_body.complete
2025-06-01 02:44:52,323 - DEBUG - response_closed.started
2025-06-01 02:44:52,323 - DEBUG - response_closed.complete
2025-06-01 02:44:52,324 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:44:52 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '72'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-5c589d798-z5tjt'), ('x-envoy-upstream-service-time', '74'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999825'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '10ms'), ('x-request-id', 'req_b802fbbe2e761f79855dae43334e8652'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=M2SI370ZiY_DpG7aP.Ha8POs2.Ng2f8tClL1GjArEXE-1748745892-1.0.1.1-7Y4xtaqS7DpQIJ5bA.I1mrSqK9qpr0Olz1mG1AWK9hk5Hns1Zq8_QgGoSNWxfIV0kt0D5AA1sejuv0TYetDt0W_sXSynjV.NRWVLw0AZ7ag; path=/; expires=Sun, 01-Jun-25 03:14:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=o3VLH25rARcl_Cmq3XlQhww0pWnUNJXw4ehVgALjFqE-1748745892341-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b5f1fbf564436-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:44:52,324 - DEBUG - request_id: req_b802fbbe2e761f79855dae43334e8652
2025-06-01 02:44:52,329 - INFO - Retrieved context:  the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
� r)`

Distributivity:

  5. `p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)`
  6. `p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)`

Other properties:

  7. `(p → (q → r)) ↔ (p ∧ q → r)`
  8. `((p ∨ q) → r) ↔ (p → r) ∧ (q → r)`
  9. `¬(p ∨ q) ↔ ¬p ∧ ¬q`
  10. `¬p ∨ ¬q → ¬(p ∧ q)`
  11. `¬(p ∧ ¬p)`
  12. `p ∧ ¬q → ¬(p → q)`
  13. `¬p → (p → q)`
  14. `(¬p ∨ q) → (p → q)`
  15. `p ∨ False ↔ p`
  16. `p ∧ False ↔ False`
  17. `¬(p ↔ ¬p)`
  18. `(p → q) → (¬q → ¬p)`

These require classical reasoning:

  19. `(p → r ∨ s) → ((p → r) ∨ (p → s))`
  20. `¬(p ∧ q) → ¬p ∨ ¬q`
  21. `¬(p → q) → p ∧ ¬q`
  22. `(p → q) → (¬p ∨ q)`
  23. `(¬q → ¬p) → (p → q)`
  24. `p ∨ ¬p`
  25. `(((p → q) → p) → p)`

The `sorry` identifier magically produces a proof of anything, or provides an
object of any data type at all. Of course, it is unsound as a proof method --
for example, you can use it to prove `False` \-- and Lean produces severe
warnings when files use or import theorems which depend on it. But it is very
useful for building long proofs incrementally. Start writing the proof from
the top down, using `sorry` to fill in subproofs. Make sure Lean accepts the
term with all the `sorry`'s; if not, there are errors that you need to
correct. Then go back and replace each `sorry` with an actual proof, until no
more remain.

Here is another useful trick. Instead of using `sorry`, you can use an
underscore `_` as a placeholder. Recall this tells Lean that the argument is
implicit, and should be filled in automatically. If Lean tries to do so and
fails, it returns with an error message "don't know how to synthesize
placeholder," followed by the type of the term it is expecting, and all the
objects and hypotheses available in the context. In other words, for each
unresolved placeholder, Lean reports the subgoal that needs to be filled at
that point. You can then construct a proof by incrementally filling in these
placeholders.

For reference, here are two sample proofs of validities taken from the list
above.

    
    
    open Classical
    
    -- distributivity
    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
      Iff.intro
        (fun h : p ∧ (q ∨ r) =>
          have hp : p := h.left
          Or.elim (h.right)
            (fun hq : q =>
              show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)
            (fun hr : r =>
              show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))
        (fun h : (p ∧ q) ∨ (p ∧ r) =>
          Or.elim h
            (fun hpq : p ∧ q =>
              have hp : p := hpq.left
              have hq : q := hpq.right
              show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)
            (fun hpr : p ∧ r =>
              have hp : p := hpr.left
              have hr : r := hpr.right
              show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))
    
    -- an example that requires classical reasoning
    example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=
      fun h : ¬(p ∧ ¬q) =>
      fun hp : p =>
      show q from
        Or.elim (em q)
          (fun hq : q => hq)
          (fun hnq : ¬q => absurd (And.intro hp hnq) h)
    

## Exercises

Prove the following identities, replacing the "sorry" placeholders with actual
proofs.

    
    
    variable (p q r : Prop)
    
    -- commutativity of ∧ and ∨
    example : p ∧ q ↔ q ∧ p := sorry
    example : p ∨ q ↔ q ∨ p := sorry
    
    -- associativity of ∧ and ∨
    example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry
    example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry
    
    -- distributivity
    example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry
    example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry
    
    -- other properties
    example : (p → (q → r)) ↔ (p ∧ q → r) := sorry
    example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry
    example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry
    example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry
    example : ¬(p ∧ ¬p) := sorry
    example : p ∧ ¬q → ¬(p → q) := sorry
    example : ¬p → (p → q) := sorry
    example : (¬p ∨ q) → (p → q) := sorry
    example : p ∨ False ↔ p := sorry
    example : p ∧ False ↔ False := sorry
    example : (p → q) → (¬q → ¬p) := sorry
    

Prove the following identities, replacing the "sorry" placeholders with actual
proofs. These require classical reasoning.

    
    
    open Classical
    
    variable (p q r : Prop)
    
    example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry
    example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry
    example : ¬(p → q) → p ∧ ¬q := sorry
    example : (p → q) → (¬p ∨ q) := sorry
    example : (¬q → ¬p) → (p → q) := sorry
    example : p ∨ ¬p := sorry
    example : (((p → q) → p) → p) := sorry
    

Prove `¬(p ↔ ¬p)` without using classical logic.

[ __](dependent_type_theory.html "Previous chapter") [
__](quantifiers_and_equality.html "Next chapter")

[ __](dependent_type_theory.html "Previous chapter") [
__](quantifiers_and_equality.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Propositions and Proofs

By now, you have seen some ways of defining objects and functions in Lean. In
this chapter, we will begin to explain how to write mathematical assertions
and proofs in the language of dependent type theory as well.

## Propositions as Types

One strategy for proving assertions about objects defined in the language of
dependent type theory is to layer an assertion language and a proof language
on top of the definition language. But there is no reason to multiply
languages in this way: dependent type theory is flexible and expressive, and
there is no reason we cannot represent assertions and proofs in the same
general framework.

For example, we could introduce a new type, `Prop`, to represent propositions,
and introduce constructors to build new propositions from others.

    
    
    def Implies (p q : Prop) : Prop := p → q
    #check And     -- Prop → Prop → Prop
    #check Or      -- Prop → Prop → Prop
    #check Not     -- Prop → Prop
    #check Implies -- Prop → Prop → Prop
    
    variable (p q r : Prop)
    #check And p q                      -- Prop
    #check Or (And p q) r               -- Prop
    #check Implies (And p q) (And q p)  -- Prop
    

We could then introduce, for each element `p : Prop`, another type `Proof p`,
for the type of proofs of `p`. An "axiom" would be a constant of such a type.

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    #check Proof   -- Proof : Prop → Type
    
    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))
    
    variable (p q : Prop)
    #check and_comm p q     -- Proof (Implies (And p q) (And q p))
    

In addition to axioms, however, we would also need rules to build new proofs
from old ones. For example, in many proof systems for propositional logic, we
have the rule of _modus ponens_ :

> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.

We could represent this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q
    

Systems of natural deduction for propositional logic also typically rely on
the following rule:

> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we
> can "cancel" the hypothesis and obtain a proof of `Implies p q`.

We could render this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)
    

This approach would provide us with a reasonable way of building assertions
and proofs. Determining that an expression `t` is a correct proof of assertion
`p` would then simply be a matter of checking that `t` has type `Proof p`.

Some simplifications are possible, however. To start with, we can avoid
writing the term `Proof` repeatedly by conflating `Proof p` with `p` itself.
In other words, whenever we have `p : Prop`, we can interpret `p` as a type,
namely, the type of its proofs. We can then read `t : p` as the assertion that
`t` is a proof of `p`.

Moreover, once we make this identification, the rules for implication show
that we can pass back and forth between `Implies p q` and `p → q`. In other
words, implication between propositions `p` and `q` corresponds to having a
function that takes any element of `p` to an element of `q`. As a result, the
introduction of the connective `Implies` is entirely redundant: we can use the
usual function space constructor `p → q` from dependent type theory as our
notion of implication.

This is the approach followed in the Calculus of Constructions, and hence in
Lean as well. The fact that the rules for implication in a proof system for
natural deduction correspond exactly to the rules governing abstraction and
application for functions is an instance of the _Curry-Howard isomorphism_ ,
sometimes known as the _propositions-as-types_ paradigm. In fact, the type
`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy
described in the last chapter. Moreover, `Type u` is also just syntactic sugar
for `Sort (u+1)`. `Prop` has some special features, but like the other type
universes, it is closed under the arrow constructor: if we have `p q : Prop`,
then `p → q : Prop`.

There are at least two ways of thinking about propositions as types. To some
who take a constructive view of logic and mathematics, this is a faithful
rendering of what it means to be a proposition: a proposition `p` represents a
sort of data type, namely, a specification of the type of data that
constitutes a proof. A proof of `p` is then simply an object `t : p` of the
right type.

Those not inclined to this ideology can view it, rather, as a simple coding
trick. To each proposition `p` we associate a type that is empty if `p` is
false and has a single element, say `*`, if `p` is true. In the latter case,
let us say that (the type associated with) `p` is _inhabited_. It just so
happens that the rules for function application and abstraction can
conveniently help us keep track of which elements of `Prop` are inhabited. So
constructing an element `t : p` tells us that `p` is indeed true. You can
think of the inhabitant of `p` as being the "fact that `p` is true." A proof
of `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is
true."

Indeed, if `p : Prop` is any proposition, Lean's kernel treats any two
elements `t1 t2 : p` as being definitionally equal, much the same way as it
treats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as
_proof irrelevance,_ and is consistent with the interpretation in the last
paragraph. It means that even though we can treat proofs `t : p` as ordinary
objects in the language of dependent type theory, they carry no information
beyond the fact that `p` is true.

The two ways we have suggested thinking about the propositions-as-types
paradigm differ in a fundamental way. From the constructive point of view,
proofs are abstract mathematical objects that are _denoted_ by suitable
expressions in dependent type theory. In contrast, if we think in terms of the
coding trick described above, then the expressions themselves do not denote
anything interesting. Rather, it is the fact that we can write them down and
check that they are well-typed that ensures that the proposition in question
is true. In other words, the expressions _themselves_ are the proofs.

In the exposition below, we will slip back and forth between these two ways of
talking, at times saying that an expression "constructs" or "produces" or
"returns" a proof of a proposition, and at other times simply saying that it
"is" such a proof. This is similar to the way that computer scientists
occasionally blur the distinction between syntax and semantics by saying, at
times, that a program "computes" a certain function, and at other times
speaking as though the program "is" the function in question.

In any case, all that really matters is the bottom line. To formally express a
mathematical assertion in the language of dependent type theory, we need to
exhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a
term `t : p`. Lean's task, as a proof assistant, is to help us to construct
such a term, `t`, and to verify that it is well-formed and has the correct
type.

## Working with Propositions as Types

In the propositions-as-types paradigm, theorems involving only `→` can be
proved using lambda abstraction and application. In Lean, the `theorem`
command introduces a new theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    

Compare this proof to the expression `fun x : α => fun y : β => x` of type `α
→ β → α`, where `α` and `β` are data types. This describes the function that
takes arguments `x` and `y` of type `α` and `β`, respectively, and returns
`x`. The proof of `t1` has the same form, the only difference being that `p`
and `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of
`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis
(trivially) to establish that the conclusion, `p`, is true.

Note that the `theorem` command is really a version of the `def` command:
under the propositions and types correspondence, proving the theorem `p → q →
p` is really the same as defining an element of the associated type. To the
kernel type checker, there is no difference between the two.

There are a few pragmatic differences between definitions and theorems,
however. In normal circumstances, it is never necessary to unfold the
"definition" of a theorem; by proof irrelevance, any two proofs of that
theorem are definitionally equal. Once the proof of a theorem is complete,
typically we only need to know that the proof exists; it doesn't matter what
the proof is. In light of that fact, Lean tags proofs as _irreducible_ , which
serves as a hint to the parser (more precisely, the _elaborator_) that there
is generally no need to unfold them when processing a file. In fact, Lean is
generally able to process and check proofs in parallel, since assessing the
correctness of one proof does not require knowing the details of another.

As with definitions, the `#print` command will show you the proof of a
theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    
    #print t1
    

Notice that the lambda abstractions `hp : p` and `hq : q` can be viewed as
temporary assumptions in the proof of `t1`. Lean also allows us to specify the
type of the final term `hp`, explicitly, with a `show` statement:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p :=
      fun hp : p =>
      fun hq : q =>
      show p from hp
    

Adding such extra information can improve the clarity of a proof and help
detect errors when writing a proof. The `show` command does nothing more than
annotate the type, and, internally, all the presentations of `t1` that we have
seen produce the same term.

As with ordinary definitions, we can move the lambda-abstracted variables to
the left of the colon:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    #print t1    -- p → q → p
    

We can use the theorem `t1` just as a function application:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    axiom hp : p
    
    theorem t2 : q → p := t1 hp
    

The `axiom` declaration postulates the existence of an element of the given
type and may compromise logical consistency. For example, we can use it to
postulate that the empty type `False` has an element:

    
    
    axiom unsound : False
    -- Everything follows from false
    theorem ex : 1 = 0 :=
      False.elim unsound
    

Declaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as
witnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`
that `p` is true yields the theorem `t1 hp : q → p`.

Recall that we can also write theorem `t1` as follows:

    
    
    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp
    
    #print t1
    

The type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the
assertion "for every pair of propositions `p q`, we have `p → q → p`." For
example, we can move all parameters to the right of the colon:

    
    
    theorem t1 : ∀ {p q : Prop}, p → q → p :=
      fun {p q : Prop} (hp : p) (hq : q) => hp
    

If `p` and `q` have been declared as variables, Lean will generalize them for
us automatically:

    
    
    variable {p q : Prop}
    
    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp
    

In fact, by the propositions-as-types correspondence, we can declare the
assumption `hp` that `p` holds, as another variable:

    
    
    variable {p q : Prop}
    variable (hp : p)
    
    theorem t1 : q → p := fun (hq : q) => hp
    

Lean detects that the proof uses `hp` and automatically adds `hp : p` as a
premise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →
q → p`. Remember that this type can just as well be written `∀ (p q : Prop)
(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type
in which the target does not depend on the bound variable.

When we generalize `t1` in such a way, we can then apply it to different pairs
of propositions, to obtain different instances of the general theorem.

    
    
    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp
    
    variable (p q r s : Prop)
    
    #check t1 p q                -- p → q → p
    #check t1 r s                -- r → s → r
    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s
    
    variable (h : r → s)
    #check t1 (r → s) (s → r) h  -- (s → r) → r → s
    

Once again, using the propositions-as-types correspondence, the variable `h`
of type `r → s` can be viewed as the hypothesis, or premise, that `r → s`
holds.

As another example, let us consider the composition function discussed in the
last chapter, now with propositions instead of types.

    
    
    variable (p q r s : Prop)
    
    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=
      fun h₃ : p =>
      show r from h₁ (h₂ h₃)
    

As a theorem of propositional logic, what does `t2` say?

Note that it is often useful to use numeric unicode subscripts, entered as
`\0`, `\1`, `\2`, ..., for hypotheses, as we did in this example.

## Propositional Logic

Lean defines all the standard logical connectives and notation. The
propositional connectives come with the following notation:

Ascii| Unicode| Editor shortcut| Definition  
---|---|---|---  
True| | | True  
False| | | False  
Not| ¬| `\not`, `\neg`| Not  
/\| ∧| `\and`| And  
\/| ∨| `\or`| Or  
->| →| `\to`, `\r`, `\imp`|   
<->| ↔| `\iff`, `\lr`| Iff  
  
They all take values in `Prop`.

    
    
    variable (p q : Prop)
    
    #check p → q → p ∧ q
    #check ¬p → p ↔ False
    #check p ∨ q → q ∨ p
    

The order of operations is as follows: unary negation `¬` binds most strongly,
then `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧
e` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right
(nothing changes now that the arguments are elements of `Prop`, instead of
some other `Type`), as do the other binary connectives. So if we have `p q r :
Prop`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This
is just the "curried" form of `p ∧ q → r`.

In the last chapter we observed that lambda abstraction can be viewed as an
"introduction rule" for `→`. In the current setting, it shows how to
"introduce" or establish an implication. Application can be viewed as an
"elimination rule," showing how to "eliminate" or use an implication in a
proof. The other propositional connectives are defined in Lean's library in
the file `Prelude.core` (see [importing
files](./interacting_with_lean.html#importing-files) for more information on
the library hierarchy), and each connective comes with its canonical
introduction and elimination rules.

### Conjunction

The expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :
p` and `h2 : q`. It is common to describe `And.intro` as the _and-
introduction_ rule. In the next example we use `And.intro` to create a proof
of `p → q → p ∧ q`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq
    
    #check fun (hp : p) (hq : q) => And.intro hp hq
    

The `example` command states a theorem without naming it or storing it in the
permanent context. Essentially, it just checks that the given term has the
indicated type. It is convenient for illustration, and we will use it often.

The expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.
Similarly, `And.right h` is a proof of `q`. They are commonly known as the
left and right _and-elimination_ rules.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : p := And.left h
    example (h : p ∧ q) : q := And.right h
    

We can now prove `p ∧ q → q ∧ p` with the following proof term.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      And.intro (And.right h) (And.left h)
    

Notice that and-introduction and and-elimination are similar to the pairing
and projection operations for the Cartesian product. The difference is that
given `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while
`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is
another instance of the Curry-Howard isomorphism, but in contrast to
implication and the function space constructor, `∧` and `×` are treated
separately in Lean. With the analogy, however, the proof we have just
constructed is similar to a function that swaps the elements of a pair.

We will see in [Chapter Structures and Records](./structures_and_records.html)
that certain types in Lean are _structures_ , which is to say, the type is
defined with a single canonical _constructor_ which builds an element of the
type from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is
an example: the canonical way to construct an element is to apply `And.intro`
to suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous
constructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the
relevant type is an inductive type and can be inferred from the context. In
particular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:

    
    
    variable (p q : Prop)
    variable (hp : p) (hq : q)
    
    #check (⟨hp, hq⟩ : p ∧ q)
    

These angle brackets are obtained by typing `\<` and `\>`, respectively.

Lean provides another useful syntactic gadget. Given an expression `e` of an
inductive type `Foo` (possibly applied to some arguments), the notation
`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of
accessing functions without opening a namespace. For example, the following
two expressions mean the same thing:

    
    
    variable (xs : List Nat)
    
    #check List.length xs
    #check xs.length
    

As a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and
`h.right` for `And.right h`. We can therefore rewrite the sample proof above
conveniently as follows:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      ⟨h.right, h.left⟩
    

There is a fine line between brevity and obfuscation, and omitting information
in this way can sometimes make a proof harder to read. But for straightforward
constructions like the one above, when the type of `h` and the goal of the
construction are salient, the notation is clean and effective.

It is common to iterate constructions like "And." Lean also allows you to
flatten nested constructors that associate to the right, so that these two
proofs are equivalent:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, ⟨h.left, h.right⟩⟩
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, h.left, h.right⟩
    

This is often useful as well.

### Disjunction

The expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof
`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a
proof `hq : q`. These are the left and right _or-introduction_ rules.

    
    
    variable (p q : Prop)
    example (hp : p) : p ∨ q := Or.intro_left q hp
    example (hq : q) : p ∨ q := Or.intro_right p hq
    

The _or-elimination_ rule is slightly more complicated. The idea is that we
can prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`
follows from `q`. In other words, it is a proof by cases. In the expression
`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :
p → r` and `hqr : q → r`, and produces a proof of `r`. In the following
example, we use `Or.elim` to prove `p ∨ q → q ∨ p`.

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h
        (fun hp : p =>
          show q ∨ p from Or.intro_right q hp)
        (fun hq : q =>
          show q ∨ p from Or.intro_left p hq)
    

In most cases, the first argument of `Or.intro_right` and `Or.intro_left` can
be inferred automatically by Lean. Lean therefore provides `Or.inr` and
`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and
`Or.intro_left _`. Thus the proof term above could be written more concisely:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Notice that there is enough information in the full expression for Lean to
infer the types of `hp` and `hq` as well. But using the type annotations in
the longer version makes the proof more readable, and can help catch and debug
errors.

Because `Or` has two constructors, we cannot use anonymous constructor
notation. But we can still write `h.elim` instead of `Or.elim h`:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Once again, you should exercise judgment as to whether such abbreviations
enhance or diminish readability.

### Negation and Falsity

Negation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by
deriving a contradiction from `p`. Similarly, the expression `hnp hp` produces
a proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both
these rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is
produced by typing `\not` or `\neg`.)

    
    
    variable (p q : Prop)
    
    example (hpq : p → q) (hnq : ¬q) : ¬p :=
      fun hp : p =>
      show False from hnq (hpq hp)
    

The connective `False` has a single elimination rule, `False.elim`, which
expresses the fact that anything follows from a contradiction. This rule is
sometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the
_principle of explosion_.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)
    

The arbitrary fact, `q`, that follows from falsity is an implicit argument in
`False.elim` and is inferred automatically. This pattern, deriving an
arbitrary fact from contradictory hypotheses, is quite common, and is
represented by `absurd`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := absurd hp hnp
    

Here, for example, is a proof of `¬p → q → (q → p) → r`:

    
    
    variable (p q r : Prop)
    
    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=
      absurd (hqp hq) hnp
    

Incidentally, just as `False` has only an elimination rule, `True` has only an
introduction rule, `True.intro : true`. In other words, `True` is simply true,
and has a canonical proof, `True.intro`.

### Logical Equivalence

The expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`
and `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from
`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔
q`. Here is a proof of `p ∧ q ↔ q ∧ p`:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      Iff.intro
        (fun h : p ∧ q =>
         show q ∧ p from And.intro (And.right h) (And.left h))
        (fun h : q ∧ p =>
         show p ∧ q from And.intro (And.right h) (And.left h))
    
    #check and_swap p q    -- p ∧ q ↔ q ∧ p
    
    variable (h : p ∧ q)
    example : q ∧ p := Iff.mp (and_swap p q) h
    

We can use the anonymous constructor notation to construct a proof of `p ↔ q`
from proofs of the forward and backward directions, and we can also use `.`
notation with `mp` and `mpr`. The previous examples can therefore be written
concisely as follows:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩
    
    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h
    

## Introducing Auxiliary Subgoals

This is a good place to introduce another device Lean offers to help structure
long proofs, namely, the `have` construct, which introduces an auxiliary
subgoal in a proof. Here is a small example, adapted from the last section:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      have hq : q := h.right
      show q ∧ p from And.intro hq hp
    

Internally, the expression `have h : p := s; t` produces the term `(fun (h :
p) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the
desired conclusion assuming `h : p`, and the two are combined by a lambda
abstraction and application. This simple device is extremely useful when it
comes to structuring long proofs, since we can use intermediate `have`'s as
stepping stones leading to the final goal.

Lean also supports a structured way of reasoning backwards from a goal, which
models the "suffices to show" construction in ordinary mathematics. The next
example simply permutes the last two lines in the previous proof.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      suffices hq : q from And.intro hq hp
      show q from And.right h
    

Writing `suffices hq : q` leaves us with two goals. First, we have to show
that it indeed suffices to show `q`, by proving the original goal of `q ∧ p`
with the additional hypothesis `hq : q`. Finally, we have to show `q`.

## Classical Logic

The introduction and elimination rules we have seen so far are all
constructive, which is to say, they reflect a computational understanding of
the logical connectives based on the propositions-as-types correspondence.
Ordinary classical logic adds to this the law of the excluded middle, `p ∨
¬p`. To use this principle, you have to open the classical namespace.

    
    
    open Classical
    
    variable (p : Prop)
    #check em p
    

Intuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts
to knowing which is the case. If `RH` represents the Riemann hypothesis, a
classical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot
yet assert either disjunct.

One consequence of the law of the excluded middle is the principle of double-
negation elimination:

    
    
    open Classical
    
    theorem dne {p : Prop} (h : ¬¬p) : p :=
      Or.elim (em p)
        (fun hp : p => hp)
        (fun hnp : ¬p => absurd hnp h)
    

Double-negation elimination allows one to prove any proposition, `p`, by
assuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In
other words, double-negation elimination allows one to carry out a proof by
contradiction, something which is not generally possible in constructive
logic. As an exercise, you might try proving the converse, that is, showing
that `em` can be proved from `dne`.

The classical axioms also give you access to additional patterns of proof that
can be justified by appeal to `em`. For example, one can carry out a proof by
cases:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byCases
        (fun h1 : p => h1)
        (fun h1 : ¬p => absurd h1 h)
    

Or you can carry out a proof by contradiction:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byContradiction
        (fun h1 : ¬p =>
         show False from h h1)
    

If you are not used to thinking constructively, it may take some time for you
to get a sense of where classical reasoning is used. It is needed in the
following example because, from a constructive standpoint, knowing that `p`
and `q` are not both true does not necessarily tell you which one is false:

    
    
    open Classical
    variable (p q : Prop)
    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=
      Or.elim (em p)
        (fun hp : p =>
          Or.inr
            (show ¬q from
              fun hq : q =>
              h ⟨hp, hq⟩))
        (fun hp : ¬p =>
          Or.inl hp)
    

We will see later that there _are_ situations in constructive logic where
principles like excluded middle and double-negation elimination are
permissible, and Lean supports the use of classical reasoning in such contexts
without relying on excluded middle.

The full list of axioms that are used in Lean to support classical reasoning
are discussed in [Axioms and Computation](./axioms_and_computation.html).

## Examples of Propositional Validities

Lean's standard library contains proofs of many valid statements of
propositional logic, all of which you are free to use in proofs of your own.
The following list includes a number of common identities.

Commutativity:

  1. `p ∧ q ↔ q ∧ p`
  2. `p ∨ q ↔ q ∨ p`

Associativity:

  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`
  4. `(p ∨ q) ∨ r ↔ p ∨ (q �
2025-06-01 02:44:52,339 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.'}], 'model': 'o3-mini'}}
2025-06-01 02:44:52,340 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:44:52,340 - DEBUG - close.started
2025-06-01 02:44:52,340 - DEBUG - close.complete
2025-06-01 02:44:52,341 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:44:52,348 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204292240>
2025-06-01 02:44:52,348 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:44:52,357 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204291fa0>
2025-06-01 02:44:52,357 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:44:52,357 - DEBUG - send_request_headers.complete
2025-06-01 02:44:52,358 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:44:52,358 - DEBUG - send_request_body.complete
2025-06-01 02:44:52,358 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:45:00,105 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:45:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7311'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7314'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199523'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'142ms'), (b'x-request-id', b'req_b8b486eeedc3f30877f6f54223cf9875'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b5f236de746f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:45:00,106 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:45:00,106 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:45:00,106 - DEBUG - receive_response_body.complete
2025-06-01 02:45:00,106 - DEBUG - response_closed.started
2025-06-01 02:45:00,106 - DEBUG - response_closed.complete
2025-06-01 02:45:00,106 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:45:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7311', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7314', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199523', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '142ms', 'x-request-id': 'req_b8b486eeedc3f30877f6f54223cf9875', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b5f236de746f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:45:00,106 - DEBUG - request_id: req_b8b486eeedc3f30877f6f54223cf9875
2025-06-01 02:45:00,107 - INFO - Attempt 1/3
2025-06-01 02:45:00,107 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that takes two integers and returns a Boolean indicating whether the two integers have opposite signs. The function should return true if one integer is positive and the other is negative, and false otherwise (including cases where one or both values are zero).",
  "steps": [
    "Define the function signature to accept two integers and return a Boolean.",
    "Implement the function using logical conditions to check if one integer is greater than zero and the other is less than zero.",
    "Explicitly ensure that the input zero is handled correctly by not considering it as either positive or negative.",
    "Combine the checks using logical OR to cover both cases: (a > 0 and b < 0) or (a < 0 and b > 0).",
    "Optionally, use case analysis in a proof or function comment to explain each branch of the conditional logic."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "conditional",
    "if-then-else",
    "logical operators",
    "inequalities"
  ],
  "proof_keywords": [
    "case analysis",
    "constructive proof",
    "boolean logic",
    "sign analysis",
    "exhaustiveness"
  ],
  "assumptions": [
    "Zero is neither positive nor negative.",
    "Standard integer ordering and boolean operations are available in Lean 4."
  ],
  "retry_guidance": "If errors occur during compilation or type checking, verify the function signature and the conditions used in the if-then-else branches. Also ensure that the Lean 4 standard library is properly imported for basic integer operations and boolean logic constructs."
}
2025-06-01 02:45:00,108 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that takes two integers and returns a Boolean indicating whether the two integers have opposite signs. The function should return true if one integer is positive and the other is negative, and false otherwise (including cases where one or both values are zero).",\n  "steps": [\n    "Define the function signature to accept two integers and return a Boolean.",\n    "Implement the function using logical conditions to check if one integer is greater than zero and the other is less than zero.",\n    "Explicitly ensure that the input zero is handled correctly by not considering it as either positive or negative.",\n    "Combine the checks using logical OR to cover both cases: (a > 0 and b < 0) or (a < 0 and b > 0).",\n    "Optionally, use case analysis in a proof or function comment to explain each branch of the conditional logic."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "conditional",\n    "if-then-else",\n    "logical operators",\n    "inequalities"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "constructive proof",\n    "boolean logic",\n    "sign analysis",\n    "exhaustiveness"\n  ],\n  "assumptions": [\n    "Zero is neither positive nor negative.",\n    "Standard integer ordering and boolean operations are available in Lean 4."\n  ],\n  "retry_guidance": "If errors occur during compilation or type checking, verify the function signature and the conditions used in the if-then-else branches. Also ensure that the Lean 4 standard library is properly imported for basic integer operations and boolean logic constructs."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n� r)`\n\nDistributivity:\n\n  5. `p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)`\n  6. `p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)`\n\nOther properties:\n\n  7. `(p → (q → r)) ↔ (p ∧ q → r)`\n  8. `((p ∨ q) → r) ↔ (p → r) ∧ (q → r)`\n  9. `¬(p ∨ q) ↔ ¬p ∧ ¬q`\n  10. `¬p ∨ ¬q → ¬(p ∧ q)`\n  11. `¬(p ∧ ¬p)`\n  12. `p ∧ ¬q → ¬(p → q)`\n  13. `¬p → (p → q)`\n  14. `(¬p ∨ q) → (p → q)`\n  15. `p ∨ False ↔ p`\n  16. `p ∧ False ↔ False`\n  17. `¬(p ↔ ¬p)`\n  18. `(p → q) → (¬q → ¬p)`\n\nThese require classical reasoning:\n\n  19. `(p → r ∨ s) → ((p → r) ∨ (p → s))`\n  20. `¬(p ∧ q) → ¬p ∨ ¬q`\n  21. `¬(p → q) → p ∧ ¬q`\n  22. `(p → q) → (¬p ∨ q)`\n  23. `(¬q → ¬p) → (p → q)`\n  24. `p ∨ ¬p`\n  25. `(((p → q) → p) → p)`\n\nThe `sorry` identifier magically produces a proof of anything, or provides an\nobject of any data type at all. Of course, it is unsound as a proof method --\nfor example, you can use it to prove `False` \\-- and Lean produces severe\nwarnings when files use or import theorems which depend on it. But it is very\nuseful for building long proofs incrementally. Start writing the proof from\nthe top down, using `sorry` to fill in subproofs. Make sure Lean accepts the\nterm with all the `sorry`\'s; if not, there are errors that you need to\ncorrect. Then go back and replace each `sorry` with an actual proof, until no\nmore remain.\n\nHere is another useful trick. Instead of using `sorry`, you can use an\nunderscore `_` as a placeholder. Recall this tells Lean that the argument is\nimplicit, and should be filled in automatically. If Lean tries to do so and\nfails, it returns with an error message "don\'t know how to synthesize\nplaceholder," followed by the type of the term it is expecting, and all the\nobjects and hypotheses available in the context. In other words, for each\nunresolved placeholder, Lean reports the subgoal that needs to be filled at\nthat point. You can then construct a proof by incrementally filling in these\nplaceholders.\n\nFor reference, here are two sample proofs of validities taken from the list\nabove.\n\n    \n    \n    open Classical\n    \n    -- distributivity\n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=\n      Iff.intro\n        (fun h : p ∧ (q ∨ r) =>\n          have hp : p := h.left\n          Or.elim (h.right)\n            (fun hq : q =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)\n            (fun hr : r =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))\n        (fun h : (p ∧ q) ∨ (p ∧ r) =>\n          Or.elim h\n            (fun hpq : p ∧ q =>\n              have hp : p := hpq.left\n              have hq : q := hpq.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)\n            (fun hpr : p ∧ r =>\n              have hp : p := hpr.left\n              have hr : r := hpr.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))\n    \n    -- an example that requires classical reasoning\n    example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=\n      fun h : ¬(p ∧ ¬q) =>\n      fun hp : p =>\n      show q from\n        Or.elim (em q)\n          (fun hq : q => hq)\n          (fun hnq : ¬q => absurd (And.intro hp hnq) h)\n    \n\n## Exercises\n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs.\n\n    \n    \n    variable (p q r : Prop)\n    \n    -- commutativity of ∧ and ∨\n    example : p ∧ q ↔ q ∧ p := sorry\n    example : p ∨ q ↔ q ∨ p := sorry\n    \n    -- associativity of ∧ and ∨\n    example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry\n    example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry\n    \n    -- distributivity\n    example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry\n    example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry\n    \n    -- other properties\n    example : (p → (q → r)) ↔ (p ∧ q → r) := sorry\n    example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry\n    example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry\n    example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry\n    example : ¬(p ∧ ¬p) := sorry\n    example : p ∧ ¬q → ¬(p → q) := sorry\n    example : ¬p → (p → q) := sorry\n    example : (¬p ∨ q) → (p → q) := sorry\n    example : p ∨ False ↔ p := sorry\n    example : p ∧ False ↔ False := sorry\n    example : (p → q) → (¬q → ¬p) := sorry\n    \n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs. These require classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (p q r : Prop)\n    \n    example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry\n    example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry\n    example : ¬(p → q) → p ∧ ¬q := sorry\n    example : (p → q) → (¬p ∨ q) := sorry\n    example : (¬q → ¬p) → (p → q) := sorry\n    example : p ∨ ¬p := sorry\n    example : (((p → q) → p) → p) := sorry\n    \n\nProve `¬(p ↔ ¬p)` without using classical logic.\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Propositions and Proofs\n\nBy now, you have seen some ways of defining objects and functions in Lean. In\nthis chapter, we will begin to explain how to write mathematical assertions\nand proofs in the language of dependent type theory as well.\n\n## Propositions as Types\n\nOne strategy for proving assertions about objects defined in the language of\ndependent type theory is to layer an assertion language and a proof language\non top of the definition language. But there is no reason to multiply\nlanguages in this way: dependent type theory is flexible and expressive, and\nthere is no reason we cannot represent assertions and proofs in the same\ngeneral framework.\n\nFor example, we could introduce a new type, `Prop`, to represent propositions,\nand introduce constructors to build new propositions from others.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    #check And     -- Prop → Prop → Prop\n    #check Or      -- Prop → Prop → Prop\n    #check Not     -- Prop → Prop\n    #check Implies -- Prop → Prop → Prop\n    \n    variable (p q r : Prop)\n    #check And p q                      -- Prop\n    #check Or (And p q) r               -- Prop\n    #check Implies (And p q) (And q p)  -- Prop\n    \n\nWe could then introduce, for each element `p : Prop`, another type `Proof p`,\nfor the type of proofs of `p`. An "axiom" would be a constant of such a type.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    #check Proof   -- Proof : Prop → Type\n    \n    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))\n    \n    variable (p q : Prop)\n    #check and_comm p q     -- Proof (Implies (And p q) (And q p))\n    \n\nIn addition to axioms, however, we would also need rules to build new proofs\nfrom old ones. For example, in many proof systems for propositional logic, we\nhave the rule of _modus ponens_ :\n\n> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.\n\nWe could represent this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q\n    \n\nSystems of natural deduction for propositional logic also typically rely on\nthe following rule:\n\n> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we\n> can "cancel" the hypothesis and obtain a proof of `Implies p q`.\n\nWe could render this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)\n    \n\nThis approach would provide us with a reasonable way of building assertions\nand proofs. Determining that an expression `t` is a correct proof of assertion\n`p` would then simply be a matter of checking that `t` has type `Proof p`.\n\nSome simplifications are possible, however. To start with, we can avoid\nwriting the term `Proof` repeatedly by conflating `Proof p` with `p` itself.\nIn other words, whenever we have `p : Prop`, we can interpret `p` as a type,\nnamely, the type of its proofs. We can then read `t : p` as the assertion that\n`t` is a proof of `p`.\n\nMoreover, once we make this identification, the rules for implication show\nthat we can pass back and forth between `Implies p q` and `p → q`. In other\nwords, implication between propositions `p` and `q` corresponds to having a\nfunction that takes any element of `p` to an element of `q`. As a result, the\nintroduction of the connective `Implies` is entirely redundant: we can use the\nusual function space constructor `p → q` from dependent type theory as our\nnotion of implication.\n\nThis is the approach followed in the Calculus of Constructions, and hence in\nLean as well. The fact that the rules for implication in a proof system for\nnatural deduction correspond exactly to the rules governing abstraction and\napplication for functions is an instance of the _Curry-Howard isomorphism_ ,\nsometimes known as the _propositions-as-types_ paradigm. In fact, the type\n`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy\ndescribed in the last chapter. Moreover, `Type u` is also just syntactic sugar\nfor `Sort (u+1)`. `Prop` has some special features, but like the other type\nuniverses, it is closed under the arrow constructor: if we have `p q : Prop`,\nthen `p → q : Prop`.\n\nThere are at least two ways of thinking about propositions as types. To some\nwho take a constructive view of logic and mathematics, this is a faithful\nrendering of what it means to be a proposition: a proposition `p` represents a\nsort of data type, namely, a specification of the type of data that\nconstitutes a proof. A proof of `p` is then simply an object `t : p` of the\nright type.\n\nThose not inclined to this ideology can view it, rather, as a simple coding\ntrick. To each proposition `p` we associate a type that is empty if `p` is\nfalse and has a single element, say `*`, if `p` is true. In the latter case,\nlet us say that (the type associated with) `p` is _inhabited_. It just so\nhappens that the rules for function application and abstraction can\nconveniently help us keep track of which elements of `Prop` are inhabited. So\nconstructing an element `t : p` tells us that `p` is indeed true. You can\nthink of the inhabitant of `p` as being the "fact that `p` is true." A proof\nof `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is\ntrue."\n\nIndeed, if `p : Prop` is any proposition, Lean\'s kernel treats any two\nelements `t1 t2 : p` as being definitionally equal, much the same way as it\ntreats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as\n_proof irrelevance,_ and is consistent with the interpretation in the last\nparagraph. It means that even though we can treat proofs `t : p` as ordinary\nobjects in the language of dependent type theory, they carry no information\nbeyond the fact that `p` is true.\n\nThe two ways we have suggested thinking about the propositions-as-types\nparadigm differ in a fundamental way. From the constructive point of view,\nproofs are abstract mathematical objects that are _denoted_ by suitable\nexpressions in dependent type theory. In contrast, if we think in terms of the\ncoding trick described above, then the expressions themselves do not denote\nanything interesting. Rather, it is the fact that we can write them down and\ncheck that they are well-typed that ensures that the proposition in question\nis true. In other words, the expressions _themselves_ are the proofs.\n\nIn the exposition below, we will slip back and forth between these two ways of\ntalking, at times saying that an expression "constructs" or "produces" or\n"returns" a proof of a proposition, and at other times simply saying that it\n"is" such a proof. This is similar to the way that computer scientists\noccasionally blur the distinction between syntax and semantics by saying, at\ntimes, that a program "computes" a certain function, and at other times\nspeaking as though the program "is" the function in question.\n\nIn any case, all that really matters is the bottom line. To formally express a\nmathematical assertion in the language of dependent type theory, we need to\nexhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a\nterm `t : p`. Lean\'s task, as a proof assistant, is to help us to construct\nsuch a term, `t`, and to verify that it is well-formed and has the correct\ntype.\n\n## Working with Propositions as Types\n\nIn the propositions-as-types paradigm, theorems involving only `→` can be\nproved using lambda abstraction and application. In Lean, the `theorem`\ncommand introduces a new theorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    \n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n\nCompare this proof to the expression `fun x : α => fun y : β => x` of type `α\n→ β → α`, where `α` and `β` are data types. This describes the function that\ntakes arguments `x` and `y` of type `α` and `β`, respectively, and returns\n`x`. The proof of `t1` has the same form, the only difference being that `p`\nand `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of\n`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis\n(trivially) to establish that the conclusion, `p`, is true.\n\nNote that the `theorem` command is really a version of the `def` command:\nunder the propositions and types correspondence, proving the theorem `p → q →\np` is really the same as defining an element of the associated type. To the\nkernel type checker, there is no difference between the two.\n\nThere are a few pragmatic differences between definitions and theorems,\nhowever. In normal circumstances, it is never necessary to unfold the\n"definition" of a theorem; by proof irrelevance, any two proofs of that\ntheorem are definitionally equal. Once the proof of a theorem is complete,\ntypically we only need to know that the proof exists; it doesn\'t matter what\nthe proof is. In light of that fact, Lean tags proofs as _irreducible_ , which\nserves as a hint to the parser (more precisely, the _elaborator_) that there\nis generally no need to unfold them when processing a file. In fact, Lean is\ngenerally able to process and check proofs in parallel, since assessing the\ncorrectness of one proof does not require knowing the details of another.\n\nAs with definitions, the `#print` command will show you the proof of a\ntheorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n    #print t1\n    \n\nNotice that the lambda abstractions `hp : p` and `hq : q` can be viewed as\ntemporary assumptions in the proof of `t1`. Lean also allows us to specify the\ntype of the final term `hp`, explicitly, with a `show` statement:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p :=\n      fun hp : p =>\n      fun hq : q =>\n      show p from hp\n    \n\nAdding such extra information can improve the clarity of a proof and help\ndetect errors when writing a proof. The `show` command does nothing more than\nannotate the type, and, internally, all the presentations of `t1` that we have\nseen produce the same term.\n\nAs with ordinary definitions, we can move the lambda-abstracted variables to\nthe left of the colon:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    #print t1    -- p → q → p\n    \n\nWe can use the theorem `t1` just as a function application:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    axiom hp : p\n    \n    theorem t2 : q → p := t1 hp\n    \n\nThe `axiom` declaration postulates the existence of an element of the given\ntype and may compromise logical consistency. For example, we can use it to\npostulate that the empty type `False` has an element:\n\n    \n    \n    axiom unsound : False\n    -- Everything follows from false\n    theorem ex : 1 = 0 :=\n      False.elim unsound\n    \n\nDeclaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as\nwitnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`\nthat `p` is true yields the theorem `t1 hp : q → p`.\n\nRecall that we can also write theorem `t1` as follows:\n\n    \n    \n    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp\n    \n    #print t1\n    \n\nThe type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the\nassertion "for every pair of propositions `p q`, we have `p → q → p`." For\nexample, we can move all parameters to the right of the colon:\n\n    \n    \n    theorem t1 : ∀ {p q : Prop}, p → q → p :=\n      fun {p q : Prop} (hp : p) (hq : q) => hp\n    \n\nIf `p` and `q` have been declared as variables, Lean will generalize them for\nus automatically:\n\n    \n    \n    variable {p q : Prop}\n    \n    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp\n    \n\nIn fact, by the propositions-as-types correspondence, we can declare the\nassumption `hp` that `p` holds, as another variable:\n\n    \n    \n    variable {p q : Prop}\n    variable (hp : p)\n    \n    theorem t1 : q → p := fun (hq : q) => hp\n    \n\nLean detects that the proof uses `hp` and automatically adds `hp : p` as a\npremise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →\nq → p`. Remember that this type can just as well be written `∀ (p q : Prop)\n(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type\nin which the target does not depend on the bound variable.\n\nWhen we generalize `t1` in such a way, we can then apply it to different pairs\nof propositions, to obtain different instances of the general theorem.\n\n    \n    \n    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp\n    \n    variable (p q r s : Prop)\n    \n    #check t1 p q                -- p → q → p\n    #check t1 r s                -- r → s → r\n    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s\n    \n    variable (h : r → s)\n    #check t1 (r → s) (s → r) h  -- (s → r) → r → s\n    \n\nOnce again, using the propositions-as-types correspondence, the variable `h`\nof type `r → s` can be viewed as the hypothesis, or premise, that `r → s`\nholds.\n\nAs another example, let us consider the composition function discussed in the\nlast chapter, now with propositions instead of types.\n\n    \n    \n    variable (p q r s : Prop)\n    \n    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=\n      fun h₃ : p =>\n      show r from h₁ (h₂ h₃)\n    \n\nAs a theorem of propositional logic, what does `t2` say?\n\nNote that it is often useful to use numeric unicode subscripts, entered as\n`\\0`, `\\1`, `\\2`, ..., for hypotheses, as we did in this example.\n\n## Propositional Logic\n\nLean defines all the standard logical connectives and notation. The\npropositional connectives come with the following notation:\n\nAscii| Unicode| Editor shortcut| Definition  \n---|---|---|---  \nTrue| | | True  \nFalse| | | False  \nNot| ¬| `\\not`, `\\neg`| Not  \n/\\| ∧| `\\and`| And  \n\\/| ∨| `\\or`| Or  \n->| →| `\\to`, `\\r`, `\\imp`|   \n<->| ↔| `\\iff`, `\\lr`| Iff  \n  \nThey all take values in `Prop`.\n\n    \n    \n    variable (p q : Prop)\n    \n    #check p → q → p ∧ q\n    #check ¬p → p ↔ False\n    #check p ∨ q → q ∨ p\n    \n\nThe order of operations is as follows: unary negation `¬` binds most strongly,\nthen `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧\ne` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right\n(nothing changes now that the arguments are elements of `Prop`, instead of\nsome other `Type`), as do the other binary connectives. So if we have `p q r :\nProp`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This\nis just the "curried" form of `p ∧ q → r`.\n\nIn the last chapter we observed that lambda abstraction can be viewed as an\n"introduction rule" for `→`. In the current setting, it shows how to\n"introduce" or establish an implication. Application can be viewed as an\n"elimination rule," showing how to "eliminate" or use an implication in a\nproof. The other propositional connectives are defined in Lean\'s library in\nthe file `Prelude.core` (see [importing\nfiles](./interacting_with_lean.html#importing-files) for more information on\nthe library hierarchy), and each connective comes with its canonical\nintroduction and elimination rules.\n\n### Conjunction\n\nThe expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :\np` and `h2 : q`. It is common to describe `And.intro` as the _and-\nintroduction_ rule. In the next example we use `And.intro` to create a proof\nof `p → q → p ∧ q`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq\n    \n    #check fun (hp : p) (hq : q) => And.intro hp hq\n    \n\nThe `example` command states a theorem without naming it or storing it in the\npermanent context. Essentially, it just checks that the given term has the\nindicated type. It is convenient for illustration, and we will use it often.\n\nThe expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.\nSimilarly, `And.right h` is a proof of `q`. They are commonly known as the\nleft and right _and-elimination_ rules.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : p := And.left h\n    example (h : p ∧ q) : q := And.right h\n    \n\nWe can now prove `p ∧ q → q ∧ p` with the following proof term.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      And.intro (And.right h) (And.left h)\n    \n\nNotice that and-introduction and and-elimination are similar to the pairing\nand projection operations for the Cartesian product. The difference is that\ngiven `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while\n`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is\nanother instance of the Curry-Howard isomorphism, but in contrast to\nimplication and the function space constructor, `∧` and `×` are treated\nseparately in Lean. With the analogy, however, the proof we have just\nconstructed is similar to a function that swaps the elements of a pair.\n\nWe will see in [Chapter Structures and Records](./structures_and_records.html)\nthat certain types in Lean are _structures_ , which is to say, the type is\ndefined with a single canonical _constructor_ which builds an element of the\ntype from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is\nan example: the canonical way to construct an element is to apply `And.intro`\nto suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous\nconstructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the\nrelevant type is an inductive type and can be inferred from the context. In\nparticular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:\n\n    \n    \n    variable (p q : Prop)\n    variable (hp : p) (hq : q)\n    \n    #check (⟨hp, hq⟩ : p ∧ q)\n    \n\nThese angle brackets are obtained by typing `\\<` and `\\>`, respectively.\n\nLean provides another useful syntactic gadget. Given an expression `e` of an\ninductive type `Foo` (possibly applied to some arguments), the notation\n`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of\naccessing functions without opening a namespace. For example, the following\ntwo expressions mean the same thing:\n\n    \n    \n    variable (xs : List Nat)\n    \n    #check List.length xs\n    #check xs.length\n    \n\nAs a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and\n`h.right` for `And.right h`. We can therefore rewrite the sample proof above\nconveniently as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      ⟨h.right, h.left⟩\n    \n\nThere is a fine line between brevity and obfuscation, and omitting information\nin this way can sometimes make a proof harder to read. But for straightforward\nconstructions like the one above, when the type of `h` and the goal of the\nconstruction are salient, the notation is clean and effective.\n\nIt is common to iterate constructions like "And." Lean also allows you to\nflatten nested constructors that associate to the right, so that these two\nproofs are equivalent:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, ⟨h.left, h.right⟩⟩\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, h.left, h.right⟩\n    \n\nThis is often useful as well.\n\n### Disjunction\n\nThe expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof\n`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a\nproof `hq : q`. These are the left and right _or-introduction_ rules.\n\n    \n    \n    variable (p q : Prop)\n    example (hp : p) : p ∨ q := Or.intro_left q hp\n    example (hq : q) : p ∨ q := Or.intro_right p hq\n    \n\nThe _or-elimination_ rule is slightly more complicated. The idea is that we\ncan prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`\nfollows from `q`. In other words, it is a proof by cases. In the expression\n`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :\np → r` and `hqr : q → r`, and produces a proof of `r`. In the following\nexample, we use `Or.elim` to prove `p ∨ q → q ∨ p`.\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h\n        (fun hp : p =>\n          show q ∨ p from Or.intro_right q hp)\n        (fun hq : q =>\n          show q ∨ p from Or.intro_left p hq)\n    \n\nIn most cases, the first argument of `Or.intro_right` and `Or.intro_left` can\nbe inferred automatically by Lean. Lean therefore provides `Or.inr` and\n`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and\n`Or.intro_left _`. Thus the proof term above could be written more concisely:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nNotice that there is enough information in the full expression for Lean to\ninfer the types of `hp` and `hq` as well. But using the type annotations in\nthe longer version makes the proof more readable, and can help catch and debug\nerrors.\n\nBecause `Or` has two constructors, we cannot use anonymous constructor\nnotation. But we can still write `h.elim` instead of `Or.elim h`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nOnce again, you should exercise judgment as to whether such abbreviations\nenhance or diminish readability.\n\n### Negation and Falsity\n\nNegation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by\nderiving a contradiction from `p`. Similarly, the expression `hnp hp` produces\na proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both\nthese rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is\nproduced by typing `\\not` or `\\neg`.)\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hpq : p → q) (hnq : ¬q) : ¬p :=\n      fun hp : p =>\n      show False from hnq (hpq hp)\n    \n\nThe connective `False` has a single elimination rule, `False.elim`, which\nexpresses the fact that anything follows from a contradiction. This rule is\nsometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the\n_principle of explosion_.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)\n    \n\nThe arbitrary fact, `q`, that follows from falsity is an implicit argument in\n`False.elim` and is inferred automatically. This pattern, deriving an\narbitrary fact from contradictory hypotheses, is quite common, and is\nrepresented by `absurd`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := absurd hp hnp\n    \n\nHere, for example, is a proof of `¬p → q → (q → p) → r`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=\n      absurd (hqp hq) hnp\n    \n\nIncidentally, just as `False` has only an elimination rule, `True` has only an\nintroduction rule, `True.intro : true`. In other words, `True` is simply true,\nand has a canonical proof, `True.intro`.\n\n### Logical Equivalence\n\nThe expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`\nand `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from\n`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔\nq`. Here is a proof of `p ∧ q ↔ q ∧ p`:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      Iff.intro\n        (fun h : p ∧ q =>\n         show q ∧ p from And.intro (And.right h) (And.left h))\n        (fun h : q ∧ p =>\n         show p ∧ q from And.intro (And.right h) (And.left h))\n    \n    #check and_swap p q    -- p ∧ q ↔ q ∧ p\n    \n    variable (h : p ∧ q)\n    example : q ∧ p := Iff.mp (and_swap p q) h\n    \n\nWe can use the anonymous constructor notation to construct a proof of `p ↔ q`\nfrom proofs of the forward and backward directions, and we can also use `.`\nnotation with `mp` and `mpr`. The previous examples can therefore be written\nconcisely as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩\n    \n    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h\n    \n\n## Introducing Auxiliary Subgoals\n\nThis is a good place to introduce another device Lean offers to help structure\nlong proofs, namely, the `have` construct, which introduces an auxiliary\nsubgoal in a proof. Here is a small example, adapted from the last section:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      have hq : q := h.right\n      show q ∧ p from And.intro hq hp\n    \n\nInternally, the expression `have h : p := s; t` produces the term `(fun (h :\np) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the\ndesired conclusion assuming `h : p`, and the two are combined by a lambda\nabstraction and application. This simple device is extremely useful when it\ncomes to structuring long proofs, since we can use intermediate `have`\'s as\nstepping stones leading to the final goal.\n\nLean also supports a structured way of reasoning backwards from a goal, which\nmodels the "suffices to show" construction in ordinary mathematics. The next\nexample simply permutes the last two lines in the previous proof.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      suffices hq : q from And.intro hq hp\n      show q from And.right h\n    \n\nWriting `suffices hq : q` leaves us with two goals. First, we have to show\nthat it indeed suffices to show `q`, by proving the original goal of `q ∧ p`\nwith the additional hypothesis `hq : q`. Finally, we have to show `q`.\n\n## Classical Logic\n\nThe introduction and elimination rules we have seen so far are all\nconstructive, which is to say, they reflect a computational understanding of\nthe logical connectives based on the propositions-as-types correspondence.\nOrdinary classical logic adds to this the law of the excluded middle, `p ∨\n¬p`. To use this principle, you have to open the classical namespace.\n\n    \n    \n    open Classical\n    \n    variable (p : Prop)\n    #check em p\n    \n\nIntuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts\nto knowing which is the case. If `RH` represents the Riemann hypothesis, a\nclassical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot\nyet assert either disjunct.\n\nOne consequence of the law of the excluded middle is the principle of double-\nnegation elimination:\n\n    \n    \n    open Classical\n    \n    theorem dne {p : Prop} (h : ¬¬p) : p :=\n      Or.elim (em p)\n        (fun hp : p => hp)\n        (fun hnp : ¬p => absurd hnp h)\n    \n\nDouble-negation elimination allows one to prove any proposition, `p`, by\nassuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In\nother words, double-negation elimination allows one to carry out a proof by\ncontradiction, something which is not generally possible in constructive\nlogic. As an exercise, you might try proving the converse, that is, showing\nthat `em` can be proved from `dne`.\n\nThe classical axioms also give you access to additional patterns of proof that\ncan be justified by appeal to `em`. For example, one can carry out a proof by\ncases:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byCases\n        (fun h1 : p => h1)\n        (fun h1 : ¬p => absurd h1 h)\n    \n\nOr you can carry out a proof by contradiction:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byContradiction\n        (fun h1 : ¬p =>\n         show False from h h1)\n    \n\nIf you are not used to thinking constructively, it may take some time for you\nto get a sense of where classical reasoning is used. It is needed in the\nfollowing example because, from a constructive standpoint, knowing that `p`\nand `q` are not both true does not necessarily tell you which one is false:\n\n    \n    \n    open Classical\n    variable (p q : Prop)\n    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=\n      Or.elim (em p)\n        (fun hp : p =>\n          Or.inr\n            (show ¬q from\n              fun hq : q =>\n              h ⟨hp, hq⟩))\n        (fun hp : ¬p =>\n          Or.inl hp)\n    \n\nWe will see later that there _are_ situations in constructive logic where\nprinciples like excluded middle and double-negation elimination are\npermissible, and Lean supports the use of classical reasoning in such contexts\nwithout relying on excluded middle.\n\nThe full list of axioms that are used in Lean to support classical reasoning\nare discussed in [Axioms and Computation](./axioms_and_computation.html).\n\n## Examples of Propositional Validities\n\nLean\'s standard library contains proofs of many valid statements of\npropositional logic, all of which you are free to use in proofs of your own.\nThe following list includes a number of common identities.\n\nCommutativity:\n\n  1. `p ∧ q ↔ q ∧ p`\n  2. `p ∨ q ↔ q ∨ p`\n\nAssociativity:\n\n  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`\n  4. `(p ∨ q) ∨ r ↔ p ∨ (q �'}], 'model': 'gpt-4o'}}
2025-06-01 02:45:00,109 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:45:00,109 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:45:00,109 - DEBUG - send_request_headers.complete
2025-06-01 02:45:00,109 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:45:00,115 - DEBUG - send_request_body.complete
2025-06-01 02:45:00,115 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:45:07,517 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:45:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7148'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7154'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'15451'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'29.097s'), (b'x-request-id', b'req_95a2841b158795708b3bf609aaa8d35b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b5f53dab846f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:45:07,518 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:45:07,518 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:45:07,521 - DEBUG - receive_response_body.complete
2025-06-01 02:45:07,521 - DEBUG - response_closed.started
2025-06-01 02:45:07,521 - DEBUG - response_closed.complete
2025-06-01 02:45:07,521 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:45:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7148', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7154', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '15451', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '29.097s', 'x-request-id': 'req_95a2841b158795708b3bf609aaa8d35b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b5f53dab846f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:45:07,521 - DEBUG - request_id: req_95a2841b158795708b3bf609aaa8d35b
2025-06-01 02:45:07,522 - INFO - Raw solution received: ```json
{
  "code": "a > 0 && b < 0 || a < 0 && b > 0",
  "proof": "unfold hasOppositeSign_spec\n  by_cases ha : a > 0\n  by_cases hb : b < 0\n  simp [ha, hb]\n  trivial\n  simp [ha, hb]\n  by_cases hc : b > 0\n  simp [hc]\n  exfalso\n  apply lt_asymm hb hc\n  simp\n  by_cases hc : b < 0\n  simp [hc]\n  exfalso\n  apply lt_asymm ha hc\n  simp\n  unfold hasOppositeSign_spec\n  by_cases ha : a < 0\n  by_cases hb : b > 0\n  simp [ha, hb]\n  trivial\n  simp [ha, hb]\n  by_cases hc : b < 0\n  simp [hc]\n  exfalso\n  apply lt_asymm ha hc\n  simp\n  by_cases hc : b > 0\n  simp [hc]\n  exfalso\n  apply lt_asymm hb hc\n  simp\n  unfold hasOppositeSign_spec\n  by_cases ha : a = 0\n  simp [ha]\n  by_cases hb : b > 0\n  simp [hb]\n  triv\n  sima\n  by_cases hb : b < 0\n  simp [hb]\n  trival\n  simp\n  simp"
}
```
2025-06-01 02:45:07,522 - INFO - <class 'str'>
2025-06-01 02:45:07,522 - INFO - Generated solution: {'code': 'a > 0 && b < 0 || a < 0 && b > 0', 'proof': 'unfold hasOppositeSign_spec\n  by_cases ha : a > 0\n  by_cases hb : b < 0\n  simp [ha, hb]\n  trivial\n  simp [ha, hb]\n  by_cases hc : b > 0\n  simp [hc]\n  exfalso\n  apply lt_asymm hb hc\n  simp\n  by_cases hc : b < 0\n  simp [hc]\n  exfalso\n  apply lt_asymm ha hc\n  simp\n  unfold hasOppositeSign_spec\n  by_cases ha : a < 0\n  by_cases hb : b > 0\n  simp [ha, hb]\n  trivial\n  simp [ha, hb]\n  by_cases hc : b < 0\n  simp [hc]\n  exfalso\n  apply lt_asymm ha hc\n  simp\n  by_cases hc : b > 0\n  simp [hc]\n  exfalso\n  apply lt_asymm hb hc\n  simp\n  unfold hasOppositeSign_spec\n  by_cases ha : a = 0\n  simp [ha]\n  by_cases hb : b > 0\n  simp [hb]\n  triv\n  sima\n  by_cases hb : b < 0\n  simp [hb]\n  trival\n  simp\n  simp'}
2025-06-01 02:45:12,815 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:59:3: error: unknown tactic
2025-06-01 02:45:12,816 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na > 0 && b < 0 || a < 0 && b > 0\n\nGenerated Proof:\nunfold hasOppositeSign_spec\n  by_cases ha : a > 0\n  by_cases hb : b < 0\n  simp [ha, hb]\n  trivial\n  simp [ha, hb]\n  by_cases hc : b > 0\n  simp [hc]\n  exfalso\n  apply lt_asymm hb hc\n  simp\n  by_cases hc : b < 0\n  simp [hc]\n  exfalso\n  apply lt_asymm ha hc\n  simp\n  unfold hasOppositeSign_spec\n  by_cases ha : a < 0\n  by_cases hb : b > 0\n  simp [ha, hb]\n  trivial\n  simp [ha, hb]\n  by_cases hc : b < 0\n  simp [hc]\n  exfalso\n  apply lt_asymm ha hc\n  simp\n  by_cases hc : b > 0\n  simp [hc]\n  exfalso\n  apply lt_asymm hb hc\n  simp\n  unfold hasOppositeSign_spec\n  by_cases ha : a = 0\n  simp [ha]\n  by_cases hb : b > 0\n  simp [hb]\n  triv\n  sima\n  by_cases hb : b < 0\n  simp [hb]\n  trival\n  simp\n  simp\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:59:3: error: unknown tactic'}], 'model': 'o3-mini'}}
2025-06-01 02:45:12,817 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:45:12,817 - DEBUG - close.started
2025-06-01 02:45:12,817 - DEBUG - close.complete
2025-06-01 02:45:12,817 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:45:12,824 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20429cc20>
2025-06-01 02:45:12,824 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:45:12,833 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20429cb60>
2025-06-01 02:45:12,833 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:45:12,833 - DEBUG - send_request_headers.complete
2025-06-01 02:45:12,833 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:45:12,833 - DEBUG - send_request_body.complete
2025-06-01 02:45:12,833 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:45:18,914 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:45:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5580'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5585'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199086'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'274ms'), (b'x-request-id', b'req_4e88b9530e8a7e6e6d9819c71b73b725'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b5fa35c9d4278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:45:18,914 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:45:18,914 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:45:18,915 - DEBUG - receive_response_body.complete
2025-06-01 02:45:18,915 - DEBUG - response_closed.started
2025-06-01 02:45:18,915 - DEBUG - response_closed.complete
2025-06-01 02:45:18,915 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:45:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5580', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5585', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199086', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '274ms', 'x-request-id': 'req_4e88b9530e8a7e6e6d9819c71b73b725', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b5fa35c9d4278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:45:18,915 - DEBUG - request_id: req_4e88b9530e8a7e6e6d9819c71b73b725
2025-06-01 02:45:18,915 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof contains unrecognized tactics ('sima' and 'trival') which lead to the error 'unknown tactic'. This indicates that the proof is using non-existent tactics that Lean does not recognize.", 'error_type': 'proof', 'suggested_fix': "Replace the unknown tactics 'sima' and 'trival' with valid Lean tactics such as 'simp' or 'trivial'. For example, use 'trivial' when the goal is immediately solvable, and ensure that any tactic names used are correctly spelled and exist in Lean 4. Additionally, consider restructuring the proof by breaking it into cases and simplifying each case with well-known tactics like 'simp', 'by_cases', or 'exact' as appropriate.", 'retry_strategy': "Revise the proof to remove the unknown tactics and use standard Lean tactics. Step through the case analysis clearly and ensure each branch of the proof is handled with valid tactics. Consider reformatting the proof to avoid repeated unfolding and complexity; for instance, perform a case analysis on one variable at a time and then use 'simp' to simplify the conditions, ensuring that each tactic invocation is correctly spelled."}
2025-06-01 02:45:18,915 - INFO - Solution generated in 27.19 seconds
2025-06-01 02:45:18,915 - INFO - Generated code length: 32 characters
2025-06-01 02:45:18,915 - INFO - Generated proof length: 694 characters
2025-06-01 02:45:18,916 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:45:18,916 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:45:24,318 - INFO - Implementation test result: PASS
2025-06-01 02:45:24,318 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:45:29,632 - INFO - Full solution test result: FAIL
2025-06-01 02:45:29,632 - ERROR - Proof error: lean_playground/TempTest.lean:59:3: error: unknown tactic...
2025-06-01 02:45:29,632 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:45:29,632 - ERROR - ❌ Proof has errors
2025-06-01 02:45:29,632 - INFO - 
==================================================
2025-06-01 02:45:29,632 - INFO - Processing task task_id_77...
2025-06-01 02:45:29,632 - INFO - Reading problem description and code template from tasks/task_id_77...
2025-06-01 02:45:29,632 - INFO - Problem description length: 456 characters
2025-06-01 02:45:29,632 - INFO - Reading unit tests from tasks/task_id_77...
2025-06-01 02:45:29,632 - INFO - Unit tests length: 449 characters
2025-06-01 02:45:29,632 - INFO - Running main workflow to generate solution...
2025-06-01 02:45:29,633 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.

-----Input-----
The input consists of:
n: An integer to check for divisibility by 11.

-----Output-----
The output is a Boolean value:
Returns true if the input number is divisible by 11.
Returns false if the input number is not divisible by 11.
2025-06-01 02:45:29,633 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def isDivisibleBy11 (n : Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result is true if n is divisible by 11
def isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=
  -- << SPEC START >>
  n % 11 = 0 ↔ result
  -- << SPEC END >>

theorem isDivisibleBy11_spec_satisfied (n : Int) :
  isDivisibleBy11_spec n (isDivisibleBy11 n) := by
  -- << PROOF START >>
  unfold isDivisibleBy11 isDivisibleBy11_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:45:29,662 - DEBUG - close.started
2025-06-01 02:45:29,663 - DEBUG - close.complete
2025-06-01 02:45:29,663 - DEBUG - close.started
2025-06-01 02:45:29,663 - DEBUG - close.complete
2025-06-01 02:45:29,667 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x74e2042868e0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:45:29,667 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:45:29,667 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:45:29,674 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e2042928a0>
2025-06-01 02:45:29,674 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e204264150> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:45:29,683 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204292690>
2025-06-01 02:45:29,684 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:45:29,684 - DEBUG - send_request_headers.complete
2025-06-01 02:45:29,684 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:45:29,684 - DEBUG - send_request_body.complete
2025-06-01 02:45:29,684 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:45:29,993 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:45:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'53'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7fbbd4cf65-hrw4w'), (b'x-envoy-upstream-service-time', b'56'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999886'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_c56462bf1fe7501d53ac48b1a70ca24c'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=yYuuSe3NIeeLyr_2ZVVIcrKN5emXn8E3t1fxffMNvOU-1748745930-1.0.1.1-NFfoWgKMCN4_mtI.L0LgYRqFRAu30QwIfhUZo0x0Rnjm.XjR2bejFuTCmYkkkL5jwyhAZXulpnbGfWFsyBc97SfkEKhr5XsnRZPFTFHQh8k; path=/; expires=Sun, 01-Jun-25 03:15:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=.Stvp.MCyS0isowJejmgW6urAnrYwPMf9uKJn3ELPfM-1748745930013-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b600cbad38fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:45:29,994 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:45:29,994 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:45:29,994 - DEBUG - receive_response_body.complete
2025-06-01 02:45:29,994 - DEBUG - response_closed.started
2025-06-01 02:45:29,994 - DEBUG - response_closed.complete
2025-06-01 02:45:29,995 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:45:30 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '53'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-7fbbd4cf65-hrw4w'), ('x-envoy-upstream-service-time', '56'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999886'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '6ms'), ('x-request-id', 'req_c56462bf1fe7501d53ac48b1a70ca24c'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=yYuuSe3NIeeLyr_2ZVVIcrKN5emXn8E3t1fxffMNvOU-1748745930-1.0.1.1-NFfoWgKMCN4_mtI.L0LgYRqFRAu30QwIfhUZo0x0Rnjm.XjR2bejFuTCmYkkkL5jwyhAZXulpnbGfWFsyBc97SfkEKhr5XsnRZPFTFHQh8k; path=/; expires=Sun, 01-Jun-25 03:15:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=.Stvp.MCyS0isowJejmgW6urAnrYwPMf9uKJn3ELPfM-1748745930013-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b600cbad38fcd-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:45:29,995 - DEBUG - request_id: req_c56462bf1fe7501d53ac48b1a70ca24c
2025-06-01 02:45:30,000 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
 the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
2025-06-01 02:45:30,011 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.'}], 'model': 'o3-mini'}}
2025-06-01 02:45:30,012 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:45:30,012 - DEBUG - close.started
2025-06-01 02:45:30,012 - DEBUG - close.complete
2025-06-01 02:45:30,012 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:45:30,029 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204290dd0>
2025-06-01 02:45:30,029 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:45:30,037 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204292060>
2025-06-01 02:45:30,037 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:45:30,037 - DEBUG - send_request_headers.complete
2025-06-01 02:45:30,037 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:45:30,037 - DEBUG - send_request_body.complete
2025-06-01 02:45:30,037 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:45:37,384 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:45:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7119'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7124'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199585'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'124ms'), (b'x-request-id', b'req_bc09cc2039b556a8ae14fbb27a5de4ba'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b600ee955ff9b-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:45:37,384 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:45:37,384 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:45:37,385 - DEBUG - receive_response_body.complete
2025-06-01 02:45:37,385 - DEBUG - response_closed.started
2025-06-01 02:45:37,385 - DEBUG - response_closed.complete
2025-06-01 02:45:37,385 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:45:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7119', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7124', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199585', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '124ms', 'x-request-id': 'req_bc09cc2039b556a8ae14fbb27a5de4ba', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b600ee955ff9b-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:45:37,385 - DEBUG - request_id: req_bc09cc2039b556a8ae14fbb27a5de4ba
2025-06-01 02:45:37,385 - INFO - Attempt 1/3
2025-06-01 02:45:37,385 - INFO - Current plan: {
  "plan_summary": "Implement a Lean 4 function that checks whether an integer is divisible by 11 by computing the remainder of the integer when divided by 11, and then comparing the result to 0.",
  "steps": [
    "1. Define a function that accepts an integer parameter, n.",
    "2. Use Lean's modulus operator to compute n % 11.",
    "3. Check if the result of the modulo operation is equal to 0.",
    "4. Return true if n % 11 equals 0; otherwise, return false.",
    "5. Optionally, add tests or examples to validate the function."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "integer",
    "modulus operation",
    "if then else"
  ],
  "proof_keywords": [
    "divisibility",
    "remainders",
    "mod arithmetic"
  ],
  "assumptions": [
    "Lean 4 provides a modulus operator for integers.",
    "The function should correctly handle negative integers.",
    "Basic control flow constructs (if-else) are available."
  ],
  "retry_guidance": "If issues occur, verify that the correct modulus operator is used in Lean for integers and ensure the type signature properly corresponds to an integer input and Boolean output."
}
2025-06-01 02:45:37,386 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Implement a Lean 4 function that checks whether an integer is divisible by 11 by computing the remainder of the integer when divided by 11, and then comparing the result to 0.",\n  "steps": [\n    "1. Define a function that accepts an integer parameter, n.",\n    "2. Use Lean\'s modulus operator to compute n % 11.",\n    "3. Check if the result of the modulo operation is equal to 0.",\n    "4. Return true if n % 11 equals 0; otherwise, return false.",\n    "5. Optionally, add tests or examples to validate the function."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "integer",\n    "modulus operation",\n    "if then else"\n  ],\n  "proof_keywords": [\n    "divisibility",\n    "remainders",\n    "mod arithmetic"\n  ],\n  "assumptions": [\n    "Lean 4 provides a modulus operator for integers.",\n    "The function should correctly handle negative integers.",\n    "Basic control flow constructs (if-else) are available."\n  ],\n  "retry_guidance": "If issues occur, verify that the correct modulus operator is used in Lean for integers and ensure the type signature properly corresponds to an integer input and Boolean output."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  n % 11 = 0 ↔ result\n  -- << SPEC END >>\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- << PROOF START >>\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The'}], 'model': 'gpt-4o'}}
2025-06-01 02:45:37,387 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:45:37,388 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:45:37,388 - DEBUG - send_request_headers.complete
2025-06-01 02:45:37,388 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:45:37,392 - DEBUG - send_request_body.complete
2025-06-01 02:45:37,392 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:45:39,860 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:45:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2247'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2251'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'16294'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'27.412s'), (b'x-request-id', b'req_32997d78b1c22222e9bec9704bc43589'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b603cdcdaff9b-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:45:39,861 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:45:39,861 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:45:39,861 - DEBUG - receive_response_body.complete
2025-06-01 02:45:39,861 - DEBUG - response_closed.started
2025-06-01 02:45:39,861 - DEBUG - response_closed.complete
2025-06-01 02:45:39,861 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:45:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2247', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2251', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '16294', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '27.412s', 'x-request-id': 'req_32997d78b1c22222e9bec9704bc43589', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b603cdcdaff9b-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:45:39,862 - DEBUG - request_id: req_32997d78b1c22222e9bec9704bc43589
2025-06-01 02:45:39,862 - INFO - Raw solution received: ```json
{
  "code": "n % 11 == 0",
  "proof": "by_cases h : n % 11 = 0\n  simp [h]\n  exact h\n  simp [h]\n  exfalso\n  apply h\n  exact Nat.mod_eq_zero_of_dvd (Nat.dvd_of_mod_eq_zero h)"
}
```
2025-06-01 02:45:39,862 - INFO - <class 'str'>
2025-06-01 02:45:39,862 - INFO - Generated solution: {'code': 'n % 11 == 0', 'proof': 'by_cases h : n % 11 = 0\n  simp [h]\n  exact h\n  simp [h]\n  exfalso\n  apply h\n  exact Nat.mod_eq_zero_of_dvd (Nat.dvd_of_mod_eq_zero h)'}
2025-06-01 02:45:45,066 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:23:2: error: type mismatch
  h
has type
  ¬n % 11 = 0 : Prop
but is expected to have type
  n % 11 = 0 ↔ (n % 11 == 0) = true : Prop
2025-06-01 02:45:45,067 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  n % 11 = 0 ↔ result\n  -- << SPEC END >>\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- << PROOF START >>\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nn % 11 == 0\n\nGenerated Proof:\nby_cases h : n % 11 = 0\n  simp [h]\n  exact h\n  simp [h]\n  exfalso\n  apply h\n  exact Nat.mod_eq_zero_of_dvd (Nat.dvd_of_mod_eq_zero h)\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:23:2: error: type mismatch\n  h\nhas type\n  ¬n % 11 = 0 : Prop\nbut is expected to have type\n  n % 11 = 0 ↔ (n % 11 == 0) = true : Prop'}], 'model': 'o3-mini'}}
2025-06-01 02:45:45,068 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:45:45,068 - DEBUG - close.started
2025-06-01 02:45:45,068 - DEBUG - close.complete
2025-06-01 02:45:45,068 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:45:45,076 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204271610>
2025-06-01 02:45:45,076 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:45:45,086 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e2042713d0>
2025-06-01 02:45:45,086 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:45:45,086 - DEBUG - send_request_headers.complete
2025-06-01 02:45:45,087 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:45:45,087 - DEBUG - send_request_body.complete
2025-06-01 02:45:45,087 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:46:09,819 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:46:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'24509'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'24511'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199282'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'215ms'), (b'x-request-id', b'req_ea0cebb9bf04bfb34c41c00e917b78e5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b606cff4246f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:46:09,819 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:46:09,820 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:46:09,820 - DEBUG - receive_response_body.complete
2025-06-01 02:46:09,820 - DEBUG - response_closed.started
2025-06-01 02:46:09,820 - DEBUG - response_closed.complete
2025-06-01 02:46:09,820 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:46:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '24509', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '24511', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199282', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '215ms', 'x-request-id': 'req_ea0cebb9bf04bfb34c41c00e917b78e5', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b606cff4246f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:46:09,820 - DEBUG - request_id: req_ea0cebb9bf04bfb34c41c00e917b78e5
2025-06-01 02:46:09,821 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails because using by_cases on 'n % 11 = 0' gives a hypothesis h of type 'n % 11 = 0' in one branch and '¬ (n % 11 = 0)' in the other. However, the goal is to prove an equivalence between 'n % 11 = 0' and '(n % 11 == 0) = true'. The tactics in the generated proof try to use h directly in places where an equivalence (↔) is expected, causing a type mismatch error.", 'error_type': 'proof', 'suggested_fix': "Instead of using by_cases, split the goal into two implications. That is, prove separately that (1) if n % 11 = 0 then (n % 11 == 0) = true, and (2) if (n % 11 == 0) = true then n % 11 = 0. You can either use the 'split' tactic and then use appropriate simp/rewrite tactics, or directly apply a lemma that relates boolean equality to the corresponding propositional equality (such as a lemma of the form 'Int.eq_true_iff'). For example:\n\n  theorem isDivisibleBy11_spec_satisfied (n : Int) :\n    n % 11 = 0 ↔ (n % 11 == 0) = true := by\n    split\n    case mp => intro h; simp [h]\n    case mpr => intro h; rw [Int.eq_true_iff] at h; exact h\n\nMake sure that the lemma 'Int.eq_true_iff' (or an equivalent conversion lemma for booleans) is available. If not, you may need to prove that (n % 11 == 0) = true if and only if n % 11 = 0.", 'retry_strategy': "Rewrite the proof to avoid by_cases. Split the equivalence into two directions using 'split' and prove each direction using simplification and an appropriate boolean-to-prop conversion lemma. Verify that the conversion lemma (like Int.eq_true_iff) is imported or defined."}
2025-06-01 02:46:09,821 - INFO - Solution generated in 40.19 seconds
2025-06-01 02:46:09,821 - INFO - Generated code length: 11 characters
2025-06-01 02:46:09,821 - INFO - Generated proof length: 133 characters
2025-06-01 02:46:09,821 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:46:09,821 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:46:15,044 - INFO - Implementation test result: PASS
2025-06-01 02:46:15,044 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:46:20,367 - INFO - Full solution test result: FAIL
2025-06-01 02:46:20,368 - ERROR - Proof error: lean_playground/TempTest.lean:23:2: error: type mismatch
  h
has type
  ¬n % 11 = 0 : Prop
but is expected to have type
  n % 11 = 0 ↔ (n % 11 == 0) =...
2025-06-01 02:46:20,368 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:46:20,368 - ERROR - ❌ Proof has errors
2025-06-01 02:46:20,368 - INFO - 
==================================================
2025-06-01 02:46:20,368 - INFO - Processing task task_id_127...
2025-06-01 02:46:20,368 - INFO - Reading problem description and code template from tasks/task_id_127...
2025-06-01 02:46:20,368 - INFO - Problem description length: 342 characters
2025-06-01 02:46:20,368 - INFO - Reading unit tests from tasks/task_id_127...
2025-06-01 02:46:20,368 - INFO - Unit tests length: 219 characters
2025-06-01 02:46:20,368 - INFO - Running main workflow to generate solution...
2025-06-01 02:46:20,368 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.

-----Input-----
The input consists of:
a: The first integer.
b: The second integer.

-----Output-----
The output is an integer:
Returns the product of the two input integers (a * b).
2025-06-01 02:46:20,368 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def multiply (a : Int) (b : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result should be the product of the two input integers
def multiply_spec (a : Int) (b : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  result = a * b
  -- << SPEC END >>

theorem multiply_spec_satisfied (a : Int) (b : Int) :
  multiply_spec a b (multiply a b) := by
  -- << PROOF START >>
  unfold multiply multiply_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:46:20,396 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x74e20422dd00>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.\n\n-----Input-----\nThe input consists of:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the product of the two input integers (a * b).', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:46:20,396 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:46:20,397 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:46:20,403 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204907440>
2025-06-01 02:46:20,403 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2042806d0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:46:20,413 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e2049072c0>
2025-06-01 02:46:20,413 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:46:20,414 - DEBUG - send_request_headers.complete
2025-06-01 02:46:20,414 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:46:20,414 - DEBUG - send_request_body.complete
2025-06-01 02:46:20,414 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:46:21,012 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:46:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'50'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-canary-7bb5dbcbf5-wxw95'), (b'x-envoy-upstream-service-time', b'55'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999915'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'x-request-id', b'req_07e3a7e132e7d5fe7c68623b4ca942af'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=iJdJ0tm4YTSuh1axK0QYatvvQBZZX7XhBleHa0mGbOk-1748745981-1.0.1.1-R7gsbYHjiX8KgQXwKGgBSKu1VGH4kt8Ynq71nx1IFZtIw0ySM2xvz0.7_sOVJoPjzFjKlmJXbj57dhtZoMByPLU2RHOSwUVydwwDz1KYDF8; path=/; expires=Sun, 01-Jun-25 03:16:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=ISiRKojKdpRIWGXdW6U1vgiroJc765uTMSO._rFvFhE-1748745981026-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6149baf73bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:46:21,012 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:46:21,013 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:46:21,013 - DEBUG - receive_response_body.complete
2025-06-01 02:46:21,013 - DEBUG - response_closed.started
2025-06-01 02:46:21,013 - DEBUG - response_closed.complete
2025-06-01 02:46:21,013 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:46:21 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '50'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-canary-7bb5dbcbf5-wxw95'), ('x-envoy-upstream-service-time', '55'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999915'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '5ms'), ('x-request-id', 'req_07e3a7e132e7d5fe7c68623b4ca942af'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=iJdJ0tm4YTSuh1axK0QYatvvQBZZX7XhBleHa0mGbOk-1748745981-1.0.1.1-R7gsbYHjiX8KgQXwKGgBSKu1VGH4kt8Ynq71nx1IFZtIw0ySM2xvz0.7_sOVJoPjzFjKlmJXbj57dhtZoMByPLU2RHOSwUVydwwDz1KYDF8; path=/; expires=Sun, 01-Jun-25 03:16:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=ISiRKojKdpRIWGXdW6U1vgiroJc765uTMSO._rFvFhE-1748745981026-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b6149baf73bfe-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:46:21,013 - DEBUG - request_id: req_07e3a7e132e7d5fe7c68623b4ca942af
2025-06-01 02:46:21,018 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Interacting with Lean

You are now familiar with the fundamentals of dependent type theory, both as a
language for defining mathematical objects and a language for constructing
proofs. The one thing you are missing is a mechanism for defining new data
types. We will fill this gap in the next chapter, which introduces the notion
of an _inductive data type_. But first, in this chapter, we take a break from
the mechanics of type theory to explore some pragmatic aspects of interacting
with Lean.

Not all of the information found here will be useful to you right away. We
recommend skimming this section to get a sense of Lean's features, and then
returning to it as necessary.

## Importing Files

The goal of Lean's front end is to interpret user input, construct formal
expressions, and check that they are well-formed and type-correct. Lean also
supports the use of various editors, which provide continuous checking and
feedback. More information can be found on the Lean [documentation
pages](https://lean-lang.org/documentation/).

The definitions and theorems in Lean's standard library are spread across
multiple files. Users may also wish to make use of additional libraries, or
develop their own projects across multiple files. When Lean starts, it
automatically imports the contents of the library `Init` folder, which
includes a number of fundamental definitions and constructions. As a result,
most of the examples we present here work "out of the box."

If you want to use additional files, however, they need to be imported
manually, via an `import` statement at the beginning of a file. The command

    
    
    import Bar.Baz.Blah
    

imports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted
relative to the Lean _search path_. Information as to how the search path is
determined can be found on the [documentation pages](https://lean-
lang.org/documentation/). By default, it includes the standard library
directory, and (in some contexts) the root of the user's local project.

Importing is transitive. In other words, if you import `Foo` and `Foo` imports
`Bar`, then you also have access to the contents of `Bar`, and do not need to
import it explicitly.

## More on Sections

Lean provides various sectioning mechanisms to help structure a theory. You
saw in [Variables and Sections](./dependent_type_theory.html#variables-and-
sections) that the `section` command makes it possible not only to group
together elements of a theory that go together, but also to declare variables
that are inserted as arguments to theorems and definitions, as necessary.
Remember that the point of the `variable` command is to declare variables for
use in theorems, as in the following example:

    
    
    section
    variable (x y : Nat)
    
    def double := x + x
    
    #check double y
    #check double (2 * x)
    
    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm
    
    theorem t1 : double (x + y) = double x + double y := by
      simp [double]
    
    #check t1 y
    #check t1 (2 * x)
    
    theorem t2 : double (x * y) = double x * y := by
      simp [double, Nat.add_mul]
    
    end
    

The definition of `double` does not have to declare `x` as an argument; Lean
detects the dependence and inserts it automatically. Similarly, Lean detects
the occurrence of `x` in `t1` and `t2`, and inserts it automatically there,
too. Note that `double` does _not_ have `y` as argument. Variables are only
included in declarations where they are actually used.

## More on Namespaces

In Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We
saw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean
provides mechanisms for working with hierarchical names. The command
`namespace foo` causes `foo` to be prepended to the name of each definition
and theorem until `end foo` is encountered. The command `open foo` then
creates temporary _aliases_ to definitions and theorems that begin with prefix
`foo`.

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    
    open Foo
    
    #check bar
    #check Foo.bar
    

The following definition

    
    
    def Foo.bar : Nat := 1
    

is treated as a macro, and expands to

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    

Although the names of theorems and definitions have to be unique, the aliases
that identify them do not. When we open a namespace, an identifier may be
ambiguous. Lean tries to use type information to disambiguate the meaning in
context, but you can always disambiguate by giving the full name. To that end,
the string `_root_` is an explicit description of the empty prefix.

    
    
    def String.add (a b : String) : String :=
      a ++ b
    
    def Bool.add (a b : Bool) : Bool :=
      a != b
    
    def add (α β : Type) : Type := Sum α β
    
    open Bool
    open String
    -- #check add -- ambiguous
    #check String.add           -- String → String → String
    #check Bool.add             -- Bool → Bool → Bool
    #check _root_.add           -- Type → Type → Type
    
    #check add "hello" "world"  -- String
    #check add true false       -- Bool
    #check add Nat Nat          -- Type
    

We can prevent the shorter alias from being created by using the `protected`
keyword:

    
    
    protected def Foo.bar : Nat := 1
    
    open Foo
    
    -- #check bar -- error
    #check Foo.bar
    

This is often used for names like `Nat.rec` and `Nat.recOn`, to prevent
overloading of common names.

The `open` command admits variations. The command

    
    
    open Nat (succ zero gcd)
    #check zero     -- Nat
    #eval gcd 15 6  -- 3
    

creates aliases for only the identifiers listed. The command

    
    
    open Nat hiding succ gcd
    #check zero     -- Nat
    -- #eval gcd 15 6  -- error
    #eval Nat.gcd 15 6  -- 3
    

creates aliases for everything in the `Nat` namespace _except_ the identifiers
listed.

    
    
    open Nat renaming mul → times, add → plus
    #eval plus (times 2 2) 3  -- 7
    

creates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.

It is sometimes useful to `export` aliases from one namespace to another, or
to the top level. The command

    
    
    export Nat (succ add sub)
    

creates aliases for `succ`, `add`, and `sub` in the current namespace, so that
whenever the namespace is open, these aliases are available. If this command
is used outside a namespace, the aliases are exported to the top level.

## Attributes

The main function of Lean is to translate user input to formal expressions
that are checked by the kernel for correctness and then stored in the
environment for later use. But some commands have other effects on the
environment, either assigning attributes to objects in the environment,
defining notation, or declaring instances of type classes, as described in
[Chapter Type Classes](./type_classes.html). Most of these commands have
global effects, which is to say, they remain in effect not only in the current
file, but also in any file that imports it. However, such commands often
support the `local` modifier, which indicates that they only have effect until
the current `section` or `namespace` is closed, or until the end of the
current file.

In [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw
that theorems can be annotated with the `[simp]` attribute, which makes them
available for use by the simplifier. The following example defines the prefix
relation on lists, proves that this relation is reflexive, and assigns the
`[simp]` attribute to that theorem.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    

The simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to
`True`.

One can also assign the attribute any time after the definition takes place:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [simp] List.isPrefix_self
    

In all these cases, the attribute remains in effect in any file that imports
the one in which the declaration occurs. Adding the `local` modifier restricts
the scope:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    section
    
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [local simp] List.isPrefix_self
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    
    end
    
    -- Error:
    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by
    --  simp
    

For another example, we can use the `instance` command to assign the notation
`≤` to the `isPrefix` relation. That command, which will be explained in
[Chapter Type Classes](./type_classes.html), works by assigning an
`[instance]` attribute to the associated definition.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    instance : LE (List α) where
      le := isPrefix
    
    theorem List.isPrefix_self (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    

That assignment can also be made local:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    def instLe : LE (List α) :=
      { le := isPrefix }
    
    section
    attribute [local instance] instLe
    
    example (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    
    end
    
    -- Error:
    -- example (as : List α) : as ≤ as :=
    --  ⟨[], by simp⟩
    

In Section Notation below, we will discuss Lean's mechanisms for defining
notation, and see that they also support the `local` modifier. However, in
Section Setting Options, we will discuss Lean's mechanisms for setting
options, which does _not_ follow this pattern: options can _only_ be set
locally, which is to say, their scope is always restricted to the current
section or current file.

## More on Implicit Arguments

In [Section Implicit Arguments](./dependent_type_theory.html#implicit-
arguments), we saw that if Lean displays the type of a term `t` as `{x : α} →
β x`, then the curly brackets indicate that `x` has been marked as an
_implicit argument_ to `t`. This means that whenever you write `t`, a
placeholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you
don't want that to happen, you have to write `@t` instead.

Notice that implicit arguments are inserted eagerly. Suppose we define a
function `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,
when we write the expression `f 7` without further arguments, it is parsed as
`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that
a placeholder should only be added _before_ a subsequent explicit argument.
This annotation can also be written using as `⦃y : Nat⦄`, where the unicode
brackets are entered as `\{{` and `\}}`, respectively. With this annotation,
the expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as
`f 7 _ 3`, just as it would be with the strong annotation.

To illustrate the difference, consider the following example, which shows that
a reflexive euclidean relation is both symmetric and transitive.

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b : α}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
     th2 (th1 reflr @euclr) @euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3
    

The results are broken down into small steps: `th1` shows that a relation that
is reflexive and euclidean is symmetric, and `th2` shows that a relation that
is symmetric and euclidean is transitive. Then `th3` combines the two results.
But notice that we have to manually disable the implicit arguments in `euclr`,
because otherwise too many implicit arguments are inserted. The problem goes
away if we use weak implicit arguments:

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b : α}}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
      th2 (th1 reflr euclr) euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- euclidean r
    

There is a third kind of implicit argument that is denoted with square
brackets, `[` and `]`. These are used for type classes, as explained in
[Chapter Type Classes](./type_classes.html).

## Notation

Identifiers in Lean can include any alphanumeric characters, including Greek
characters (other than ∀ , Σ , and λ , which, as we have seen, have a special
meaning in the dependent type theory). They can also include subscripts, which
can be entered by typing `\_` followed by the desired subscripted character.

Lean's parser is extensible, which is to say, we can define new notation.

Lean's syntax can be extended and customized by users at every level, ranging
from basic "mixfix" notations to custom elaborators. In fact, all builtin
syntax is parsed and processed using the same mechanisms and APIs open to
users. In this section, we will describe and explain the various extension
points.

While introducing new notations is a relatively rare feature in programming
languages and sometimes even frowned upon because of its potential to obscure
code, it is an invaluable tool in formalization for expressing established
conventions and notations of the respective field succinctly in code. Going
beyond basic notations, Lean's ability to factor out common boilerplate code
into (well-behaved) macros and to embed entire custom domain specific
languages (DSLs) to textually encode subproblems efficiently and readably can
be of great benefit to both programmers and proof engineers alike.

### Notations and Precedence

The most basic syntax extension commands allow introducing new (or overloading
existing) prefix, infix, and postfix operators.

    
    
    infixl:65   " + " => HAdd.hAdd  -- left-associative
    infix:50    " = " => Eq         -- non-associative
    infixr:80   " ^ " => HPow.hPow  -- right-associative
    prefix:100  "-"   => Neg.neg
    set_option quotPrecheck false
    postfix:max "⁻¹"  => Inv.inv
    

After the initial command name describing the operator kind (its "fixity"), we
give the _parsing precedence_ of the operator preceded by a colon `:`, then a
new or existing token surrounded by double quotes (the whitespace is used for
pretty printing), then the function this operator should be translated to
after the arrow `=>`.

The precedence is a natural number describing how "tightly" an operator binds
to its arguments, encoding the order of operations. We can make this more
precise by looking at the commands the above unfold to:

    
    
    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs
    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs
    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs
    notation:100 "-" arg:100 => Neg.neg arg
    set_option quotPrecheck false
    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024
    

It turns out that all commands from the first code block are in fact command
_macros_ translating to the more general `notation` command. We will learn
about writing such macros below. Instead of a single token, the `notation`
command accepts a mixed sequence of tokens and named term placeholders with
precedences, which can be referenced on the right-hand side of `=>` and will
be replaced by the respective term parsed at that position. A placeholder with
precedence `p` accepts only notations with precedence at least `p` in that
place. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +
(b + c)` because the right-hand side operand of an `infixl` notation has
precedence one greater than the notation itself. In contrast, `infixr` reuses
the notation's precedence for the right-hand side operand, so `a ^ b ^ c`
_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to
introduce an infix notation like

    
    
    set_option quotPrecheck false
    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs
    

where the precedences do not sufficiently determine associativity, Lean's
parser will default to right associativity. More precisely, Lean's parser
follows a local _longest parse_ rule in the presence of ambiguous grammars:
when parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue
parsing as long as possible (as the current precedence allows), not stopping
after `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~
c)`.

As mentioned above, the `notation` command allows us to define arbitrary
_mixfix_ syntax freely mixing tokens and placeholders.

    
    
    set_option quotPrecheck false
    notation:max "(" e ")" => e
    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ
    

Placeholders without precedence default to `0`, i.e. they accept notations of
any precedence in their place. If two notations overlap, we again apply the
longest parse rule:

    
    
    notation:65 a " + " b:66 " + " c:66 => a + b - c
    #eval 1 + 2 + 3  -- 0
    

The new notation is preferred to the binary notation since the latter, before
chaining, would stop parsing after `1 + 2`. If there are multiple notations
accepting the same longest parse, the choice will be delayed until
elaboration, which will fail unless exactly one overload is type-correct.

## Coercions

In Lean, the type of natural numbers, `Nat`, is different from the type of
integers, `Int`. But there is a function `Int.ofNat` that embeds the natural
numbers in the integers, meaning that we can view any natural number as an
integer, when needed. Lean has mechanisms to detect and insert _coercions_ of
this sort.

    
    
    variable (m n : Nat)
    variable (i j : Int)
    
    #check i + m      -- i + Int.ofNat m : Int
    #check i + m + j  -- i + Int.ofNat m + j : Int
    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int
    

## Displaying Information

There are a number of ways in which you can query Lean for information about
its current state and the objects and theorems that are available in the
current context. You have already seen two of the most common ones, `#check`
and `#eval`. Remember that `#check` is often used in conjunction with the `@`
operator, which makes all of the arguments to a theorem or definition
explicit. In addition, you can use the `#print` command to get information
about any identifier. If the identifier denotes a definition or theorem, Lean
prints the type of the symbol, and its definition. If it is a constant or an
axiom, Lean indicates that fact, and shows the type.

    
    
    -- examples with equality
    #check Eq
    #check @Eq
    #check Eq.symm
    #check @Eq.symm
    
    #print Eq.symm
    
    -- examples with And
    #check And
    #check And.intro
    #check @And.intro
    
    -- a user-defined function
    def foo {α : Type u} (x : α) : α := x
    
    #check foo
    #check @foo
    #print foo
    

## Setting Options

Lean maintains a number of internal variables that can be set by users to
control its behavior. The syntax for doing so is as follows:

    
    
    set_option <name> <value>
    

One very useful family of options controls the way Lean's _pretty- printer_
displays terms. The following options take an input of true or false:

    
    
    pp.explicit  : display implicit arguments
    pp.universes : display hidden universe parameters
    pp.notation  : display output using defined notations
    

As an example, the following settings yield much longer output:

    
    
    set_option pp.explicit true
    set_option pp.universes true
    set_option pp.notation false
    
    #check 2 + 2 = 4
    #reduce (fun x => x + 2) = (fun x => x + 3)
    #check (fun x => x + 1) 1
    

The command `set_option pp.all true` carries out these settings all at once,
whereas `set_option pp.all false` reverts to the previous values. Pretty
printing additional information is often very useful when you are debugging a
proof, or trying to understand a cryptic error message. Too much information
can be overwhelming, though, and Lean's defaults are generally sufficient for
ordinary interactions.

## Using the Library

To use Lean effectively you will inevitably need to make use of definitions
and theorems in the library. Recall that the `import` command at the beginning
of a file imports previously compiled results from other files, and that
importing is transitive; if you import `Foo` and `Foo` imports `Bar`, then the
definitions and theorems from `Bar` are available to you as well. But the act
of opening a namespace, which provides shorter names, does not carry over. In
each file, you need to open the namespaces you wish to use.

In general, it is important for you to be familiar with the library and its
contents, so you know what theorems, definitions, notations, and resources are
available to you. Below we will see that Lean's editor modes can also help you
find things you need, but studying the contents of the library directly is
often unavoidable. Lean's standard library can be found online, on GitHub:

  * <https://github.com/leanprover/lean4/tree/master/src/Init>

  * <https://github.com/leanprover/std4/tree/main/Std>

You can see the contents of these directories and files using GitHub's browser
interface. If you have installed Lean on your own computer, you can find the
library in the `lean` folder, and explore it with your file manager. Comment
headers at the top of each file provide additional information.

Lean's library developers follow general naming guidelines to make it easier
to guess the name of a theorem you need, or to find it using tab completion in
editors with a Lean mode that supports this, which is discussed in the next
section. Identifiers are generally `camelCase`, and types are `CamelCase`. For
theorem names, we rely on descriptive names where the different components are
separated by `_`s. Often the name of theorem simply describes the conclusion:

    
    
    #check Nat.succ_ne_zero
    #check Nat.zero_add
    #check Nat.mul_one
    #check Nat.le_of_succ_le_succ
    

Remember that identifiers in Lean can be organized into hierarchical
namespaces. For example, the theorem named `le_of_succ_le_succ` in the
namespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name
is made available by the command `open Nat` (for names not marked as
`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)
and [Chapter Structures and Records](./structures_and_records.html) that
defining structures and inductive data types in Lean generates associated
operations, and these are stored in a namespace with the same name as the type
under definition. For example, the product type comes with the following
operations:

    
    
    #check @Prod.mk
    #check @Prod.fst
    #check @Prod.snd
    #check @Prod.rec
    

The first is used to construct a pair, whereas the next two, `Prod.fst` and
`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another
mechanism for defining functions on a product in terms of a function on the
two components. Names like `Prod.rec` are _protected_ , which means that one
has to use the full name even when the `Prod` namespace is open.

With the propositions as types correspondence, logical connectives are also
instances of inductive types, and so we tend to use dot notation for them as
well:

    
    
    #check @And.intro
    #check @And.casesOn
    #check @And.left
    #check @And.right
    #check @Or.inl
    #check @Or.inr
    #check @Or.elim
    #check @Exists.intro
    #check @Exists.elim
    #check @Eq.refl
    #check @Eq.subst
    

## Auto Bound Implicit Arguments

In the previous section, we have shown how implicit arguments make functions
more convenient to use. However, functions such as `compose` are still quite
verbose to define. Note that the universe polymorphic `compose` is even more
verbose than the one previously defined.

    
    
    universe u v w
    def compose {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

You can avoid the `universe` command by providing the universe parameters when
defining `compose`.

    
    
    def compose.{u, v, w}
                {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

Lean 4 supports a new feature called _auto bound implicit arguments_. It makes
functions such as `compose` much more convenient to write. When Lean processes
the header of a declaration, any unbound identifier is automatically added as
an implicit argument _if_ it is a single lower case or greek letter. With this
feature we can write `compose` as

    
    
    def compose (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    
    #check @compose
    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ
    

Note that Lean inferred a more general type using `Sort` instead of `Type`.

Although we love this feature and use it extensively when implementing Lean,
we realize some users may feel uncomfortable with it. Thus, you can disable it
using the command `set_option autoImplicit false`.

    
    
    set_option autoImplicit false
    /- The following definition produces `unknown identifier` errors -/
    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=
    --   g (f x)
    

## Implicit Lambdas

In Lean 3 stdlib, we find many
[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)
of the dreadful `@`+`_` idiom. It is often used when the expected type is a
function type with implicit arguments, and we have a constant (`reader_t.pure`
in the example) which also takes implicit arguments. In Lean 4, the elaborator
automatically introduces lambdas for consuming implicit arguments. We are
still exploring this feature and analyzing its impact, but the experience so
far has been very positive. Here is the example from the link above using Lean
4 implicit lambdas.

    
    
    variable (ρ : Type) (m : Type → Type) [Monad m]
    instance : Monad (ReaderT ρ m) where
      pure := ReaderT.pure
      bind := ReaderT.bind
    

Users can disable the implicit lambda feature by using `@` or writing a lambda
expression with `{}` or `[]` binder annotations. Here are few examples

    
    
    namespace ex2
    def id1 : {α : Type} → α → α :=
      fun x => x
    
    def listId : List ({α : Type} → α → α) :=
      (fun x => x) :: []
    
    -- In this example, implicit lambda introduction has been disabled because
    -- we use `@` before `fun`
    def id2 : {α : Type} → α → α :=
      @fun α (x : α) => id1 x
    
    def id3 : {α : Type} → α → α :=
      @fun α x => id1 x
    
    def id4 : {α : Type} → α → α :=
      fun x => id1 x
    
    -- In this example, implicit lambda introduction has been disabled
    -- because we used the binder annotation `{...}`
    def id5 : {α : Type} → α → α :=
      fun {α} x => id1 x
    end ex2
    

## Sugar for Simple Functions

In Lean 3, we can create simple functions from infix operators by using
parentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we
generalize this notation using `·` as a placeholder. Here are a few examples:

    
    
    namespace ex3
    #check (· + 1)
    -- fun a => a + 1
    #check (2 - ·)
    -- fun a => 2 - a
    #eval [1, 2, 3, 4, 5].foldl (·*·) 1
    -- 120
    
    def f (x y z : Nat) :=
      x + y + z
    
    #check (f · 1 ·)
    -- fun a b => f a 1 b
    
    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)
    -- [1, 3, 5]
    end ex3
    

As in Lean 3, the notation is activated using parentheses, and the lambda
abstraction is created by collecting the nested `·`s. The collection is
interrupted by nested parentheses. In the following example, two different
lambda expressions are created.

    
    
    #check (Prod.mk · (· + 1))
    -- fun a => (a, fun b => b + 1)
    

## Named Arguments

Named arguments enable you to specify an argument for a parameter by matching
the argument with its name rather than with its position in the parameter
list. If you don't remember the order of the parameters but know their names,
you can send the arguments in any order. You may also provide the value for an
implicit parameter when
 modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
2025-06-01 02:46:21,030 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.\n\n-----Input-----\nThe input consists of:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the product of the two input integers (a * b).'}], 'model': 'o3-mini'}}
2025-06-01 02:46:21,031 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:46:21,031 - DEBUG - close.started
2025-06-01 02:46:21,031 - DEBUG - close.complete
2025-06-01 02:46:21,031 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:46:21,038 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204273080>
2025-06-01 02:46:21,038 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:46:21,047 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204270530>
2025-06-01 02:46:21,047 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:46:21,048 - DEBUG - send_request_headers.complete
2025-06-01 02:46:21,048 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:46:21,048 - DEBUG - send_request_body.complete
2025-06-01 02:46:21,048 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:46:26,889 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:46:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5607'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5613'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199613'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'115ms'), (b'x-request-id', b'req_06945f10d1e5bd5b44ddb323a5c9f692'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b614db8ec4436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:46:26,890 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:46:26,890 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:46:26,890 - DEBUG - receive_response_body.complete
2025-06-01 02:46:26,890 - DEBUG - response_closed.started
2025-06-01 02:46:26,890 - DEBUG - response_closed.complete
2025-06-01 02:46:26,890 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:46:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5607', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5613', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199613', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '115ms', 'x-request-id': 'req_06945f10d1e5bd5b44ddb323a5c9f692', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b614db8ec4436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:46:26,890 - DEBUG - request_id: req_06945f10d1e5bd5b44ddb323a5c9f692
2025-06-01 02:46:26,891 - INFO - Attempt 1/3
2025-06-01 02:46:26,891 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that takes two integers and returns their product. The plan involves creating a function with integer parameters and using Lean's built-in multiplication operator to compute the product. This is a straightforward implementation that leverages Lean's arithmetic capabilities.",
  "steps": [
    "Define a Lean function with two integer parameters, typically named a and b.",
    "Use Lean's built-in multiplication operator (*) to calculate the product of a and b.",
    "Return the computed product as the output of the function.",
    "Optionally, include a simple example or test to verify the correctness of the function implementation."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "integer multiplication",
    "operator *"
  ],
  "proof_keywords": [
    "direct implementation",
    "algebraic properties",
    "identity of multiplication"
  ],
  "assumptions": [
    "The built-in multiplication operator is used, so no custom multiplication algorithm is necessary.",
    "Inputs are assumed to be valid integers; error handling for non-integer inputs is not required."
  ],
  "retry_guidance": "If errors occur, ensure that the integer type is correctly specified and that Lean's built-in multiplication operator is properly applied. Double-check the function signature and return type to match the problem description. Consider checking example usage in Lean 4 documentation if unexpected behavior is observed."
}
2025-06-01 02:46:26,891 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that takes two integers and returns their product. The plan involves creating a function with integer parameters and using Lean\'s built-in multiplication operator to compute the product. This is a straightforward implementation that leverages Lean\'s arithmetic capabilities.",\n  "steps": [\n    "Define a Lean function with two integer parameters, typically named a and b.",\n    "Use Lean\'s built-in multiplication operator (*) to calculate the product of a and b.",\n    "Return the computed product as the output of the function.",\n    "Optionally, include a simple example or test to verify the correctness of the function implementation."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "integer multiplication",\n    "operator *"\n  ],\n  "proof_keywords": [\n    "direct implementation",\n    "algebraic properties",\n    "identity of multiplication"\n  ],\n  "assumptions": [\n    "The built-in multiplication operator is used, so no custom multiplication algorithm is necessary.",\n    "Inputs are assumed to be valid integers; error handling for non-integer inputs is not required."\n  ],\n  "retry_guidance": "If errors occur, ensure that the integer type is correctly specified and that Lean\'s built-in multiplication operator is properly applied. Double-check the function signature and return type to match the problem description. Consider checking example usage in Lean 4 documentation if unexpected behavior is observed."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef multiply (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result should be the product of the two input integers\ndef multiply_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = a * b\n  -- << SPEC END >>\n\ntheorem multiply_spec_satisfied (a : Int) (b : Int) :\n  multiply_spec a b (multiply a b) := by\n  -- << PROOF START >>\n  unfold multiply multiply_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 02:46:26,893 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:46:26,893 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:46:26,893 - DEBUG - send_request_headers.complete
2025-06-01 02:46:26,893 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:46:26,899 - DEBUG - send_request_body.complete
2025-06-01 02:46:26,899 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:46:28,552 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:46:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'1420'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1423'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'11747'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'36.506s'), (b'x-request-id', b'req_6f2e373a2eb87d5d94f5285b29ad7c90'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b61723d754436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:46:28,552 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:46:28,552 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:46:28,553 - DEBUG - receive_response_body.complete
2025-06-01 02:46:28,553 - DEBUG - response_closed.started
2025-06-01 02:46:28,553 - DEBUG - response_closed.complete
2025-06-01 02:46:28,554 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:46:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '1420', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1423', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '11747', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '36.506s', 'x-request-id': 'req_6f2e373a2eb87d5d94f5285b29ad7c90', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b61723d754436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:46:28,554 - DEBUG - request_id: req_6f2e373a2eb87d5d94f5285b29ad7c90
2025-06-01 02:46:28,554 - INFO - Raw solution received: ```json
{
  "code": "a * b",
  "proof": "\nsimp\n"
}
```
2025-06-01 02:46:28,554 - INFO - <class 'str'>
2025-06-01 02:46:28,554 - INFO - Generated solution: {'code': 'a * b', 'proof': '\nsimp\n'}
2025-06-01 02:46:33,772 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:18:38: error: unsolved goals
a b : ℤ
⊢ a * b = a * b
lean_playground/TempTest.lean:22:0: error: unexpected identifier; expected command
2025-06-01 02:46:33,773 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.\n\n-----Input-----\nThe input consists of:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the product of the two input integers (a * b).\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef multiply (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result should be the product of the two input integers\ndef multiply_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = a * b\n  -- << SPEC END >>\n\ntheorem multiply_spec_satisfied (a : Int) (b : Int) :\n  multiply_spec a b (multiply a b) := by\n  -- << PROOF START >>\n  unfold multiply multiply_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na * b\n\nGenerated Proof:\n\nsimp\n\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:18:38: error: unsolved goals\na b : ℤ\n⊢ a * b = a * b\nlean_playground/TempTest.lean:22:0: error: unexpected identifier; expected command'}], 'model': 'o3-mini'}}
2025-06-01 02:46:33,774 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:46:33,774 - DEBUG - close.started
2025-06-01 02:46:33,774 - DEBUG - close.complete
2025-06-01 02:46:33,774 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:46:33,783 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e203e6d130>
2025-06-01 02:46:33,783 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:46:33,791 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e2042930b0>
2025-06-01 02:46:33,791 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:46:33,791 - DEBUG - send_request_headers.complete
2025-06-01 02:46:33,791 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:46:33,792 - DEBUG - send_request_body.complete
2025-06-01 02:46:33,792 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:46:44,172 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:46:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'10160'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'10163'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199345'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'196ms'), (b'x-request-id', b'req_035e9ad29f26737413c1158b9d99fc0a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b619d5fe34278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:46:44,172 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:46:44,172 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:46:44,173 - DEBUG - receive_response_body.complete
2025-06-01 02:46:44,173 - DEBUG - response_closed.started
2025-06-01 02:46:44,173 - DEBUG - response_closed.complete
2025-06-01 02:46:44,173 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:46:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '10160', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '10163', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199345', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '196ms', 'x-request-id': 'req_035e9ad29f26737413c1158b9d99fc0a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b619d5fe34278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:46:44,173 - DEBUG - request_id: req_035e9ad29f26737413c1158b9d99fc0a
2025-06-01 02:46:44,173 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof failed because after unfolding, the goal remains unsolved: 'a * b = a * b'. Although this is an obvious equality, the 'simp' tactic did not automatically discharge it. In addition, Lean reported an 'unexpected identifier' error after the proof block. This likely arises from an extra or misformatted line following the proof.", 'error_type': 'proof', 'suggested_fix': "Replace the 'simp' tactic with 'rfl' since 'rfl' directly proves reflexive equalities like 'a * b = a * b'. Also, check that there are no extraneous identifiers or commands after the proof block that could be causing a syntax issue.", 'retry_strategy': "Modify the proof as follows:\n\n  theorem multiply_spec_satisfied (a : Int) (b : Int) :\n    multiply_spec a b (multiply a b) := by\n      unfold multiply multiply_spec\n      rfl\n\nThen ensure that the file contains no extra text or identifiers after the '-- << PROOF END >>' marker. Re-run Lean to verify that the proof compiles and all goals are solved."}
2025-06-01 02:46:44,173 - INFO - Solution generated in 23.81 seconds
2025-06-01 02:46:44,173 - INFO - Generated code length: 5 characters
2025-06-01 02:46:44,174 - INFO - Generated proof length: 6 characters
2025-06-01 02:46:44,174 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:46:44,174 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:46:49,439 - INFO - Implementation test result: PASS
2025-06-01 02:46:49,439 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:46:54,726 - INFO - Full solution test result: FAIL
2025-06-01 02:46:54,726 - ERROR - Proof error: lean_playground/TempTest.lean:18:38: error: unsolved goals
a b : ℤ
⊢ a * b = a * b
lean_playground/TempTest.lean:22:0: error: unexpected identifier; e...
2025-06-01 02:46:54,726 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:46:54,726 - ERROR - ❌ Proof has errors
2025-06-01 02:46:54,726 - INFO - 
==================================================
2025-06-01 02:46:54,726 - INFO - Processing task task_id_227...
2025-06-01 02:46:54,726 - INFO - Reading problem description and code template from tasks/task_id_227...
2025-06-01 02:46:54,726 - INFO - Problem description length: 608 characters
2025-06-01 02:46:54,726 - INFO - Reading unit tests from tasks/task_id_227...
2025-06-01 02:46:54,727 - INFO - Unit tests length: 339 characters
2025-06-01 02:46:54,727 - INFO - Running main workflow to generate solution...
2025-06-01 02:46:54,727 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.

-----Input-----
The input consists of three integers:
a: The first integer.
b: The second integer.
c: The third integer.

-----Output-----
The output is an integer:
Returns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.
2025-06-01 02:46:54,727 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def minOfThree (a : Int) (b : Int) (c : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The returned value is the minimum of the three input numbers
def minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  (result <= a ∧ result <= b ∧ result <= c) ∧
  (result = a ∨ result = b ∨ result = c)
  -- << SPEC END >>

theorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :
  minOfThree_spec a b c (minOfThree a b c) := by
  -- << PROOF START >>
  unfold minOfThree minOfThree_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:46:54,756 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x74e203e82660>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:46:54,757 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:46:54,757 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:46:54,765 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20429cbc0>
2025-06-01 02:46:54,765 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2042666d0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:46:54,773 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20429c560>
2025-06-01 02:46:54,773 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:46:54,773 - DEBUG - send_request_headers.complete
2025-06-01 02:46:54,774 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:46:54,774 - DEBUG - send_request_body.complete
2025-06-01 02:46:54,774 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:46:55,430 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:46:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'89'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-canary-656df74c88-zhbgc'), (b'x-envoy-upstream-service-time', b'94'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999847'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_c7770ddeed1f06905ff0dceb3c852330'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=D9koJi_gMMeurj39_VDGX5oc5Bdp43LJRPucCAnA0Vs-1748746015-1.0.1.1-dq8RTzSFsmbW1Ds.X1Ur5TpY7eHYOP9ik0hDBGEB3p44egSFWk0s5i2usRv.AtcIIz7eLnh8kdCmHqWYHOA6QOimUSecyX3EJHt8aYaZ5z0; path=/; expires=Sun, 01-Jun-25 03:16:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=ackXW.16uc_05JrA6toR.bzucgYDTM2jJKN8u4BKsag-1748746015449-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b62207a194436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:46:55,430 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:46:55,430 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:46:55,431 - DEBUG - receive_response_body.complete
2025-06-01 02:46:55,431 - DEBUG - response_closed.started
2025-06-01 02:46:55,431 - DEBUG - response_closed.complete
2025-06-01 02:46:55,431 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:46:55 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '89'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-canary-656df74c88-zhbgc'), ('x-envoy-upstream-service-time', '94'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999847'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '9ms'), ('x-request-id', 'req_c7770ddeed1f06905ff0dceb3c852330'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=D9koJi_gMMeurj39_VDGX5oc5Bdp43LJRPucCAnA0Vs-1748746015-1.0.1.1-dq8RTzSFsmbW1Ds.X1Ur5TpY7eHYOP9ik0hDBGEB3p44egSFWk0s5i2usRv.AtcIIz7eLnh8kdCmHqWYHOA6QOimUSecyX3EJHt8aYaZ5z0; path=/; expires=Sun, 01-Jun-25 03:16:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=ackXW.16uc_05JrA6toR.bzucgYDTM2jJKN8u4BKsag-1748746015449-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b62207a194436-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:46:55,431 - DEBUG - request_id: req_c7770ddeed1f06905ff0dceb3c852330
2025-06-01 02:46:55,436 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Interacting with Lean

You are now familiar with the fundamentals of dependent type theory, both as a
language for defining mathematical objects and a language for constructing
proofs. The one thing you are missing is a mechanism for defining new data
types. We will fill this gap in the next chapter, which introduces the notion
of an _inductive data type_. But first, in this chapter, we take a break from
the mechanics of type theory to explore some pragmatic aspects of interacting
with Lean.

Not all of the information found here will be useful to you right away. We
recommend skimming this section to get a sense of Lean's features, and then
returning to it as necessary.

## Importing Files

The goal of Lean's front end is to interpret user input, construct formal
expressions, and check that they are well-formed and type-correct. Lean also
supports the use of various editors, which provide continuous checking and
feedback. More information can be found on the Lean [documentation
pages](https://lean-lang.org/documentation/).

The definitions and theorems in Lean's standard library are spread across
multiple files. Users may also wish to make use of additional libraries, or
develop their own projects across multiple files. When Lean starts, it
automatically imports the contents of the library `Init` folder, which
includes a number of fundamental definitions and constructions. As a result,
most of the examples we present here work "out of the box."

If you want to use additional files, however, they need to be imported
manually, via an `import` statement at the beginning of a file. The command

    
    
    import Bar.Baz.Blah
    

imports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted
relative to the Lean _search path_. Information as to how the search path is
determined can be found on the [documentation pages](https://lean-
lang.org/documentation/). By default, it includes the standard library
directory, and (in some contexts) the root of the user's local project.

Importing is transitive. In other words, if you import `Foo` and `Foo` imports
`Bar`, then you also have access to the contents of `Bar`, and do not need to
import it explicitly.

## More on Sections

Lean provides various sectioning mechanisms to help structure a theory. You
saw in [Variables and Sections](./dependent_type_theory.html#variables-and-
sections) that the `section` command makes it possible not only to group
together elements of a theory that go together, but also to declare variables
that are inserted as arguments to theorems and definitions, as necessary.
Remember that the point of the `variable` command is to declare variables for
use in theorems, as in the following example:

    
    
    section
    variable (x y : Nat)
    
    def double := x + x
    
    #check double y
    #check double (2 * x)
    
    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm
    
    theorem t1 : double (x + y) = double x + double y := by
      simp [double]
    
    #check t1 y
    #check t1 (2 * x)
    
    theorem t2 : double (x * y) = double x * y := by
      simp [double, Nat.add_mul]
    
    end
    

The definition of `double` does not have to declare `x` as an argument; Lean
detects the dependence and inserts it automatically. Similarly, Lean detects
the occurrence of `x` in `t1` and `t2`, and inserts it automatically there,
too. Note that `double` does _not_ have `y` as argument. Variables are only
included in declarations where they are actually used.

## More on Namespaces

In Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We
saw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean
provides mechanisms for working with hierarchical names. The command
`namespace foo` causes `foo` to be prepended to the name of each definition
and theorem until `end foo` is encountered. The command `open foo` then
creates temporary _aliases_ to definitions and theorems that begin with prefix
`foo`.

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    
    open Foo
    
    #check bar
    #check Foo.bar
    

The following definition

    
    
    def Foo.bar : Nat := 1
    

is treated as a macro, and expands to

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    

Although the names of theorems and definitions have to be unique, the aliases
that identify them do not. When we open a namespace, an identifier may be
ambiguous. Lean tries to use type information to disambiguate the meaning in
context, but you can always disambiguate by giving the full name. To that end,
the string `_root_` is an explicit description of the empty prefix.

    
    
    def String.add (a b : String) : String :=
      a ++ b
    
    def Bool.add (a b : Bool) : Bool :=
      a != b
    
    def add (α β : Type) : Type := Sum α β
    
    open Bool
    open String
    -- #check add -- ambiguous
    #check String.add           -- String → String → String
    #check Bool.add             -- Bool → Bool → Bool
    #check _root_.add           -- Type → Type → Type
    
    #check add "hello" "world"  -- String
    #check add true false       -- Bool
    #check add Nat Nat          -- Type
    

We can prevent the shorter alias from being created by using the `protected`
keyword:

    
    
    protected def Foo.bar : Nat := 1
    
    open Foo
    
    -- #check bar -- error
    #check Foo.bar
    

This is often used for names like `Nat.rec` and `Nat.recOn`, to prevent
overloading of common names.

The `open` command admits variations. The command

    
    
    open Nat (succ zero gcd)
    #check zero     -- Nat
    #eval gcd 15 6  -- 3
    

creates aliases for only the identifiers listed. The command

    
    
    open Nat hiding succ gcd
    #check zero     -- Nat
    -- #eval gcd 15 6  -- error
    #eval Nat.gcd 15 6  -- 3
    

creates aliases for everything in the `Nat` namespace _except_ the identifiers
listed.

    
    
    open Nat renaming mul → times, add → plus
    #eval plus (times 2 2) 3  -- 7
    

creates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.

It is sometimes useful to `export` aliases from one namespace to another, or
to the top level. The command

    
    
    export Nat (succ add sub)
    

creates aliases for `succ`, `add`, and `sub` in the current namespace, so that
whenever the namespace is open, these aliases are available. If this command
is used outside a namespace, the aliases are exported to the top level.

## Attributes

The main function of Lean is to translate user input to formal expressions
that are checked by the kernel for correctness and then stored in the
environment for later use. But some commands have other effects on the
environment, either assigning attributes to objects in the environment,
defining notation, or declaring instances of type classes, as described in
[Chapter Type Classes](./type_classes.html). Most of these commands have
global effects, which is to say, they remain in effect not only in the current
file, but also in any file that imports it. However, such commands often
support the `local` modifier, which indicates that they only have effect until
the current `section` or `namespace` is closed, or until the end of the
current file.

In [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw
that theorems can be annotated with the `[simp]` attribute, which makes them
available for use by the simplifier. The following example defines the prefix
relation on lists, proves that this relation is reflexive, and assigns the
`[simp]` attribute to that theorem.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    

The simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to
`True`.

One can also assign the attribute any time after the definition takes place:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [simp] List.isPrefix_self
    

In all these cases, the attribute remains in effect in any file that imports
the one in which the declaration occurs. Adding the `local` modifier restricts
the scope:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    section
    
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [local simp] List.isPrefix_self
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    
    end
    
    -- Error:
    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by
    --  simp
    

For another example, we can use the `instance` command to assign the notation
`≤` to the `isPrefix` relation. That command, which will be explained in
[Chapter Type Classes](./type_classes.html), works by assigning an
`[instance]` attribute to the associated definition.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    instance : LE (List α) where
      le := isPrefix
    
    theorem List.isPrefix_self (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    

That assignment can also be made local:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    def instLe : LE (List α) :=
      { le := isPrefix }
    
    section
    attribute [local instance] instLe
    
    example (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    
    end
    
    -- Error:
    -- example (as : List α) : as ≤ as :=
    --  ⟨[], by simp⟩
    

In Section Notation below, we will discuss Lean's mechanisms for defining
notation, and see that they also support the `local` modifier. However, in
Section Setting Options, we will discuss Lean's mechanisms for setting
options, which does _not_ follow this pattern: options can _only_ be set
locally, which is to say, their scope is always restricted to the current
section or current file.

## More on Implicit Arguments

In [Section Implicit Arguments](./dependent_type_theory.html#implicit-
arguments), we saw that if Lean displays the type of a term `t` as `{x : α} →
β x`, then the curly brackets indicate that `x` has been marked as an
_implicit argument_ to `t`. This means that whenever you write `t`, a
placeholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you
don't want that to happen, you have to write `@t` instead.

Notice that implicit arguments are inserted eagerly. Suppose we define a
function `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,
when we write the expression `f 7` without further arguments, it is parsed as
`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that
a placeholder should only be added _before_ a subsequent explicit argument.
This annotation can also be written using as `⦃y : Nat⦄`, where the unicode
brackets are entered as `\{{` and `\}}`, respectively. With this annotation,
the expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as
`f 7 _ 3`, just as it would be with the strong annotation.

To illustrate the difference, consider the following example, which shows that
a reflexive euclidean relation is both symmetric and transitive.

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b : α}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
     th2 (th1 reflr @euclr) @euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3
    

The results are broken down into small steps: `th1` shows that a relation that
is reflexive and euclidean is symmetric, and `th2` shows that a relation that
is symmetric and euclidean is transitive. Then `th3` combines the two results.
But notice that we have to manually disable the implicit arguments in `euclr`,
because otherwise too many implicit arguments are inserted. The problem goes
away if we use weak implicit arguments:

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b : α}}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
      th2 (th1 reflr euclr) euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- euclidean r
    

There is a third kind of implicit argument that is denoted with square
brackets, `[` and `]`. These are used for type classes, as explained in
[Chapter Type Classes](./type_classes.html).

## Notation

Identifiers in Lean can include any alphanumeric characters, including Greek
characters (other than ∀ , Σ , and λ , which, as we have seen, have a special
meaning in the dependent type theory). They can also include subscripts, which
can be entered by typing `\_` followed by the desired subscripted character.

Lean's parser is extensible, which is to say, we can define new notation.

Lean's syntax can be extended and customized by users at every level, ranging
from basic "mixfix" notations to custom elaborators. In fact, all builtin
syntax is parsed and processed using the same mechanisms and APIs open to
users. In this section, we will describe and explain the various extension
points.

While introducing new notations is a relatively rare feature in programming
languages and sometimes even frowned upon because of its potential to obscure
code, it is an invaluable tool in formalization for expressing established
conventions and notations of the respective field succinctly in code. Going
beyond basic notations, Lean's ability to factor out common boilerplate code
into (well-behaved) macros and to embed entire custom domain specific
languages (DSLs) to textually encode subproblems efficiently and readably can
be of great benefit to both programmers and proof engineers alike.

### Notations and Precedence

The most basic syntax extension commands allow introducing new (or overloading
existing) prefix, infix, and postfix operators.

    
    
    infixl:65   " + " => HAdd.hAdd  -- left-associative
    infix:50    " = " => Eq         -- non-associative
    infixr:80   " ^ " => HPow.hPow  -- right-associative
    prefix:100  "-"   => Neg.neg
    set_option quotPrecheck false
    postfix:max "⁻¹"  => Inv.inv
    

After the initial command name describing the operator kind (its "fixity"), we
give the _parsing precedence_ of the operator preceded by a colon `:`, then a
new or existing token surrounded by double quotes (the whitespace is used for
pretty printing), then the function this operator should be translated to
after the arrow `=>`.

The precedence is a natural number describing how "tightly" an operator binds
to its arguments, encoding the order of operations. We can make this more
precise by looking at the commands the above unfold to:

    
    
    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs
    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs
    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs
    notation:100 "-" arg:100 => Neg.neg arg
    set_option quotPrecheck false
    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024
    

It turns out that all commands from the first code block are in fact command
_macros_ translating to the more general `notation` command. We will learn
about writing such macros below. Instead of a single token, the `notation`
command accepts a mixed sequence of tokens and named term placeholders with
precedences, which can be referenced on the right-hand side of `=>` and will
be replaced by the respective term parsed at that position. A placeholder with
precedence `p` accepts only notations with precedence at least `p` in that
place. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +
(b + c)` because the right-hand side operand of an `infixl` notation has
precedence one greater than the notation itself. In contrast, `infixr` reuses
the notation's precedence for the right-hand side operand, so `a ^ b ^ c`
_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to
introduce an infix notation like

    
    
    set_option quotPrecheck false
    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs
    

where the precedences do not sufficiently determine associativity, Lean's
parser will default to right associativity. More precisely, Lean's parser
follows a local _longest parse_ rule in the presence of ambiguous grammars:
when parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue
parsing as long as possible (as the current precedence allows), not stopping
after `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~
c)`.

As mentioned above, the `notation` command allows us to define arbitrary
_mixfix_ syntax freely mixing tokens and placeholders.

    
    
    set_option quotPrecheck false
    notation:max "(" e ")" => e
    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ
    

Placeholders without precedence default to `0`, i.e. they accept notations of
any precedence in their place. If two notations overlap, we again apply the
longest parse rule:

    
    
    notation:65 a " + " b:66 " + " c:66 => a + b - c
    #eval 1 + 2 + 3  -- 0
    

The new notation is preferred to the binary notation since the latter, before
chaining, would stop parsing after `1 + 2`. If there are multiple notations
accepting the same longest parse, the choice will be delayed until
elaboration, which will fail unless exactly one overload is type-correct.

## Coercions

In Lean, the type of natural numbers, `Nat`, is different from the type of
integers, `Int`. But there is a function `Int.ofNat` that embeds the natural
numbers in the integers, meaning that we can view any natural number as an
integer, when needed. Lean has mechanisms to detect and insert _coercions_ of
this sort.

    
    
    variable (m n : Nat)
    variable (i j : Int)
    
    #check i + m      -- i + Int.ofNat m : Int
    #check i + m + j  -- i + Int.ofNat m + j : Int
    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int
    

## Displaying Information

There are a number of ways in which you can query Lean for information about
its current state and the objects and theorems that are available in the
current context. You have already seen two of the most common ones, `#check`
and `#eval`. Remember that `#check` is often used in conjunction with the `@`
operator, which makes all of the arguments to a theorem or definition
explicit. In addition, you can use the `#print` command to get information
about any identifier. If the identifier denotes a definition or theorem, Lean
prints the type of the symbol, and its definition. If it is a constant or an
axiom, Lean indicates that fact, and shows the type.

    
    
    -- examples with equality
    #check Eq
    #check @Eq
    #check Eq.symm
    #check @Eq.symm
    
    #print Eq.symm
    
    -- examples with And
    #check And
    #check And.intro
    #check @And.intro
    
    -- a user-defined function
    def foo {α : Type u} (x : α) : α := x
    
    #check foo
    #check @foo
    #print foo
    

## Setting Options

Lean maintains a number of internal variables that can be set by users to
control its behavior. The syntax for doing so is as follows:

    
    
    set_option <name> <value>
    

One very useful family of options controls the way Lean's _pretty- printer_
displays terms. The following options take an input of true or false:

    
    
    pp.explicit  : display implicit arguments
    pp.universes : display hidden universe parameters
    pp.notation  : display output using defined notations
    

As an example, the following settings yield much longer output:

    
    
    set_option pp.explicit true
    set_option pp.universes true
    set_option pp.notation false
    
    #check 2 + 2 = 4
    #reduce (fun x => x + 2) = (fun x => x + 3)
    #check (fun x => x + 1) 1
    

The command `set_option pp.all true` carries out these settings all at once,
whereas `set_option pp.all false` reverts to the previous values. Pretty
printing additional information is often very useful when you are debugging a
proof, or trying to understand a cryptic error message. Too much information
can be overwhelming, though, and Lean's defaults are generally sufficient for
ordinary interactions.

## Using the Library

To use Lean effectively you will inevitably need to make use of definitions
and theorems in the library. Recall that the `import` command at the beginning
of a file imports previously compiled results from other files, and that
importing is transitive; if you import `Foo` and `Foo` imports `Bar`, then the
definitions and theorems from `Bar` are available to you as well. But the act
of opening a namespace, which provides shorter names, does not carry over. In
each file, you need to open the namespaces you wish to use.

In general, it is important for you to be familiar with the library and its
contents, so you know what theorems, definitions, notations, and resources are
available to you. Below we will see that Lean's editor modes can also help you
find things you need, but studying the contents of the library directly is
often unavoidable. Lean's standard library can be found online, on GitHub:

  * <https://github.com/leanprover/lean4/tree/master/src/Init>

  * <https://github.com/leanprover/std4/tree/main/Std>

You can see the contents of these directories and files using GitHub's browser
interface. If you have installed Lean on your own computer, you can find the
library in the `lean` folder, and explore it with your file manager. Comment
headers at the top of each file provide additional information.

Lean's library developers follow general naming guidelines to make it easier
to guess the name of a theorem you need, or to find it using tab completion in
editors with a Lean mode that supports this, which is discussed in the next
section. Identifiers are generally `camelCase`, and types are `CamelCase`. For
theorem names, we rely on descriptive names where the different components are
separated by `_`s. Often the name of theorem simply describes the conclusion:

    
    
    #check Nat.succ_ne_zero
    #check Nat.zero_add
    #check Nat.mul_one
    #check Nat.le_of_succ_le_succ
    

Remember that identifiers in Lean can be organized into hierarchical
namespaces. For example, the theorem named `le_of_succ_le_succ` in the
namespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name
is made available by the command `open Nat` (for names not marked as
`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)
and [Chapter Structures and Records](./structures_and_records.html) that
defining structures and inductive data types in Lean generates associated
operations, and these are stored in a namespace with the same name as the type
under definition. For example, the product type comes with the following
operations:

    
    
    #check @Prod.mk
    #check @Prod.fst
    #check @Prod.snd
    #check @Prod.rec
    

The first is used to construct a pair, whereas the next two, `Prod.fst` and
`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another
mechanism for defining functions on a product in terms of a function on the
two components. Names like `Prod.rec` are _protected_ , which means that one
has to use the full name even when the `Prod` namespace is open.

With the propositions as types correspondence, logical connectives are also
instances of inductive types, and so we tend to use dot notation for them as
well:

    
    
    #check @And.intro
    #check @And.casesOn
    #check @And.left
    #check @And.right
    #check @Or.inl
    #check @Or.inr
    #check @Or.elim
    #check @Exists.intro
    #check @Exists.elim
    #check @Eq.refl
    #check @Eq.subst
    

## Auto Bound Implicit Arguments

In the previous section, we have shown how implicit arguments make functions
more convenient to use. However, functions such as `compose` are still quite
verbose to define. Note that the universe polymorphic `compose` is even more
verbose than the one previously defined.

    
    
    universe u v w
    def compose {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

You can avoid the `universe` command by providing the universe parameters when
defining `compose`.

    
    
    def compose.{u, v, w}
                {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

Lean 4 supports a new feature called _auto bound implicit arguments_. It makes
functions such as `compose` much more convenient to write. When Lean processes
the header of a declaration, any unbound identifier is automatically added as
an implicit argument _if_ it is a single lower case or greek letter. With this
feature we can write `compose` as

    
    
    def compose (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    
    #check @compose
    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ
    

Note that Lean inferred a more general type using `Sort` instead of `Type`.

Although we love this feature and use it extensively when implementing Lean,
we realize some users may feel uncomfortable with it. Thus, you can disable it
using the command `set_option autoImplicit false`.

    
    
    set_option autoImplicit false
    /- The following definition produces `unknown identifier` errors -/
    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=
    --   g (f x)
    

## Implicit Lambdas

In Lean 3 stdlib, we find many
[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)
of the dreadful `@`+`_` idiom. It is often used when the expected type is a
function type with implicit arguments, and we have a constant (`reader_t.pure`
in the example) which also takes implicit arguments. In Lean 4, the elaborator
automatically introduces lambdas for consuming implicit arguments. We are
still exploring this feature and analyzing its impact, but the experience so
far has been very positive. Here is the example from the link above using Lean
4 implicit lambdas.

    
    
    variable (ρ : Type) (m : Type → Type) [Monad m]
    instance : Monad (ReaderT ρ m) where
      pure := ReaderT.pure
      bind := ReaderT.bind
    

Users can disable the implicit lambda feature by using `@` or writing a lambda
expression with `{}` or `[]` binder annotations. Here are few examples

    
    
    namespace ex2
    def id1 : {α : Type} → α → α :=
      fun x => x
    
    def listId : List ({α : Type} → α → α) :=
      (fun x => x) :: []
    
    -- In this example, implicit lambda introduction has been disabled because
    -- we use `@` before `fun`
    def id2 : {α : Type} → α → α :=
      @fun α (x : α) => id1 x
    
    def id3 : {α : Type} → α → α :=
      @fun α x => id1 x
    
    def id4 : {α : Type} → α → α :=
      fun x => id1 x
    
    -- In this example, implicit lambda introduction has been disabled
    -- because we used the binder annotation `{...}`
    def id5 : {α : Type} → α → α :=
      fun {α} x => id1 x
    end ex2
    

## Sugar for Simple Functions

In Lean 3, we can create simple functions from infix operators by using
parentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we
generalize this notation using `·` as a placeholder. Here are a few examples:

    
    
    namespace ex3
    #check (· + 1)
    -- fun a => a + 1
    #check (2 - ·)
    -- fun a => 2 - a
    #eval [1, 2, 3, 4, 5].foldl (·*·) 1
    -- 120
    
    def f (x y z : Nat) :=
      x + y + z
    
    #check (f · 1 ·)
    -- fun a b => f a 1 b
    
    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)
    -- [1, 3, 5]
    end ex3
    

As in Lean 3, the notation is activated using parentheses, and the lambda
abstraction is created by collecting the nested `·`s. The collection is
interrupted by nested parentheses. In the following example, two different
lambda expressions are created.

    
    
    #check (Prod.mk · (· + 1))
    -- fun a => (a, fun b => b + 1)
    

## Named Arguments

Named arguments enable you to specify an argument for a parameter by matching
the argument with its name rather than with its position in the parameter
list. If you don't remember the order of the parameters but know their names,
you can send the arguments in any order. You may also provide the value for an
implicit parameter when
2025-06-01 02:46:55,439 - DEBUG - close.started
2025-06-01 02:46:55,439 - DEBUG - close.complete
2025-06-01 02:46:55,449 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.'}], 'model': 'o3-mini'}}
2025-06-01 02:46:55,449 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:46:55,449 - DEBUG - close.started
2025-06-01 02:46:55,450 - DEBUG - close.complete
2025-06-01 02:46:55,450 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:46:55,458 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20473b8f0>
2025-06-01 02:46:55,458 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:46:55,469 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20473bf80>
2025-06-01 02:46:55,469 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:46:55,469 - DEBUG - send_request_headers.complete
2025-06-01 02:46:55,469 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:46:55,469 - DEBUG - send_request_body.complete
2025-06-01 02:46:55,469 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:47:04,651 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:47:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6898'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6912'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199547'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'135ms'), (b'x-request-id', b'req_b8e52947e9feaec58fa0c765daab5901'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6224d84a46f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:47:04,652 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:47:04,652 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:47:04,652 - DEBUG - receive_response_body.complete
2025-06-01 02:47:04,652 - DEBUG - response_closed.started
2025-06-01 02:47:04,652 - DEBUG - response_closed.complete
2025-06-01 02:47:04,652 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:47:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6898', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6912', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199547', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '135ms', 'x-request-id': 'req_b8e52947e9feaec58fa0c765daab5901', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6224d84a46f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:47:04,652 - DEBUG - request_id: req_b8e52947e9feaec58fa0c765daab5901
2025-06-01 02:47:04,653 - INFO - Attempt 1/3
2025-06-01 02:47:04,653 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that computes the minimum of three integers by comparing them pairwise using if-else constructs. The result must satisfy the properties of being less than or equal to each of the three provided inputs and be one of the inputs.",
  "steps": [
    "Define the function signature, e.g., def min3 (a b c : Int) : Int, to take three integers as arguments.",
    "Compute the minimum of the first two integers using an if-else expression: let m := if a ≤ b then a else b.",
    "Compare the intermediary result m with the third integer using another if-else expression: if m ≤ c then m else c.",
    "Ensure that the resulting integer is indeed less than or equal to a, b, and c, and matches one of them.",
    "Optionally, include comments or an explanation to make the properties of the function clear.",
    "If necessary, prepare a simple inductive proof or case analysis to show that the returned value satisfies the desired conditions."
  ],
  "code_keywords": [
    "Lean 4",
    "def",
    "if-else",
    "comparison",
    "Int",
    "function"
  ],
  "proof_keywords": [
    "case analysis",
    "inductive proof",
    "inequality",
    "property verification"
  ],
  "assumptions": [
    "The integers are of type Int in Lean 4.",
    "Comparison operations (≤, >) are correctly defined for Int.",
    "The if-else structure is sufficient to enforce that the returned value is one of the input values."
  ],
  "retry_guidance": "If errors arise, verify that the if-else conditions correctly compare the integers and that the ordering conditions (less than or equal) are appropriately used. Ensure that the function returns an input value and that there is no type mismatch in Lean 4."
}
2025-06-01 02:47:04,654 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that computes the minimum of three integers by comparing them pairwise using if-else constructs. The result must satisfy the properties of being less than or equal to each of the three provided inputs and be one of the inputs.",\n  "steps": [\n    "Define the function signature, e.g., def min3 (a b c : Int) : Int, to take three integers as arguments.",\n    "Compute the minimum of the first two integers using an if-else expression: let m := if a ≤ b then a else b.",\n    "Compare the intermediary result m with the third integer using another if-else expression: if m ≤ c then m else c.",\n    "Ensure that the resulting integer is indeed less than or equal to a, b, and c, and matches one of them.",\n    "Optionally, include comments or an explanation to make the properties of the function clear.",\n    "If necessary, prepare a simple inductive proof or case analysis to show that the returned value satisfies the desired conditions."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "def",\n    "if-else",\n    "comparison",\n    "Int",\n    "function"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "inductive proof",\n    "inequality",\n    "property verification"\n  ],\n  "assumptions": [\n    "The integers are of type Int in Lean 4.",\n    "Comparison operations (≤, >) are correctly defined for Int.",\n    "The if-else structure is sufficient to enforce that the returned value is one of the input values."\n  ],\n  "retry_guidance": "If errors arise, verify that the if-else conditions correctly compare the integers and that the ordering conditions (less than or equal) are appropriately used. Ensure that the function returns an input value and that there is no type mismatch in Lean 4."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned value is the minimum of the three input numbers\ndef minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result <= a ∧ result <= b ∧ result <= c) ∧\n  (result = a ∨ result = b ∨ result = c)\n  -- << SPEC END >>\n\ntheorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :\n  minOfThree_spec a b c (minOfThree a b c) := by\n  -- << PROOF START >>\n  unfold minOfThree minOfThree_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:47:04,655 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:47:04,655 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:47:04,656 - DEBUG - send_request_headers.complete
2025-06-01 02:47:04,656 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:47:04,661 - DEBUG - send_request_body.complete
2025-06-01 02:47:04,662 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:47:12,971 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:47:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8073'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8077'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'10735'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'38.529s'), (b'x-request-id', b'req_1f9b36fef9fce2005619602e3315bdf1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b625e4a5746f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:47:12,972 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:47:12,972 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:47:12,972 - DEBUG - receive_response_body.complete
2025-06-01 02:47:12,972 - DEBUG - response_closed.started
2025-06-01 02:47:12,972 - DEBUG - response_closed.complete
2025-06-01 02:47:12,972 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:47:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8073', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8077', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '10735', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '38.529s', 'x-request-id': 'req_1f9b36fef9fce2005619602e3315bdf1', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b625e4a5746f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:47:12,973 - DEBUG - request_id: req_1f9b36fef9fce2005619602e3315bdf1
2025-06-01 02:47:12,973 - INFO - Raw solution received: ```json
{
  "code": "
  let m := if a ≤ b then a else b
  if m ≤ c then m else c
  ",
  "proof": "
  by_cases h1 : a ≤ b
  { by_cases h2 : a ≤ c
    { simp [h1, h2], exact ⟨h2, h1, le_refl a, Or.inl rfl⟩ }
    { simp [h1, h2], exact ⟨le_trans h1 (le_of_not_le h2), le_refl b, le_of_not_le h2, Or.inr (Or.inl rfl)⟩ }
  }
  { by_cases h3 : b ≤ c
    { simp [h1, h3], exact ⟨h3, le_refl b, le_refl b, Or.inr (Or.inl rfl)⟩ }
    { simp [h1, h3], exact ⟨le_of_not_le h1, le_of_not_le h1, le_refl c, Or.inr (Or.inr rfl)⟩ }
  }
  "
}
```
2025-06-01 02:47:12,973 - INFO - <class 'str'>
2025-06-01 02:47:12,973 - ERROR - Failed to parse generated solution as JSON. Using default 'sorry' values.
2025-06-01 02:47:12,973 - ERROR - <class 'Exception'>
2025-06-01 02:47:12,973 - ERROR - Fallback Generated solution: {'code': 'sorry', 'proof': 'sorry'}
2025-06-01 02:47:18,245 - INFO - Lean execution result: Lean code executed successfully.
lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:18:8: warning: declaration uses 'sorry'
2025-06-01 02:47:18,246 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned value is the minimum of the three input numbers\ndef minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result <= a ∧ result <= b ∧ result <= c) ∧\n  (result = a ∨ result = b ∨ result = c)\n  -- << SPEC END >>\n\ntheorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :\n  minOfThree_spec a b c (minOfThree a b c) := by\n  -- << PROOF START >>\n  unfold minOfThree minOfThree_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nsorry\n\nGenerated Proof:\nsorry\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean code executed successfully.\nlean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'\nlean_playground/TempTest.lean:18:8: warning: declaration uses 'sorry'"}], 'model': 'o3-mini'}}
2025-06-01 02:47:18,246 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:47:18,246 - DEBUG - close.started
2025-06-01 02:47:18,247 - DEBUG - close.complete
2025-06-01 02:47:18,247 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:47:18,254 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204273dd0>
2025-06-01 02:47:18,254 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:47:18,270 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204272d50>
2025-06-01 02:47:18,270 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:47:18,270 - DEBUG - send_request_headers.complete
2025-06-01 02:47:18,270 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:47:18,270 - DEBUG - send_request_body.complete
2025-06-01 02:47:18,270 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:47:22,611 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:47:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4098'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4105'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199248'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'225ms'), (b'x-request-id', b'req_d86fbb6b09956f70886f13ad1be44739'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b62b3595d47bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:47:22,612 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:47:22,612 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:47:22,612 - DEBUG - receive_response_body.complete
2025-06-01 02:47:22,612 - DEBUG - response_closed.started
2025-06-01 02:47:22,612 - DEBUG - response_closed.complete
2025-06-01 02:47:22,612 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:47:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4098', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4105', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199248', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '225ms', 'x-request-id': 'req_d86fbb6b09956f70886f13ad1be44739', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b62b3595d47bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:47:22,612 - DEBUG - request_id: req_d86fbb6b09956f70886f13ad1be44739
2025-06-01 02:47:22,613 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The implementation and proof still contain 'sorry' placeholders, meaning the method for finding the minimum and its proof have not been implemented. The Lean code compiles with warnings, but the proof obligations remain unresolved.", 'error_type': 'proof', 'suggested_fix': "Replace the 'sorry' in the implementation with a correct definition of minOfThree. For example, use if-else comparisons to return the minimum of the three values. Then, replace the 'sorry' in the proof with a structured proof that unfolds the definition and uses simple case analysis or comparison tactics to verify that the result is less than or equal to a, b, and c and equal to one of them.", 'retry_strategy': "Implement the function using conditional expressions, and then prove the specification by first unfolding the definitions. Consider using tactics such as 'by_cases' for comparing integers and 'simp' to simplify inequalities."}
2025-06-01 02:47:22,613 - INFO - Solution generated in 27.89 seconds
2025-06-01 02:47:22,613 - INFO - Generated code length: 5 characters
2025-06-01 02:47:22,613 - INFO - Generated proof length: 5 characters
2025-06-01 02:47:22,613 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:47:22,613 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:47:27,822 - INFO - Implementation test result: FAIL
2025-06-01 02:47:27,822 - ERROR - Implementation error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:18:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:47:27,822 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:47:33,069 - INFO - Full solution test result: FAIL
2025-06-01 02:47:33,069 - ERROR - Proof error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:18:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:47:33,069 - ERROR - ❌ Implementation fails unit tests
2025-06-01 02:47:33,069 - ERROR - ❌ Proof has errors
2025-06-01 02:47:33,069 - INFO - 
==================================================
2025-06-01 02:47:33,069 - INFO - Processing task task_id_404...
2025-06-01 02:47:33,069 - INFO - Reading problem description and code template from tasks/task_id_404...
2025-06-01 02:47:33,069 - INFO - Problem description length: 483 characters
2025-06-01 02:47:33,069 - INFO - Reading unit tests from tasks/task_id_404...
2025-06-01 02:47:33,069 - INFO - Unit tests length: 228 characters
2025-06-01 02:47:33,069 - INFO - Running main workflow to generate solution...
2025-06-01 02:47:33,070 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.

-----Input-----
The input consists of two integers:
a: The first integer.
b: The second integer.

-----Output-----
The output is an integer:
Returns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.
2025-06-01 02:47:33,070 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def myMin (a : Int) (b : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b
def myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  (result ≤ a ∧ result ≤ b) ∧
  (result = a ∨ result = b)
  -- << SPEC END >>

theorem myMin_spec_satisfied (a : Int) (b : Int) :
  myMin_spec a b (myMin a b) := by
  -- << PROOF START >>
  unfold myMin myMin_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:47:33,098 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x74e203e82840>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:47:33,099 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:47:33,099 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:47:33,107 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e203e6dc40>
2025-06-01 02:47:33,107 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e204914950> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:47:33,116 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e203e6e780>
2025-06-01 02:47:33,116 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:47:33,116 - DEBUG - send_request_headers.complete
2025-06-01 02:47:33,116 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:47:33,116 - DEBUG - send_request_body.complete
2025-06-01 02:47:33,117 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:47:33,481 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:47:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'45'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-786c6cd5df-6x856'), (b'x-envoy-upstream-service-time', b'48'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999880'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_82ba2ed1011939d131a059fae290acee'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ul2mE_n5rh8WdTlcdXRuP7QaeW.D6r1PUMd_7D_TpGU-1748746053-1.0.1.1-96xsC7WtvEFFEHXDGhVd0mtMii.YKVHzzedzyZur89qjBEPcnFDWQ1k_D43BM3TvBX5b8u9rYmtdP1A7ofe82hPYQv04_YHkKpwejHd9x7Y; path=/; expires=Sun, 01-Jun-25 03:17:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=W9e2.lM4HPAWf0C0._IIdgrr2HcVk_l3Xjvfs_Rj4sU-1748746053501-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b631028b146f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:47:33,482 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:47:33,482 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:47:33,482 - DEBUG - receive_response_body.complete
2025-06-01 02:47:33,482 - DEBUG - response_closed.started
2025-06-01 02:47:33,482 - DEBUG - response_closed.complete
2025-06-01 02:47:33,483 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:47:33 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '45'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-786c6cd5df-6x856'), ('x-envoy-upstream-service-time', '48'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999880'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '7ms'), ('x-request-id', 'req_82ba2ed1011939d131a059fae290acee'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=ul2mE_n5rh8WdTlcdXRuP7QaeW.D6r1PUMd_7D_TpGU-1748746053-1.0.1.1-96xsC7WtvEFFEHXDGhVd0mtMii.YKVHzzedzyZur89qjBEPcnFDWQ1k_D43BM3TvBX5b8u9rYmtdP1A7ofe82hPYQv04_YHkKpwejHd9x7Y; path=/; expires=Sun, 01-Jun-25 03:17:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=W9e2.lM4HPAWf0C0._IIdgrr2HcVk_l3Xjvfs_Rj4sU-1748746053501-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b631028b146f0-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:47:33,483 - DEBUG - request_id: req_82ba2ed1011939d131a059fae290acee
2025-06-01 02:47:33,488 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Interacting with Lean

You are now familiar with the fundamentals of dependent type theory, both as a
language for defining mathematical objects and a language for constructing
proofs. The one thing you are missing is a mechanism for defining new data
types. We will fill this gap in the next chapter, which introduces the notion
of an _inductive data type_. But first, in this chapter, we take a break from
the mechanics of type theory to explore some pragmatic aspects of interacting
with Lean.

Not all of the information found here will be useful to you right away. We
recommend skimming this section to get a sense of Lean's features, and then
returning to it as necessary.

## Importing Files

The goal of Lean's front end is to interpret user input, construct formal
expressions, and check that they are well-formed and type-correct. Lean also
supports the use of various editors, which provide continuous checking and
feedback. More information can be found on the Lean [documentation
pages](https://lean-lang.org/documentation/).

The definitions and theorems in Lean's standard library are spread across
multiple files. Users may also wish to make use of additional libraries, or
develop their own projects across multiple files. When Lean starts, it
automatically imports the contents of the library `Init` folder, which
includes a number of fundamental definitions and constructions. As a result,
most of the examples we present here work "out of the box."

If you want to use additional files, however, they need to be imported
manually, via an `import` statement at the beginning of a file. The command

    
    
    import Bar.Baz.Blah
    

imports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted
relative to the Lean _search path_. Information as to how the search path is
determined can be found on the [documentation pages](https://lean-
lang.org/documentation/). By default, it includes the standard library
directory, and (in some contexts) the root of the user's local project.

Importing is transitive. In other words, if you import `Foo` and `Foo` imports
`Bar`, then you also have access to the contents of `Bar`, and do not need to
import it explicitly.

## More on Sections

Lean provides various sectioning mechanisms to help structure a theory. You
saw in [Variables and Sections](./dependent_type_theory.html#variables-and-
sections) that the `section` command makes it possible not only to group
together elements of a theory that go together, but also to declare variables
that are inserted as arguments to theorems and definitions, as necessary.
Remember that the point of the `variable` command is to declare variables for
use in theorems, as in the following example:

    
    
    section
    variable (x y : Nat)
    
    def double := x + x
    
    #check double y
    #check double (2 * x)
    
    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm
    
    theorem t1 : double (x + y) = double x + double y := by
      simp [double]
    
    #check t1 y
    #check t1 (2 * x)
    
    theorem t2 : double (x * y) = double x * y := by
      simp [double, Nat.add_mul]
    
    end
    

The definition of `double` does not have to declare `x` as an argument; Lean
detects the dependence and inserts it automatically. Similarly, Lean detects
the occurrence of `x` in `t1` and `t2`, and inserts it automatically there,
too. Note that `double` does _not_ have `y` as argument. Variables are only
included in declarations where they are actually used.

## More on Namespaces

In Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We
saw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean
provides mechanisms for working with hierarchical names. The command
`namespace foo` causes `foo` to be prepended to the name of each definition
and theorem until `end foo` is encountered. The command `open foo` then
creates temporary _aliases_ to definitions and theorems that begin with prefix
`foo`.

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    
    open Foo
    
    #check bar
    #check Foo.bar
    

The following definition

    
    
    def Foo.bar : Nat := 1
    

is treated as a macro, and expands to

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    

Although the names of theorems and definitions have to be unique, the aliases
that identify them do not. When we open a namespace, an identifier may be
ambiguous. Lean tries to use type information to disambiguate the meaning in
context, but you can always disambiguate by giving the full name. To that end,
the string `_root_` is an explicit description of the empty prefix.

    
    
    def String.add (a b : String) : String :=
      a ++ b
    
    def Bool.add (a b : Bool) : Bool :=
      a != b
    
    def add (α β : Type) : Type := Sum α β
    
    open Bool
    open String
    -- #check add -- ambiguous
    #check String.add           -- String → String → String
    #check Bool.add             -- Bool → Bool → Bool
    #check _root_.add           -- Type → Type → Type
    
    #check add "hello" "world"  -- String
    #check add true false       -- Bool
    #check add Nat Nat          -- Type
    

We can prevent the shorter alias from being created by using the `protected`
keyword:

    
    
    protected def Foo.bar : Nat := 1
    
    open Foo
    
    -- #check bar -- error
    #check Foo.bar
    

This is often used for names like `Nat.rec` and `Nat.recOn`, to prevent
overloading of common names.

The `open` command admits variations. The command

    
    
    open Nat (succ zero gcd)
    #check zero     -- Nat
    #eval gcd 15 6  -- 3
    

creates aliases for only the identifiers listed. The command

    
    
    open Nat hiding succ gcd
    #check zero     -- Nat
    -- #eval gcd 15 6  -- error
    #eval Nat.gcd 15 6  -- 3
    

creates aliases for everything in the `Nat` namespace _except_ the identifiers
listed.

    
    
    open Nat renaming mul → times, add → plus
    #eval plus (times 2 2) 3  -- 7
    

creates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.

It is sometimes useful to `export` aliases from one namespace to another, or
to the top level. The command

    
    
    export Nat (succ add sub)
    

creates aliases for `succ`, `add`, and `sub` in the current namespace, so that
whenever the namespace is open, these aliases are available. If this command
is used outside a namespace, the aliases are exported to the top level.

## Attributes

The main function of Lean is to translate user input to formal expressions
that are checked by the kernel for correctness and then stored in the
environment for later use. But some commands have other effects on the
environment, either assigning attributes to objects in the environment,
defining notation, or declaring instances of type classes, as described in
[Chapter Type Classes](./type_classes.html). Most of these commands have
global effects, which is to say, they remain in effect not only in the current
file, but also in any file that imports it. However, such commands often
support the `local` modifier, which indicates that they only have effect until
the current `section` or `namespace` is closed, or until the end of the
current file.

In [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw
that theorems can be annotated with the `[simp]` attribute, which makes them
available for use by the simplifier. The following example defines the prefix
relation on lists, proves that this relation is reflexive, and assigns the
`[simp]` attribute to that theorem.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    

The simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to
`True`.

One can also assign the attribute any time after the definition takes place:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [simp] List.isPrefix_self
    

In all these cases, the attribute remains in effect in any file that imports
the one in which the declaration occurs. Adding the `local` modifier restricts
the scope:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    section
    
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [local simp] List.isPrefix_self
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    
    end
    
    -- Error:
    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by
    --  simp
    

For another example, we can use the `instance` command to assign the notation
`≤` to the `isPrefix` relation. That command, which will be explained in
[Chapter Type Classes](./type_classes.html), works by assigning an
`[instance]` attribute to the associated definition.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    instance : LE (List α) where
      le := isPrefix
    
    theorem List.isPrefix_self (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    

That assignment can also be made local:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    def instLe : LE (List α) :=
      { le := isPrefix }
    
    section
    attribute [local instance] instLe
    
    example (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    
    end
    
    -- Error:
    -- example (as : List α) : as ≤ as :=
    --  ⟨[], by simp⟩
    

In Section Notation below, we will discuss Lean's mechanisms for defining
notation, and see that they also support the `local` modifier. However, in
Section Setting Options, we will discuss Lean's mechanisms for setting
options, which does _not_ follow this pattern: options can _only_ be set
locally, which is to say, their scope is always restricted to the current
section or current file.

## More on Implicit Arguments

In [Section Implicit Arguments](./dependent_type_theory.html#implicit-
arguments), we saw that if Lean displays the type of a term `t` as `{x : α} →
β x`, then the curly brackets indicate that `x` has been marked as an
_implicit argument_ to `t`. This means that whenever you write `t`, a
placeholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you
don't want that to happen, you have to write `@t` instead.

Notice that implicit arguments are inserted eagerly. Suppose we define a
function `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,
when we write the expression `f 7` without further arguments, it is parsed as
`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that
a placeholder should only be added _before_ a subsequent explicit argument.
This annotation can also be written using as `⦃y : Nat⦄`, where the unicode
brackets are entered as `\{{` and `\}}`, respectively. With this annotation,
the expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as
`f 7 _ 3`, just as it would be with the strong annotation.

To illustrate the difference, consider the following example, which shows that
a reflexive euclidean relation is both symmetric and transitive.

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b : α}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
     th2 (th1 reflr @euclr) @euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3
    

The results are broken down into small steps: `th1` shows that a relation that
is reflexive and euclidean is symmetric, and `th2` shows that a relation that
is symmetric and euclidean is transitive. Then `th3` combines the two results.
But notice that we have to manually disable the implicit arguments in `euclr`,
because otherwise too many implicit arguments are inserted. The problem goes
away if we use weak implicit arguments:

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b : α}}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
      th2 (th1 reflr euclr) euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- euclidean r
    

There is a third kind of implicit argument that is denoted with square
brackets, `[` and `]`. These are used for type classes, as explained in
[Chapter Type Classes](./type_classes.html).

## Notation

Identifiers in Lean can include any alphanumeric characters, including Greek
characters (other than ∀ , Σ , and λ , which, as we have seen, have a special
meaning in the dependent type theory). They can also include subscripts, which
can be entered by typing `\_` followed by the desired subscripted character.

Lean's parser is extensible, which is to say, we can define new notation.

Lean's syntax can be extended and customized by users at every level, ranging
from basic "mixfix" notations to custom elaborators. In fact, all builtin
syntax is parsed and processed using the same mechanisms and APIs open to
users. In this section, we will describe and explain the various extension
points.

While introducing new notations is a relatively rare feature in programming
languages and sometimes even frowned upon because of its potential to obscure
code, it is an invaluable tool in formalization for expressing established
conventions and notations of the respective field succinctly in code. Going
beyond basic notations, Lean's ability to factor out common boilerplate code
into (well-behaved) macros and to embed entire custom domain specific
languages (DSLs) to textually encode subproblems efficiently and readably can
be of great benefit to both programmers and proof engineers alike.

### Notations and Precedence

The most basic syntax extension commands allow introducing new (or overloading
existing) prefix, infix, and postfix operators.

    
    
    infixl:65   " + " => HAdd.hAdd  -- left-associative
    infix:50    " = " => Eq         -- non-associative
    infixr:80   " ^ " => HPow.hPow  -- right-associative
    prefix:100  "-"   => Neg.neg
    set_option quotPrecheck false
    postfix:max "⁻¹"  => Inv.inv
    

After the initial command name describing the operator kind (its "fixity"), we
give the _parsing precedence_ of the operator preceded by a colon `:`, then a
new or existing token surrounded by double quotes (the whitespace is used for
pretty printing), then the function this operator should be translated to
after the arrow `=>`.

The precedence is a natural number describing how "tightly" an operator binds
to its arguments, encoding the order of operations. We can make this more
precise by looking at the commands the above unfold to:

    
    
    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs
    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs
    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs
    notation:100 "-" arg:100 => Neg.neg arg
    set_option quotPrecheck false
    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024
    

It turns out that all commands from the first code block are in fact command
_macros_ translating to the more general `notation` command. We will learn
about writing such macros below. Instead of a single token, the `notation`
command accepts a mixed sequence of tokens and named term placeholders with
precedences, which can be referenced on the right-hand side of `=>` and will
be replaced by the respective term parsed at that position. A placeholder with
precedence `p` accepts only notations with precedence at least `p` in that
place. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +
(b + c)` because the right-hand side operand of an `infixl` notation has
precedence one greater than the notation itself. In contrast, `infixr` reuses
the notation's precedence for the right-hand side operand, so `a ^ b ^ c`
_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to
introduce an infix notation like

    
    
    set_option quotPrecheck false
    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs
    

where the precedences do not sufficiently determine associativity, Lean's
parser will default to right associativity. More precisely, Lean's parser
follows a local _longest parse_ rule in the presence of ambiguous grammars:
when parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue
parsing as long as possible (as the current precedence allows), not stopping
after `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~
c)`.

As mentioned above, the `notation` command allows us to define arbitrary
_mixfix_ syntax freely mixing tokens and placeholders.

    
    
    set_option quotPrecheck false
    notation:max "(" e ")" => e
    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ
    

Placeholders without precedence default to `0`, i.e. they accept notations of
any precedence in their place. If two notations overlap, we again apply the
longest parse rule:

    
    
    notation:65 a " + " b:66 " + " c:66 => a + b - c
    #eval 1 + 2 + 3  -- 0
    

The new notation is preferred to the binary notation since the latter, before
chaining, would stop parsing after `1 + 2`. If there are multiple notations
accepting the same longest parse, the choice will be delayed until
elaboration, which will fail unless exactly one overload is type-correct.

## Coercions

In Lean, the type of natural numbers, `Nat`, is different from the type of
integers, `Int`. But there is a function `Int.ofNat` that embeds the natural
numbers in the integers, meaning that we can view any natural number as an
integer, when needed. Lean has mechanisms to detect and insert _coercions_ of
this sort.

    
    
    variable (m n : Nat)
    variable (i j : Int)
    
    #check i + m      -- i + Int.ofNat m : Int
    #check i + m + j  -- i + Int.ofNat m + j : Int
    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int
    

## Displaying Information

There are a number of ways in which you can query Lean for information about
its current state and the objects and theorems that are available in the
current context. You have already seen two of the most common ones, `#check`
and `#eval`. Remember that `#check` is often used in conjunction with the `@`
operator, which makes all of the arguments to a theorem or definition
explicit. In addition, you can use the `#print` command to get information
about any identifier. If the identifier denotes a definition or theorem, Lean
prints the type of the symbol, and its definition. If it is a constant or an
axiom, Lean indicates that fact, and shows the type.

    
    
    -- examples with equality
    #check Eq
    #check @Eq
    #check Eq.symm
    #check @Eq.symm
    
    #print Eq.symm
    
    -- examples with And
    #check And
    #check And.intro
    #check @And.intro
    
    -- a user-defined function
    def foo {α : Type u} (x : α) : α := x
    
    #check foo
    #check @foo
    #print foo
    

## Setting Options

Lean maintains a number of internal variables that can be set by users to
control its behavior. The syntax for doing so is as follows:

    
    
    set_option <name> <value>
    

One very useful family of options controls the way Lean's _pretty- printer_
displays terms. The following options take an input of true or false:

    
    
    pp.explicit  : display implicit arguments
    pp.universes : display hidden universe parameters
    pp.notation  : display output using defined notations
    

As an example, the following settings yield much longer output:

    
    
    set_option pp.explicit true
    set_option pp.universes true
    set_option pp.notation false
    
    #check 2 + 2 = 4
    #reduce (fun x => x + 2) = (fun x => x + 3)
    #check (fun x => x + 1) 1
    

The command `set_option pp.all true` carries out these settings all at once,
whereas `set_option pp.all false` reverts to the previous values. Pretty
printing additional information is often very useful when you are debugging a
proof, or trying to understand a cryptic error message. Too much information
can be overwhelming, though, and Lean's defaults are generally sufficient for
ordinary interactions.

## Using the Library

To use Lean effectively you will inevitably need to make use of definitions
and theorems in the library. Recall that the `import` command at the beginning
of a file imports previously compiled results from other files, and that
importing is transitive; if you import `Foo` and `Foo` imports `Bar`, then the
definitions and theorems from `Bar` are available to you as well. But the act
of opening a namespace, which provides shorter names, does not carry over. In
each file, you need to open the namespaces you wish to use.

In general, it is important for you to be familiar with the library and its
contents, so you know what theorems, definitions, notations, and resources are
available to you. Below we will see that Lean's editor modes can also help you
find things you need, but studying the contents of the library directly is
often unavoidable. Lean's standard library can be found online, on GitHub:

  * <https://github.com/leanprover/lean4/tree/master/src/Init>

  * <https://github.com/leanprover/std4/tree/main/Std>

You can see the contents of these directories and files using GitHub's browser
interface. If you have installed Lean on your own computer, you can find the
library in the `lean` folder, and explore it with your file manager. Comment
headers at the top of each file provide additional information.

Lean's library developers follow general naming guidelines to make it easier
to guess the name of a theorem you need, or to find it using tab completion in
editors with a Lean mode that supports this, which is discussed in the next
section. Identifiers are generally `camelCase`, and types are `CamelCase`. For
theorem names, we rely on descriptive names where the different components are
separated by `_`s. Often the name of theorem simply describes the conclusion:

    
    
    #check Nat.succ_ne_zero
    #check Nat.zero_add
    #check Nat.mul_one
    #check Nat.le_of_succ_le_succ
    

Remember that identifiers in Lean can be organized into hierarchical
namespaces. For example, the theorem named `le_of_succ_le_succ` in the
namespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name
is made available by the command `open Nat` (for names not marked as
`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)
and [Chapter Structures and Records](./structures_and_records.html) that
defining structures and inductive data types in Lean generates associated
operations, and these are stored in a namespace with the same name as the type
under definition. For example, the product type comes with the following
operations:

    
    
    #check @Prod.mk
    #check @Prod.fst
    #check @Prod.snd
    #check @Prod.rec
    

The first is used to construct a pair, whereas the next two, `Prod.fst` and
`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another
mechanism for defining functions on a product in terms of a function on the
two components. Names like `Prod.rec` are _protected_ , which means that one
has to use the full name even when the `Prod` namespace is open.

With the propositions as types correspondence, logical connectives are also
instances of inductive types, and so we tend to use dot notation for them as
well:

    
    
    #check @And.intro
    #check @And.casesOn
    #check @And.left
    #check @And.right
    #check @Or.inl
    #check @Or.inr
    #check @Or.elim
    #check @Exists.intro
    #check @Exists.elim
    #check @Eq.refl
    #check @Eq.subst
    

## Auto Bound Implicit Arguments

In the previous section, we have shown how implicit arguments make functions
more convenient to use. However, functions such as `compose` are still quite
verbose to define. Note that the universe polymorphic `compose` is even more
verbose than the one previously defined.

    
    
    universe u v w
    def compose {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

You can avoid the `universe` command by providing the universe parameters when
defining `compose`.

    
    
    def compose.{u, v, w}
                {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

Lean 4 supports a new feature called _auto bound implicit arguments_. It makes
functions such as `compose` much more convenient to write. When Lean processes
the header of a declaration, any unbound identifier is automatically added as
an implicit argument _if_ it is a single lower case or greek letter. With this
feature we can write `compose` as

    
    
    def compose (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    
    #check @compose
    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ
    

Note that Lean inferred a more general type using `Sort` instead of `Type`.

Although we love this feature and use it extensively when implementing Lean,
we realize some users may feel uncomfortable with it. Thus, you can disable it
using the command `set_option autoImplicit false`.

    
    
    set_option autoImplicit false
    /- The following definition produces `unknown identifier` errors -/
    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=
    --   g (f x)
    

## Implicit Lambdas

In Lean 3 stdlib, we find many
[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)
of the dreadful `@`+`_` idiom. It is often used when the expected type is a
function type with implicit arguments, and we have a constant (`reader_t.pure`
in the example) which also takes implicit arguments. In Lean 4, the elaborator
automatically introduces lambdas for consuming implicit arguments. We are
still exploring this feature and analyzing its impact, but the experience so
far has been very positive. Here is the example from the link above using Lean
4 implicit lambdas.

    
    
    variable (ρ : Type) (m : Type → Type) [Monad m]
    instance : Monad (ReaderT ρ m) where
      pure := ReaderT.pure
      bind := ReaderT.bind
    

Users can disable the implicit lambda feature by using `@` or writing a lambda
expression with `{}` or `[]` binder annotations. Here are few examples

    
    
    namespace ex2
    def id1 : {α : Type} → α → α :=
      fun x => x
    
    def listId : List ({α : Type} → α → α) :=
      (fun x => x) :: []
    
    -- In this example, implicit lambda introduction has been disabled because
    -- we use `@` before `fun`
    def id2 : {α : Type} → α → α :=
      @fun α (x : α) => id1 x
    
    def id3 : {α : Type} → α → α :=
      @fun α x => id1 x
    
    def id4 : {α : Type} → α → α :=
      fun x => id1 x
    
    -- In this example, implicit lambda introduction has been disabled
    -- because we used the binder annotation `{...}`
    def id5 : {α : Type} → α → α :=
      fun {α} x => id1 x
    end ex2
    

## Sugar for Simple Functions

In Lean 3, we can create simple functions from infix operators by using
parentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we
generalize this notation using `·` as a placeholder. Here are a few examples:

    
    
    namespace ex3
    #check (· + 1)
    -- fun a => a + 1
    #check (2 - ·)
    -- fun a => 2 - a
    #eval [1, 2, 3, 4, 5].foldl (·*·) 1
    -- 120
    
    def f (x y z : Nat) :=
      x + y + z
    
    #check (f · 1 ·)
    -- fun a b => f a 1 b
    
    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)
    -- [1, 3, 5]
    end ex3
    

As in Lean 3, the notation is activated using parentheses, and the lambda
abstraction is created by collecting the nested `·`s. The collection is
interrupted by nested parentheses. In the following example, two different
lambda expressions are created.

    
    
    #check (Prod.mk · (· + 1))
    -- fun a => (a, fun b => b + 1)
    

## Named Arguments

Named arguments enable you to specify an argument for a parameter by matching
the argument with its name rather than with its position in the parameter
list. If you don't remember the order of the parameters but know their names,
you can send the arguments in any order. You may also provide the value for an
implicit parameter when
2025-06-01 02:47:33,491 - DEBUG - close.started
2025-06-01 02:47:33,491 - DEBUG - close.complete
2025-06-01 02:47:33,502 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.'}], 'model': 'o3-mini'}}
2025-06-01 02:47:33,503 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:47:33,503 - DEBUG - close.started
2025-06-01 02:47:33,503 - DEBUG - close.complete
2025-06-01 02:47:33,503 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:47:33,510 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e2042708f0>
2025-06-01 02:47:33,510 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:47:33,518 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e203e6e5a0>
2025-06-01 02:47:33,518 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:47:33,518 - DEBUG - send_request_headers.complete
2025-06-01 02:47:33,518 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:47:33,518 - DEBUG - send_request_body.complete
2025-06-01 02:47:33,518 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:47:40,091 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:47:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6345'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6348'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199578'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'126ms'), (b'x-request-id', b'req_80fcc2cc38f7e7cdf3b07f9dac761f25'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6312a9383deb-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:47:40,092 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:47:40,092 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:47:40,092 - DEBUG - receive_response_body.complete
2025-06-01 02:47:40,092 - DEBUG - response_closed.started
2025-06-01 02:47:40,092 - DEBUG - response_closed.complete
2025-06-01 02:47:40,092 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:47:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6345', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6348', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199578', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '126ms', 'x-request-id': 'req_80fcc2cc38f7e7cdf3b07f9dac761f25', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6312a9383deb-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:47:40,092 - DEBUG - request_id: req_80fcc2cc38f7e7cdf3b07f9dac761f25
2025-06-01 02:47:40,093 - INFO - Attempt 1/3
2025-06-01 02:47:40,093 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that takes two integers and returns the smaller one using a conditional (if-then-else) construct. Optionally, prove that the returned value is less than or equal to both inputs.",
  "steps": [
    "Define the function signature that accepts two integers (a and b) and returns an integer.",
    "Implement the function using if-then-else: check if a <= b. If true, return a; otherwise, return b.",
    "Optionally, add a proof or lemma that establishes that the output of the function is less than or equal to both a and b.",
    "Test the function conceptually with different cases (a < b, a > b, and a = b) to ensure correctness."
  ],
  "code_keywords": [
    "Lean 4",
    "if-then-else",
    "function definition",
    "integer comparison"
  ],
  "proof_keywords": [
    "case analysis",
    "inequalities",
    "min property",
    "proof by cases"
  ],
  "assumptions": [
    "Standard Lean 4 integer type is used.",
    "The basic comparison operators (<=, etc.) are available.",
    "The environment supports conditional expressions."
  ],
  "retry_guidance": "If errors occur, check type consistency in the if-then-else branches and verify that the correct integer comparison operations are used. Also, ensure that the proofs properly handle all cases (a <= b and a > b)."
}
2025-06-01 02:47:40,094 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that takes two integers and returns the smaller one using a conditional (if-then-else) construct. Optionally, prove that the returned value is less than or equal to both inputs.",\n  "steps": [\n    "Define the function signature that accepts two integers (a and b) and returns an integer.",\n    "Implement the function using if-then-else: check if a <= b. If true, return a; otherwise, return b.",\n    "Optionally, add a proof or lemma that establishes that the output of the function is less than or equal to both a and b.",\n    "Test the function conceptually with different cases (a < b, a > b, and a = b) to ensure correctness."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "if-then-else",\n    "function definition",\n    "integer comparison"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "inequalities",\n    "min property",\n    "proof by cases"\n  ],\n  "assumptions": [\n    "Standard Lean 4 integer type is used.",\n    "The basic comparison operators (<=, etc.) are available.",\n    "The environment supports conditional expressions."\n  ],\n  "retry_guidance": "If errors occur, check type consistency in the if-then-else branches and verify that the correct integer comparison operations are used. Also, ensure that the proofs properly handle all cases (a <= b and a > b)."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef myMin (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b\ndef myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result ≤ a ∧ result ≤ b) ∧\n  (result = a ∨ result = b)\n  -- << SPEC END >>\n\ntheorem myMin_spec_satisfied (a : Int) (b : Int) :\n  myMin_spec a b (myMin a b) := by\n  -- << PROOF START >>\n  unfold myMin myMin_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:47:40,095 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:47:40,095 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:47:40,096 - DEBUG - send_request_headers.complete
2025-06-01 02:47:40,096 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:47:40,100 - DEBUG - send_request_body.complete
2025-06-01 02:47:40,100 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:47:43,522 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:47:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'3155'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'3162'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'8475'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'43.049s'), (b'x-request-id', b'req_fbfaf0e7a47214996dbebe7e85eb988e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b633bcc123deb-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:47:43,522 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:47:43,523 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:47:43,565 - DEBUG - receive_response_body.complete
2025-06-01 02:47:43,565 - DEBUG - response_closed.started
2025-06-01 02:47:43,565 - DEBUG - response_closed.complete
2025-06-01 02:47:43,565 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:47:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '3155', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '3162', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '8475', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '43.049s', 'x-request-id': 'req_fbfaf0e7a47214996dbebe7e85eb988e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b633bcc123deb-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:47:43,565 - DEBUG - request_id: req_fbfaf0e7a47214996dbebe7e85eb988e
2025-06-01 02:47:43,566 - INFO - Raw solution received: ```json
{
  "code": "if a <= b then a else b",
  "proof": "by_cases h : a <= b\n  simp [h]\n  intro; exact ⟨trivial, le_of_not_le h⟩\nby_cases h : a > b\n  simp [h]\n  intro; exact ⟨le_of_not_le h, trivial⟩"
}
```
2025-06-01 02:47:43,566 - INFO - <class 'str'>
2025-06-01 02:47:43,566 - INFO - Generated solution: {'code': 'if a <= b then a else b', 'proof': 'by_cases h : a <= b\n  simp [h]\n  intro; exact ⟨trivial, le_of_not_le h⟩\nby_cases h : a > b\n  simp [h]\n  intro; exact ⟨le_of_not_le h, trivial⟩'}
2025-06-01 02:47:48,845 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:24:2: error: tactic 'introN' failed, insufficient number of binders
case neg
a b : ℤ
h : ¬a ≤ b
⊢ ((if a ≤ b then a else b) ≤ a ∧ (if a ≤ b then a else b) ≤ b) ∧
    ((if a ≤ b then a else b) = a ∨ (if a ≤ b then a else b) = b)
lean_playground/TempTest.lean:25:0: error: unexpected identifier; expected command
2025-06-01 02:47:48,846 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef myMin (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b\ndef myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result ≤ a ∧ result ≤ b) ∧\n  (result = a ∨ result = b)\n  -- << SPEC END >>\n\ntheorem myMin_spec_satisfied (a : Int) (b : Int) :\n  myMin_spec a b (myMin a b) := by\n  -- << PROOF START >>\n  unfold myMin myMin_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a <= b then a else b\n\nGenerated Proof:\nby_cases h : a <= b\n  simp [h]\n  intro; exact ⟨trivial, le_of_not_le h⟩\nby_cases h : a > b\n  simp [h]\n  intro; exact ⟨le_of_not_le h, trivial⟩\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:24:2: error: tactic 'introN' failed, insufficient number of binders\ncase neg\na b : ℤ\nh : ¬a ≤ b\n⊢ ((if a ≤ b then a else b) ≤ a ∧ (if a ≤ b then a else b) ≤ b) ∧\n    ((if a ≤ b then a else b) = a ∨ (if a ≤ b then a else b) = b)\nlean_playground/TempTest.lean:25:0: error: unexpected identifier; expected command"}], 'model': 'o3-mini'}}
2025-06-01 02:47:48,846 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:47:48,846 - DEBUG - close.started
2025-06-01 02:47:48,847 - DEBUG - close.complete
2025-06-01 02:47:48,847 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:47:48,855 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e2042935c0>
2025-06-01 02:47:48,855 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:47:48,864 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204290ec0>
2025-06-01 02:47:48,864 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:47:48,864 - DEBUG - send_request_headers.complete
2025-06-01 02:47:48,864 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:47:48,864 - DEBUG - send_request_body.complete
2025-06-01 02:47:48,864 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:48:01,627 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:48:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'12532'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'12537'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199207'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'237ms'), (b'x-request-id', b'req_d4a20634bcb7546333d28db3c14d90b0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b63729ba14436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:48:01,627 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:48:01,627 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:48:01,628 - DEBUG - receive_response_body.complete
2025-06-01 02:48:01,628 - DEBUG - response_closed.started
2025-06-01 02:48:01,628 - DEBUG - response_closed.complete
2025-06-01 02:48:01,628 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:48:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '12532', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '12537', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199207', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '237ms', 'x-request-id': 'req_d4a20634bcb7546333d28db3c14d90b0', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b63729ba14436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:48:01,628 - DEBUG - request_id: req_d4a20634bcb7546333d28db3c14d90b0
2025-06-01 02:48:01,628 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof is using an 'intro' tactic incorrectly, leading to a failure with 'tactic 'introN' failed, insufficient number of binders' and an unexpected identifier error. The structure of the proof is off: after doing by_cases on (a ≤ b), the 'intro' tactic is not needed since the goal is not a function type, and splitting the conjunction and disjunction can be done directly with tactics like 'split' and 'exact'.", 'error_type': 'proof', 'suggested_fix': "Rewrite the proof to perform case analysis on (a ≤ b) without using 'intro'. For example, first simplify the definitions using 'dsimp [myMin, myMin_spec]', then use 'by_cases' to split the proof into two cases. In the case where a ≤ b, note that myMin a b reduces to a, so provide the proof using 'split' yielding (a ≤ a ∧ a ≤ b) and (a = a ∨ a = b). In the other case (i.e., ¬ a ≤ b), myMin reduces to b, and the proof should show (b ≤ a ∧ b ≤ b) and (b = a ∨ b = b). You can use 'split' and 'exact' without extraneous 'intro' calls. A corrected proof might look like:\n\n  theorem myMin_spec_satisfied (a : Int) (b : Int) : myMin_spec a b (myMin a b) := by\n    dsimp [myMin, myMin_spec]\n    by_cases h : a ≤ b\n    { -- Case: a ≤ b, so myMin = a\n      simp [h]\n      split\n      { exact ⟨le_refl a, h⟩ }\n      { left, rfl }\n    }\n    { -- Case: ¬ a ≤ b, so a > b and myMin = b\n      simp [h]\n      split\n      { exact ⟨le_of_lt (lt_of_not_ge h), le_refl b⟩ }\n      { right, rfl }\n    }\n\nThis revised proof avoids the use of 'intro' where it’s not needed and explicitly splits the goals according to the structure of the specification.", 'retry_strategy': "Revise the proof by removing the unnecessary 'intro' tactics and instead use 'dsimp', 'by_cases', 'split', and 'exact' to handle both cases separately. Test the proof with Lean to ensure no compilation errors."}
2025-06-01 02:48:01,629 - INFO - Solution generated in 28.56 seconds
2025-06-01 02:48:01,629 - INFO - Generated code length: 23 characters
2025-06-01 02:48:01,629 - INFO - Generated proof length: 142 characters
2025-06-01 02:48:01,629 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:48:01,629 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:48:06,921 - INFO - Implementation test result: PASS
2025-06-01 02:48:06,921 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:48:12,136 - INFO - Full solution test result: FAIL
2025-06-01 02:48:12,136 - ERROR - Proof error: lean_playground/TempTest.lean:24:2: error: tactic 'introN' failed, insufficient number of binders
case neg
a b : ℤ
h : ¬a ≤ b
⊢ ((if a ≤ b then a else...
2025-06-01 02:48:12,136 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:48:12,137 - ERROR - ❌ Proof has errors
2025-06-01 02:48:12,137 - INFO - 
==================================================
2025-06-01 02:48:12,137 - INFO - Processing task task_id_431...
2025-06-01 02:48:12,137 - INFO - Reading problem description and code template from tasks/task_id_431...
2025-06-01 02:48:12,137 - INFO - Problem description length: 597 characters
2025-06-01 02:48:12,137 - INFO - Reading unit tests from tasks/task_id_431...
2025-06-01 02:48:12,137 - INFO - Unit tests length: 465 characters
2025-06-01 02:48:12,137 - INFO - Running main workflow to generate solution...
2025-06-01 02:48:12,137 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.

-----Input-----
The input consists of:
a: An array of integers.
b: An array of integers.

-----Output-----
The output is a Boolean value:
Returns true if there is at least one common element between the two arrays.
Returns false if there are no common elements shared by the arrays or at least one array is empty.
2025-06-01 02:48:12,137 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def hasCommonElement (a : Array Int) (b : Array Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: If the method returns true, there exists at least one common element between the two arrays; If the method returns false, there are no common elements between the two arrays
def hasCommonElement_spec (a : Array Int) (b : Array Int) (result : Bool) : Prop :=
  -- << SPEC START >>
  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ result
  -- << SPEC END >>

theorem hasCommonElement_spec_satisfied (a : Array Int) (b : Array Int) :
  hasCommonElement_spec a b (hasCommonElement a b) := by
  -- << PROOF START >>
  unfold hasCommonElement hasCommonElement_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:48:12,165 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x74e203e827a0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:48:12,165 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:48:12,166 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:48:12,176 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20429d430>
2025-06-01 02:48:12,176 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e204266450> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:48:12,187 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20429d4c0>
2025-06-01 02:48:12,187 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:48:12,187 - DEBUG - send_request_headers.complete
2025-06-01 02:48:12,187 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:48:12,187 - DEBUG - send_request_body.complete
2025-06-01 02:48:12,187 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:48:12,487 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:48:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'56'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7fbbd4cf65-wsxl2'), (b'x-envoy-upstream-service-time', b'59'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999851'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_d186727c7aeb6ba1fc446f9029f38c3d'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mUjHBFuPtjC2s8WaH8pxY_8c5atuwUUnk5m9YmKE.P4-1748746092-1.0.1.1-60ipNC_WipxWRYlPrReu3mUdmxIXKJKegTkbPmNto6weU.dOsxm32pf0esNsTjt1MtT27TBgZI2mZhYF71Ite9UAz2f2fOB2YVUBEnJg4vs; path=/; expires=Sun, 01-Jun-25 03:18:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=5RPkKbGLENhXatMU5Y7ItIjVhyI_ewpvXN2g0G4QrVw-1748746092507-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6404595946f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:48:12,488 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:48:12,488 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:48:12,488 - DEBUG - receive_response_body.complete
2025-06-01 02:48:12,488 - DEBUG - response_closed.started
2025-06-01 02:48:12,488 - DEBUG - response_closed.complete
2025-06-01 02:48:12,488 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:48:12 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '56'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-7fbbd4cf65-wsxl2'), ('x-envoy-upstream-service-time', '59'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999851'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_d186727c7aeb6ba1fc446f9029f38c3d'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=mUjHBFuPtjC2s8WaH8pxY_8c5atuwUUnk5m9YmKE.P4-1748746092-1.0.1.1-60ipNC_WipxWRYlPrReu3mUdmxIXKJKegTkbPmNto6weU.dOsxm32pf0esNsTjt1MtT27TBgZI2mZhYF71Ite9UAz2f2fOB2YVUBEnJg4vs; path=/; expires=Sun, 01-Jun-25 03:18:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=5RPkKbGLENhXatMU5Y7ItIjVhyI_ewpvXN2g0G4QrVw-1748746092507-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b6404595946f0-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:48:12,489 - DEBUG - request_id: req_d186727c7aeb6ba1fc446f9029f38c3d
2025-06-01 02:48:12,493 - INFO - Retrieved context:  the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Propositions and Proofs

By now, you have seen some ways of defining objects and functions in Lean. In
this chapter, we will begin to explain how to write mathematical assertions
and proofs in the language of dependent type theory as well.

## Propositions as Types

One strategy for proving assertions about objects defined in the language of
dependent type theory is to layer an assertion language and a proof language
on top of the definition language. But there is no reason to multiply
languages in this way: dependent type theory is flexible and expressive, and
there is no reason we cannot represent assertions and proofs in the same
general framework.

For example, we could introduce a new type, `Prop`, to represent propositions,
and introduce constructors to build new propositions from others.

    
    
    def Implies (p q : Prop) : Prop := p → q
    #check And     -- Prop → Prop → Prop
    #check Or      -- Prop → Prop → Prop
    #check Not     -- Prop → Prop
    #check Implies -- Prop → Prop → Prop
    
    variable (p q r : Prop)
    #check And p q                      -- Prop
    #check Or (And p q) r               -- Prop
    #check Implies (And p q) (And q p)  -- Prop
    

We could then introduce, for each element `p : Prop`, another type `Proof p`,
for the type of proofs of `p`. An "axiom" would be a constant of such a type.

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    #check Proof   -- Proof : Prop → Type
    
    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))
    
    variable (p q : Prop)
    #check and_comm p q     -- Proof (Implies (And p q) (And q p))
    

In addition to axioms, however, we would also need rules to build new proofs
from old ones. For example, in many proof systems for propositional logic, we
have the rule of _modus ponens_ :

> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.

We could represent this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q
    

Systems of natural deduction for propositional logic also typically rely on
the following rule:

> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we
> can "cancel" the hypothesis and obtain a proof of `Implies p q`.

We could render this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)
    

This approach would provide us with a reasonable way of building assertions
and proofs. Determining that an expression `t` is a correct proof of assertion
`p` would then simply be a matter of checking that `t` has type `Proof p`.

Some simplifications are possible, however. To start with, we can avoid
writing the term `Proof` repeatedly by conflating `Proof p` with `p` itself.
In other words, whenever we have `p : Prop`, we can interpret `p` as a type,
namely, the type of its proofs. We can then read `t : p` as the assertion that
`t` is a proof of `p`.

Moreover, once we make this identification, the rules for implication show
that we can pass back and forth between `Implies p q` and `p → q`. In other
words, implication between propositions `p` and `q` corresponds to having a
function that takes any element of `p` to an element of `q`. As a result, the
introduction of the connective `Implies` is entirely redundant: we can use the
usual function space constructor `p → q` from dependent type theory as our
notion of implication.

This is the approach followed in the Calculus of Constructions, and hence in
Lean as well. The fact that the rules for implication in a proof system for
natural deduction correspond exactly to the rules governing abstraction and
application for functions is an instance of the _Curry-Howard isomorphism_ ,
sometimes known as the _propositions-as-types_ paradigm. In fact, the type
`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy
described in the last chapter. Moreover, `Type u` is also just syntactic sugar
for `Sort (u+1)`. `Prop` has some special features, but like the other type
universes, it is closed under the arrow constructor: if we have `p q : Prop`,
then `p → q : Prop`.

There are at least two ways of thinking about propositions as types. To some
who take a constructive view of logic and mathematics, this is a faithful
rendering of what it means to be a proposition: a proposition `p` represents a
sort of data type, namely, a specification of the type of data that
constitutes a proof. A proof of `p` is then simply an object `t : p` of the
right type.

Those not inclined to this ideology can view it, rather, as a simple coding
trick. To each proposition `p` we associate a type that is empty if `p` is
false and has a single element, say `*`, if `p` is true. In the latter case,
let us say that (the type associated with) `p` is _inhabited_. It just so
happens that the rules for function application and abstraction can
conveniently help us keep track of which elements of `Prop` are inhabited. So
constructing an element `t : p` tells us that `p` is indeed true. You can
think of the inhabitant of `p` as being the "fact that `p` is true." A proof
of `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is
true."

Indeed, if `p : Prop` is any proposition, Lean's kernel treats any two
elements `t1 t2 : p` as being definitionally equal, much the same way as it
treats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as
_proof irrelevance,_ and is consistent with the interpretation in the last
paragraph. It means that even though we can treat proofs `t : p` as ordinary
objects in the language of dependent type theory, they carry no information
beyond the fact that `p` is true.

The two ways we have suggested thinking about the propositions-as-types
paradigm differ in a fundamental way. From the constructive point of view,
proofs are abstract mathematical objects that are _denoted_ by suitable
expressions in dependent type theory. In contrast, if we think in terms of the
coding trick described above, then the expressions themselves do not denote
anything interesting. Rather, it is the fact that we can write them down and
check that they are well-typed that ensures that the proposition in question
is true. In other words, the expressions _themselves_ are the proofs.

In the exposition below, we will slip back and forth between these two ways of
talking, at times saying that an expression "constructs" or "produces" or
"returns" a proof of a proposition, and at other times simply saying that it
"is" such a proof. This is similar to the way that computer scientists
occasionally blur the distinction between syntax and semantics by saying, at
times, that a program "computes" a certain function, and at other times
speaking as though the program "is" the function in question.

In any case, all that really matters is the bottom line. To formally express a
mathematical assertion in the language of dependent type theory, we need to
exhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a
term `t : p`. Lean's task, as a proof assistant, is to help us to construct
such a term, `t`, and to verify that it is well-formed and has the correct
type.

## Working with Propositions as Types

In the propositions-as-types paradigm, theorems involving only `→` can be
proved using lambda abstraction and application. In Lean, the `theorem`
command introduces a new theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    

Compare this proof to the expression `fun x : α => fun y : β => x` of type `α
→ β → α`, where `α` and `β` are data types. This describes the function that
takes arguments `x` and `y` of type `α` and `β`, respectively, and returns
`x`. The proof of `t1` has the same form, the only difference being that `p`
and `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of
`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis
(trivially) to establish that the conclusion, `p`, is true.

Note that the `theorem` command is really a version of the `def` command:
under the propositions and types correspondence, proving the theorem `p → q →
p` is really the same as defining an element of the associated type. To the
kernel type checker, there is no difference between the two.

There are a few pragmatic differences between definitions and theorems,
however. In normal circumstances, it is never necessary to unfold the
"definition" of a theorem; by proof irrelevance, any two proofs of that
theorem are definitionally equal. Once the proof of a theorem is complete,
typically we only need to know that the proof exists; it doesn't matter what
the proof is. In light of that fact, Lean tags proofs as _irreducible_ , which
serves as a hint to the parser (more precisely, the _elaborator_) that there
is generally no need to unfold them when processing a file. In fact, Lean is
generally able to process and check proofs in parallel, since assessing the
correctness of one proof does not require knowing the details of another.

As with definitions, the `#print` command will show you the proof of a
theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    
    #print t1
    

Notice that the lambda abstractions `hp : p` and `hq : q` can be viewed as
temporary assumptions in the proof of `t1`. Lean also allows us to specify the
type of the final term `hp`, explicitly, with a `show` statement:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p :=
      fun hp : p =>
      fun hq : q =>
      show p from hp
    

Adding such extra information can improve the clarity of a proof and help
detect errors when writing a proof. The `show` command does nothing more than
annotate the type, and, internally, all the presentations of `t1` that we have
seen produce the same term.

As with ordinary definitions, we can move the lambda-abstracted variables to
the left of the colon:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    #print t1    -- p → q → p
    

We can use the theorem `t1` just as a function application:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    axiom hp : p
    
    theorem t2 : q → p := t1 hp
    

The `axiom` declaration postulates the existence of an element of the given
type and may compromise logical consistency. For example, we can use it to
postulate that the empty type `False` has an element:

    
    
    axiom unsound : False
    -- Everything follows from false
    theorem ex : 1 = 0 :=
      False.elim unsound
    

Declaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as
witnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`
that `p` is true yields the theorem `t1 hp : q → p`.

Recall that we can also write theorem `t1` as follows:

    
    
    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp
    
    #print t1
    

The type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the
assertion "for every pair of propositions `p q`, we have `p → q → p`." For
example, we can move all parameters to the right of the colon:

    
    
    theorem t1 : ∀ {p q : Prop}, p → q → p :=
      fun {p q : Prop} (hp : p) (hq : q) => hp
    

If `p` and `q` have been declared as variables, Lean will generalize them for
us automatically:

    
    
    variable {p q : Prop}
    
    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp
    

In fact, by the propositions-as-types correspondence, we can declare the
assumption `hp` that `p` holds, as another variable:

    
    
    variable {p q : Prop}
    variable (hp : p)
    
    theorem t1 : q → p := fun (hq : q) => hp
    

Lean detects that the proof uses `hp` and automatically adds `hp : p` as a
premise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →
q → p`. Remember that this type can just as well be written `∀ (p q : Prop)
(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type
in which the target does not depend on the bound variable.

When we generalize `t1` in such a way, we can then apply it to different pairs
of propositions, to obtain different instances of the general theorem.

    
    
    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp
    
    variable (p q r s : Prop)
    
    #check t1 p q                -- p → q → p
    #check t1 r s                -- r → s → r
    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s
    
    variable (h : r → s)
    #check t1 (r → s) (s → r) h  -- (s → r) → r → s
    

Once again, using the propositions-as-types correspondence, the variable `h`
of type `r → s` can be viewed as the hypothesis, or premise, that `r → s`
holds.

As another example, let us consider the composition function discussed in the
last chapter, now with propositions instead of types.

    
    
    variable (p q r s : Prop)
    
    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=
      fun h₃ : p =>
      show r from h₁ (h₂ h₃)
    

As a theorem of propositional logic, what does `t2` say?

Note that it is often useful to use numeric unicode subscripts, entered as
`\0`, `\1`, `\2`, ..., for hypotheses, as we did in this example.

## Propositional Logic

Lean defines all the standard logical connectives and notation. The
propositional connectives come with the following notation:

Ascii| Unicode| Editor shortcut| Definition  
---|---|---|---  
True| | | True  
False| | | False  
Not| ¬| `\not`, `\neg`| Not  
/\| ∧| `\and`| And  
\/| ∨| `\or`| Or  
->| →| `\to`, `\r`, `\imp`|   
<->| ↔| `\iff`, `\lr`| Iff  
  
They all take values in `Prop`.

    
    
    variable (p q : Prop)
    
    #check p → q → p ∧ q
    #check ¬p → p ↔ False
    #check p ∨ q → q ∨ p
    

The order of operations is as follows: unary negation `¬` binds most strongly,
then `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧
e` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right
(nothing changes now that the arguments are elements of `Prop`, instead of
some other `Type`), as do the other binary connectives. So if we have `p q r :
Prop`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This
is just the "curried" form of `p ∧ q → r`.

In the last chapter we observed that lambda abstraction can be viewed as an
"introduction rule" for `→`. In the current setting, it shows how to
"introduce" or establish an implication. Application can be viewed as an
"elimination rule," showing how to "eliminate" or use an implication in a
proof. The other propositional connectives are defined in Lean's library in
the file `Prelude.core` (see [importing
files](./interacting_with_lean.html#importing-files) for more information on
the library hierarchy), and each connective comes with its canonical
introduction and elimination rules.

### Conjunction

The expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :
p` and `h2 : q`. It is common to describe `And.intro` as the _and-
introduction_ rule. In the next example we use `And.intro` to create a proof
of `p → q → p ∧ q`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq
    
    #check fun (hp : p) (hq : q) => And.intro hp hq
    

The `example` command states a theorem without naming it or storing it in the
permanent context. Essentially, it just checks that the given term has the
indicated type. It is convenient for illustration, and we will use it often.

The expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.
Similarly, `And.right h` is a proof of `q`. They are commonly known as the
left and right _and-elimination_ rules.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : p := And.left h
    example (h : p ∧ q) : q := And.right h
    

We can now prove `p ∧ q → q ∧ p` with the following proof term.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      And.intro (And.right h) (And.left h)
    

Notice that and-introduction and and-elimination are similar to the pairing
and projection operations for the Cartesian product. The difference is that
given `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while
`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is
another instance of the Curry-Howard isomorphism, but in contrast to
implication and the function space constructor, `∧` and `×` are treated
separately in Lean. With the analogy, however, the proof we have just
constructed is similar to a function that swaps the elements of a pair.

We will see in [Chapter Structures and Records](./structures_and_records.html)
that certain types in Lean are _structures_ , which is to say, the type is
defined with a single canonical _constructor_ which builds an element of the
type from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is
an example: the canonical way to construct an element is to apply `And.intro`
to suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous
constructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the
relevant type is an inductive type and can be inferred from the context. In
particular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:

    
    
    variable (p q : Prop)
    variable (hp : p) (hq : q)
    
    #check (⟨hp, hq⟩ : p ∧ q)
    

These angle brackets are obtained by typing `\<` and `\>`, respectively.

Lean provides another useful syntactic gadget. Given an expression `e` of an
inductive type `Foo` (possibly applied to some arguments), the notation
`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of
accessing functions without opening a namespace. For example, the following
two expressions mean the same thing:

    
    
    variable (xs : List Nat)
    
    #check List.length xs
    #check xs.length
    

As a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and
`h.right` for `And.right h`. We can therefore rewrite the sample proof above
conveniently as follows:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      ⟨h.right, h.left⟩
    

There is a fine line between brevity and obfuscation, and omitting information
in this way can sometimes make a proof harder to read. But for straightforward
constructions like the one above, when the type of `h` and the goal of the
construction are salient, the notation is clean and effective.

It is common to iterate constructions like "And." Lean also allows you to
flatten nested constructors that associate to the right, so that these two
proofs are equivalent:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, ⟨h.left, h.right⟩⟩
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, h.left, h.right⟩
    

This is often useful as well.

### Disjunction

The expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof
`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a
proof `hq : q`. These are the left and right _or-introduction_ rules.

    
    
    variable (p q : Prop)
    example (hp : p) : p ∨ q := Or.intro_left q hp
    example (hq : q) : p ∨ q := Or.intro_right p hq
    

The _or-elimination_ rule is slightly more complicated. The idea is that we
can prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`
follows from `q`. In other words, it is a proof by cases. In the expression
`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :
p → r` and `hqr : q → r`, and produces a proof of `r`. In the following
example, we use `Or.elim` to prove `p ∨ q → q ∨ p`.

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h
        (fun hp : p =>
          show q ∨ p from Or.intro_right q hp)
        (fun hq : q =>
          show q ∨ p from Or.intro_left p hq)
    

In most cases, the first argument of `Or.intro_right` and `Or.intro_left` can
be inferred automatically by Lean. Lean therefore provides `Or.inr` and
`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and
`Or.intro_left _`. Thus the proof term above could be written more concisely:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Notice that there is enough information in the full expression for Lean to
infer the types of `hp` and `hq` as well. But using the type annotations in
the longer version makes the proof more readable, and can help catch and debug
errors.

Because `Or` has two constructors, we cannot use anonymous constructor
notation. But we can still write `h.elim` instead of `Or.elim h`:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Once again, you should exercise judgment as to whether such abbreviations
enhance or diminish readability.

### Negation and Falsity

Negation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by
deriving a contradiction from `p`. Similarly, the expression `hnp hp` produces
a proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both
these rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is
produced by typing `\not` or `\neg`.)

    
    
    variable (p q : Prop)
    
    example (hpq : p → q) (hnq : ¬q) : ¬p :=
      fun hp : p =>
      show False from hnq (hpq hp)
    

The connective `False` has a single elimination rule, `False.elim`, which
expresses the fact that anything follows from a contradiction. This rule is
sometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the
_principle of explosion_.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)
    

The arbitrary fact, `q`, that follows from falsity is an implicit argument in
`False.elim` and is inferred automatically. This pattern, deriving an
arbitrary fact from contradictory hypotheses, is quite common, and is
represented by `absurd`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := absurd hp hnp
    

Here, for example, is a proof of `¬p → q → (q → p) → r`:

    
    
    variable (p q r : Prop)
    
    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=
      absurd (hqp hq) hnp
    

Incidentally, just as `False` has only an elimination rule, `True` has only an
introduction rule, `True.intro : true`. In other words, `True` is simply true,
and has a canonical proof, `True.intro`.

### Logical Equivalence

The expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`
and `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from
`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔
q`. Here is a proof of `p ∧ q ↔ q ∧ p`:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      Iff.intro
        (fun h : p ∧ q =>
         show q ∧ p from And.intro (And.right h) (And.left h))
        (fun h : q ∧ p =>
         show p ∧ q from And.intro (And.right h) (And.left h))
    
    #check and_swap p q    -- p ∧ q ↔ q ∧ p
    
    variable (h : p ∧ q)
    example : q ∧ p := Iff.mp (and_swap p q) h
    

We can use the anonymous constructor notation to construct a proof of `p ↔ q`
from proofs of the forward and backward directions, and we can also use `.`
notation with `mp` and `mpr`. The previous examples can therefore be written
concisely as follows:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩
    
    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h
    

## Introducing Auxiliary Subgoals

This is a good place to introduce another device Lean offers to help structure
long proofs, namely, the `have` construct, which introduces an auxiliary
subgoal in a proof. Here is a small example, adapted from the last section:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      have hq : q := h.right
      show q ∧ p from And.intro hq hp
    

Internally, the expression `have h : p := s; t` produces the term `(fun (h :
p) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the
desired conclusion assuming `h : p`, and the two are combined by a lambda
abstraction and application. This simple device is extremely useful when it
comes to structuring long proofs, since we can use intermediate `have`'s as
stepping stones leading to the final goal.

Lean also supports a structured way of reasoning backwards from a goal, which
models the "suffices to show" construction in ordinary mathematics. The next
example simply permutes the last two lines in the previous proof.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      suffices hq : q from And.intro hq hp
      show q from And.right h
    

Writing `suffices hq : q` leaves us with two goals. First, we have to show
that it indeed suffices to show `q`, by proving the original goal of `q ∧ p`
with the additional hypothesis `hq : q`. Finally, we have to show `q`.

## Classical Logic

The introduction and elimination rules we have seen so far are all
constructive, which is to say, they reflect a computational understanding of
the logical connectives based on the propositions-as-types correspondence.
Ordinary classical logic adds to this the law of the excluded middle, `p ∨
¬p`. To use this principle, you have to open the classical namespace.

    
    
    open Classical
    
    variable (p : Prop)
    #check em p
    

Intuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts
to knowing which is the case. If `RH` represents the Riemann hypothesis, a
classical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot
yet assert either disjunct.

One consequence of the law of the excluded middle is the principle of double-
negation elimination:

    
    
    open Classical
    
    theorem dne {p : Prop} (h : ¬¬p) : p :=
      Or.elim (em p)
        (fun hp : p => hp)
        (fun hnp : ¬p => absurd hnp h)
    

Double-negation elimination allows one to prove any proposition, `p`, by
assuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In
other words, double-negation elimination allows one to carry out a proof by
contradiction, something which is not generally possible in constructive
logic. As an exercise, you might try proving the converse, that is, showing
that `em` can be proved from `dne`.

The classical axioms also give you access to additional patterns of proof that
can be justified by appeal to `em`. For example, one can carry out a proof by
cases:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byCases
        (fun h1 : p => h1)
        (fun h1 : ¬p => absurd h1 h)
    

Or you can carry out a proof by contradiction:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byContradiction
        (fun h1 : ¬p =>
         show False from h h1)
    

If you are not used to thinking constructively, it may take some time for you
to get a sense of where classical reasoning is used. It is needed in the
following example because, from a constructive standpoint, knowing that `p`
and `q` are not both true does not necessarily tell you which one is false:

    
    
    open Classical
    variable (p q : Prop)
    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=
      Or.elim (em p)
        (fun hp : p =>
          Or.inr
            (show ¬q from
              fun hq : q =>
              h ⟨hp, hq⟩))
        (fun hp : ¬p =>
          Or.inl hp)
    

We will see later that there _are_ situations in constructive logic where
principles like excluded middle and double-negation elimination are
permissible, and Lean supports the use of classical reasoning in such contexts
without relying on excluded middle.

The full list of axioms that are used in Lean to support classical reasoning
are discussed in [Axioms and Computation](./axioms_and_computation.html).

## Examples of Propositional Validities

Lean's standard library contains proofs of many valid statements of
propositional logic, all of which you are free to use in proofs of your own.
The following list includes a number of common identities.

Commutativity:

  1. `p ∧ q ↔ q ∧ p`
  2. `p ∨ q ↔ q ∨ p`

Associativity:

  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`
  4. `(p ∨ q) ∨ r ↔ p ∨ (q �
2025-06-01 02:48:12,497 - DEBUG - close.started
2025-06-01 02:48:12,497 - DEBUG - close.complete
2025-06-01 02:48:12,507 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.'}], 'model': 'o3-mini'}}
2025-06-01 02:48:12,507 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:48:12,507 - DEBUG - close.started
2025-06-01 02:48:12,507 - DEBUG - close.complete
2025-06-01 02:48:12,507 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:48:12,515 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20429f1d0>
2025-06-01 02:48:12,515 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:48:12,524 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e2042a4860>
2025-06-01 02:48:12,524 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:48:12,524 - DEBUG - send_request_headers.complete
2025-06-01 02:48:12,525 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:48:12,525 - DEBUG - send_request_body.complete
2025-06-01 02:48:12,525 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:48:18,462 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:48:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5707'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5711'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199550'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'135ms'), (b'x-request-id', b'req_ed3f16aab3f1937498815119097bdaba'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b64067d994278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:48:18,462 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:48:18,462 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:48:18,462 - DEBUG - receive_response_body.complete
2025-06-01 02:48:18,462 - DEBUG - response_closed.started
2025-06-01 02:48:18,463 - DEBUG - response_closed.complete
2025-06-01 02:48:18,463 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:48:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5707', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5711', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199550', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '135ms', 'x-request-id': 'req_ed3f16aab3f1937498815119097bdaba', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b64067d994278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:48:18,463 - DEBUG - request_id: req_ed3f16aab3f1937498815119097bdaba
2025-06-01 02:48:18,463 - INFO - Attempt 1/3
2025-06-01 02:48:18,463 - INFO - Current plan: {
  "plan_summary": "Design a Lean 4 function that checks for at least one common integer in two arrays by iterating over one array and checking for membership in the other, while handling empty arrays by returning false.",
  "steps": [
    "Check if either array is empty. If so, return false immediately.",
    "Iterate through the elements of the first array.",
    "For each element, use an appropriate method (such as 'Array.exists' or a custom loop) to determine if the element appears in the second array.",
    "Return true as soon as a common element is found. If the loop finishes without finding a match, return false."
  ],
  "code_keywords": [
    "Lean 4",
    "Array",
    "Int",
    "exists",
    "contains",
    "iteration"
  ],
  "proof_keywords": [
    "constructive proof", 
    "case analysis", 
    "empty array analysis"
  ],
  "assumptions": [
    "Arrays can be iterated over using standard Lean 4 functions.",
    "A membership check (such as Array.contains or Array.exists) is available.",
    "If either input array is empty, the function should return false."
  ],
  "retry_guidance": "If the initial approach leads to index or performance issues, consider using lean's built-in functions like 'Array.exists' directly with an appropriate predicate or you may optimize membership checks by considering sorting or using a hash set if performance becomes a concern."
}
2025-06-01 02:48:18,464 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Design a Lean 4 function that checks for at least one common integer in two arrays by iterating over one array and checking for membership in the other, while handling empty arrays by returning false.",\n  "steps": [\n    "Check if either array is empty. If so, return false immediately.",\n    "Iterate through the elements of the first array.",\n    "For each element, use an appropriate method (such as \'Array.exists\' or a custom loop) to determine if the element appears in the second array.",\n    "Return true as soon as a common element is found. If the loop finishes without finding a match, return false."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array",\n    "Int",\n    "exists",\n    "contains",\n    "iteration"\n  ],\n  "proof_keywords": [\n    "constructive proof", \n    "case analysis", \n    "empty array analysis"\n  ],\n  "assumptions": [\n    "Arrays can be iterated over using standard Lean 4 functions.",\n    "A membership check (such as Array.contains or Array.exists) is available.",\n    "If either input array is empty, the function should return false."\n  ],\n  "retry_guidance": "If the initial approach leads to index or performance issues, consider using lean\'s built-in functions like \'Array.exists\' directly with an appropriate predicate or you may optimize membership checks by considering sorting or using a hash set if performance becomes a concern."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasCommonElement (a : Array Int) (b : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the method returns true, there exists at least one common element between the two arrays; If the method returns false, there are no common elements between the two arrays\ndef hasCommonElement_spec (a : Array Int) (b : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ result\n  -- << SPEC END >>\n\ntheorem hasCommonElement_spec_satisfied (a : Array Int) (b : Array Int) :\n  hasCommonElement_spec a b (hasCommonElement a b) := by\n  -- << PROOF START >>\n  unfold hasCommonElement hasCommonElement_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Propositions and Proofs\n\nBy now, you have seen some ways of defining objects and functions in Lean. In\nthis chapter, we will begin to explain how to write mathematical assertions\nand proofs in the language of dependent type theory as well.\n\n## Propositions as Types\n\nOne strategy for proving assertions about objects defined in the language of\ndependent type theory is to layer an assertion language and a proof language\non top of the definition language. But there is no reason to multiply\nlanguages in this way: dependent type theory is flexible and expressive, and\nthere is no reason we cannot represent assertions and proofs in the same\ngeneral framework.\n\nFor example, we could introduce a new type, `Prop`, to represent propositions,\nand introduce constructors to build new propositions from others.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    #check And     -- Prop → Prop → Prop\n    #check Or      -- Prop → Prop → Prop\n    #check Not     -- Prop → Prop\n    #check Implies -- Prop → Prop → Prop\n    \n    variable (p q r : Prop)\n    #check And p q                      -- Prop\n    #check Or (And p q) r               -- Prop\n    #check Implies (And p q) (And q p)  -- Prop\n    \n\nWe could then introduce, for each element `p : Prop`, another type `Proof p`,\nfor the type of proofs of `p`. An "axiom" would be a constant of such a type.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    #check Proof   -- Proof : Prop → Type\n    \n    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))\n    \n    variable (p q : Prop)\n    #check and_comm p q     -- Proof (Implies (And p q) (And q p))\n    \n\nIn addition to axioms, however, we would also need rules to build new proofs\nfrom old ones. For example, in many proof systems for propositional logic, we\nhave the rule of _modus ponens_ :\n\n> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.\n\nWe could represent this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q\n    \n\nSystems of natural deduction for propositional logic also typically rely on\nthe following rule:\n\n> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we\n> can "cancel" the hypothesis and obtain a proof of `Implies p q`.\n\nWe could render this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)\n    \n\nThis approach would provide us with a reasonable way of building assertions\nand proofs. Determining that an expression `t` is a correct proof of assertion\n`p` would then simply be a matter of checking that `t` has type `Proof p`.\n\nSome simplifications are possible, however. To start with, we can avoid\nwriting the term `Proof` repeatedly by conflating `Proof p` with `p` itself.\nIn other words, whenever we have `p : Prop`, we can interpret `p` as a type,\nnamely, the type of its proofs. We can then read `t : p` as the assertion that\n`t` is a proof of `p`.\n\nMoreover, once we make this identification, the rules for implication show\nthat we can pass back and forth between `Implies p q` and `p → q`. In other\nwords, implication between propositions `p` and `q` corresponds to having a\nfunction that takes any element of `p` to an element of `q`. As a result, the\nintroduction of the connective `Implies` is entirely redundant: we can use the\nusual function space constructor `p → q` from dependent type theory as our\nnotion of implication.\n\nThis is the approach followed in the Calculus of Constructions, and hence in\nLean as well. The fact that the rules for implication in a proof system for\nnatural deduction correspond exactly to the rules governing abstraction and\napplication for functions is an instance of the _Curry-Howard isomorphism_ ,\nsometimes known as the _propositions-as-types_ paradigm. In fact, the type\n`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy\ndescribed in the last chapter. Moreover, `Type u` is also just syntactic sugar\nfor `Sort (u+1)`. `Prop` has some special features, but like the other type\nuniverses, it is closed under the arrow constructor: if we have `p q : Prop`,\nthen `p → q : Prop`.\n\nThere are at least two ways of thinking about propositions as types. To some\nwho take a constructive view of logic and mathematics, this is a faithful\nrendering of what it means to be a proposition: a proposition `p` represents a\nsort of data type, namely, a specification of the type of data that\nconstitutes a proof. A proof of `p` is then simply an object `t : p` of the\nright type.\n\nThose not inclined to this ideology can view it, rather, as a simple coding\ntrick. To each proposition `p` we associate a type that is empty if `p` is\nfalse and has a single element, say `*`, if `p` is true. In the latter case,\nlet us say that (the type associated with) `p` is _inhabited_. It just so\nhappens that the rules for function application and abstraction can\nconveniently help us keep track of which elements of `Prop` are inhabited. So\nconstructing an element `t : p` tells us that `p` is indeed true. You can\nthink of the inhabitant of `p` as being the "fact that `p` is true." A proof\nof `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is\ntrue."\n\nIndeed, if `p : Prop` is any proposition, Lean\'s kernel treats any two\nelements `t1 t2 : p` as being definitionally equal, much the same way as it\ntreats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as\n_proof irrelevance,_ and is consistent with the interpretation in the last\nparagraph. It means that even though we can treat proofs `t : p` as ordinary\nobjects in the language of dependent type theory, they carry no information\nbeyond the fact that `p` is true.\n\nThe two ways we have suggested thinking about the propositions-as-types\nparadigm differ in a fundamental way. From the constructive point of view,\nproofs are abstract mathematical objects that are _denoted_ by suitable\nexpressions in dependent type theory. In contrast, if we think in terms of the\ncoding trick described above, then the expressions themselves do not denote\nanything interesting. Rather, it is the fact that we can write them down and\ncheck that they are well-typed that ensures that the proposition in question\nis true. In other words, the expressions _themselves_ are the proofs.\n\nIn the exposition below, we will slip back and forth between these two ways of\ntalking, at times saying that an expression "constructs" or "produces" or\n"returns" a proof of a proposition, and at other times simply saying that it\n"is" such a proof. This is similar to the way that computer scientists\noccasionally blur the distinction between syntax and semantics by saying, at\ntimes, that a program "computes" a certain function, and at other times\nspeaking as though the program "is" the function in question.\n\nIn any case, all that really matters is the bottom line. To formally express a\nmathematical assertion in the language of dependent type theory, we need to\nexhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a\nterm `t : p`. Lean\'s task, as a proof assistant, is to help us to construct\nsuch a term, `t`, and to verify that it is well-formed and has the correct\ntype.\n\n## Working with Propositions as Types\n\nIn the propositions-as-types paradigm, theorems involving only `→` can be\nproved using lambda abstraction and application. In Lean, the `theorem`\ncommand introduces a new theorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    \n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n\nCompare this proof to the expression `fun x : α => fun y : β => x` of type `α\n→ β → α`, where `α` and `β` are data types. This describes the function that\ntakes arguments `x` and `y` of type `α` and `β`, respectively, and returns\n`x`. The proof of `t1` has the same form, the only difference being that `p`\nand `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of\n`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis\n(trivially) to establish that the conclusion, `p`, is true.\n\nNote that the `theorem` command is really a version of the `def` command:\nunder the propositions and types correspondence, proving the theorem `p → q →\np` is really the same as defining an element of the associated type. To the\nkernel type checker, there is no difference between the two.\n\nThere are a few pragmatic differences between definitions and theorems,\nhowever. In normal circumstances, it is never necessary to unfold the\n"definition" of a theorem; by proof irrelevance, any two proofs of that\ntheorem are definitionally equal. Once the proof of a theorem is complete,\ntypically we only need to know that the proof exists; it doesn\'t matter what\nthe proof is. In light of that fact, Lean tags proofs as _irreducible_ , which\nserves as a hint to the parser (more precisely, the _elaborator_) that there\nis generally no need to unfold them when processing a file. In fact, Lean is\ngenerally able to process and check proofs in parallel, since assessing the\ncorrectness of one proof does not require knowing the details of another.\n\nAs with definitions, the `#print` command will show you the proof of a\ntheorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n    #print t1\n    \n\nNotice that the lambda abstractions `hp : p` and `hq : q` can be viewed as\ntemporary assumptions in the proof of `t1`. Lean also allows us to specify the\ntype of the final term `hp`, explicitly, with a `show` statement:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p :=\n      fun hp : p =>\n      fun hq : q =>\n      show p from hp\n    \n\nAdding such extra information can improve the clarity of a proof and help\ndetect errors when writing a proof. The `show` command does nothing more than\nannotate the type, and, internally, all the presentations of `t1` that we have\nseen produce the same term.\n\nAs with ordinary definitions, we can move the lambda-abstracted variables to\nthe left of the colon:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    #print t1    -- p → q → p\n    \n\nWe can use the theorem `t1` just as a function application:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    axiom hp : p\n    \n    theorem t2 : q → p := t1 hp\n    \n\nThe `axiom` declaration postulates the existence of an element of the given\ntype and may compromise logical consistency. For example, we can use it to\npostulate that the empty type `False` has an element:\n\n    \n    \n    axiom unsound : False\n    -- Everything follows from false\n    theorem ex : 1 = 0 :=\n      False.elim unsound\n    \n\nDeclaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as\nwitnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`\nthat `p` is true yields the theorem `t1 hp : q → p`.\n\nRecall that we can also write theorem `t1` as follows:\n\n    \n    \n    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp\n    \n    #print t1\n    \n\nThe type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the\nassertion "for every pair of propositions `p q`, we have `p → q → p`." For\nexample, we can move all parameters to the right of the colon:\n\n    \n    \n    theorem t1 : ∀ {p q : Prop}, p → q → p :=\n      fun {p q : Prop} (hp : p) (hq : q) => hp\n    \n\nIf `p` and `q` have been declared as variables, Lean will generalize them for\nus automatically:\n\n    \n    \n    variable {p q : Prop}\n    \n    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp\n    \n\nIn fact, by the propositions-as-types correspondence, we can declare the\nassumption `hp` that `p` holds, as another variable:\n\n    \n    \n    variable {p q : Prop}\n    variable (hp : p)\n    \n    theorem t1 : q → p := fun (hq : q) => hp\n    \n\nLean detects that the proof uses `hp` and automatically adds `hp : p` as a\npremise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →\nq → p`. Remember that this type can just as well be written `∀ (p q : Prop)\n(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type\nin which the target does not depend on the bound variable.\n\nWhen we generalize `t1` in such a way, we can then apply it to different pairs\nof propositions, to obtain different instances of the general theorem.\n\n    \n    \n    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp\n    \n    variable (p q r s : Prop)\n    \n    #check t1 p q                -- p → q → p\n    #check t1 r s                -- r → s → r\n    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s\n    \n    variable (h : r → s)\n    #check t1 (r → s) (s → r) h  -- (s → r) → r → s\n    \n\nOnce again, using the propositions-as-types correspondence, the variable `h`\nof type `r → s` can be viewed as the hypothesis, or premise, that `r → s`\nholds.\n\nAs another example, let us consider the composition function discussed in the\nlast chapter, now with propositions instead of types.\n\n    \n    \n    variable (p q r s : Prop)\n    \n    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=\n      fun h₃ : p =>\n      show r from h₁ (h₂ h₃)\n    \n\nAs a theorem of propositional logic, what does `t2` say?\n\nNote that it is often useful to use numeric unicode subscripts, entered as\n`\\0`, `\\1`, `\\2`, ..., for hypotheses, as we did in this example.\n\n## Propositional Logic\n\nLean defines all the standard logical connectives and notation. The\npropositional connectives come with the following notation:\n\nAscii| Unicode| Editor shortcut| Definition  \n---|---|---|---  \nTrue| | | True  \nFalse| | | False  \nNot| ¬| `\\not`, `\\neg`| Not  \n/\\| ∧| `\\and`| And  \n\\/| ∨| `\\or`| Or  \n->| →| `\\to`, `\\r`, `\\imp`|   \n<->| ↔| `\\iff`, `\\lr`| Iff  \n  \nThey all take values in `Prop`.\n\n    \n    \n    variable (p q : Prop)\n    \n    #check p → q → p ∧ q\n    #check ¬p → p ↔ False\n    #check p ∨ q → q ∨ p\n    \n\nThe order of operations is as follows: unary negation `¬` binds most strongly,\nthen `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧\ne` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right\n(nothing changes now that the arguments are elements of `Prop`, instead of\nsome other `Type`), as do the other binary connectives. So if we have `p q r :\nProp`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This\nis just the "curried" form of `p ∧ q → r`.\n\nIn the last chapter we observed that lambda abstraction can be viewed as an\n"introduction rule" for `→`. In the current setting, it shows how to\n"introduce" or establish an implication. Application can be viewed as an\n"elimination rule," showing how to "eliminate" or use an implication in a\nproof. The other propositional connectives are defined in Lean\'s library in\nthe file `Prelude.core` (see [importing\nfiles](./interacting_with_lean.html#importing-files) for more information on\nthe library hierarchy), and each connective comes with its canonical\nintroduction and elimination rules.\n\n### Conjunction\n\nThe expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :\np` and `h2 : q`. It is common to describe `And.intro` as the _and-\nintroduction_ rule. In the next example we use `And.intro` to create a proof\nof `p → q → p ∧ q`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq\n    \n    #check fun (hp : p) (hq : q) => And.intro hp hq\n    \n\nThe `example` command states a theorem without naming it or storing it in the\npermanent context. Essentially, it just checks that the given term has the\nindicated type. It is convenient for illustration, and we will use it often.\n\nThe expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.\nSimilarly, `And.right h` is a proof of `q`. They are commonly known as the\nleft and right _and-elimination_ rules.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : p := And.left h\n    example (h : p ∧ q) : q := And.right h\n    \n\nWe can now prove `p ∧ q → q ∧ p` with the following proof term.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      And.intro (And.right h) (And.left h)\n    \n\nNotice that and-introduction and and-elimination are similar to the pairing\nand projection operations for the Cartesian product. The difference is that\ngiven `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while\n`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is\nanother instance of the Curry-Howard isomorphism, but in contrast to\nimplication and the function space constructor, `∧` and `×` are treated\nseparately in Lean. With the analogy, however, the proof we have just\nconstructed is similar to a function that swaps the elements of a pair.\n\nWe will see in [Chapter Structures and Records](./structures_and_records.html)\nthat certain types in Lean are _structures_ , which is to say, the type is\ndefined with a single canonical _constructor_ which builds an element of the\ntype from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is\nan example: the canonical way to construct an element is to apply `And.intro`\nto suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous\nconstructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the\nrelevant type is an inductive type and can be inferred from the context. In\nparticular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:\n\n    \n    \n    variable (p q : Prop)\n    variable (hp : p) (hq : q)\n    \n    #check (⟨hp, hq⟩ : p ∧ q)\n    \n\nThese angle brackets are obtained by typing `\\<` and `\\>`, respectively.\n\nLean provides another useful syntactic gadget. Given an expression `e` of an\ninductive type `Foo` (possibly applied to some arguments), the notation\n`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of\naccessing functions without opening a namespace. For example, the following\ntwo expressions mean the same thing:\n\n    \n    \n    variable (xs : List Nat)\n    \n    #check List.length xs\n    #check xs.length\n    \n\nAs a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and\n`h.right` for `And.right h`. We can therefore rewrite the sample proof above\nconveniently as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      ⟨h.right, h.left⟩\n    \n\nThere is a fine line between brevity and obfuscation, and omitting information\nin this way can sometimes make a proof harder to read. But for straightforward\nconstructions like the one above, when the type of `h` and the goal of the\nconstruction are salient, the notation is clean and effective.\n\nIt is common to iterate constructions like "And." Lean also allows you to\nflatten nested constructors that associate to the right, so that these two\nproofs are equivalent:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, ⟨h.left, h.right⟩⟩\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, h.left, h.right⟩\n    \n\nThis is often useful as well.\n\n### Disjunction\n\nThe expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof\n`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a\nproof `hq : q`. These are the left and right _or-introduction_ rules.\n\n    \n    \n    variable (p q : Prop)\n    example (hp : p) : p ∨ q := Or.intro_left q hp\n    example (hq : q) : p ∨ q := Or.intro_right p hq\n    \n\nThe _or-elimination_ rule is slightly more complicated. The idea is that we\ncan prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`\nfollows from `q`. In other words, it is a proof by cases. In the expression\n`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :\np → r` and `hqr : q → r`, and produces a proof of `r`. In the following\nexample, we use `Or.elim` to prove `p ∨ q → q ∨ p`.\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h\n        (fun hp : p =>\n          show q ∨ p from Or.intro_right q hp)\n        (fun hq : q =>\n          show q ∨ p from Or.intro_left p hq)\n    \n\nIn most cases, the first argument of `Or.intro_right` and `Or.intro_left` can\nbe inferred automatically by Lean. Lean therefore provides `Or.inr` and\n`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and\n`Or.intro_left _`. Thus the proof term above could be written more concisely:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nNotice that there is enough information in the full expression for Lean to\ninfer the types of `hp` and `hq` as well. But using the type annotations in\nthe longer version makes the proof more readable, and can help catch and debug\nerrors.\n\nBecause `Or` has two constructors, we cannot use anonymous constructor\nnotation. But we can still write `h.elim` instead of `Or.elim h`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nOnce again, you should exercise judgment as to whether such abbreviations\nenhance or diminish readability.\n\n### Negation and Falsity\n\nNegation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by\nderiving a contradiction from `p`. Similarly, the expression `hnp hp` produces\na proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both\nthese rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is\nproduced by typing `\\not` or `\\neg`.)\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hpq : p → q) (hnq : ¬q) : ¬p :=\n      fun hp : p =>\n      show False from hnq (hpq hp)\n    \n\nThe connective `False` has a single elimination rule, `False.elim`, which\nexpresses the fact that anything follows from a contradiction. This rule is\nsometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the\n_principle of explosion_.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)\n    \n\nThe arbitrary fact, `q`, that follows from falsity is an implicit argument in\n`False.elim` and is inferred automatically. This pattern, deriving an\narbitrary fact from contradictory hypotheses, is quite common, and is\nrepresented by `absurd`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := absurd hp hnp\n    \n\nHere, for example, is a proof of `¬p → q → (q → p) → r`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=\n      absurd (hqp hq) hnp\n    \n\nIncidentally, just as `False` has only an elimination rule, `True` has only an\nintroduction rule, `True.intro : true`. In other words, `True` is simply true,\nand has a canonical proof, `True.intro`.\n\n### Logical Equivalence\n\nThe expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`\nand `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from\n`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔\nq`. Here is a proof of `p ∧ q ↔ q ∧ p`:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      Iff.intro\n        (fun h : p ∧ q =>\n         show q ∧ p from And.intro (And.right h) (And.left h))\n        (fun h : q ∧ p =>\n         show p ∧ q from And.intro (And.right h) (And.left h))\n    \n    #check and_swap p q    -- p ∧ q ↔ q ∧ p\n    \n    variable (h : p ∧ q)\n    example : q ∧ p := Iff.mp (and_swap p q) h\n    \n\nWe can use the anonymous constructor notation to construct a proof of `p ↔ q`\nfrom proofs of the forward and backward directions, and we can also use `.`\nnotation with `mp` and `mpr`. The previous examples can therefore be written\nconcisely as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩\n    \n    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h\n    \n\n## Introducing Auxiliary Subgoals\n\nThis is a good place to introduce another device Lean offers to help structure\nlong proofs, namely, the `have` construct, which introduces an auxiliary\nsubgoal in a proof. Here is a small example, adapted from the last section:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      have hq : q := h.right\n      show q ∧ p from And.intro hq hp\n    \n\nInternally, the expression `have h : p := s; t` produces the term `(fun (h :\np) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the\ndesired conclusion assuming `h : p`, and the two are combined by a lambda\nabstraction and application. This simple device is extremely useful when it\ncomes to structuring long proofs, since we can use intermediate `have`\'s as\nstepping stones leading to the final goal.\n\nLean also supports a structured way of reasoning backwards from a goal, which\nmodels the "suffices to show" construction in ordinary mathematics. The next\nexample simply permutes the last two lines in the previous proof.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      suffices hq : q from And.intro hq hp\n      show q from And.right h\n    \n\nWriting `suffices hq : q` leaves us with two goals. First, we have to show\nthat it indeed suffices to show `q`, by proving the original goal of `q ∧ p`\nwith the additional hypothesis `hq : q`. Finally, we have to show `q`.\n\n## Classical Logic\n\nThe introduction and elimination rules we have seen so far are all\nconstructive, which is to say, they reflect a computational understanding of\nthe logical connectives based on the propositions-as-types correspondence.\nOrdinary classical logic adds to this the law of the excluded middle, `p ∨\n¬p`. To use this principle, you have to open the classical namespace.\n\n    \n    \n    open Classical\n    \n    variable (p : Prop)\n    #check em p\n    \n\nIntuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts\nto knowing which is the case. If `RH` represents the Riemann hypothesis, a\nclassical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot\nyet assert either disjunct.\n\nOne consequence of the law of the excluded middle is the principle of double-\nnegation elimination:\n\n    \n    \n    open Classical\n    \n    theorem dne {p : Prop} (h : ¬¬p) : p :=\n      Or.elim (em p)\n        (fun hp : p => hp)\n        (fun hnp : ¬p => absurd hnp h)\n    \n\nDouble-negation elimination allows one to prove any proposition, `p`, by\nassuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In\nother words, double-negation elimination allows one to carry out a proof by\ncontradiction, something which is not generally possible in constructive\nlogic. As an exercise, you might try proving the converse, that is, showing\nthat `em` can be proved from `dne`.\n\nThe classical axioms also give you access to additional patterns of proof that\ncan be justified by appeal to `em`. For example, one can carry out a proof by\ncases:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byCases\n        (fun h1 : p => h1)\n        (fun h1 : ¬p => absurd h1 h)\n    \n\nOr you can carry out a proof by contradiction:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byContradiction\n        (fun h1 : ¬p =>\n         show False from h h1)\n    \n\nIf you are not used to thinking constructively, it may take some time for you\nto get a sense of where classical reasoning is used. It is needed in the\nfollowing example because, from a constructive standpoint, knowing that `p`\nand `q` are not both true does not necessarily tell you which one is false:\n\n    \n    \n    open Classical\n    variable (p q : Prop)\n    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=\n      Or.elim (em p)\n        (fun hp : p =>\n          Or.inr\n            (show ¬q from\n              fun hq : q =>\n              h ⟨hp, hq⟩))\n        (fun hp : ¬p =>\n          Or.inl hp)\n    \n\nWe will see later that there _are_ situations in constructive logic where\nprinciples like excluded middle and double-negation elimination are\npermissible, and Lean supports the use of classical reasoning in such contexts\nwithout relying on excluded middle.\n\nThe full list of axioms that are used in Lean to support classical reasoning\nare discussed in [Axioms and Computation](./axioms_and_computation.html).\n\n## Examples of Propositional Validities\n\nLean\'s standard library contains proofs of many valid statements of\npropositional logic, all of which you are free to use in proofs of your own.\nThe following list includes a number of common identities.\n\nCommutativity:\n\n  1. `p ∧ q ↔ q ∧ p`\n  2. `p ∨ q ↔ q ∨ p`\n\nAssociativity:\n\n  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`\n  4. `(p ∨ q) ∨ r ↔ p ∨ (q �'}], 'model': 'gpt-4o'}}
2025-06-01 02:48:18,465 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:48:18,465 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:48:18,466 - DEBUG - send_request_headers.complete
2025-06-01 02:48:18,466 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:48:18,471 - DEBUG - send_request_body.complete
2025-06-01 02:48:18,471 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:48:26,499 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:48:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7781'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7788'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'12871'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'34.256s'), (b'x-request-id', b'req_21565ef01fed44d6882dc00c49fbd07d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b642b9f694278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:48:26,499 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:48:26,500 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:48:26,501 - DEBUG - receive_response_body.complete
2025-06-01 02:48:26,501 - DEBUG - response_closed.started
2025-06-01 02:48:26,501 - DEBUG - response_closed.complete
2025-06-01 02:48:26,501 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:48:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7781', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7788', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '12871', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '34.256s', 'x-request-id': 'req_21565ef01fed44d6882dc00c49fbd07d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b642b9f694278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:48:26,501 - DEBUG - request_id: req_21565ef01fed44d6882dc00c49fbd07d
2025-06-01 02:48:26,501 - INFO - Raw solution received: ```json
{
  "code": "if a.isEmpty || b.isEmpty then\n    false\n  else\n    a.any (fun x => b.contains x)",
  "proof": "by\n  intros a b\n  unfold hasCommonElement hasCommonElement_spec\n  by_cases h: a.isEmpty || b.isEmpty\n  \n  -- Case 1: a or b is empty\n  { simp [h]\n    intro nontrivial\n    cases nontrivial with i ji\n    cases ji with ai bi\n    cases ai with ai_in a_sz\n    cases bi with bj_in b_sz\n    \n    have : a.size ≠ 0 := a_sz\n    contradiction\n  }\n  \n  -- Case 2: Neither a nor b is empty\n  { simp [h]\n    intro h_existence\n    split\n    \n    -- (a) If P is true, show result is true\n    intro common\n    cases common with x ⟨i, ai⟩ ⟨j, bj⟩\n    apply Array.any_mem_of_inj ai (b.contains_mem bj)\n    \n    -- (b) If result is true, show P is true\n    intro result\n    dsimp at result\n    rcases result with ⟨x, hx⟩\n    use [0, ⟨Array.getElem? ⟨a, 0, ai⟩ hx.left, 0, b.contains_to_inj hx.right⟩]\n  }"
}
```
2025-06-01 02:48:26,502 - INFO - <class 'str'>
2025-06-01 02:48:26,502 - INFO - Generated solution: {'code': 'if a.isEmpty || b.isEmpty then\n    false\n  else\n    a.any (fun x => b.contains x)', 'proof': 'by\n  intros a b\n  unfold hasCommonElement hasCommonElement_spec\n  by_cases h: a.isEmpty || b.isEmpty\n  \n  -- Case 1: a or b is empty\n  { simp [h]\n    intro nontrivial\n    cases nontrivial with i ji\n    cases ji with ai bi\n    cases ai with ai_in a_sz\n    cases bi with bj_in b_sz\n    \n    have : a.size ≠ 0 := a_sz\n    contradiction\n  }\n  \n  -- Case 2: Neither a nor b is empty\n  { simp [h]\n    intro h_existence\n    split\n    \n    -- (a) If P is true, show result is true\n    intro common\n    cases common with x ⟨i, ai⟩ ⟨j, bj⟩\n    apply Array.any_mem_of_inj ai (b.contains_mem bj)\n    \n    -- (b) If result is true, show P is true\n    intro result\n    dsimp at result\n    rcases result with ⟨x, hx⟩\n    use [0, ⟨Array.getElem? ⟨a, 0, ai⟩ hx.left, 0, b.contains_to_inj hx.right⟩]\n  }'}
2025-06-01 02:48:31,739 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:21:54: error: unsolved goals
a b : Array ℤ
⊢ (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔
    (if (a.isEmpty || b.isEmpty) = true then false else a.any fun x => b.contains x) = true
lean_playground/TempTest.lean:24:2: error: unexpected token 'by'; expected command
2025-06-01 02:48:31,740 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasCommonElement (a : Array Int) (b : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the method returns true, there exists at least one common element between the two arrays; If the method returns false, there are no common elements between the two arrays\ndef hasCommonElement_spec (a : Array Int) (b : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ result\n  -- << SPEC END >>\n\ntheorem hasCommonElement_spec_satisfied (a : Array Int) (b : Array Int) :\n  hasCommonElement_spec a b (hasCommonElement a b) := by\n  -- << PROOF START >>\n  unfold hasCommonElement hasCommonElement_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a.isEmpty || b.isEmpty then\n    false\n  else\n    a.any (fun x => b.contains x)\n\nGenerated Proof:\nby\n  intros a b\n  unfold hasCommonElement hasCommonElement_spec\n  by_cases h: a.isEmpty || b.isEmpty\n  \n  -- Case 1: a or b is empty\n  { simp [h]\n    intro nontrivial\n    cases nontrivial with i ji\n    cases ji with ai bi\n    cases ai with ai_in a_sz\n    cases bi with bj_in b_sz\n    \n    have : a.size ≠ 0 := a_sz\n    contradiction\n  }\n  \n  -- Case 2: Neither a nor b is empty\n  { simp [h]\n    intro h_existence\n    split\n    \n    -- (a) If P is true, show result is true\n    intro common\n    cases common with x ⟨i, ai⟩ ⟨j, bj⟩\n    apply Array.any_mem_of_inj ai (b.contains_mem bj)\n    \n    -- (b) If result is true, show P is true\n    intro result\n    dsimp at result\n    rcases result with ⟨x, hx⟩\n    use [0, ⟨Array.getElem? ⟨a, 0, ai⟩ hx.left, 0, b.contains_to_inj hx.right⟩]\n  }\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:21:54: error: unsolved goals\na b : Array ℤ\n⊢ (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔\n    (if (a.isEmpty || b.isEmpty) = true then false else a.any fun x => b.contains x) = true\nlean_playground/TempTest.lean:24:2: error: unexpected token 'by'; expected command"}], 'model': 'o3-mini'}}
2025-06-01 02:48:31,740 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:48:31,740 - DEBUG - close.started
2025-06-01 02:48:31,741 - DEBUG - close.complete
2025-06-01 02:48:31,741 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:48:31,748 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204291bb0>
2025-06-01 02:48:31,748 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:48:31,758 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204291370>
2025-06-01 02:48:31,758 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:48:31,758 - DEBUG - send_request_headers.complete
2025-06-01 02:48:31,758 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:48:31,758 - DEBUG - send_request_body.complete
2025-06-01 02:48:31,758 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:48:39,965 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:48:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7960'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7965'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198961'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'311ms'), (b'x-request-id', b'req_5f422a5b2d35086c4dc861d00c87f27a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b647ea8eb4436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:48:39,965 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:48:39,966 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:48:39,966 - DEBUG - receive_response_body.complete
2025-06-01 02:48:39,967 - DEBUG - response_closed.started
2025-06-01 02:48:39,967 - DEBUG - response_closed.complete
2025-06-01 02:48:39,967 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:48:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7960', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7965', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198961', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '311ms', 'x-request-id': 'req_5f422a5b2d35086c4dc861d00c87f27a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b647ea8eb4436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:48:39,967 - DEBUG - request_id: req_5f422a5b2d35086c4dc861d00c87f27a
2025-06-01 02:48:39,967 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof contains unsolved goals and syntactic errors. In particular, the error message 'unsolved goals' indicates that not all obligations were discharged, and the token 'by' appears unexpectedly, suggesting a misstructured tactic block. In addition, the proof uses non-existent or incorrectly applied lemmas (e.g., 'Array.any_mem_of_inj', 'b.contains_mem', 'b.contains_to_inj') that likely do not exist in the standard library, which further contributes to the failure.", 'error_type': 'proof', 'suggested_fix': "Revise the proof by explicitly splitting the 'if and only if' into two separate directions. For the case when one of the arrays is empty, show directly that the existence statement is false. For the non-empty case, prove both directions: (1) if there is a common element, then the function returns true, and (2) if the function returns true, then provide a witness for the existence of a common element. Remove or replace any non-existent lemmas with valid ones (for example, use direct case analysis or induction on the array) and ensure that the tactic blocks are correctly structured without extraneous tokens. Finally, check that all tactics properly close their goals before ending the proof block.", 'retry_strategy': "Restructure the proof by first using 'by_cases' to split the empty and non-empty cases. In each case, explicitly prove the two implications of the equivalence. Consider breaking the proof into smaller lemmas if necessary. Verify that all names and tactics align with Lean 4’s standard library and that there are no stray tokens. Once revised, re-run the proof to ensure that all goals are solved."}
2025-06-01 02:48:39,967 - INFO - Solution generated in 27.83 seconds
2025-06-01 02:48:39,967 - INFO - Generated code length: 81 characters
2025-06-01 02:48:39,968 - INFO - Generated proof length: 785 characters
2025-06-01 02:48:39,968 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:48:39,968 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:48:45,320 - INFO - Implementation test result: PASS
2025-06-01 02:48:45,320 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:48:50,703 - INFO - Full solution test result: FAIL
2025-06-01 02:48:50,703 - ERROR - Proof error: lean_playground/TempTest.lean:21:54: error: unsolved goals
a b : Array ℤ
⊢ (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔
    (if (a.isEmpty || b....
2025-06-01 02:48:50,703 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:48:50,703 - ERROR - ❌ Proof has errors
2025-06-01 02:48:50,703 - INFO - 
==================================================
2025-06-01 02:48:50,703 - INFO - Processing task task_id_433...
2025-06-01 02:48:50,703 - INFO - Reading problem description and code template from tasks/task_id_433...
2025-06-01 02:48:50,703 - INFO - Problem description length: 646 characters
2025-06-01 02:48:50,703 - INFO - Reading unit tests from tasks/task_id_433...
2025-06-01 02:48:50,703 - INFO - Unit tests length: 367 characters
2025-06-01 02:48:50,703 - INFO - Running main workflow to generate solution...
2025-06-01 02:48:50,704 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.

-----Input-----
The input consists of:
n: An integer.
a: An array of integers.

-----Output-----
The output is a Boolean value:
Returns true if the integer is greater than all elements in the array.
Returns false if there is at least one element in the array that is greater than or equal to the integer.

-----Note-----
The array is assumed to be non-null.
2025-06-01 02:48:50,704 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def isGreater (n : Int) (a : Array Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: If the result is true, then n is greater than all elements in the array; If the result is false, then there exists at least one element in the array that is greater than or equal to n
def isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=
  -- << SPEC START >>
  (∀ i, i < a.size → n > a[i]!) ↔ result
  -- << SPEC END >>

theorem isGreater_spec_satisfied (n : Int) (a : Array Int) :
  isGreater_spec n a (isGreater n a) := by
  -- << PROOF START >>
  unfold isGreater isGreater_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:48:50,732 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x74e203e823e0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:48:50,732 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:48:50,732 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:48:50,741 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e2042715e0>
2025-06-01 02:48:50,741 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e20448dcd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:48:50,751 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204270b00>
2025-06-01 02:48:50,751 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:48:50,751 - DEBUG - send_request_headers.complete
2025-06-01 02:48:50,751 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:48:50,751 - DEBUG - send_request_body.complete
2025-06-01 02:48:50,751 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:48:51,074 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:48:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'90'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7fbbd4cf65-s8cqc'), (b'x-envoy-upstream-service-time', b'93'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999838'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_8930dd2f2b6f9e979bef7b3251d4b951'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=NLKr8bUFj1msy3Rj4Vu2Eh4W6VDBmqNC2T5E2czh4Yw-1748746131-1.0.1.1-UpEdbIMpZf9Gxg9v3XEgyV22MI.yXvMy5inuGuBX.XGIvxJYgy0C8SidzYnUpRS7EAosZSE4AW9PjviHJE1h0ALUpkvL7IR2Q.yWfGxFG0k; path=/; expires=Sun, 01-Jun-25 03:18:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=j6MjuNw1mJliU2W1x8z2BBiGMu1mTDqzAFx_5MAEYMw-1748746131094-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b64f55a7446f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:48:51,074 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:48:51,074 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:48:51,075 - DEBUG - receive_response_body.complete
2025-06-01 02:48:51,075 - DEBUG - response_closed.started
2025-06-01 02:48:51,075 - DEBUG - response_closed.complete
2025-06-01 02:48:51,075 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:48:51 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '90'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-7fbbd4cf65-s8cqc'), ('x-envoy-upstream-service-time', '93'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999838'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '9ms'), ('x-request-id', 'req_8930dd2f2b6f9e979bef7b3251d4b951'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=NLKr8bUFj1msy3Rj4Vu2Eh4W6VDBmqNC2T5E2czh4Yw-1748746131-1.0.1.1-UpEdbIMpZf9Gxg9v3XEgyV22MI.yXvMy5inuGuBX.XGIvxJYgy0C8SidzYnUpRS7EAosZSE4AW9PjviHJE1h0ALUpkvL7IR2Q.yWfGxFG0k; path=/; expires=Sun, 01-Jun-25 03:18:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=j6MjuNw1mJliU2W1x8z2BBiGMu1mTDqzAFx_5MAEYMw-1748746131094-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b64f55a7446f0-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:48:51,075 - DEBUG - request_id: req_8930dd2f2b6f9e979bef7b3251d4b951
2025-06-01 02:48:51,080 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
 the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
2025-06-01 02:48:51,083 - DEBUG - close.started
2025-06-01 02:48:51,083 - DEBUG - close.complete
2025-06-01 02:48:51,093 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.'}], 'model': 'o3-mini'}}
2025-06-01 02:48:51,093 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:48:51,094 - DEBUG - close.started
2025-06-01 02:48:51,094 - DEBUG - close.complete
2025-06-01 02:48:51,094 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:48:51,100 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204271730>
2025-06-01 02:48:51,100 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:48:51,108 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e2042715b0>
2025-06-01 02:48:51,108 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:48:51,108 - DEBUG - send_request_headers.complete
2025-06-01 02:48:51,108 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:48:51,108 - DEBUG - send_request_body.complete
2025-06-01 02:48:51,108 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:48:57,788 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:48:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6434'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6439'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199537'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'138ms'), (b'x-request-id', b'req_da1475fc7c81c8239548e937ab7b2ab0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b64f79acd47bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:48:57,789 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:48:57,789 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:48:57,789 - DEBUG - receive_response_body.complete
2025-06-01 02:48:57,789 - DEBUG - response_closed.started
2025-06-01 02:48:57,789 - DEBUG - response_closed.complete
2025-06-01 02:48:57,789 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:48:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6434', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6439', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199537', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '138ms', 'x-request-id': 'req_da1475fc7c81c8239548e937ab7b2ab0', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b64f79acd47bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:48:57,789 - DEBUG - request_id: req_da1475fc7c81c8239548e937ab7b2ab0
2025-06-01 02:48:57,790 - INFO - Attempt 1/3
2025-06-01 02:48:57,790 - INFO - Current plan: {
  "plan_summary": "The goal is to implement a Lean 4 function that takes an integer and an array of integers, and returns true if and only if the integer is strictly greater than every element in the array. The approach involves iterating over the array and checking that each element is less than the given integer.",
  "steps": [
    "Define the function with the appropriate type signature accepting an integer and an array of integers.",
    "Iterate over the array, checking that each element is strictly less than the given integer. This may be done using a built-in function such as forall or by writing an explicit recursive function.",
    "Return true if the condition holds for all elements; otherwise, return false.",
    "Use pattern matching or higher-order functions to cleanly handle the iteration and condition checking.",
    "Optionally, prove correctness by structural induction on the array if a formal proof is required in the context of Lean 4."
  ],
  "code_keywords": [
    "Lean 4",
    "function",
    "Array",
    "forall",
    "iteration",
    "pattern matching",
    "recursion"
  ],
  "proof_keywords": [
    "structural induction",
    "inductive proof",
    "correctness",
    "base case",
    "inductive step"
  ],
  "assumptions": [
    "The array is non-null.",
    "The integer comparison uses the standard < operator.",
    "The Lean environment provides basic iteration utilities for arrays."
  ],
  "retry_guidance": "Review how Lean 4 handles arrays and if built-in functions like forall are available. Ensure that the type signatures match Lean's conventions for arrays and that the iteration logic correctly distinguishes strictly less-than comparisons."
}
2025-06-01 02:48:57,791 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "The goal is to implement a Lean 4 function that takes an integer and an array of integers, and returns true if and only if the integer is strictly greater than every element in the array. The approach involves iterating over the array and checking that each element is less than the given integer.",\n  "steps": [\n    "Define the function with the appropriate type signature accepting an integer and an array of integers.",\n    "Iterate over the array, checking that each element is strictly less than the given integer. This may be done using a built-in function such as forall or by writing an explicit recursive function.",\n    "Return true if the condition holds for all elements; otherwise, return false.",\n    "Use pattern matching or higher-order functions to cleanly handle the iteration and condition checking.",\n    "Optionally, prove correctness by structural induction on the array if a formal proof is required in the context of Lean 4."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function",\n    "Array",\n    "forall",\n    "iteration",\n    "pattern matching",\n    "recursion"\n  ],\n  "proof_keywords": [\n    "structural induction",\n    "inductive proof",\n    "correctness",\n    "base case",\n    "inductive step"\n  ],\n  "assumptions": [\n    "The array is non-null.",\n    "The integer comparison uses the standard < operator.",\n    "The Lean environment provides basic iteration utilities for arrays."\n  ],\n  "retry_guidance": "Review how Lean 4 handles arrays and if built-in functions like forall are available. Ensure that the type signatures match Lean\'s conventions for arrays and that the iteration logic correctly distinguishes strictly less-than comparisons."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isGreater (n : Int) (a : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the result is true, then n is greater than all elements in the array; If the result is false, then there exists at least one element in the array that is greater than or equal to n\ndef isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∀ i, i < a.size → n > a[i]!) ↔ result\n  -- << SPEC END >>\n\ntheorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n  isGreater_spec n a (isGreater n a) := by\n  -- << PROOF START >>\n  unfold isGreater isGreater_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The'}], 'model': 'gpt-4o'}}
2025-06-01 02:48:57,792 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:48:57,792 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:48:57,792 - DEBUG - send_request_headers.complete
2025-06-01 02:48:57,792 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:48:57,797 - DEBUG - send_request_body.complete
2025-06-01 02:48:57,797 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:49:02,537 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:49:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4433'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4436'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'16116'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'27.768s'), (b'x-request-id', b'req_58742e0a789b0282d5580b121d198956'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6521596647bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:49:02,537 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:49:02,537 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:49:02,542 - DEBUG - receive_response_body.complete
2025-06-01 02:49:02,542 - DEBUG - response_closed.started
2025-06-01 02:49:02,542 - DEBUG - response_closed.complete
2025-06-01 02:49:02,542 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:49:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4433', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4436', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '16116', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '27.768s', 'x-request-id': 'req_58742e0a789b0282d5580b121d198956', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6521596647bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:49:02,542 - DEBUG - request_id: req_58742e0a789b0282d5580b121d198956
2025-06-01 02:49:02,542 - INFO - Raw solution received: ```json
{
  "code": "a.all (fun x => n > x)",
  "proof": "\n    intro h\n    apply Iff.intro\n    \n    -- Proving (∀ i, i < a.size → n > a[i]) → isGreater n a = true\n    intro h₁\n    simp [h, h₁]\n    \n    -- Proving isGreater n a = true → (∀ i, i < a.size → n > a[i])\n    intro h₂ i h₃\n    simp [h, h₂] at h₃\n    exact h₃\n  "
}
```
2025-06-01 02:49:02,543 - INFO - <class 'str'>
2025-06-01 02:49:02,543 - INFO - Generated solution: {'code': 'a.all (fun x => n > x)', 'proof': '\n    intro h\n    apply Iff.intro\n    \n    -- Proving (∀ i, i < a.size → n > a[i]) → isGreater n a = true\n    intro h₁\n    simp [h, h₁]\n    \n    -- Proving isGreater n a = true → (∀ i, i < a.size → n > a[i])\n    intro h₂ i h₃\n    simp [h, h₂] at h₃\n    exact h₃\n  '}
2025-06-01 02:49:07,951 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:22:4: error: unknown identifier 'intro'
lean_playground/TempTest.lean:27:9: error: unexpected token '['; expected command
2025-06-01 02:49:07,952 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isGreater (n : Int) (a : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the result is true, then n is greater than all elements in the array; If the result is false, then there exists at least one element in the array that is greater than or equal to n\ndef isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∀ i, i < a.size → n > a[i]!) ↔ result\n  -- << SPEC END >>\n\ntheorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n  isGreater_spec n a (isGreater n a) := by\n  -- << PROOF START >>\n  unfold isGreater isGreater_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na.all (fun x => n > x)\n\nGenerated Proof:\n\n    intro h\n    apply Iff.intro\n    \n    -- Proving (∀ i, i < a.size → n > a[i]) → isGreater n a = true\n    intro h₁\n    simp [h, h₁]\n    \n    -- Proving isGreater n a = true → (∀ i, i < a.size → n > a[i])\n    intro h₂ i h₃\n    simp [h, h₂] at h₃\n    exact h₃\n  \n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:22:4: error: unknown identifier 'intro'\nlean_playground/TempTest.lean:27:9: error: unexpected token '['; expected command"}], 'model': 'o3-mini'}}
2025-06-01 02:49:07,952 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:49:07,952 - DEBUG - close.started
2025-06-01 02:49:07,953 - DEBUG - close.complete
2025-06-01 02:49:07,953 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:49:07,961 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204293980>
2025-06-01 02:49:07,961 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:49:07,970 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204292180>
2025-06-01 02:49:07,970 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:49:07,970 - DEBUG - send_request_headers.complete
2025-06-01 02:49:07,970 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:49:07,970 - DEBUG - send_request_body.complete
2025-06-01 02:49:07,970 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:49:22,494 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:49:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'14299'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'14301'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199152'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'254ms'), (b'x-request-id', b'req_68420162b395ef219db4e97685a72450'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6560fdac46f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:49:22,494 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:49:22,494 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:49:22,494 - DEBUG - receive_response_body.complete
2025-06-01 02:49:22,495 - DEBUG - response_closed.started
2025-06-01 02:49:22,495 - DEBUG - response_closed.complete
2025-06-01 02:49:22,495 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:49:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '14299', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '14301', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199152', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '254ms', 'x-request-id': 'req_68420162b395ef219db4e97685a72450', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6560fdac46f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:49:22,495 - DEBUG - request_id: req_68420162b395ef219db4e97685a72450
2025-06-01 02:49:22,495 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof failed to compile due to syntax issues. Lean reports an 'unknown identifier `intro`' error and an 'unexpected token '['; expected command'. This indicates that tactic commands are not recognized as written, likely due to improper tactic block formatting and/or incorrect tactic syntax in Lean 4.", 'error_type': 'syntax', 'suggested_fix': "Enclose the proof in an explicit tactic block (using 'begin ... end' or proper indentation after 'by') and ensure that tactics are used with correct Lean 4 syntax. For example, replace the generated proof with something like:\n\n  theorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n    isGreater_spec n a (isGreater n a) :=\n  begin\n    unfold isGreater isGreater_spec,\n    apply Iff.intro,\n    { intros h i hi,\n      -- Here use a tactic such as by simpa using the appropriate lemmas about Array.all\n      simp [Array.all] at h, exact h i hi },\n    { intro h,\n      -- Use appropriate reasoning to show that a.all (λ x, n > x) = true\n      simp [Array.all], exact fun x => h } \n  end\n\nAdjust the inner proofs with correct reasoning or use existing lemmas for Array.all if available.", 'retry_strategy': "Revise the proof section by properly formatting the tactic block and using Lean 4’s syntax for tactics. Make sure to import any required modules (if necessary) and verify that all tactic commands ('intros', 'simp', etc.) are recognized in the Lean 4 environment, then recompile."}
2025-06-01 02:49:22,495 - INFO - Solution generated in 31.79 seconds
2025-06-01 02:49:22,495 - INFO - Generated code length: 22 characters
2025-06-01 02:49:22,495 - INFO - Generated proof length: 263 characters
2025-06-01 02:49:22,496 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:49:22,496 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:49:27,906 - INFO - Implementation test result: PASS
2025-06-01 02:49:27,906 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:49:33,386 - INFO - Full solution test result: FAIL
2025-06-01 02:49:33,387 - ERROR - Proof error: lean_playground/TempTest.lean:22:4: error: unknown identifier 'intro'
lean_playground/TempTest.lean:27:9: error: unexpected token '['; expected comman...
2025-06-01 02:49:33,387 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:49:33,387 - ERROR - ❌ Proof has errors
2025-06-01 02:49:33,387 - INFO - 
==================================================
2025-06-01 02:49:33,387 - INFO - Processing task task_id_435...
2025-06-01 02:49:33,387 - INFO - Reading problem description and code template from tasks/task_id_435...
2025-06-01 02:49:33,387 - INFO - Problem description length: 596 characters
2025-06-01 02:49:33,387 - INFO - Reading unit tests from tasks/task_id_435...
2025-06-01 02:49:33,387 - INFO - Unit tests length: 231 characters
2025-06-01 02:49:33,387 - INFO - Running main workflow to generate solution...
2025-06-01 02:49:33,388 - INFO - Problem description: -----Description-----  
This task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.

-----Input-----  
The input consists of a single value:  
n: A non-negative integer.

-----Output-----  
The output is an integer:  
Returns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.

-----Note-----  
It is assumed that the input number n is non-negative.
2025-06-01 02:49:33,388 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def lastDigit (n : Nat) : Nat :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The returned digit d should be between 0 and 9; d should be the last digit of the input number n
def lastDigit_spec (n : Nat) (result : Nat) : Prop :=
  -- << SPEC START >>
  (0 ≤ result ∧ result < 10) ∧
  (n % 10 = result)
  -- << SPEC END >>

theorem lastDigit_spec_satisfied (n : Nat) :
  lastDigit_spec n (lastDigit n) := by
  -- << PROOF START >>
  unfold lastDigit lastDigit_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:49:33,416 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x74e203e82340>, 'json_data': {'input': '-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:49:33,417 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:49:33,417 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:49:33,424 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e2042a4860>
2025-06-01 02:49:33,424 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e204266650> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:49:33,432 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e2ee524440>
2025-06-01 02:49:33,432 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:49:33,433 - DEBUG - send_request_headers.complete
2025-06-01 02:49:33,433 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:49:33,433 - DEBUG - send_request_body.complete
2025-06-01 02:49:33,433 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:49:33,773 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:49:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'96'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-568fcbbc46-dd8hh'), (b'x-envoy-upstream-service-time', b'101'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999851'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_7638bf9b14acb158cc9194f1ef75e455'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=H7j_exps4ohhioxl97.qmbVwt5F2qABh4bOI407rPA4-1748746173-1.0.1.1-OO65whDBn6bQAl6uJPG7rTxtVLaPUvvvyqngWPBwlY4tnbWfJmNSlpe.9P5N6eVFEZAg1X4VuDTrKgHUAuWMCe3ijRuKqo0yXwEW2vMm.hU; path=/; expires=Sun, 01-Jun-25 03:19:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=c53Tjsa4oRCVgnu.fFvHanQIMkNPoFNJY4fSZLdqasQ-1748746173793-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b66001cd047bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:49:33,773 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:49:33,773 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:49:33,774 - DEBUG - receive_response_body.complete
2025-06-01 02:49:33,774 - DEBUG - response_closed.started
2025-06-01 02:49:33,774 - DEBUG - response_closed.complete
2025-06-01 02:49:33,774 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:49:33 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '96'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-568fcbbc46-dd8hh'), ('x-envoy-upstream-service-time', '101'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999851'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_7638bf9b14acb158cc9194f1ef75e455'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=H7j_exps4ohhioxl97.qmbVwt5F2qABh4bOI407rPA4-1748746173-1.0.1.1-OO65whDBn6bQAl6uJPG7rTxtVLaPUvvvyqngWPBwlY4tnbWfJmNSlpe.9P5N6eVFEZAg1X4VuDTrKgHUAuWMCe3ijRuKqo0yXwEW2vMm.hU; path=/; expires=Sun, 01-Jun-25 03:19:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=c53Tjsa4oRCVgnu.fFvHanQIMkNPoFNJY4fSZLdqasQ-1748746173793-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b66001cd047bc-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:49:33,774 - DEBUG - request_id: req_7638bf9b14acb158cc9194f1ef75e455
2025-06-01 02:49:33,782 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
 modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
2025-06-01 02:49:33,787 - DEBUG - close.started
2025-06-01 02:49:33,787 - DEBUG - close.complete
2025-06-01 02:49:33,803 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.'}], 'model': 'o3-mini'}}
2025-06-01 02:49:33,804 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:49:33,804 - DEBUG - close.started
2025-06-01 02:49:33,804 - DEBUG - close.complete
2025-06-01 02:49:33,804 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:49:33,811 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20429c9b0>
2025-06-01 02:49:33,811 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:49:33,819 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20473bf20>
2025-06-01 02:49:33,819 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:49:33,820 - DEBUG - send_request_headers.complete
2025-06-01 02:49:33,820 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:49:33,820 - DEBUG - send_request_body.complete
2025-06-01 02:49:33,820 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:49:38,963 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:49:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4904'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4909'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199550'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'135ms'), (b'x-request-id', b'req_6363f7d20fb53f38049e3d97631fb535'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b66028be03deb-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:49:38,964 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:49:38,964 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:49:38,964 - DEBUG - receive_response_body.complete
2025-06-01 02:49:38,964 - DEBUG - response_closed.started
2025-06-01 02:49:38,964 - DEBUG - response_closed.complete
2025-06-01 02:49:38,964 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:49:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4904', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4909', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199550', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '135ms', 'x-request-id': 'req_6363f7d20fb53f38049e3d97631fb535', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b66028be03deb-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:49:38,964 - DEBUG - request_id: req_6363f7d20fb53f38049e3d97631fb535
2025-06-01 02:49:38,965 - INFO - Attempt 1/3
2025-06-01 02:49:38,965 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that computes the last digit of a given non-negative integer using the modulus operator. The implementation is straightforward and relies on the assurance that the input is non-negative.",
  "steps": [
    "Define the function with a clear and descriptive name (e.g., last_digit) that accepts a natural number (n) as input.",
    "Utilize Lean's built-in modulus operator (%) to compute n mod 10.",
    "Ensure that the function returns a value between 0 and 9.",
    "Optionally, consider adding a simple proof or comment to verify that the result satisfies the required range and handles edge cases."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "modulus operator",
    "nat",
    "n mod 10"
  ],
  "proof_keywords": [
    "inductive reasoning (if needed for further correctness)",
    "modular arithmetic",
    "range verification",
    "boundary conditions"
  ],
  "assumptions": [
    "The input n is guaranteed to be a non-negative integer.",
    "The modulus operator (%) in Lean 4 returns a remainder between 0 and the divisor minus one."
  ],
  "retry_guidance": "If errors occur, verify that the correct type (nat) is used for the parameter and that the modulus operator is applied properly. Ensure the function signature matches Lean's syntax and that there is no ambiguity in the defined operation."
}
2025-06-01 02:49:38,966 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that computes the last digit of a given non-negative integer using the modulus operator. The implementation is straightforward and relies on the assurance that the input is non-negative.",\n  "steps": [\n    "Define the function with a clear and descriptive name (e.g., last_digit) that accepts a natural number (n) as input.",\n    "Utilize Lean\'s built-in modulus operator (%) to compute n mod 10.",\n    "Ensure that the function returns a value between 0 and 9.",\n    "Optionally, consider adding a simple proof or comment to verify that the result satisfies the required range and handles edge cases."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "modulus operator",\n    "nat",\n    "n mod 10"\n  ],\n  "proof_keywords": [\n    "inductive reasoning (if needed for further correctness)",\n    "modular arithmetic",\n    "range verification",\n    "boundary conditions"\n  ],\n  "assumptions": [\n    "The input n is guaranteed to be a non-negative integer.",\n    "The modulus operator (%) in Lean 4 returns a remainder between 0 and the divisor minus one."\n  ],\n  "retry_guidance": "If errors occur, verify that the correct type (nat) is used for the parameter and that the modulus operator is applied properly. Ensure the function signature matches Lean\'s syntax and that there is no ambiguity in the defined operation."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef lastDigit (n : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned digit d should be between 0 and 9; d should be the last digit of the input number n\ndef lastDigit_spec (n : Nat) (result : Nat) : Prop :=\n  -- << SPEC START >>\n  (0 ≤ result ∧ result < 10) ∧\n  (n % 10 = result)\n  -- << SPEC END >>\n\ntheorem lastDigit_spec_satisfied (n : Nat) :\n  lastDigit_spec n (lastDigit n) := by\n  -- << PROOF START >>\n  unfold lastDigit lastDigit_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 02:49:38,967 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:49:38,967 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:49:38,967 - DEBUG - send_request_headers.complete
2025-06-01 02:49:38,967 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:49:38,972 - DEBUG - send_request_body.complete
2025-06-01 02:49:38,972 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:49:42,116 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:49:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2888'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2891'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'12165'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'35.67s'), (b'x-request-id', b'req_2177a1078321ed67470e493dec6038cf'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6622bf2c3deb-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:49:42,116 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:49:42,116 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:49:42,117 - DEBUG - receive_response_body.complete
2025-06-01 02:49:42,117 - DEBUG - response_closed.started
2025-06-01 02:49:42,117 - DEBUG - response_closed.complete
2025-06-01 02:49:42,117 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:49:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2888', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2891', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '12165', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '35.67s', 'x-request-id': 'req_2177a1078321ed67470e493dec6038cf', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6622bf2c3deb-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:49:42,117 - DEBUG - request_id: req_2177a1078321ed67470e493dec6038cf
2025-06-01 02:49:42,117 - INFO - Raw solution received: ```json
{
  "code": "n % 10",
  "proof": "\n  by_cases h: n < 10\n  simp [h]\n  · have : n % 10 = n := Nat.mod_eq_of_lt h\n    simp [this, h]\n  · have : n % 10 < 10 := Nat.mod_lt _ (by decide)\n    simp [this, h]\n  · exact h\n"
}
```
2025-06-01 02:49:42,117 - INFO - <class 'str'>
2025-06-01 02:49:42,117 - INFO - Generated solution: {'code': 'n % 10', 'proof': '\n  by_cases h: n < 10\n  simp [h]\n  · have : n % 10 = n := Nat.mod_eq_of_lt h\n    simp [this, h]\n  · have : n % 10 < 10 := Nat.mod_lt _ (by decide)\n    simp [this, h]\n  · exact h\n'}
2025-06-01 02:49:47,210 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:29:2: error: no goals to be solved
2025-06-01 02:49:47,211 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef lastDigit (n : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned digit d should be between 0 and 9; d should be the last digit of the input number n\ndef lastDigit_spec (n : Nat) (result : Nat) : Prop :=\n  -- << SPEC START >>\n  (0 ≤ result ∧ result < 10) ∧\n  (n % 10 = result)\n  -- << SPEC END >>\n\ntheorem lastDigit_spec_satisfied (n : Nat) :\n  lastDigit_spec n (lastDigit n) := by\n  -- << PROOF START >>\n  unfold lastDigit lastDigit_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nn % 10\n\nGenerated Proof:\n\n  by_cases h: n < 10\n  simp [h]\n  · have : n % 10 = n := Nat.mod_eq_of_lt h\n    simp [this, h]\n  · have : n % 10 < 10 := Nat.mod_lt _ (by decide)\n    simp [this, h]\n  · exact h\n\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:29:2: error: no goals to be solved'}], 'model': 'o3-mini'}}
2025-06-01 02:49:47,211 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:49:47,211 - DEBUG - close.started
2025-06-01 02:49:47,212 - DEBUG - close.complete
2025-06-01 02:49:47,212 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:49:47,219 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204292240>
2025-06-01 02:49:47,220 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:49:47,229 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e203e6e9f0>
2025-06-01 02:49:47,229 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:49:47,229 - DEBUG - send_request_headers.complete
2025-06-01 02:49:47,229 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:49:47,229 - DEBUG - send_request_body.complete
2025-06-01 02:49:47,229 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:49:54,895 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:49:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7441'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7444'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199251'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'224ms'), (b'x-request-id', b'req_5e1331a8b21249f9e3b05b87a962dedd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b665659414436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:49:54,896 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:49:54,896 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:49:54,896 - DEBUG - receive_response_body.complete
2025-06-01 02:49:54,896 - DEBUG - response_closed.started
2025-06-01 02:49:54,896 - DEBUG - response_closed.complete
2025-06-01 02:49:54,896 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:49:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7441', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7444', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199251', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '224ms', 'x-request-id': 'req_5e1331a8b21249f9e3b05b87a962dedd', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b665659414436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:49:54,896 - DEBUG - request_id: req_5e1331a8b21249f9e3b05b87a962dedd
2025-06-01 02:49:54,897 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails because after using 'by_cases', there is an extraneous branch with 'exact h' that is not solving any goal, leading to the error 'no goals to be solved'. Moreover, the case-analysis is unnecessary for this trivial equality since lastDigit is defined as n % 10 and the properties about Nat.mod hold automatically.", 'error_type': 'proof', 'suggested_fix': 'Replace the by_cases proof with a simpler proof. One way to fix the proof is to use simp and known lemmas from Nat, such as Nat.mod_lt for the bound and Nat.zero_le. For example:\n\n  theorem lastDigit_spec_satisfied (n : Nat) :\n    lastDigit_spec n (lastDigit n) := by\n      simp [lastDigit, lastDigit_spec, Nat.mod_lt, Nat.zero_le]\n\nThis directly shows that (n % 10) is between 0 and 9 (using Nat.mod_lt) and that n % 10 equals lastDigit n.', 'retry_strategy': 'Simplify the proof by avoiding unnecessary case analysis and directly invoking simp to close the goals using the definitions and available lemmas.'}
2025-06-01 02:49:54,897 - INFO - Solution generated in 21.51 seconds
2025-06-01 02:49:54,897 - INFO - Generated code length: 6 characters
2025-06-01 02:49:54,897 - INFO - Generated proof length: 178 characters
2025-06-01 02:49:54,897 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:49:54,897 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:50:00,102 - INFO - Implementation test result: PASS
2025-06-01 02:50:00,102 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:50:05,497 - INFO - Full solution test result: FAIL
2025-06-01 02:50:05,497 - ERROR - Proof error: lean_playground/TempTest.lean:29:2: error: no goals to be solved...
2025-06-01 02:50:05,497 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:50:05,497 - ERROR - ❌ Proof has errors
2025-06-01 02:50:05,497 - INFO - 
==================================================
2025-06-01 02:50:05,497 - INFO - Processing task task_id_441...
2025-06-01 02:50:05,497 - INFO - Reading problem description and code template from tasks/task_id_441...
2025-06-01 02:50:05,497 - INFO - Problem description length: 489 characters
2025-06-01 02:50:05,497 - INFO - Reading unit tests from tasks/task_id_441...
2025-06-01 02:50:05,497 - INFO - Unit tests length: 171 characters
2025-06-01 02:50:05,497 - INFO - Running main workflow to generate solution...
2025-06-01 02:50:05,498 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.

-----Input-----
The input consists of:
size: An integer representing the length of an edge of the cube.

-----Output-----
The output is an integer:
Returns the surface area of the cube.

-----Note-----
The input edge length is assumed to be greater than 0.
2025-06-01 02:50:05,498 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def cubeSurfaceArea (size : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The surface area of the cube is calculated correctly
def cubeSurfaceArea_spec (size : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  result = 6 * size * size
  -- << SPEC END >>

theorem cubeSurfaceArea_spec_satisfied (size : Int):
  cubeSurfaceArea_spec size (cubeSurfaceArea size) := by
  -- << PROOF START >>
  unfold cubeSurfaceArea cubeSurfaceArea_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:50:05,527 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x74e203e837e0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.\n\n-----Input-----\nThe input consists of:\nsize: An integer representing the length of an edge of the cube.\n\n-----Output-----\nThe output is an integer:\nReturns the surface area of the cube.\n\n-----Note-----\nThe input edge length is assumed to be greater than 0.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:50:05,527 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:50:05,527 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:50:05,537 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204271370>
2025-06-01 02:50:05,537 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e20448fad0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:50:05,545 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e2042730b0>
2025-06-01 02:50:05,546 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:50:05,546 - DEBUG - send_request_headers.complete
2025-06-01 02:50:05,546 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:50:05,546 - DEBUG - send_request_body.complete
2025-06-01 02:50:05,546 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:50:05,857 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:50:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'76'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7fbbd4cf65-c6gnk'), (b'x-envoy-upstream-service-time', b'81'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999877'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_b169272c6cd7dfc298748246cd1168e8'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=iW.WwGkexuszPjxqxGM2AHQ5ocgpzcic7d5gJ9NyLXw-1748746205-1.0.1.1-9XYGgvzc5hCZWB2hVmSnLtlNAe96ZO.20Zd_Q0UejSYlZecQ6RwWkg657bMYR3anIk_3HFeijHRr67j237icko4jWJj9oucz.5fb13_IETg; path=/; expires=Sun, 01-Jun-25 03:20:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=7e.3y_.b6CNEsy_IvMsMNf1Ff7dJ5IoCSGmiRf8JGts-1748746205878-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b66c8d99f46f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:50:05,858 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:50:05,858 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:50:05,858 - DEBUG - receive_response_body.complete
2025-06-01 02:50:05,858 - DEBUG - response_closed.started
2025-06-01 02:50:05,858 - DEBUG - response_closed.complete
2025-06-01 02:50:05,858 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:50:05 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '76'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-7fbbd4cf65-c6gnk'), ('x-envoy-upstream-service-time', '81'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999877'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '7ms'), ('x-request-id', 'req_b169272c6cd7dfc298748246cd1168e8'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=iW.WwGkexuszPjxqxGM2AHQ5ocgpzcic7d5gJ9NyLXw-1748746205-1.0.1.1-9XYGgvzc5hCZWB2hVmSnLtlNAe96ZO.20Zd_Q0UejSYlZecQ6RwWkg657bMYR3anIk_3HFeijHRr67j237icko4jWJj9oucz.5fb13_IETg; path=/; expires=Sun, 01-Jun-25 03:20:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=7e.3y_.b6CNEsy_IvMsMNf1Ff7dJ5IoCSGmiRf8JGts-1748746205878-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b66c8d99f46f0-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:50:05,858 - DEBUG - request_id: req_b169272c6cd7dfc298748246cd1168e8
2025-06-01 02:50:05,863 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
 modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
 m by rw [Nat.zero_add, Nat.add_zero])
       (fun (n : Nat) (ih : m + n = n + m) =>
        show m + succ n = succ n + m from
        calc m + succ n
          _ = succ (m + n) := rfl
          _ = succ (n + m) := by rw [ih]
          _ = succ n + m   := sorry)
    

At this point, we see that we need another supporting fact, namely, that `succ
(n + m) = succ n + m`. You can prove this by induction on `m`:

    
    
    open Nat
    
    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m
        (show succ n + 0 = succ (n + 0) from rfl)
        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>
         show succ n + succ m = succ (n + succ m) from
         calc succ n + succ m
           _ = succ (succ n + m)   := rfl
           _ = succ (succ (n + m)) := by rw [ih]
           _ = succ (n + succ m)   := rfl)
    

You can then replace the `sorry` in the previous proof with `succ_add`. Yet
again, the proofs can be compressed:

    
    
    namespace Hidden
    open Nat
    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m
        rfl
        (fun m ih => by simp only [add_succ, ih])
    
    theorem add_comm (m n : Nat) : m + n = n + m :=
      Nat.recOn (motive := fun x => m + x = x + m) n
        (by simp)
        (fun m ih => by simp [add_succ, succ_add, ih])
    end Hidden
    

## Other Recursive Data Types

Let us consider some more examples of inductively defined types. For any type,
`α`, the type `List α` of lists of elements of `α` is defined in the library.

    
    
    namespace Hidden
    inductive List (α : Type u) where
      | nil  : List α
      | cons : α → List α → List α
    
    namespace List
    
    def append (as bs : List α) : List α :=
      match as with
      | nil       => bs
      | cons a as => cons a (append as bs)
    
    theorem nil_append (as : List α) : append nil as = as :=
      rfl
    
    theorem cons_append (a : α) (as bs : List α)
                        : append (cons a as) bs = cons a (append as bs) :=
      rfl
    
    end List
    end Hidden
    

A list of elements of type `α` is either the empty list, `nil`, or an element
`h : α` followed by a list `t : List α`. The first element, `h`, is commonly
known as the "head" of the list, and the remainder, `t`, is known as the
"tail."

As an exercise, prove the following:

    
    
    namespace Hidden
    inductive List (α : Type u) where
    | nil  : List α
    | cons : α → List α → List α
    namespace List
    def append (as bs : List α) : List α :=
     match as with
     | nil       => bs
     | cons a as => cons a (append as bs)
    theorem nil_append (as : List α) : append nil as = as :=
     rfl
    theorem cons_append (a : α) (as bs : List α)
                        : append (cons a as) bs = cons a (append as bs) :=
     rfl
    theorem append_nil (as : List α) : append as nil = as :=
      sorry
    
    theorem append_assoc (as bs cs : List α)
            : append (append as bs) cs = append as (append bs cs) :=
      sorry
    end List
    end Hidden
    

Try also defining the function `length : {α : Type u} → List α → Nat` that
returns the length of a list, and prove that it behaves as expected (for
example, `length (append as bs) = length as + length bs`).

For another example, we can define the type of binary trees:

    
    
    inductive BinaryTree where
      | leaf : BinaryTree
      | node : BinaryTree → BinaryTree → BinaryTree
    

In fact, we can even define the type of countably branching trees:

    
    
    inductive CBTree where
      | leaf : CBTree
      | sup : (Nat → CBTree) → CBTree
    
    namespace CBTree
    
    def succ (t : CBTree) : CBTree :=
      sup (fun _ => t)
    
    def toCBTree : Nat → CBTree
      | 0 => leaf
      | n+1 => succ (toCBTree n)
    
    def omega : CBTree :=
      sup toCBTree
    
    end CBTree
    

## Tactics for Inductive Types

Given the fundamental importance of inductive types in Lean, it should not be
surprising that there are a number of tactics designed to work with them
effectively. We describe some of them here.

The `cases` tactic works on elements of an inductively defined type, and does
what the name suggests: it decomposes the element according to each of the
possible constructors. In its most basic form, it is applied to an element `x`
in the local context. It then reduces the goal to cases in which `x` is
replaced by each of the constructions.

    
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by
      intro n
      cases n
      . exact hz  -- goal is p 0
      . apply hs  -- goal is a : Nat ⊢ p (succ a)
    

There are extra bells and whistles. For one thing, `cases` allows you to
choose the names for each alternative using a `with` clause. In the next
example, for example, we choose the name `m` for the argument to `succ`, so
that the second case refers to `succ m`. More importantly, the cases tactic
will detect any items in the local context that depend on the target variable.
It reverts these elements, does the split, and reintroduces them. In the
example below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in
the first branch, and `h : succ m ≠ 0` in the second.

    
    
    open Nat
    
    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by
      cases n with
      | zero =>
        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0
        apply absurd rfl h
      | succ m =>
        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m
        rfl
    

Notice that `cases` can be used to produce data as well as prove propositions.

    
    
    def f (n : Nat) : Nat := by
      cases n; exact 3; exact 7
    
    example : f 0 = 3 := rfl
    example : f 5 = 7 := rfl
    

Once again, cases will revert, split, and then reintroduce dependencies in the
context.

    
    
    def Tuple (α : Type) (n : Nat) :=
      { as : List α // as.length = n }
    
    def f {n : Nat} (t : Tuple α n) : Nat := by
      cases n; exact 3; exact 7
    
    def myTuple : Tuple Nat 3 :=
      ⟨[0, 1, 2], rfl⟩
    
    example : f myTuple = 7 :=
      rfl
    

Here is an example of multiple constructors with arguments.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    
    def silly (x : Foo) : Nat := by
      cases x with
      | bar1 a b => exact b
      | bar2 c d e => exact e
    

The alternatives for each constructor don't need to be solved in the order the
constructors were declared.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x with
      | bar2 c d e => exact e
      | bar1 a b => exact b
    

The syntax of the `with` is convenient for writing structured proofs. Lean
also provides a complementary `case` tactic, which allows you to focus on goal
assign variable names.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x
      case bar1 a b => exact b
      case bar2 c d e => exact e
    

The `case` tactic is clever, in that it will match the constructor to the
appropriate goal. For example, we can fill the goals above in the opposite
order:

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x
      case bar2 c d e => exact e
      case bar1 a b => exact b
    

You can also use `cases` with an arbitrary expression. Assuming that
expression occurs in the goal, the cases tactic will generalize over the
expression, introduce the resulting universally quantified variable, and case
on that.

    
    
    open Nat
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
            : p (m + 3 * k) := by
      cases m + 3 * k
      exact hz   -- goal is p 0
      apply hs   -- goal is a : Nat ⊢ p (succ a)
    

Think of this as saying "split on cases as to whether `m + 3 * k` is zero or
the successor of some number." The result is functionally equivalent to the
following:

    
    
    open Nat
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
            : p (m + 3 * k) := by
      generalize m + 3 * k = n
      cases n
      exact hz   -- goal is p 0
      apply hs   -- goal is a : Nat ⊢ p (succ a)
    

Notice that the expression `m + 3 * k` is erased by `generalize`; all that
matters is whether it is of the form `0` or `succ a`. This form of `cases`
will _not_ revert any hypotheses that also mention the expression in the
equation (in this case, `m + 3 * k`). If such a term appears in a hypothesis
and you want to generalize over that as well, you need to `revert` it
explicitly.

If the expression you case on does not appear in the goal, the `cases` tactic
uses `have` to put the type of the expression into the context. Here is an
example:

    
    
    example (p : Prop) (m n : Nat)
            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by
      cases Nat.lt_or_ge m n
      case inl hlt => exact h₁ hlt
      case inr hge => exact h₂ hge
    

The theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to
think of the proof above as splitting on these two cases. In the first branch,
we have the hypothesis `hlt : m < n`, and in the second we have the hypothesis
`hge : m ≥ n`. The proof above is functionally equivalent to the following:

    
    
    example (p : Prop) (m n : Nat)
            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by
      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n
      cases h
      case inl hlt => exact h₁ hlt
      case inr hge => exact h₂ hge
    

After the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we
simply do cases on that.

Here is another example, where we use the decidability of equality on the
natural numbers to split on the cases `m = n` and `m ≠ n`.

    
    
    #check Nat.sub_self
    
    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by
      cases Decidable.em (m = n) with
      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n
      | inr hne => apply Or.inr; exact hne
    

Remember that if you `open Classical`, you can use the law of the excluded
middle for any proposition at all. But using type class inference (see
[Chapter Type Classes](./type_classes.html)), Lean can actually find the
relevant decision procedure, which means that you can use the case split in a
computable function.

Just as the `cases` tactic can be used to carry out proof by cases, the
`induction` tactic can be used to carry out proofs by induction. The syntax is
similar to that of `cases`, except that the argument can only be a term in the
local context. Here is an example:

    
    
    namespace Hidden
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n with
      | zero => rfl
      | succ n ih => rw [Nat.add_succ, ih]
    end Hidden
    

As with `cases`, we can use the `case` tactic instead of `with`.

    
    
    namespace Hidden
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n
      case zero => rfl
      case succ n ih => rw [Nat.add_succ, ih]
    end Hidden
    

Here are some additional examples:

    
    
    namespace Hidden
    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n
    open Nat
    
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n <;> simp [*, add_zero, add_succ]
    
    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by
      induction n <;> simp [*, add_zero, add_succ]
    
    theorem add_comm (m n : Nat) : m + n = n + m := by
      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]
    
    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by
      induction k <;> simp [*, add_zero, add_succ]
    end Hidden
    

The `induction` tactic also supports user-defined induction principles with
multiple targets (aka major premises).

    
    
    /-
    theorem Nat.mod.inductionOn
          {motive : Nat → Nat → Sort u}
          (x y  : Nat)
          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)
          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)
          : motive x y :=
    -/
    
    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by
      induction x, y using Nat.mod.inductionOn with
      | ind x y h₁ ih =>
        rw [Nat.mod_eq_sub_mod h₁.2]
        exact ih h
      | base x y h₁ =>
        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁
        match this with
        | Or.inl h₁ => exact absurd h h₁
        | Or.inr h₁ =>
          have hgt : y > x := Nat.gt_of_not_le h₁
          rw [← Nat.mod_eq_of_lt hgt] at hgt
          assumption
    

You can use the `match` notation in tactics too:

    
    
    example : p ∨ q → q ∨ p := by
      intro h
      match h with
      | Or.inl _  => apply Or.inr; assumption
      | Or.inr h2 => apply Or.inl; exact h2
    

As a convenience, pattern-matching has been integrated into tactics such as
`intro` and `funext`.

    
    
    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by
      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩
      exact ⟨hq, hp⟩
    
    example :
        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)
        =
        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by
      funext (a, b) (c, d)
      show a + d = d + a
      rw [Nat.add_comm]
    

We close this section with one last tactic that is designed to facilitate
working with inductive types, namely, the `injection` tactic. By design, the
elements of an inductive type are freely generated, which is to say, the
constructors are injective and have disjoint ranges. The `injection` tactic is
designed to make use of this fact:

    
    
    open Nat
    
    example (m n k : Nat) (h : succ (succ m) = succ (succ n))
            : n + k = m + k := by
      injection h with h'
      injection h' with h''
      rw [h'']
    

The first instance of the tactic adds `h' : succ m = succ n` to the context,
and the second adds `h'' : m = n`.

The `injection` tactic also detects contradictions that arise when different
constructors are set equal to one another, and uses them to close the goal.

    
    
    open Nat
    
    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
      injection h
    
    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
      contradiction
    
    example (h : 7 = 4) : False := by
      contradiction
    

As the second example shows, the `contradiction` tactic also detects
contradictions of this form.

## Inductive Families

We are almost done describing the full range of inductive definitions accepted
by Lean. So far, you have seen that Lean allows you to introduce inductive
types with any number of recursive constructors. In fact, a single inductive
definition can introduce an indexed _family_ of inductive types, in a manner
we now describe.

An inductive family is an indexed family of types defined by a simultaneous
induction of the following form:

    
    
    inductive foo : ... → Sort u where
      | constructor₁ : ... → foo ...
      | constructor₂ : ... → foo ...
      ...
      | constructorₙ : ... → foo ...
    

In contrast to an ordinary inductive definition, which constructs an element
of some `Sort u`, the more general version constructs a function `... → Sort
u`, where "`...`" denotes a sequence of argument types, also known as
_indices_. Each constructor then constructs an element of some member of the
family. One example is the definition of `Vector α n`, the type of vectors of
elements of `α` of length `n`:

    
    
    namespace Hidden
    inductive Vector (α : Type u) : Nat → Type u where
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    end Hidden
    

Notice that the `cons` constructor takes an element of `Vector α n` and
returns an element of `Vector α (n+1)`, thereby using an element of one member
of the family to build an element of another.

A more exotic example is given by the definition of the equality type in Lean:

    
    
    namespace Hidden
    inductive Eq {α : Sort u} (a : α) : α → Prop where
      | refl : Eq a a
    end Hidden
    

For each fixed `α : Sort u` and `a : α`, this definition constructs a family
of types `Eq a x`, indexed by `x : α`. Notably, however, there is only one
constructor, `refl`, which is an element of `Eq a a`. Intuitively, the only
way to construct a proof of `Eq a x` is to use reflexivity, in the case where
`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of
types `Eq a x`. The elimination principle generated by Lean is as follows:

    
    
    universe u v
    
    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}
                      → motive a rfl → {b : α} → (h : a = b) → motive b h)
    

It is a remarkable fact that all the basic axioms for equality follow from the
constructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality
is atypical, however; see the discussion in Section Axiomatic Details.

The recursor `Eq.rec` is also used to define substitution:

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      Eq.rec (motive := fun x _ => p x) h₂ h₁
    end Hidden
    

You can also define `subst` using `match`.

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      match h₁ with
      | rfl => h₂
    end Hidden
    

Actually, Lean compiles the `match` expressions using a definition based on
`Eq.rec`.

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      match h₁ with
      | rfl => h₂
    
    set_option pp.all true
    #print subst
      -- ... subst.match_1 ...
    #print subst.match_1
      -- ... Eq.casesOn ...
    #print Eq.casesOn
      -- ... Eq.rec ...
    end Hidden
    

Using the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are
the same, in which case, `p b` and `p a` are the same.

It is not hard to prove that `Eq` is symmetric and transitive. In the
following example, we prove `symm` and leave as exercises the theorems `trans`
and `congr` (congruence).

    
    
    namespace Hidden
    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=
      match h with
      | rfl => rfl
    
    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=
      sorry
    
    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=
      sorry
    end Hidden
    

In the type theory literature, there are further generalizations of inductive
definitions, for example, the principles of _induction-recursion_ and
_induction-induction_. These are not supported by Lean.

## Axiomatic Details

We have described inductive types and their syntax through examples. This
section provides additional information for those interested in the axiomatic
foundations.

We have seen that the constructor to an inductive type takes _parameters_ \---
intuitively, the arguments that remain fixed throughout the inductive
construction --- and _indices_ , the arguments parameterizing the family of
types that is simultaneously under construction. Each constructor should have
a type, where the argument types are built up from previously defined types,
the parameter and index types, and the inductive family currently being
defined. The requirement is that if the latter is present at all, it occurs
only _strictly positively_. This means simply that any argument to the
constructor in which it occurs is a dependent arrow type in which the
inductive type under definition occurs only as the resulting type, where the
indices are given in terms of constants and previous arguments.

Since an inductive type lives in `Sort u` for some `u`, it is reasonable to
ask _which_ universe levels `u` can be instantiated to. Each constructor `c`
in the definition of a family `C` of inductive types is of the form

    
    
      c : (a : α) → (b : β[a]) → C a p[a,b]
    

where `a` is a sequence of data type parameters, `b` is the sequence of
arguments to the constructors, and `p[a, b]` are the indices, which determine
which element of the inductive family the construction inhabits. (Note that
this description is somewhat misleading, in that the arguments to the
constructor can appear in any order as long as the dependencies make sense.)
The constraints on the universe level of `C` fall into two cases, depending on
whether or not the inductive type is specified to land in `Prop` (that is,
`Sort 0`).

Let us first consider the case where the inductive type is _not_ specified to
land in `Prop`. Then the universe level `u` is constrained to satisfy the
following:

> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,
> if `βk[a] : Sort v`, we have `u` ≥ `v`.

In other words, the universe level `u` is required to be at least as large as
the universe level of each type that represents an argument to a constructor.

When the inductive type is specified to land in `Prop`, there are no
constraints on the universe levels of the constructor arguments. But these
universe levels do have a bearing on the elimination rule. Generally speaking,
for an inductive type in `Prop`, the motive of the elimination rule is
required to be in `Prop`.

There is an exception to this last rule: we are allowed to eliminate from an
inductively defined `Prop` to an arbitrary `Sort` when there is only one
constructor and each constructor argument is either in `Prop` or an index. The
intuition is that in this case the elimination does not make use of any
information that is not already given by the mere fact that the type of
argument is inhabited. This special case is known as _singleton elimination_.

We have already seen singleton elimination at play in applications of
`Eq.rec`, the eliminator for the inductively defined equality type. We can use
an element `h : Eq a b` to cast an element `t' : p a` to `p b` even when `p a`
and `p b` are arbitrary types, because the cast does not produce new data; it
only reinterprets the data we already have. Singleton elimination is also used
with heterogeneous equality and well-founded recursion, which will be
discussed in a [Chapter Induction and
Recursion](./induction_and_recursion.html#well-founded-recursion-and-
induction).

## Mutual and Nested Inductive Types

We now consider two generalizations of inductive types that are often useful,
which Lean supports by "compiling" them down to the more primitive kinds of
inductive types described above. In other words, Lean parses the more general
definitions, defines auxiliary inductive types based on them, and then uses
the auxiliary types to define the ones we really want. Lean's equation
compiler, described in the next chapter, is needed to make use of these types
effectively. Nonetheless, it makes sense to describe the declarations here,
because they are straightforward variations on ordinary inductive definitions.

First, Lean supports _mutually defined_ inductive types. The idea is that we
can define two (or more) inductive types at the same time, where each one
refers to the other(s).

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : (n : Nat) → Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : (n : Nat) → Even n → Odd (n + 1)
    end
    

In this example, two types are defined simultaneously: a natural number `n` is
`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one
more than an `Even` number. In the exercises below, you are asked to spell out
the details.

A mutual inductive definition can also be used to define the notation of a
finite tree with nodes labelled by elements of `α`:

    
    
    mutual
        inductive Tree (α : Type u) where
          | node : α → TreeList α → Tree α
    
        inductive TreeList (α : Type u) where
          | nil  : TreeList α
          | cons : Tree α → TreeList α → TreeList α
    end
    

With this definition, one can construct an element of `Tree α` by giving an
element of `α` together with a list of subtrees, possibly empty. The list of
subtrees is represented by the type `TreeList α`, which is defined to be
either the empty list, `nil`, or the `cons` of a tree and an element of
`TreeList α`.

This definition is inconvenient to work with, however. It would be much nicer
if the list of subtrees were given by the type `List (Tree α)`, especially
since Lean's library contains a number of functions and theorems for working
with lists. One can show that the type `TreeList α` is _isomorphic_ to `List
(Tree α)`, but translating results back and forth along this isomorphism is
tedious.

In fact, Lean allows us to define the inductive type we really want:

    
    
    inductive Tree (α : Type u) where
      | mk : α → List (Tree α) → Tree α
    

This is known as a _nested_ inductive type. It falls outside the strict
specification of an inductive type given in the last section because `Tree`
does not occur strictly positively among the arguments to `mk`, but, rather,
nested inside the `List` type constructor. Lean then automatically builds the
isomorphism between `TreeList α` and `List (Tree α)` in its kernel, and
defines the constructors for `Tree` in terms of the isomorphism.

## Exercises

  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.

Since many of these are already defined in Lean's core library, you should
work within a namespace named `Hidden`, or something like that, in order to
avoid name clashes.

  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:

a. `length (s ++ t) = length s + length t`

b. `length (reverse t) = length t`

c. `reverse (reverse t) = t`

  3. Define an inductive data type consisting of terms built up from the following constructors:

     * `const n`, a constant denoting the natural number `n`
     * `var n`, a variable, numbered `n`
     * `plus s t`, denoting the sum of `s` and `t`
     * `times s t`, denoting the product of `s` and `t`

Recursively define a function that evaluates any such term with respect to an
assignment of values to the variables.

  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.

[ __](interacting_with_lean.html "Previous chapter") [
__](induction_and_recursion.html "Next chapter")

[ __](interacting_with_lean.html "Previous chapter") [
__](induction_and_recursion.html "Next chapter")
2025-06-01 02:50:05,867 - DEBUG - close.started
2025-06-01 02:50:05,867 - DEBUG - close.complete
2025-06-01 02:50:05,879 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.\n\n-----Input-----\nThe input consists of:\nsize: An integer representing the length of an edge of the cube.\n\n-----Output-----\nThe output is an integer:\nReturns the surface area of the cube.\n\n-----Note-----\nThe input edge length is assumed to be greater than 0.'}], 'model': 'o3-mini'}}
2025-06-01 02:50:05,879 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:50:05,879 - DEBUG - close.started
2025-06-01 02:50:05,879 - DEBUG - close.complete
2025-06-01 02:50:05,880 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:50:05,886 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204273e90>
2025-06-01 02:50:05,886 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:50:05,894 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204272180>
2025-06-01 02:50:05,894 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:50:05,894 - DEBUG - send_request_headers.complete
2025-06-01 02:50:05,894 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:50:05,894 - DEBUG - send_request_body.complete
2025-06-01 02:50:05,894 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:50:10,204 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:50:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4083'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4085'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199577'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'126ms'), (b'x-request-id', b'req_46e03d39d810ebc9677cf802d2f79364'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b66cb0d9047bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:50:10,204 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:50:10,204 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:50:10,205 - DEBUG - receive_response_body.complete
2025-06-01 02:50:10,205 - DEBUG - response_closed.started
2025-06-01 02:50:10,205 - DEBUG - response_closed.complete
2025-06-01 02:50:10,205 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:50:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4083', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4085', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199577', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '126ms', 'x-request-id': 'req_46e03d39d810ebc9677cf802d2f79364', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b66cb0d9047bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:50:10,205 - DEBUG - request_id: req_46e03d39d810ebc9677cf802d2f79364
2025-06-01 02:50:10,205 - INFO - Attempt 1/3
2025-06-01 02:50:10,205 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that takes an integer (cube edge length) and returns the computed surface area using the formula: surface_area = 6 * (edge^2). The plan involves basic arithmetic operations in Lean.",
  "steps": [
    "Define a Lean 4 function with a single parameter 'size' of type integer.",
    "Compute the square of the provided edge length (size * size).",
    "Multiply the result by 6 to obtain the surface area.",
    "Return the computed surface area as an integer."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "arithmetic operations",
    "multiplication",
    "cube surface area"
  ],
  "proof_keywords": [
    "inductive proof",
    "arithmetic reasoning",
    "basic algebra"
  ],
  "assumptions": [
    "Input 'size' is an integer greater than 0",
    "Standard arithmetic operations are available in Lean 4"
  ],
  "retry_guidance": "If there are previous errors, re-check the arithmetic operator precedence and ensure proper type usage in Lean 4."
}
2025-06-01 02:50:10,206 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that takes an integer (cube edge length) and returns the computed surface area using the formula: surface_area = 6 * (edge^2). The plan involves basic arithmetic operations in Lean.",\n  "steps": [\n    "Define a Lean 4 function with a single parameter \'size\' of type integer.",\n    "Compute the square of the provided edge length (size * size).",\n    "Multiply the result by 6 to obtain the surface area.",\n    "Return the computed surface area as an integer."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "arithmetic operations",\n    "multiplication",\n    "cube surface area"\n  ],\n  "proof_keywords": [\n    "inductive proof",\n    "arithmetic reasoning",\n    "basic algebra"\n  ],\n  "assumptions": [\n    "Input \'size\' is an integer greater than 0",\n    "Standard arithmetic operations are available in Lean 4"\n  ],\n  "retry_guidance": "If there are previous errors, re-check the arithmetic operator precedence and ensure proper type usage in Lean 4."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeSurfaceArea (size : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The surface area of the cube is calculated correctly\ndef cubeSurfaceArea_spec (size : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = 6 * size * size\n  -- << SPEC END >>\n\ntheorem cubeSurfaceArea_spec_satisfied (size : Int):\n  cubeSurfaceArea_spec size (cubeSurfaceArea size) := by\n  -- << PROOF START >>\n  unfold cubeSurfaceArea cubeSurfaceArea_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 02:50:10,208 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:50:10,208 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:50:10,208 - DEBUG - send_request_headers.complete
2025-06-01 02:50:10,208 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:50:10,212 - DEBUG - send_request_body.complete
2025-06-01 02:50:10,212 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:50:12,837 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:50:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2294'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2375'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'9368'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'41.262s'), (b'x-request-id', b'req_93d43ae7044e7e0a32c5bfd67b80d115'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b66e5fbe247bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:50:12,838 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:50:12,838 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:50:12,839 - DEBUG - receive_response_body.complete
2025-06-01 02:50:12,839 - DEBUG - response_closed.started
2025-06-01 02:50:12,839 - DEBUG - response_closed.complete
2025-06-01 02:50:12,839 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:50:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2294', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2375', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '9368', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '41.262s', 'x-request-id': 'req_93d43ae7044e7e0a32c5bfd67b80d115', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b66e5fbe247bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:50:12,839 - DEBUG - request_id: req_93d43ae7044e7e0a32c5bfd67b80d115
2025-06-01 02:50:12,840 - INFO - Raw solution received: ```json
{
  "code": "6 * size * size",
  "proof": "by_cases size < 0\n  . simp [cubeSurfaceArea_spec]; simp [Int.mul_assoc]; exact Eq.refl (6 * size * size)\n  . simp [cubeSurfaceArea_spec]; exact Eq.refl (6 * size * size)"
}
```
2025-06-01 02:50:12,840 - INFO - <class 'str'>
2025-06-01 02:50:12,840 - INFO - Generated solution: {'code': '6 * size * size', 'proof': 'by_cases size < 0\n  . simp [cubeSurfaceArea_spec]; simp [Int.mul_assoc]; exact Eq.refl (6 * size * size)\n  . simp [cubeSurfaceArea_spec]; exact Eq.refl (6 * size * size)'}
2025-06-01 02:50:18,142 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:22:33: error: no goals to be solved
lean_playground/TempTest.lean:23:33: error: no goals to be solved
2025-06-01 02:50:18,143 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.\n\n-----Input-----\nThe input consists of:\nsize: An integer representing the length of an edge of the cube.\n\n-----Output-----\nThe output is an integer:\nReturns the surface area of the cube.\n\n-----Note-----\nThe input edge length is assumed to be greater than 0.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeSurfaceArea (size : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The surface area of the cube is calculated correctly\ndef cubeSurfaceArea_spec (size : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = 6 * size * size\n  -- << SPEC END >>\n\ntheorem cubeSurfaceArea_spec_satisfied (size : Int):\n  cubeSurfaceArea_spec size (cubeSurfaceArea size) := by\n  -- << PROOF START >>\n  unfold cubeSurfaceArea cubeSurfaceArea_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\n6 * size * size\n\nGenerated Proof:\nby_cases size < 0\n  . simp [cubeSurfaceArea_spec]; simp [Int.mul_assoc]; exact Eq.refl (6 * size * size)\n  . simp [cubeSurfaceArea_spec]; exact Eq.refl (6 * size * size)\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:22:33: error: no goals to be solved\nlean_playground/TempTest.lean:23:33: error: no goals to be solved'}], 'model': 'o3-mini'}}
2025-06-01 02:50:18,144 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:50:18,144 - DEBUG - close.started
2025-06-01 02:50:18,144 - DEBUG - close.complete
2025-06-01 02:50:18,144 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:50:18,158 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20429fc20>
2025-06-01 02:50:18,158 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:50:18,167 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20429f350>
2025-06-01 02:50:18,167 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:50:18,168 - DEBUG - send_request_headers.complete
2025-06-01 02:50:18,168 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:50:18,168 - DEBUG - send_request_body.complete
2025-06-01 02:50:18,168 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:50:23,593 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:50:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4818'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4824'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199266'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'220ms'), (b'x-request-id', b'req_c34458b8b9257749774a88599ed7759f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6717be548fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:50:23,593 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:50:23,593 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:50:23,594 - DEBUG - receive_response_body.complete
2025-06-01 02:50:23,594 - DEBUG - response_closed.started
2025-06-01 02:50:23,594 - DEBUG - response_closed.complete
2025-06-01 02:50:23,594 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:50:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4818', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4824', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199266', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '220ms', 'x-request-id': 'req_c34458b8b9257749774a88599ed7759f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6717be548fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:50:23,594 - DEBUG - request_id: req_c34458b8b9257749774a88599ed7759f
2025-06-01 02:50:23,594 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The generated proof script uses 'by_cases' on 'size < 0', but after unfolding the definitions, the goal is already solved by simplification. This results in 'no goals to be solved' because there is nothing left to prove in those branches.", 'error_type': 'proof', 'suggested_fix': "Remove the 'by_cases size < 0' case split and simply finish the proof with 'rfl' or 'simp'. For example, after unfolding, you can use 'rfl' to complete the proof since the equality is definitionally true.", 'retry_strategy': "Simplify the proof by eliminating unnecessary case splits. Instead, update the proof to use a straightforward tactic sequence (e.g., 'unfold cubeSurfaceArea cubeSurfaceArea_spec; rfl') to close the goal."}
2025-06-01 02:50:23,594 - INFO - Solution generated in 18.10 seconds
2025-06-01 02:50:23,595 - INFO - Generated code length: 15 characters
2025-06-01 02:50:23,595 - INFO - Generated proof length: 169 characters
2025-06-01 02:50:23,595 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:50:23,595 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:50:28,812 - INFO - Implementation test result: PASS
2025-06-01 02:50:28,813 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:50:33,964 - INFO - Full solution test result: FAIL
2025-06-01 02:50:33,964 - ERROR - Proof error: lean_playground/TempTest.lean:22:33: error: no goals to be solved
lean_playground/TempTest.lean:23:33: error: no goals to be solved...
2025-06-01 02:50:33,964 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:50:33,964 - ERROR - ❌ Proof has errors
2025-06-01 02:50:33,964 - INFO - 
==================================================
2025-06-01 02:50:33,964 - INFO - Processing task task_id_447...
2025-06-01 02:50:33,964 - INFO - Reading problem description and code template from tasks/task_id_447...
2025-06-01 02:50:33,964 - INFO - Problem description length: 691 characters
2025-06-01 02:50:33,965 - INFO - Reading unit tests from tasks/task_id_447...
2025-06-01 02:50:33,965 - INFO - Unit tests length: 234 characters
2025-06-01 02:50:33,965 - INFO - Running main workflow to generate solution...
2025-06-01 02:50:33,965 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.

-----Input-----
The input consists of:
a: An array of integers (which may be empty or non-empty).

-----Output-----
The output is an array of integers:
Returns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.

-----Note-----
There are no additional preconditions; the method should work correctly for any array of integers.
2025-06-01 02:50:33,965 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def cubeElements (a : Array Int) : Array Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array
def cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=
  -- << SPEC START >>
  (result.size = a.size) ∧
  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)
  -- << SPEC END >>

theorem cubeElements_spec_satisfied (a : Array Int) :
  cubeElements_spec a (cubeElements a) := by
  -- << PROOF START >>
  unfold cubeElements cubeElements_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:50:33,993 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x74e203e82ac0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:50:33,993 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:50:33,993 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:50:34,018 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20473b440>
2025-06-01 02:50:34,018 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e204267c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:50:34,044 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20473bd70>
2025-06-01 02:50:34,044 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:50:34,045 - DEBUG - send_request_headers.complete
2025-06-01 02:50:34,045 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:50:34,045 - DEBUG - send_request_body.complete
2025-06-01 02:50:34,045 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:50:36,408 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:50:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'97'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-55d56c9f55-tp6kw'), (b'x-envoy-upstream-service-time', b'105'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999827'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_fa5832787b6dd1ca09c1a255b621ab1f'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=08crnuHUR1typ4XXTeUKQ8SD4nrnqmc4W5BdklbKf4o-1748746236-1.0.1.1-HO7hJvpt58jrxgF5IrMTr22UN03CQky92pD4AkhkryWhLnhvmKiMji_3W0PTvRVvwhbk92q72iBIiqWu.XxgJSwPHyGL1xwoxN_nNIyrpNU; path=/; expires=Sun, 01-Jun-25 03:20:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=I.yL3yfOJ3c9vfBEC2ZDsOUJ4EN8_SVIimS5lHzJwYE-1748746236428-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b677b0c774436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:50:36,408 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:50:36,408 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:50:36,409 - DEBUG - receive_response_body.complete
2025-06-01 02:50:36,409 - DEBUG - response_closed.started
2025-06-01 02:50:36,409 - DEBUG - response_closed.complete
2025-06-01 02:50:36,409 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:50:36 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '97'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-55d56c9f55-tp6kw'), ('x-envoy-upstream-service-time', '105'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999827'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '10ms'), ('x-request-id', 'req_fa5832787b6dd1ca09c1a255b621ab1f'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=08crnuHUR1typ4XXTeUKQ8SD4nrnqmc4W5BdklbKf4o-1748746236-1.0.1.1-HO7hJvpt58jrxgF5IrMTr22UN03CQky92pD4AkhkryWhLnhvmKiMji_3W0PTvRVvwhbk92q72iBIiqWu.XxgJSwPHyGL1xwoxN_nNIyrpNU; path=/; expires=Sun, 01-Jun-25 03:20:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=I.yL3yfOJ3c9vfBEC2ZDsOUJ4EN8_SVIimS5lHzJwYE-1748746236428-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b677b0c774436-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:50:36,409 - DEBUG - request_id: req_fa5832787b6dd1ca09c1a255b621ab1f
2025-06-01 02:50:36,414 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
 m by rw [Nat.zero_add, Nat.add_zero])
       (fun (n : Nat) (ih : m + n = n + m) =>
        show m + succ n = succ n + m from
        calc m + succ n
          _ = succ (m + n) := rfl
          _ = succ (n + m) := by rw [ih]
          _ = succ n + m   := sorry)
    

At this point, we see that we need another supporting fact, namely, that `succ
(n + m) = succ n + m`. You can prove this by induction on `m`:

    
    
    open Nat
    
    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m
        (show succ n + 0 = succ (n + 0) from rfl)
        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>
         show succ n + succ m = succ (n + succ m) from
         calc succ n + succ m
           _ = succ (succ n + m)   := rfl
           _ = succ (succ (n + m)) := by rw [ih]
           _ = succ (n + succ m)   := rfl)
    

You can then replace the `sorry` in the previous proof with `succ_add`. Yet
again, the proofs can be compressed:

    
    
    namespace Hidden
    open Nat
    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m
        rfl
        (fun m ih => by simp only [add_succ, ih])
    
    theorem add_comm (m n : Nat) : m + n = n + m :=
      Nat.recOn (motive := fun x => m + x = x + m) n
        (by simp)
        (fun m ih => by simp [add_succ, succ_add, ih])
    end Hidden
    

## Other Recursive Data Types

Let us consider some more examples of inductively defined types. For any type,
`α`, the type `List α` of lists of elements of `α` is defined in the library.

    
    
    namespace Hidden
    inductive List (α : Type u) where
      | nil  : List α
      | cons : α → List α → List α
    
    namespace List
    
    def append (as bs : List α) : List α :=
      match as with
      | nil       => bs
      | cons a as => cons a (append as bs)
    
    theorem nil_append (as : List α) : append nil as = as :=
      rfl
    
    theorem cons_append (a : α) (as bs : List α)
                        : append (cons a as) bs = cons a (append as bs) :=
      rfl
    
    end List
    end Hidden
    

A list of elements of type `α` is either the empty list, `nil`, or an element
`h : α` followed by a list `t : List α`. The first element, `h`, is commonly
known as the "head" of the list, and the remainder, `t`, is known as the
"tail."

As an exercise, prove the following:

    
    
    namespace Hidden
    inductive List (α : Type u) where
    | nil  : List α
    | cons : α → List α → List α
    namespace List
    def append (as bs : List α) : List α :=
     match as with
     | nil       => bs
     | cons a as => cons a (append as bs)
    theorem nil_append (as : List α) : append nil as = as :=
     rfl
    theorem cons_append (a : α) (as bs : List α)
                        : append (cons a as) bs = cons a (append as bs) :=
     rfl
    theorem append_nil (as : List α) : append as nil = as :=
      sorry
    
    theorem append_assoc (as bs cs : List α)
            : append (append as bs) cs = append as (append bs cs) :=
      sorry
    end List
    end Hidden
    

Try also defining the function `length : {α : Type u} → List α → Nat` that
returns the length of a list, and prove that it behaves as expected (for
example, `length (append as bs) = length as + length bs`).

For another example, we can define the type of binary trees:

    
    
    inductive BinaryTree where
      | leaf : BinaryTree
      | node : BinaryTree → BinaryTree → BinaryTree
    

In fact, we can even define the type of countably branching trees:

    
    
    inductive CBTree where
      | leaf : CBTree
      | sup : (Nat → CBTree) → CBTree
    
    namespace CBTree
    
    def succ (t : CBTree) : CBTree :=
      sup (fun _ => t)
    
    def toCBTree : Nat → CBTree
      | 0 => leaf
      | n+1 => succ (toCBTree n)
    
    def omega : CBTree :=
      sup toCBTree
    
    end CBTree
    

## Tactics for Inductive Types

Given the fundamental importance of inductive types in Lean, it should not be
surprising that there are a number of tactics designed to work with them
effectively. We describe some of them here.

The `cases` tactic works on elements of an inductively defined type, and does
what the name suggests: it decomposes the element according to each of the
possible constructors. In its most basic form, it is applied to an element `x`
in the local context. It then reduces the goal to cases in which `x` is
replaced by each of the constructions.

    
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by
      intro n
      cases n
      . exact hz  -- goal is p 0
      . apply hs  -- goal is a : Nat ⊢ p (succ a)
    

There are extra bells and whistles. For one thing, `cases` allows you to
choose the names for each alternative using a `with` clause. In the next
example, for example, we choose the name `m` for the argument to `succ`, so
that the second case refers to `succ m`. More importantly, the cases tactic
will detect any items in the local context that depend on the target variable.
It reverts these elements, does the split, and reintroduces them. In the
example below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in
the first branch, and `h : succ m ≠ 0` in the second.

    
    
    open Nat
    
    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by
      cases n with
      | zero =>
        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0
        apply absurd rfl h
      | succ m =>
        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m
        rfl
    

Notice that `cases` can be used to produce data as well as prove propositions.

    
    
    def f (n : Nat) : Nat := by
      cases n; exact 3; exact 7
    
    example : f 0 = 3 := rfl
    example : f 5 = 7 := rfl
    

Once again, cases will revert, split, and then reintroduce dependencies in the
context.

    
    
    def Tuple (α : Type) (n : Nat) :=
      { as : List α // as.length = n }
    
    def f {n : Nat} (t : Tuple α n) : Nat := by
      cases n; exact 3; exact 7
    
    def myTuple : Tuple Nat 3 :=
      ⟨[0, 1, 2], rfl⟩
    
    example : f myTuple = 7 :=
      rfl
    

Here is an example of multiple constructors with arguments.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    
    def silly (x : Foo) : Nat := by
      cases x with
      | bar1 a b => exact b
      | bar2 c d e => exact e
    

The alternatives for each constructor don't need to be solved in the order the
constructors were declared.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x with
      | bar2 c d e => exact e
      | bar1 a b => exact b
    

The syntax of the `with` is convenient for writing structured proofs. Lean
also provides a complementary `case` tactic, which allows you to focus on goal
assign variable names.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x
      case bar1 a b => exact b
      case bar2 c d e => exact e
    

The `case` tactic is clever, in that it will match the constructor to the
appropriate goal. For example, we can fill the goals above in the opposite
order:

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x
      case bar2 c d e => exact e
      case bar1 a b => exact b
    

You can also use `cases` with an arbitrary expression. Assuming that
expression occurs in the goal, the cases tactic will generalize over the
expression, introduce the resulting universally quantified variable, and case
on that.

    
    
    open Nat
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
            : p (m + 3 * k) := by
      cases m + 3 * k
      exact hz   -- goal is p 0
      apply hs   -- goal is a : Nat ⊢ p (succ a)
    

Think of this as saying "split on cases as to whether `m + 3 * k` is zero or
the successor of some number." The result is functionally equivalent to the
following:

    
    
    open Nat
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
            : p (m + 3 * k) := by
      generalize m + 3 * k = n
      cases n
      exact hz   -- goal is p 0
      apply hs   -- goal is a : Nat ⊢ p (succ a)
    

Notice that the expression `m + 3 * k` is erased by `generalize`; all that
matters is whether it is of the form `0` or `succ a`. This form of `cases`
will _not_ revert any hypotheses that also mention the expression in the
equation (in this case, `m + 3 * k`). If such a term appears in a hypothesis
and you want to generalize over that as well, you need to `revert` it
explicitly.

If the expression you case on does not appear in the goal, the `cases` tactic
uses `have` to put the type of the expression into the context. Here is an
example:

    
    
    example (p : Prop) (m n : Nat)
            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by
      cases Nat.lt_or_ge m n
      case inl hlt => exact h₁ hlt
      case inr hge => exact h₂ hge
    

The theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to
think of the proof above as splitting on these two cases. In the first branch,
we have the hypothesis `hlt : m < n`, and in the second we have the hypothesis
`hge : m ≥ n`. The proof above is functionally equivalent to the following:

    
    
    example (p : Prop) (m n : Nat)
            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by
      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n
      cases h
      case inl hlt => exact h₁ hlt
      case inr hge => exact h₂ hge
    

After the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we
simply do cases on that.

Here is another example, where we use the decidability of equality on the
natural numbers to split on the cases `m = n` and `m ≠ n`.

    
    
    #check Nat.sub_self
    
    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by
      cases Decidable.em (m = n) with
      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n
      | inr hne => apply Or.inr; exact hne
    

Remember that if you `open Classical`, you can use the law of the excluded
middle for any proposition at all. But using type class inference (see
[Chapter Type Classes](./type_classes.html)), Lean can actually find the
relevant decision procedure, which means that you can use the case split in a
computable function.

Just as the `cases` tactic can be used to carry out proof by cases, the
`induction` tactic can be used to carry out proofs by induction. The syntax is
similar to that of `cases`, except that the argument can only be a term in the
local context. Here is an example:

    
    
    namespace Hidden
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n with
      | zero => rfl
      | succ n ih => rw [Nat.add_succ, ih]
    end Hidden
    

As with `cases`, we can use the `case` tactic instead of `with`.

    
    
    namespace Hidden
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n
      case zero => rfl
      case succ n ih => rw [Nat.add_succ, ih]
    end Hidden
    

Here are some additional examples:

    
    
    namespace Hidden
    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n
    open Nat
    
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n <;> simp [*, add_zero, add_succ]
    
    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by
      induction n <;> simp [*, add_zero, add_succ]
    
    theorem add_comm (m n : Nat) : m + n = n + m := by
      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]
    
    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by
      induction k <;> simp [*, add_zero, add_succ]
    end Hidden
    

The `induction` tactic also supports user-defined induction principles with
multiple targets (aka major premises).

    
    
    /-
    theorem Nat.mod.inductionOn
          {motive : Nat → Nat → Sort u}
          (x y  : Nat)
          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)
          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)
          : motive x y :=
    -/
    
    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by
      induction x, y using Nat.mod.inductionOn with
      | ind x y h₁ ih =>
        rw [Nat.mod_eq_sub_mod h₁.2]
        exact ih h
      | base x y h₁ =>
        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁
        match this with
        | Or.inl h₁ => exact absurd h h₁
        | Or.inr h₁ =>
          have hgt : y > x := Nat.gt_of_not_le h₁
          rw [← Nat.mod_eq_of_lt hgt] at hgt
          assumption
    

You can use the `match` notation in tactics too:

    
    
    example : p ∨ q → q ∨ p := by
      intro h
      match h with
      | Or.inl _  => apply Or.inr; assumption
      | Or.inr h2 => apply Or.inl; exact h2
    

As a convenience, pattern-matching has been integrated into tactics such as
`intro` and `funext`.

    
    
    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by
      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩
      exact ⟨hq, hp⟩
    
    example :
        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)
        =
        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by
      funext (a, b) (c, d)
      show a + d = d + a
      rw [Nat.add_comm]
    

We close this section with one last tactic that is designed to facilitate
working with inductive types, namely, the `injection` tactic. By design, the
elements of an inductive type are freely generated, which is to say, the
constructors are injective and have disjoint ranges. The `injection` tactic is
designed to make use of this fact:

    
    
    open Nat
    
    example (m n k : Nat) (h : succ (succ m) = succ (succ n))
            : n + k = m + k := by
      injection h with h'
      injection h' with h''
      rw [h'']
    

The first instance of the tactic adds `h' : succ m = succ n` to the context,
and the second adds `h'' : m = n`.

The `injection` tactic also detects contradictions that arise when different
constructors are set equal to one another, and uses them to close the goal.

    
    
    open Nat
    
    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
      injection h
    
    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
      contradiction
    
    example (h : 7 = 4) : False := by
      contradiction
    

As the second example shows, the `contradiction` tactic also detects
contradictions of this form.

## Inductive Families

We are almost done describing the full range of inductive definitions accepted
by Lean. So far, you have seen that Lean allows you to introduce inductive
types with any number of recursive constructors. In fact, a single inductive
definition can introduce an indexed _family_ of inductive types, in a manner
we now describe.

An inductive family is an indexed family of types defined by a simultaneous
induction of the following form:

    
    
    inductive foo : ... → Sort u where
      | constructor₁ : ... → foo ...
      | constructor₂ : ... → foo ...
      ...
      | constructorₙ : ... → foo ...
    

In contrast to an ordinary inductive definition, which constructs an element
of some `Sort u`, the more general version constructs a function `... → Sort
u`, where "`...`" denotes a sequence of argument types, also known as
_indices_. Each constructor then constructs an element of some member of the
family. One example is the definition of `Vector α n`, the type of vectors of
elements of `α` of length `n`:

    
    
    namespace Hidden
    inductive Vector (α : Type u) : Nat → Type u where
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    end Hidden
    

Notice that the `cons` constructor takes an element of `Vector α n` and
returns an element of `Vector α (n+1)`, thereby using an element of one member
of the family to build an element of another.

A more exotic example is given by the definition of the equality type in Lean:

    
    
    namespace Hidden
    inductive Eq {α : Sort u} (a : α) : α → Prop where
      | refl : Eq a a
    end Hidden
    

For each fixed `α : Sort u` and `a : α`, this definition constructs a family
of types `Eq a x`, indexed by `x : α`. Notably, however, there is only one
constructor, `refl`, which is an element of `Eq a a`. Intuitively, the only
way to construct a proof of `Eq a x` is to use reflexivity, in the case where
`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of
types `Eq a x`. The elimination principle generated by Lean is as follows:

    
    
    universe u v
    
    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}
                      → motive a rfl → {b : α} → (h : a = b) → motive b h)
    

It is a remarkable fact that all the basic axioms for equality follow from the
constructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality
is atypical, however; see the discussion in Section Axiomatic Details.

The recursor `Eq.rec` is also used to define substitution:

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      Eq.rec (motive := fun x _ => p x) h₂ h₁
    end Hidden
    

You can also define `subst` using `match`.

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      match h₁ with
      | rfl => h₂
    end Hidden
    

Actually, Lean compiles the `match` expressions using a definition based on
`Eq.rec`.

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      match h₁ with
      | rfl => h₂
    
    set_option pp.all true
    #print subst
      -- ... subst.match_1 ...
    #print subst.match_1
      -- ... Eq.casesOn ...
    #print Eq.casesOn
      -- ... Eq.rec ...
    end Hidden
    

Using the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are
the same, in which case, `p b` and `p a` are the same.

It is not hard to prove that `Eq` is symmetric and transitive. In the
following example, we prove `symm` and leave as exercises the theorems `trans`
and `congr` (congruence).

    
    
    namespace Hidden
    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=
      match h with
      | rfl => rfl
    
    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=
      sorry
    
    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=
      sorry
    end Hidden
    

In the type theory literature, there are further generalizations of inductive
definitions, for example, the principles of _induction-recursion_ and
_induction-induction_. These are not supported by Lean.

## Axiomatic Details

We have described inductive types and their syntax through examples. This
section provides additional information for those interested in the axiomatic
foundations.

We have seen that the constructor to an inductive type takes _parameters_ \---
intuitively, the arguments that remain fixed throughout the inductive
construction --- and _indices_ , the arguments parameterizing the family of
types that is simultaneously under construction. Each constructor should have
a type, where the argument types are built up from previously defined types,
the parameter and index types, and the inductive family currently being
defined. The requirement is that if the latter is present at all, it occurs
only _strictly positively_. This means simply that any argument to the
constructor in which it occurs is a dependent arrow type in which the
inductive type under definition occurs only as the resulting type, where the
indices are given in terms of constants and previous arguments.

Since an inductive type lives in `Sort u` for some `u`, it is reasonable to
ask _which_ universe levels `u` can be instantiated to. Each constructor `c`
in the definition of a family `C` of inductive types is of the form

    
    
      c : (a : α) → (b : β[a]) → C a p[a,b]
    

where `a` is a sequence of data type parameters, `b` is the sequence of
arguments to the constructors, and `p[a, b]` are the indices, which determine
which element of the inductive family the construction inhabits. (Note that
this description is somewhat misleading, in that the arguments to the
constructor can appear in any order as long as the dependencies make sense.)
The constraints on the universe level of `C` fall into two cases, depending on
whether or not the inductive type is specified to land in `Prop` (that is,
`Sort 0`).

Let us first consider the case where the inductive type is _not_ specified to
land in `Prop`. Then the universe level `u` is constrained to satisfy the
following:

> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,
> if `βk[a] : Sort v`, we have `u` ≥ `v`.

In other words, the universe level `u` is required to be at least as large as
the universe level of each type that represents an argument to a constructor.

When the inductive type is specified to land in `Prop`, there are no
constraints on the universe levels of the constructor arguments. But these
universe levels do have a bearing on the elimination rule. Generally speaking,
for an inductive type in `Prop`, the motive of the elimination rule is
required to be in `Prop`.

There is an exception to this last rule: we are allowed to eliminate from an
inductively defined `Prop` to an arbitrary `Sort` when there is only one
constructor and each constructor argument is either in `Prop` or an index. The
intuition is that in this case the elimination does not make use of any
information that is not already given by the mere fact that the type of
argument is inhabited. This special case is known as _singleton elimination_.

We have already seen singleton elimination at play in applications of
`Eq.rec`, the eliminator for the inductively defined equality type. We can use
an element `h : Eq a b` to cast an element `t' : p a` to `p b` even when `p a`
and `p b` are arbitrary types, because the cast does not produce new data; it
only reinterprets the data we already have. Singleton elimination is also used
with heterogeneous equality and well-founded recursion, which will be
discussed in a [Chapter Induction and
Recursion](./induction_and_recursion.html#well-founded-recursion-and-
induction).

## Mutual and Nested Inductive Types

We now consider two generalizations of inductive types that are often useful,
which Lean supports by "compiling" them down to the more primitive kinds of
inductive types described above. In other words, Lean parses the more general
definitions, defines auxiliary inductive types based on them, and then uses
the auxiliary types to define the ones we really want. Lean's equation
compiler, described in the next chapter, is needed to make use of these types
effectively. Nonetheless, it makes sense to describe the declarations here,
because they are straightforward variations on ordinary inductive definitions.

First, Lean supports _mutually defined_ inductive types. The idea is that we
can define two (or more) inductive types at the same time, where each one
refers to the other(s).

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : (n : Nat) → Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : (n : Nat) → Even n → Odd (n + 1)
    end
    

In this example, two types are defined simultaneously: a natural number `n` is
`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one
more than an `Even` number. In the exercises below, you are asked to spell out
the details.

A mutual inductive definition can also be used to define the notation of a
finite tree with nodes labelled by elements of `α`:

    
    
    mutual
        inductive Tree (α : Type u) where
          | node : α → TreeList α → Tree α
    
        inductive TreeList (α : Type u) where
          | nil  : TreeList α
          | cons : Tree α → TreeList α → TreeList α
    end
    

With this definition, one can construct an element of `Tree α` by giving an
element of `α` together with a list of subtrees, possibly empty. The list of
subtrees is represented by the type `TreeList α`, which is defined to be
either the empty list, `nil`, or the `cons` of a tree and an element of
`TreeList α`.

This definition is inconvenient to work with, however. It would be much nicer
if the list of subtrees were given by the type `List (Tree α)`, especially
since Lean's library contains a number of functions and theorems for working
with lists. One can show that the type `TreeList α` is _isomorphic_ to `List
(Tree α)`, but translating results back and forth along this isomorphism is
tedious.

In fact, Lean allows us to define the inductive type we really want:

    
    
    inductive Tree (α : Type u) where
      | mk : α → List (Tree α) → Tree α
    

This is known as a _nested_ inductive type. It falls outside the strict
specification of an inductive type given in the last section because `Tree`
does not occur strictly positively among the arguments to `mk`, but, rather,
nested inside the `List` type constructor. Lean then automatically builds the
isomorphism between `TreeList α` and `List (Tree α)` in its kernel, and
defines the constructors for `Tree` in terms of the isomorphism.

## Exercises

  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.

Since many of these are already defined in Lean's core library, you should
work within a namespace named `Hidden`, or something like that, in order to
avoid name clashes.

  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:

a. `length (s ++ t) = length s + length t`

b. `length (reverse t) = length t`

c. `reverse (reverse t) = t`

  3. Define an inductive data type consisting of terms built up from the following constructors:

     * `const n`, a constant denoting the natural number `n`
     * `var n`, a variable, numbered `n`
     * `plus s t`, denoting the sum of `s` and `t`
     * `times s t`, denoting the product of `s` and `t`

Recursively define a function that evaluates any such term with respect to an
assignment of values to the variables.

  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.

[ __](interacting_with_lean.html "Previous chapter") [
__](induction_and_recursion.html "Next chapter")

[ __](interacting_with_lean.html "Previous chapter") [
__](induction_and_recursion.html "Next chapter")
 modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
2025-06-01 02:50:36,417 - DEBUG - close.started
2025-06-01 02:50:36,417 - DEBUG - close.complete
2025-06-01 02:50:36,427 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.'}], 'model': 'o3-mini'}}
2025-06-01 02:50:36,428 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:50:36,428 - DEBUG - close.started
2025-06-01 02:50:36,428 - DEBUG - close.complete
2025-06-01 02:50:36,428 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:50:36,453 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20429fb60>
2025-06-01 02:50:36,453 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:50:36,479 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e20473bef0>
2025-06-01 02:50:36,479 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:50:36,479 - DEBUG - send_request_headers.complete
2025-06-01 02:50:36,479 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:50:36,479 - DEBUG - send_request_body.complete
2025-06-01 02:50:36,479 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:50:42,055 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:50:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5337'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5342'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199526'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'141ms'), (b'x-request-id', b'req_fac77674851a9d381712873844e644c3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b678a4b8a46f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:50:42,056 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:50:42,056 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:50:42,056 - DEBUG - receive_response_body.complete
2025-06-01 02:50:42,056 - DEBUG - response_closed.started
2025-06-01 02:50:42,056 - DEBUG - response_closed.complete
2025-06-01 02:50:42,056 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:50:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5337', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5342', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199526', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '141ms', 'x-request-id': 'req_fac77674851a9d381712873844e644c3', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b678a4b8a46f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:50:42,056 - DEBUG - request_id: req_fac77674851a9d381712873844e644c3
2025-06-01 02:50:42,057 - INFO - Attempt 1/3
2025-06-01 02:50:42,057 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that takes an array of integers as input and returns a new array where each element is replaced by its cube. This can be achieved by using a mapping function (such as Array.map) that applies the cubing operation to every element. The plan ensures that the length of the resulting array matches the input array.",
  "steps": [
    "Define the function with the correct signature that accepts an array of integers.",
    "Implement the transformation using an array mapping function. For each element x in the input array, compute x * x * x.",
    "Ensure that the mapping operation preserves the array length, satisfying the requirement that every element is replaced by its cube.",
    "Include necessary type and function definitions (e.g., using Array.map) and check that the function handles edge cases, such as an empty array."
  ],
  "code_keywords": [
    "Lean 4",
    "Array.map",
    "function definition",
    "cubing",
    "integer multiplication",
    "recursion (if manual implementation)"
  ],
  "proof_keywords": [
    "inductive reasoning",
    "array mapping correctness",
    "preservation of array length",
    "function termination"
  ],
  "assumptions": [
    "Input is an array of integers, possibly empty.",
    "Standard Lean 4 libraries or functions like Array.map are available.",
    "Arithmetic operations behave as expected for integer cubing."
  ],
  "retry_guidance": "If you encounter issues such as type mismatches or errors with the mapping functionality, review the function's signature and ensure that the array operations you are using are compatible with the Lean 4 version and its library support. Verify that the cubing operation is clearly defined and applied to integers, and consider alternative implementations (like explicit recursion) if necessary."
}
2025-06-01 02:50:42,057 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that takes an array of integers as input and returns a new array where each element is replaced by its cube. This can be achieved by using a mapping function (such as Array.map) that applies the cubing operation to every element. The plan ensures that the length of the resulting array matches the input array.",\n  "steps": [\n    "Define the function with the correct signature that accepts an array of integers.",\n    "Implement the transformation using an array mapping function. For each element x in the input array, compute x * x * x.",\n    "Ensure that the mapping operation preserves the array length, satisfying the requirement that every element is replaced by its cube.",\n    "Include necessary type and function definitions (e.g., using Array.map) and check that the function handles edge cases, such as an empty array."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array.map",\n    "function definition",\n    "cubing",\n    "integer multiplication",\n    "recursion (if manual implementation)"\n  ],\n  "proof_keywords": [\n    "inductive reasoning",\n    "array mapping correctness",\n    "preservation of array length",\n    "function termination"\n  ],\n  "assumptions": [\n    "Input is an array of integers, possibly empty.",\n    "Standard Lean 4 libraries or functions like Array.map are available.",\n    "Arithmetic operations behave as expected for integer cubing."\n  ],\n  "retry_guidance": "If you encounter issues such as type mismatches or errors with the mapping functionality, review the function\'s signature and ensure that the array operations you are using are compatible with the Lean 4 version and its library support. Verify that the cubing operation is clearly defined and applied to integers, and consider alternative implementations (like explicit recursion) if necessary."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  -- << SPEC START >>\n  (result.size = a.size) ∧\n  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n  -- << SPEC END >>\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  -- << PROOF START >>\n  unfold cubeElements cubeElements_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 02:50:42,059 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:50:42,059 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:50:42,059 - DEBUG - send_request_headers.complete
2025-06-01 02:50:42,059 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:50:42,082 - DEBUG - send_request_body.complete
2025-06-01 02:50:42,082 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:50:44,862 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:50:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2487'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2490'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'6769'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'46.46s'), (b'x-request-id', b'req_b1f2bc3870490af805afbfdff27ca065'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b67ad28a946f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:50:44,862 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:50:44,862 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:50:44,862 - DEBUG - receive_response_body.complete
2025-06-01 02:50:44,862 - DEBUG - response_closed.started
2025-06-01 02:50:44,863 - DEBUG - response_closed.complete
2025-06-01 02:50:44,863 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:50:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2487', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2490', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '6769', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '46.46s', 'x-request-id': 'req_b1f2bc3870490af805afbfdff27ca065', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b67ad28a946f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:50:44,863 - DEBUG - request_id: req_b1f2bc3870490af805afbfdff27ca065
2025-06-01 02:50:44,863 - INFO - Raw solution received: ```json
{
  "code": "a.map (fun x => x * x * x)",
  "proof": "intro a\n  simp\n  apply And.intro\n  . rfl\n  . intro i hi\n    simp\n    cases hi\n    rfl"
}
```
2025-06-01 02:50:44,863 - INFO - <class 'str'>
2025-06-01 02:50:44,863 - INFO - Generated solution: {'code': 'a.map (fun x => x * x * x)', 'proof': 'intro a\n  simp\n  apply And.intro\n  . rfl\n  . intro i hi\n    simp\n    cases hi\n    rfl'}
2025-06-01 02:50:49,958 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:22:8: error: tactic 'introN' failed, insufficient number of binders
a : Array ℤ
⊢ (Array.map (fun x => x * x * x) a).size = a.size ∧
    ∀ i < a.size, (Array.map (fun x => x * x * x) a)[i]! = a[i]! * a[i]! * a[i]!
2025-06-01 02:50:49,959 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  -- << SPEC START >>\n  (result.size = a.size) ∧\n  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n  -- << SPEC END >>\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  -- << PROOF START >>\n  unfold cubeElements cubeElements_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na.map (fun x => x * x * x)\n\nGenerated Proof:\nintro a\n  simp\n  apply And.intro\n  . rfl\n  . intro i hi\n    simp\n    cases hi\n    rfl\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:22:8: error: tactic 'introN' failed, insufficient number of binders\na : Array ℤ\n⊢ (Array.map (fun x => x * x * x) a).size = a.size ∧\n    ∀ i < a.size, (Array.map (fun x => x * x * x) a)[i]! = a[i]! * a[i]! * a[i]!"}], 'model': 'o3-mini'}}
2025-06-01 02:50:49,959 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:50:49,959 - DEBUG - close.started
2025-06-01 02:50:49,959 - DEBUG - close.complete
2025-06-01 02:50:49,960 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:50:49,984 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204291640>
2025-06-01 02:50:49,984 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x74e2ec467c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:50:50,011 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x74e204293290>
2025-06-01 02:50:50,011 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:50:50,011 - DEBUG - send_request_headers.complete
2025-06-01 02:50:50,011 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:50:50,011 - DEBUG - send_request_body.complete
2025-06-01 02:50:50,011 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:50:57,689 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:50:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7426'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7431'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199158'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'252ms'), (b'x-request-id', b'req_075ed979d113834724460bc1d537c7e5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b67ded9dd4436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:50:57,689 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:50:57,689 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:50:57,690 - DEBUG - receive_response_body.complete
2025-06-01 02:50:57,690 - DEBUG - response_closed.started
2025-06-01 02:50:57,690 - DEBUG - response_closed.complete
2025-06-01 02:50:57,690 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:50:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7426', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7431', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199158', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '252ms', 'x-request-id': 'req_075ed979d113834724460bc1d537c7e5', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b67ded9dd4436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:50:57,690 - DEBUG - request_id: req_075ed979d113834724460bc1d537c7e5
2025-06-01 02:50:57,690 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails because it unnecessarily introduces the binder 'a' with the 'intro a' tactic. Since 'a' is already provided as a parameter in the theorem statement, using 'intro a' results in an insufficient binder error. Additionally, the proof uses 'cases hi' which is redundant and can be removed.", 'error_type': 'proof', 'suggested_fix': "Remove the 'intro a' tactic from the proof. After unfolding the definitions, use tactics like 'split' to handle the conjunction and 'intros i hi' for the second part. For example, you can modify the proof as follows:\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n    simp [cubeElements, cubeElements_spec]\n    split\n    . rfl\n    . intros i hi\n      simp\n      rfl\n\nThis adjustment avoids the unnecessary binder introduction and streamlines the proof.", 'retry_strategy': "Revise the proof by removing the extra 'intro a' tactic and unnecessary 'cases hi'. Try using 'simp' with 'split' and 'intros i hi' as indicated to complete the proof."}
2025-06-01 02:50:57,691 - INFO - Solution generated in 23.73 seconds
2025-06-01 02:50:57,691 - INFO - Generated code length: 26 characters
2025-06-01 02:50:57,691 - INFO - Generated proof length: 85 characters
2025-06-01 02:50:57,691 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:50:57,691 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:51:03,314 - INFO - Implementation test result: PASS
2025-06-01 02:51:03,314 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:51:08,874 - INFO - Full solution test result: FAIL
2025-06-01 02:51:08,874 - ERROR - Proof error: lean_playground/TempTest.lean:22:8: error: tactic 'introN' failed, insufficient number of binders
a : Array ℤ
⊢ (Array.map (fun x => x * x * x) a).siz...
2025-06-01 02:51:08,874 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:51:08,874 - ERROR - ❌ Proof has errors
2025-06-01 02:51:08,874 - INFO - Testing Summary:
2025-06-01 02:51:08,874 - INFO - Task task_id_0:
2025-06-01 02:51:08,874 - INFO -   Passes Unit Tests: True
2025-06-01 02:51:08,874 - INFO -   Proof is Correct: True
2025-06-01 02:51:08,874 - INFO -   Runtime: 20.259735584259033 seconds
2025-06-01 02:51:08,874 - INFO - Testing completed.
2025-06-01 02:51:08,875 - INFO - Task task_id_58:
2025-06-01 02:51:08,875 - INFO -   Passes Unit Tests: True
2025-06-01 02:51:08,875 - INFO -   Proof is Correct: False
2025-06-01 02:51:08,875 - INFO -   Runtime: 27.1941556930542 seconds
2025-06-01 02:51:08,875 - INFO - Testing completed.
2025-06-01 02:51:08,875 - INFO - Task task_id_77:
2025-06-01 02:51:08,875 - INFO -   Passes Unit Tests: True
2025-06-01 02:51:08,875 - INFO -   Proof is Correct: False
2025-06-01 02:51:08,875 - INFO -   Runtime: 40.188092947006226 seconds
2025-06-01 02:51:08,875 - INFO - Testing completed.
2025-06-01 02:51:08,875 - INFO - Task task_id_127:
2025-06-01 02:51:08,875 - INFO -   Passes Unit Tests: True
2025-06-01 02:51:08,875 - INFO -   Proof is Correct: False
2025-06-01 02:51:08,875 - INFO -   Runtime: 23.80502223968506 seconds
2025-06-01 02:51:08,875 - INFO - Testing completed.
2025-06-01 02:51:08,875 - INFO - Task task_id_227:
2025-06-01 02:51:08,875 - INFO -   Passes Unit Tests: False
2025-06-01 02:51:08,875 - INFO -   Proof is Correct: False
2025-06-01 02:51:08,875 - INFO -   Runtime: 27.886165857315063 seconds
2025-06-01 02:51:08,875 - INFO - Testing completed.
2025-06-01 02:51:08,875 - INFO - Task task_id_404:
2025-06-01 02:51:08,875 - INFO -   Passes Unit Tests: True
2025-06-01 02:51:08,875 - INFO -   Proof is Correct: False
2025-06-01 02:51:08,876 - INFO -   Runtime: 28.55904483795166 seconds
2025-06-01 02:51:08,876 - INFO - Testing completed.
2025-06-01 02:51:08,876 - INFO - Task task_id_431:
2025-06-01 02:51:08,876 - INFO -   Passes Unit Tests: True
2025-06-01 02:51:08,876 - INFO -   Proof is Correct: False
2025-06-01 02:51:08,876 - INFO -   Runtime: 27.83017587661743 seconds
2025-06-01 02:51:08,876 - INFO - Testing completed.
2025-06-01 02:51:08,876 - INFO - Task task_id_433:
2025-06-01 02:51:08,876 - INFO -   Passes Unit Tests: True
2025-06-01 02:51:08,876 - INFO -   Proof is Correct: False
2025-06-01 02:51:08,876 - INFO -   Runtime: 31.791828155517578 seconds
2025-06-01 02:51:08,876 - INFO - Testing completed.
2025-06-01 02:51:08,876 - INFO - Task task_id_435:
2025-06-01 02:51:08,876 - INFO -   Passes Unit Tests: True
2025-06-01 02:51:08,876 - INFO -   Proof is Correct: False
2025-06-01 02:51:08,876 - INFO -   Runtime: 21.509332418441772 seconds
2025-06-01 02:51:08,876 - INFO - Testing completed.
2025-06-01 02:51:08,876 - INFO - Task task_id_441:
2025-06-01 02:51:08,876 - INFO -   Passes Unit Tests: True
2025-06-01 02:51:08,876 - INFO -   Proof is Correct: False
2025-06-01 02:51:08,876 - INFO -   Runtime: 18.096914052963257 seconds
2025-06-01 02:51:08,876 - INFO - Testing completed.
2025-06-01 02:51:08,876 - INFO - Task task_id_447:
2025-06-01 02:51:08,876 - INFO -   Passes Unit Tests: True
2025-06-01 02:51:08,876 - INFO -   Proof is Correct: False
2025-06-01 02:51:08,876 - INFO -   Runtime: 23.725754737854004 seconds
2025-06-01 02:51:08,877 - INFO - Testing completed.
2025-06-01 02:51:09,012 - DEBUG - close.started
2025-06-01 02:51:09,012 - DEBUG - close.complete
2025-06-01 02:51:09,012 - DEBUG - close.started
2025-06-01 02:51:09,012 - DEBUG - close.complete
2025-06-01 02:51:09,191 - DEBUG - close.started
2025-06-01 02:51:09,191 - DEBUG - close.complete
