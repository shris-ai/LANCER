2025-06-01 01:54:21,356 - INFO - Starting test of 11 tasks: task_id_0, task_id_58, task_id_77, task_id_127, task_id_227, task_id_404, task_id_431, task_id_433, task_id_435, task_id_441, task_id_447
2025-06-01 01:54:21,357 - INFO - 
==================================================
2025-06-01 01:54:21,357 - INFO - Processing task task_id_0...
2025-06-01 01:54:21,357 - INFO - Reading problem description and code template from tasks/task_id_0...
2025-06-01 01:54:21,357 - INFO - Problem description length: 310 characters
2025-06-01 01:54:21,357 - INFO - Reading unit tests from tasks/task_id_0...
2025-06-01 01:54:21,357 - INFO - Unit tests length: 69 characters
2025-06-01 01:54:21,357 - INFO - Running main workflow to generate solution...
2025-06-01 01:54:21,357 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.

-----Input-----
The input consists of one natural number:
x: An natural number.

-----Output-----
The output is a natural number which the value equals to x.
2025-06-01 01:54:21,357 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def ident (x : Nat) : Nat :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


def ident_spec (x : Nat) (result: Nat) : Prop :=
  -- << SPEC START >>
  result = x
  -- << SPEC END >>

theorem ident_spec_satisfied (x : Nat) :
  ident_spec x (ident x) := by
  -- << PROOF START >>
  unfold ident ident_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 01:54:21,464 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Inductive Types\n\nWe have seen that Lean\'s formal foundation includes basic types, `Prop, Type\n0, Type 1, Type 2, ...`, and allows for the formation of dependent function\ntypes, `(x : α) → β`. In the examples, we have also made use of additional\ntypes like `Bool`, `Nat`, and `Int`, and type constructors, like `List`, and\nproduct, `×`. In fact, in Lean\'s library, every concrete type other than the\nuniverses and every type constructor other than dependent arrows is an\ninstance of a general family of type constructions known as _inductive types_.\nIt is remarkable that it is possible to construct a substantial edifice of\nmathematics based on nothing more than the type universes, dependent arrow\ntypes, and inductive types; everything else follows from those.\n\nIntuitively, an inductive type is built up from a specified list of\nconstructors. In Lean, the syntax for specifying such a type is as follows:\n\n    \n    \n    inductive Foo where\n      | constructor₁ : ... → Foo\n      | constructor₂ : ... → Foo\n      ...\n      | constructorₙ : ... → Foo\n    \n\nThe intuition is that each constructor specifies a way of building new objects\nof `Foo`, possibly from previously constructed values. The type `Foo` consists\nof nothing more than the objects that are constructed in this way. The first\ncharacter `|` in an inductive declaration is optional. We can also separate\nconstructors using a comma instead of `|`.\n\nWe will see below that the arguments of the constructors can include objects\nof type `Foo`, subject to a certain "positivity" constraint, which guarantees\nthat elements of `Foo` are built from the bottom up. Roughly speaking, each\n`...` can be any arrow type constructed from `Foo` and previously defined\ntypes, in which `Foo` appears, if at all, only as the "target" of the\ndependent arrow type.\n\nWe will provide a number of examples of inductive types. We will also consider\nslight generalizations of the scheme above, to mutually defined inductive\ntypes, and so-called _inductive families_.\n\nAs with the logical connectives, every inductive type comes with introduction\nrules, which show how to construct an element of the type, and elimination\nrules, which show how to "use" an element of the type in another construction.\nThe analogy to the logical connectives should not come as a surprise; as we\nwill see below, they, too, are examples of inductive type constructions. You\nhave already seen the introduction rules for an inductive type: they are just\nthe constructors that are specified in the definition of the type. The\nelimination rules provide for a principle of recursion on the type, which\nincludes, as a special case, a principle of induction as well.\n\nIn the next chapter, we will describe Lean\'s function definition package,\nwhich provides even more convenient ways to define functions on inductive\ntypes and carry out inductive proofs. But because the notion of an inductive\ntype is so fundamental, we feel it is important to start with a low-level,\nhands-on understanding. We will start with some basic examples of inductive\ntypes, and work our way up to more elaborate and complex examples.\n\n## Enumerated Types\n\nThe simplest kind of inductive type is a type with a finite, enumerated list\nof elements.\n\n    \n    \n    inductive Weekday where\n      | sunday : Weekday\n      | monday : Weekday\n      | tuesday : Weekday\n      | wednesday : Weekday\n      | thursday : Weekday\n      | friday : Weekday\n      | saturday : Weekday\n    \n\nThe `inductive` command creates a new type, `Weekday`. The constructors all\nlive in the `Weekday` namespace.\n\n    \n    \n    inductive Weekday where\n     | sunday : Weekday\n     | monday : Weekday\n     | tuesday : Weekday\n     | wednesday : Weekday\n     | thursday : Weekday\n     | friday : Weekday\n     | saturday : Weekday\n    #check Weekday.sunday\n    #check Weekday.monday\n    \n    open Weekday\n    \n    #check sunday\n    #check monday\n    \n\nYou can omit `: Weekday` when declaring the `Weekday` inductive type.\n\n    \n    \n    inductive Weekday where\n      | sunday\n      | monday\n      | tuesday\n      | wednesday\n      | thursday\n      | friday\n      | saturday\n    \n\nThink of `sunday`, `monday`, ... , `saturday` as being distinct elements of\n`Weekday`, with no other distinguishing properties. The elimination principle,\n`Weekday.rec`, is defined along with the type `Weekday` and its constructors.\nIt is also known as a _recursor_ , and it is what makes the type "inductive":\nit allows us to define a function on `Weekday` by assigning values\ncorresponding to each constructor. The intuition is that an inductive type is\nexhaustively generated by the constructors, and has no elements beyond those\nthey construct.\n\nWe will use the `match` expression to define a function from `Weekday` to the\nnatural numbers:\n\n    \n    \n    inductive Weekday where\n     | sunday : Weekday\n     | monday : Weekday\n     | tuesday : Weekday\n     | wednesday : Weekday\n     | thursday : Weekday\n     | friday : Weekday\n     | saturday : Weekday\n    open Weekday\n    \n    def numberOfDay (d : Weekday) : Nat :=\n      match d with\n      | sunday    => 1\n      | monday    => 2\n      | tuesday   => 3\n      | wednesday => 4\n      | thursday  => 5\n      | friday    => 6\n      | saturday  => 7\n    \n    #eval numberOfDay Weekday.sunday  -- 1\n    #eval numberOfDay Weekday.monday  -- 2\n    #eval numberOfDay Weekday.tuesday -- 3\n    \n\nNote that the `match` expression is compiled using the _recursor_\n`Weekday.rec` generated when you declare the inductive type.\n\n    \n    \n    inductive Weekday where\n     | sunday : Weekday\n     | monday : Weekday\n     | tuesday : Weekday\n     | wednesday : Weekday\n     | thursday : Weekday\n     | friday : Weekday\n     | saturday : Weekday\n    open Weekday\n    \n    def numberOfDay (d : Weekday) : Nat :=\n      match d with\n      | sunday    => 1\n      | monday    => 2\n      | tuesday   => 3\n      | wednesday => 4\n      | thursday  => 5\n      | friday    => 6\n      | saturday  => 7\n    \n    set_option pp.all true\n    #print numberOfDay\n    -- ... numberOfDay.match_1\n    #print numberOfDay.match_1\n    -- ... Weekday.casesOn ...\n    #print Weekday.casesOn\n    -- ... Weekday.rec ...\n    #check @Weekday.rec\n    /-\n    @Weekday.rec.{u}\n     : {motive : Weekday → Sort u} →\n        motive Weekday.sunday →\n        motive Weekday.monday →\n        motive Weekday.tuesday →\n        motive Weekday.wednesday →\n        motive Weekday.thursday →\n        motive Weekday.friday →\n        motive Weekday.saturday →\n        (t : Weekday) → motive t\n    -/\n    \n\nWhen declaring an inductive datatype, you can use `deriving Repr` to instruct\nLean to generate a function that converts `Weekday` objects into text. This\nfunction is used by the `#eval` command to display `Weekday` objects.\n\n    \n    \n    inductive Weekday where\n      | sunday\n      | monday\n      | tuesday\n      | wednesday\n      | thursday\n      | friday\n      | saturday\n      deriving Repr\n    \n    open Weekday\n    \n    #eval tuesday   -- Weekday.tuesday\n    \n\nIt is often useful to group definitions and theorems related to a structure in\na namespace with the same name. For example, we can put the `numberOfDay`\nfunction in the `Weekday` namespace. We are then allowed to use the shorter\nname when we open the namespace.\n\nWe can define functions from `Weekday` to `Weekday`:\n\n    \n    \n    inductive Weekday where\n     | sunday : Weekday\n     | monday : Weekday\n     | tuesday : Weekday\n     | wednesday : Weekday\n     | thursday : Weekday\n     | friday : Weekday\n     | saturday : Weekday\n     deriving Repr\n    namespace Weekday\n    def next (d : Weekday) : Weekday :=\n      match d with\n      | sunday    => monday\n      | monday    => tuesday\n      | tuesday   => wednesday\n      | wednesday => thursday\n      | thursday  => friday\n      | friday    => saturday\n      | saturday  => sunday\n    \n    def previous (d : Weekday) : Weekday :=\n      match d with\n      | sunday    => saturday\n      | monday    => sunday\n      | tuesday   => monday\n      | wednesday => tuesday\n      | thursday  => wednesday\n      | friday    => thursday\n      | saturday  => friday\n    \n    #eval next (next tuesday)      -- Weekday.thursday\n    #eval next (previous tuesday)  -- Weekday.tuesday\n    \n    example : next (previous tuesday) = tuesday :=\n      rfl\n    \n    end Weekday\n    \n\nHow can we prove the general theorem that `next (previous d) = d` for any\nWeekday `d`? You can use `match` to provide a proof of the claim for each\nconstructor:\n\n    \n    \n    inductive Weekday where\n     | sunday : Weekday\n     | monday : Weekday\n     | tuesday : Weekday\n     | wednesday : Weekday\n     | thursday : Weekday\n     | friday : Weekday\n     | saturday : Weekday\n     deriving Repr\n    namespace Weekday\n    def next (d : Weekday) : Weekday :=\n     match d with\n     | sunday    => monday\n     | monday    => tuesday\n     | tuesday   => wednesday\n     | wednesday => thursday\n     | thursday  => friday\n     | friday    => saturday\n     | saturday  => sunday\n    def previous (d : Weekday) : Weekday :=\n     match d with\n     | sunday    => saturday\n     | monday    => sunday\n     | tuesday   => monday\n     | wednesday => tuesday\n     | thursday  => wednesday\n     | friday    => thursday\n     | saturday  => friday\n    def next_previous (d : Weekday) : next (previous d) = d :=\n      match d with\n      | sunday    => rfl\n      | monday    => rfl\n      | tuesday   => rfl\n      | wednesday => rfl\n      | thursday  => rfl\n      | friday    => rfl\n      | saturday  => rfl\n    \n\nUsing a tactic proof, we can be even more concise:\n\n    \n    \n    inductive Weekday where\n     | sunday : Weekday\n     | monday : Weekday\n     | tuesday : Weekday\n     | wednesday : Weekday\n     | thursday : Weekday\n     | friday : Weekday\n     | saturday : Weekday\n     deriving Repr\n    namespace Weekday\n    def next (d : Weekday) : Weekday :=\n     match d with\n     | sunday    => monday\n     | monday    => tuesday\n     | tuesday   => wednesday\n     | wednesday => thursday\n     | thursday  => friday\n     | friday    => saturday\n     | saturday  => sunday\n    def previous (d : Weekday) : Weekday :=\n     match d with\n     | sunday    => saturday\n     | monday    => sunday\n     | tuesday   => monday\n     | wednesday => tuesday\n     | thursday  => wednesday\n     | friday    => thursday\n     | saturday  => friday\n    def next_previous (d : Weekday) : next (previous d) = d := by\n      cases d <;> rfl\n    \n\nTactics for Inductive Types below will introduce additional tactics that are\nspecifically designed to make use of inductive types.\n\nNotice that, under the propositions-as-types correspondence, we can use\n`match` to prove theorems as well as define functions. In other words, under\nthe propositions-as-types correspondence, the proof by cases is a kind of\ndefinition by cases, where what is being "defined" is a proof instead of a\npiece of data.\n\nThe `Bool` type in the Lean library is an instance of enumerated type.\n\n    \n    \n    namespace Hidden\n    inductive Bool where\n      | false : Bool\n      | true  : Bool\n    end Hidden\n    \n\n(To run these examples, we put them in a namespace called `Hidden`, so that a\nname like `Bool` does not conflict with the `Bool` in the standard library.\nThis is necessary because these types are part of the Lean "prelude" that is\nautomatically imported when the system is started.)\n\nAs an exercise, you should think about what the introduction and elimination\nrules for these types do. As a further exercise, we suggest defining boolean\noperations `and`, `or`, `not` on the `Bool` type, and verifying common\nidentities. Note that you can define a binary operation like `and` using\n`match`:\n\n    \n    \n    namespace Hidden\n    def and (a b : Bool) : Bool :=\n      match a with\n      | true  => b\n      | false => false\n    end Hidden\n    \n\nSimilarly, most identities can be proved by introducing suitable `match`, and\nthen using `rfl`.\n\n## Constructors with Arguments\n\nEnumerated types are a very special case of inductive types, in which the\nconstructors take no arguments at all. In general, a "construction" can depend\non data, which is then represented in the constructed argument. Consider the\ndefinitions of the product type and sum type in the library:\n\n    \n    \n    namespace Hidden\n    inductive Prod (α : Type u) (β : Type v)\n      | mk : α → β → Prod α β\n    \n    inductive Sum (α : Type u) (β : Type v) where\n      | inl : α → Sum α β\n      | inr : β → Sum α β\n    end Hidden\n    \n\nConsider what is going on in these examples. The product type has one\nconstructor, `Prod.mk`, which takes two arguments. To define a function on\n`Prod α β`, we can assume the input is of the form `Prod.mk a b`, and we have\nto specify the output, in terms of `a` and `b`. We can use this to define the\ntwo projections for `Prod`. Remember that the standard library defines\nnotation `α × β` for `Prod α β` and `(a, b)` for `Prod.mk a b`.\n\n    \n    \n    namespace Hidden\n    inductive Prod (α : Type u) (β : Type v)\n      | mk : α → β → Prod α β\n    def fst {α : Type u} {β : Type v} (p : Prod α β) : α :=\n      match p with\n      | Prod.mk a b => a\n    \n    def snd {α : Type u} {β : Type v} (p : Prod α β) : β :=\n      match p with\n      | Prod.mk a b => b\n    end Hidden\n    \n\nThe function `fst` takes a pair, `p`. The `match` interprets `p` as a pair,\n`Prod.mk a b`. Recall also from [Dependent Type\nTheory](./dependent_type_theory.html) that to give these definitions the\ngreatest generality possible, we allow the types `α` and `β` to belong to any\nuniverse.\n\nHere is another example where we use the recursor `Prod.casesOn` instead of\n`match`.\n\n    \n    \n    def prod_example (p : Bool × Nat) : Nat :=\n      Prod.casesOn (motive := fun _ => Nat) p (fun b n => cond b (2 * n) (2 * n + 1))\n    \n    #eval prod_example (true, 3)\n    #eval prod_example (false, 3)\n    \n\nThe argument `motive` is used to specify the type of the object you want to\nconstruct, and it is a function because it may depend on the pair. The `cond`\nfunction is a boolean conditional: `cond b t1 t2` returns `t1` if `b` is true,\nand `t2` otherwise. The function `prod_example` takes a pair consisting of a\nboolean, `b`, and a number, `n`, and returns either `2 * n` or `2 * n + 1`\naccording to whether `b` is true or false.\n\nIn contrast, the sum type has _two_ constructors, `inl` and `inr` (for "insert\nleft" and "insert right"), each of which takes _one_ (explicit) argument. To\ndefine a function on `Sum α β`, we have to handle two cases: either the input\nis of the form `inl a`, in which case we have to specify an output value in\nterms of `a`, or the input is of the form `inr b`, in which case we have to\nspecify an output value in terms of `b`.\n\n    \n    \n    def sum_example (s : Sum Nat Nat) : Nat :=\n      Sum.casesOn (motive := fun _ => Nat) s\n        (fun n => 2 * n)\n        (fun n => 2 * n + 1)\n    \n    #eval sum_example (Sum.inl 3)\n    #eval sum_example (Sum.inr 3)\n    \n\nThis example is similar to the previous one, but now an input to `sum_example`\nis implicitly either of the form `inl n` or `inr n`. In the first case, the\nfunction returns `2 * n`, and the second case, it returns `2 * n + 1`.\n\nNotice that the product type depends on parameters `α β : Type` which are\narguments to the constructors as well as `Prod`. Lean detects when these\narguments can be inferred from later arguments to a constructor or the return\ntype, and makes them implicit in that case.\n\nIn Section Defining the Natural Numbers we will see what happens when the\nconstructor of an inductive type takes arguments from the inductive type\nitself. What characterizes the examples we consider in this section is that\neach constructor relies only on previously specified types.\n\nNotice that a type with multiple constructors is disjunctive: an element of\n`Sum α β` is either of the form `inl a` _or_ of the form `inl b`. A\nconstructor with multiple arguments introduces conjunctive information: from\nan element `Prod.mk a b` of `Prod α β` we can extract `a` _and_ `b`. An\narbitrary inductive type can include both features, by having any number of\nconstructors, each of which takes any number of arguments.\n\nAs with function definitions, Lean\'s inductive definition syntax will let you\nput named arguments to the constructors before the colon:\n\n    \n    \n    namespace Hidden\n    inductive Prod (α : Type u) (β : Type v) where\n      | mk (fst : α) (snd : β) : Prod α β\n    \n    inductive Sum (α : Type u) (β : Type v) where\n      | inl (a : α) : Sum α β\n      | inr (b : β) : Sum α β\n    end Hidden\n    \n\nThe results of these definitions are essentially the same as the ones given\nearlier in this section.\n\nA type, like `Prod`, that has only one constructor is purely conjunctive: the\nconstructor simply packs the list of arguments into a single piece of data,\nessentially a tuple where the type of subsequent arguments can depend on the\ntype of the initial argument. We can also think of such a type as a "record"\nor a "structure". In Lean, the keyword `structure` can be used to define such\nan inductive type as well as its projections, at the same time.\n\n    \n    \n    namespace Hidden\n    structure Prod (α : Type u) (β : Type v) where\n      mk :: (fst : α) (snd : β)\n    end Hidden\n    \n\nThis example simultaneously introduces the inductive type, `Prod`, its\nconstructor, `mk`, the usual eliminators (`rec` and `recOn`), as well as the\nprojections, `fst` and `snd`, as defined above.\n\nIf you do not name the constructor, Lean uses `mk` as a default. For example,\nthe following defines a record to store a color as a triple of RGB values:\n\n    \n    \n    structure Color where\n      (red : Nat) (green : Nat) (blue : Nat)\n      deriving Repr\n    \n    def yellow := Color.mk 255 255 0\n    \n    #eval Color.red yellow\n    \n\nThe definition of `yellow` forms the record with the three values shown, and\nthe projection `Color.red` returns the red component.\n\nYou can avoid the parentheses if you add a line break between each field.\n\n    \n    \n    structure Color where\n      red : Nat\n      green : Nat\n      blue : Nat\n      deriving Repr\n    \n\nThe `structure` command is especially useful for defining algebraic\nstructures, and Lean provides substantial infrastructure to support working\nwith them. Here, for example, is the definition of a semigroup:\n\n    \n    \n    structure Semigroup where\n      carrier : Type u\n      mul : carrier → carrier → carrier\n      mul_assoc : ∀ a b c, mul (mul a b) c = mul a (mul b c)\n    \n\nWe will see more examples in [Chapter Structures and\nRecords](./structures_and_records.html).\n\nWe have already discussed the dependent product type `Sigma`:\n\n    \n    \n    namespace Hidden\n    inductive Sigma {α : Type u} (β : α → Type v) where\n      | mk : (a : α) → β a → Sigma β\n    end Hidden\n    \n\nTwo more examples of inductive types in the library are the following:\n\n    \n    \n    namespace Hidden\n    inductive Option (α : Type u) where\n      | none : Option α\n      | some : α → Option α\n    \n    inductive Inhabited (α : Type u) where\n      | mk : α → Inhabited α\n    end Hidden\n    \n\nIn the semantics of dependent type theory, there is no built-in notion of a\npartial function. Every element of a function type `α → β` or a dependent\nfunction type `(a : α) → β` is assumed to have a value at every input. The\n`Option` type provides a way of representing partial functions. An element of\n`Option β` is either `none` or of the form `some b`, for some value `b : β`.\nThus we can think of an element `f` of the type `α → Option β` as being a\npartial function from `α` to `β`: for every `a : α`, `f a` either returns\n`none`, indicating `f a` is "undefined", or `some b`.\n\nAn element of `Inhabited α` is simply a witness to the fact that there is an\nelement of `α`. Later, we will see that `Inhabited` is an example of a _type\nclass_ in Lean: Lean can be instructed that suitable base types are inhabited,\nand can automatically infer that other constructed types are inhabited on that\nbasis.\n\nAs exercises, we encourage you to develop a notion of composition for partial\nfunctions from `α` to `β` and `β` to `γ`, and show that it behaves as\nexpected. We also encourage you to show that `Bool` and `Nat` are inhabited,\nthat the product of two inhabited types is inhabited, and that the type of\nfunctions to an inhabited type is inhabited.\n\n## Inductively Defined Propositions\n\nInductively defined types can live in any type universe, including the bottom-\nmost one, `Prop`. In fact, this is exactly how the logical connectives are\ndefined.\n\n    \n    \n    namespace Hidden\n    inductive False : Prop\n    \n    inductive True : Prop where\n      | intro : True\n    \n    inductive And (a b : Prop) : Prop where\n      | intro : a → b → And a b\n    \n    inductive Or (a b : Prop) : Prop where\n      | inl : a → Or a b\n      | inr : b → Or a b\n    end Hidden\n    \n\nYou should think about how these give rise to the introduction and elimination\nrules that you have already seen. There are rules that govern what the\neliminator of an inductive type can eliminate _to_ , that is, what kinds of\ntypes can be the target of a recursor. Roughly speaking, what characterizes\ninductive types in `Prop` is that one can only eliminate to other types in\n`Prop`. This is consistent with the understanding that if `p : Prop`, an\nelement `hp : p` carries no data. There is a small exception to this rule,\nhowever, which we will discuss below, in Section Inductive Families.\n\nEven the existential quantifier is inductively defined:\n\n    \n    \n    namespace Hidden\n    inductive Exists {α : Sort u} (p : α → Prop) : Prop where\n      | intro (w : α) (h : p w) : Exists p\n    end Hidden\n    \n\nKeep in mind that the notation `∃ x : α, p` is syntactic sugar for `Exists\n(fun x : α => p)`.\n\nThe definitions of `False`, `True`, `And`, and `Or` are perfectly analogous to\nthe definitions of `Empty`, `Unit`, `Prod`, and `Sum`. The difference is that\nthe first group yields elements of `Prop`, and the second yields elements of\n`Type u` for some `u`. In a similar way, `∃ x : α, p` is a `Prop`-valued\nvariant of `Σ x : α, p`.\n\nThis is a good place to mention another inductive type, denoted `{x : α //\np}`, which is sort of a hybrid between `∃ x : α, P` and `Σ x : α, P`.\n\n    \n    \n    namespace Hidden\n    inductive Subtype {α : Type u} (p : α → Prop) where\n      | mk : (x : α) → p x → Subtype p\n    end Hidden\n    \n\nIn fact, in Lean, `Subtype` is defined using the structure command:\n\n    \n    \n    namespace Hidden\n    structure Subtype {α : Sort u} (p : α → Prop) where\n      val : α\n      property : p val\n    end Hidden\n    \n\nThe notation `{x : α // p x}` is syntactic sugar for `Subtype (fun x : α => p\nx)`. It is modeled after subset notation in set theory: the idea is that `{x :\nα // p x}` denotes the collection of elements of `α` that have property `p`.\n\n## Defining the Natural Numbers\n\nThe inductively defined types we have seen so far are "flat": constructors\nwrap data and insert it into a type, and the corresponding recursor unpacks\nthe data and acts on it. Things get much more interesting when the\nconstructors act on elements of the very type being defined. A canonical\nexample is the type `Nat` of natural numbers:\n\n    \n    \n    namespace Hidden\n    inductive Nat where\n      | zero : Nat\n      | succ : Nat → Nat\n    end Hidden\n    \n\nThere are two constructors. We start with `zero : Nat`; it takes no arguments,\nso we have it from the start. In contrast, the constructor `succ` can only be\napplied to a previously constructed `Nat`. Applying it to `zero` yields `succ\nzero : Nat`. Applying it again yields `succ (succ zero) : Nat`, and so on.\nIntuitively, `Nat` is the "smallest" type with these constructors, meaning\nthat it is exhaustively (and freely) generated by starting with `zero` and\napplying `succ` repeatedly.\n\nAs before, the recursor for `Nat` is designed to define a dependent function\n`f` from `Nat` to any domain, that is, an element `f` of `(n : Nat) → motive\nn` for some `motive : Nat → Sort u`. It has to handle two cases: the case\nwhere the input is `zero`, and the case where the input is of the form `succ\nn` for some `n : Nat`. In the first case, we simply specify a target value\nwith the appropriate type, as before. In the second case, however, the\nrecursor can assume that a value of `f` at `n` has already been computed. As a\nresult, the next argument to the recursor specifies a value for `f (succ n)`\nin terms of `n` and `f n`. If we check the type of the recursor,\n\n    \n    \n    namespace Hidden\n    inductive Nat where\n     | zero : Nat\n     | succ : Nat → Nat\n    #check @Nat.rec\n    end Hidden\n    \n\nyou find the following:\n\n    \n    \n      {motive : Nat → Sort u}\n      → motive Nat.zero\n      → ((n : Nat) → motive n → motive (Nat.succ n))\n      → (t : Nat) → motive t\n    \n\nThe implicit argument, `motive`, is the codomain of the function being\ndefined. In type theory it is common to say `motive` is the _motive_ for the\nelimination/recursion, since it describes the kind of object we wish to\nconstruct. The next two arguments specify how to compute the zero and\nsuccessor cases, as described above. They are also known as the _minor\npremises_. Finally, the `t : Nat`, is the input to the function. It is also\nknown as the _major premise_.\n\nThe `Nat.recOn` is similar to `Nat.rec` but the major premise occurs before\nthe minor premises.\n\n    \n    \n    @Nat.recOn :\n      {motive : Nat → Sort u}\n      → (t : Nat)\n      → motive Nat.zero\n      → ((n : Nat) → motive n → motive (Nat.succ n))\n      → motive t\n    \n\nConsider, for example, the addition function `add m n` on the natural numbers.\nFixing `m`, we can define addition by recursion on `n`. In the base case, we\nset `add m zero` to `m`. In the successor step, assuming the value `add m n`\nis already determined, we define `add m (succ n)` to be `succ (add m n)`.\n\n    \n    \n    namespace Hidden\n    inductive Nat where\n      | zero : Nat\n      | succ : Nat → Nat\n      deriving Repr\n    \n    def add (m n : Nat) : Nat :=\n      match n with\n      | Nat.zero   => m\n      | Nat.succ n => Nat.succ (add m n)\n    \n    open Nat\n    \n    #eval add (succ (succ zero)) (succ zero)\n    end Hidden\n    \n\nIt is useful to put such definitions into a namespace, `Nat`. We can then go\non to define familiar notation in that namespace. The two defining equations\nfor addition now hold definitionally:\n\n    \n    \n    namespace Hidden\n    inductive Nat where\n     | zero : Nat\n     | succ : Nat → Nat\n     deriving Repr\n    namespace Nat\n    \n    def add (m n : Nat) : Nat :=\n      match n with\n      | Nat.zero   => m\n      | Nat.succ n => Nat.succ (add m n)\n    \n    instance : Add Nat where\n      add := add\n    \n    theorem add_zero (m : Nat) : m + zero = m := rfl\n    theorem add_succ (m n : Nat) : m + succ n = succ (m + n) := rfl\n    \n    end Nat\n    end Hidden\n    \n\nWe will explain how the `instance` command works in [Chapter Type\nClasses](./type_classes.html). In the examples below, we will use Lean\'s\nversion of the natural numbers.\n\nProving a fact like `zero + m = m`, however, requires a proof by induction. As\nobserved above, the induction principle is just a special case of the\nrecursion principle, when the codomain `motive n` is an element of `Prop`. It\nrepresents the familiar pattern of an inductive proof: to prove `∀ n, motive\nn`, first prove `motive 0`, and then, for arbitrary `n`, assume `ih : motive\nn` and prove `motive (succ n)`.\n\n    \n    \n    namespace Hidden\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n :=\n      Nat.recOn (motive := fun x => 0 + x = x)\n       n\n       (show 0 + 0 = 0 from rfl)\n       (fun (n : Nat) (ih : 0 + n = n) =>\n        show 0 + succ n = succ n from\n        calc 0 + succ n\n          _ = succ (0 + n) := rfl\n          _ = succ n       := by rw [ih])\n    end Hidden\n    \n\nNotice that, once again, when `Nat.recOn` is used in the context of a proof,\nit is really the induction principle in disguise. The `rewrite` and `simp`\ntactics tend to be very effective in proofs like these. In this case, each can\nbe used to reduce the proof to:\n\n    \n    \n    namespace Hidden\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n :=\n      Nat.recOn (motive := fun x => 0 + x = x) n\n        rfl\n        (fun n ih => by simp [add_succ, ih])\n    end Hidden\n    \n\nAs another example, let us prove the associativity of addition, `∀ m n k, m +\nn + k = m + (n + k)`. (The notation `+`, as we have defined it, associates to\nthe left, so `m + n + k` is really `(m + n) + k`.) The hardest part is\nfiguring out which variable to do the induction on. Since addition is defined\nby recursion on the second argument, `k` is a good guess, and once we make\nthat choice the proof almost writes itself:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) :=\n      Nat.recOn (motive := fun k => m + n + k = m + (n + k)) k\n        (show m + n + 0 = m + (n + 0) from rfl)\n        (fun k (ih : m + n + k = m + (n + k)) =>\n          show m + n + succ k = m + (n + succ k) from\n          calc m + n + succ k\n            _ = succ (m + n + k)   := rfl\n            _ = succ (m + (n + k)) := by rw [ih]\n            _ = m + succ (n + k)   := rfl\n            _ = m + (n + succ k)   := rfl)\n    end Hidden\n    \n\nOnce again, you can reduce the proof to:\n\n    \n    \n    open Nat\n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) :=\n      Nat.recOn (motive := fun k => m + n + k = m + (n + k)) k\n        rfl\n        (fun k ih => by simp [Nat.add_succ, ih])\n    \n\nSuppose we try to prove the commutativity of addition. Choosing induction on\nthe second argument, we might begin as follows:\n\n    \n    \n    open Nat\n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n       (show m + 0 = 0 +', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:21,466 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:21,467 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:54:21,473 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59a778fb0>
2025-06-01 01:54:21,474 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x75d59b04eed0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:54:21,481 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59b1ce780>
2025-06-01 01:54:21,481 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:21,482 - DEBUG - send_request_headers.complete
2025-06-01 01:54:21,482 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:21,482 - DEBUG - send_request_body.complete
2025-06-01 01:54:21,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:22,675 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'216'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-6b5d94d96-45wrh'), (b'x-envoy-upstream-service-time', b'221'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'992252'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'464ms'), (b'x-request-id', b'req_f26159c82178248d0175a2bd2492c526'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=iQgnW4Q9IQofC8_0DZuZ3kAnjpHuMlgFnl5CRW6GHYI-1748742862-1.0.1.1-oidD2.VL766D3xeEEGSuCytkhYvhdvR.odjz35h6LZVGUd01njTfdFDnWAV8RamVhIYzOH8OuVJhMuqgjGDQQKKCp.QHFo1M0SKxBrRa8D8; path=/; expires=Sun, 01-Jun-25 02:24:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=n5V.MSw69MGN2pHjM.8ZBZDHybrrWSrHzBmst_6iSA0-1748742862671-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b15244a773bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:22,676 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:22,676 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:22,676 - DEBUG - receive_response_body.complete
2025-06-01 01:54:22,676 - DEBUG - response_closed.started
2025-06-01 01:54:22,677 - DEBUG - response_closed.complete
2025-06-01 01:54:22,677 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 01:54:22 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '216'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-6b5d94d96-45wrh'), ('x-envoy-upstream-service-time', '221'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '992252'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '464ms'), ('x-request-id', 'req_f26159c82178248d0175a2bd2492c526'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=iQgnW4Q9IQofC8_0DZuZ3kAnjpHuMlgFnl5CRW6GHYI-1748742862-1.0.1.1-oidD2.VL766D3xeEEGSuCytkhYvhdvR.odjz35h6LZVGUd01njTfdFDnWAV8RamVhIYzOH8OuVJhMuqgjGDQQKKCp.QHFo1M0SKxBrRa8D8; path=/; expires=Sun, 01-Jun-25 02:24:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=n5V.MSw69MGN2pHjM.8ZBZDHybrrWSrHzBmst_6iSA0-1748742862671-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b15244a773bfe-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 01:54:22,677 - DEBUG - request_id: req_f26159c82178248d0175a2bd2492c526
2025-06-01 01:54:22,679 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': ' m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:22,680 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:22,680 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:22,681 - DEBUG - send_request_headers.complete
2025-06-01 01:54:22,681 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:22,681 - DEBUG - send_request_body.complete
2025-06-01 01:54:22,681 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:23,297 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'169'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7fbbd4cf65-fxcjm'), (b'x-envoy-upstream-service-time', b'173'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'993051'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'416ms'), (b'x-request-id', b'req_5b74e1b234ec491f34f1b5d1dfe84aa8'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b152bce113bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:23,297 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:23,297 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:23,298 - DEBUG - receive_response_body.complete
2025-06-01 01:54:23,298 - DEBUG - response_closed.started
2025-06-01 01:54:23,298 - DEBUG - response_closed.complete
2025-06-01 01:54:23,298 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '169', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-7fbbd4cf65-fxcjm', 'x-envoy-upstream-service-time': '173', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '993051', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '416ms', 'x-request-id': 'req_5b74e1b234ec491f34f1b5d1dfe84aa8', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b152bce113bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:23,298 - DEBUG - request_id: req_5b74e1b234ec491f34f1b5d1dfe84aa8
2025-06-01 01:54:23,299 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Axioms and Computation\n\nWe have seen that the version of the Calculus of Constructions that has been\nimplemented in Lean includes dependent function types, inductive types, and a\nhierarchy of universes that starts with an impredicative, proof-irrelevant\n`Prop` at the bottom. In this chapter, we consider ways of extending the CIC\nwith additional axioms and rules. Extending a foundational system in such a\nway is often convenient; it can make it possible to prove more theorems, as\nwell as make it easier to prove theorems that could have been proved\notherwise. But there can be negative consequences of adding additional axioms,\nconsequences which may go beyond concerns about their correctness. In\nparticular, the use of axioms bears on the computational content of\ndefinitions and theorems, in ways we will explore here.\n\nLean is designed to support both computational and classical reasoning. Users\nthat are so inclined can stick to a "computationally pure" fragment, which\nguarantees that closed expressions in the system evaluate to canonical normal\nforms. In particular, any closed computationally pure expression of type\n`Nat`, for example, will reduce to a numeral.\n\nLean\'s standard library defines an additional axiom, propositional\nextensionality, and a quotient construction which in turn implies the\nprinciple of function extensionality. These extensions are used, for example,\nto develop theories of sets and finite sets. We will see below that using\nthese theorems can block evaluation in Lean\'s kernel, so that closed terms of\ntype `Nat` no longer evaluate to numerals. But Lean erases types and\npropositional information when compiling definitions to bytecode for its\nvirtual machine evaluator, and since these axioms only add new propositions,\nthey are compatible with that computational interpretation. Even\ncomputationally inclined users may wish to use the classical law of the\nexcluded middle to reason about computation. This also blocks evaluation in\nthe kernel, but it is compatible with compilation to bytecode.\n\nThe standard library also defines a choice principle that is entirely\nantithetical to a computational interpretation, since it magically produces\n"data" from a proposition asserting its existence. Its use is essential to\nsome classical constructions, and users can import it when needed. But\nexpressions that use this construction to produce data do not have\ncomputational content, and in Lean we are required to mark such definitions as\n`noncomputable` to flag that fact.\n\nUsing a clever trick (known as Diaconescu\'s theorem), one can use\npropositional extensionality, function extensionality, and choice to derive\nthe law of the excluded middle. As noted above, however, use of the law of the\nexcluded middle is still compatible with bytecode compilation and code\nextraction, as are other classical principles, as long as they are not used to\nmanufacture data.\n\nTo summarize, then, on top of the underlying framework of universes, dependent\nfunction types, and inductive types, the standard library adds three\nadditional components:\n\n  * the axiom of propositional extensionality\n  * a quotient construction, which implies function extensionality\n  * a choice principle, which produces data from an existential proposition.\n\nThe first two of these block normalization within Lean, but are compatible\nwith bytecode evaluation, whereas the third is not amenable to computational\ninterpretation. We will spell out the details more precisely below.\n\n## Historical and Philosophical Context\n\nFor most of its history, mathematics was essentially computational: geometry\ndealt with constructions of geometric objects, algebra was concerned with\nalgorithmic solutions to systems of equations, and analysis provided means to\ncompute the future behavior of systems evolving over time. From the proof of a\ntheorem to the effect that "for every `x`, there is a `y` such that ...", it\nwas generally straightforward to extract an algorithm to compute such a `y`\ngiven `x`.\n\nIn the nineteenth century, however, increases in the complexity of\nmathematical arguments pushed mathematicians to develop new styles of\nreasoning that suppress algorithmic information and invoke descriptions of\nmathematical objects that abstract away the details of how those objects are\nrepresented. The goal was to obtain a powerful "conceptual" understanding\nwithout getting bogged down in computational details, but this had the effect\nof admitting mathematical theorems that are simply _false_ on a direct\ncomputational reading.\n\nThere is still fairly uniform agreement today that computation is important to\nmathematics. But there are different views as to how best to address\ncomputational concerns. From a _constructive_ point of view, it is a mistake\nto separate mathematics from its computational roots; every meaningful\nmathematical theorem should have a direct computational interpretation. From a\n_classical_ point of view, it is more fruitful to maintain a separation of\nconcerns: we can use one language and body of methods to write computer\nprograms, while maintaining the freedom to use nonconstructive theories and\nmethods to reason about them. Lean is designed to support both of these\napproaches. Core parts of the library are developed constructively, but the\nsystem also provides support for carrying out classical mathematical\nreasoning.\n\nComputationally, the purest part of dependent type theory avoids the use of\n`Prop` entirely. Inductive types and dependent function types can be viewed as\ndata types, and terms of these types can be "evaluated" by applying reduction\nrules until no more rules can be applied. In principle, any closed term (that\nis, term with no free variables) of type `Nat` should evaluate to a numeral,\n`succ (... (succ zero)...)`.\n\nIntroducing a proof-irrelevant `Prop` and marking theorems irreducible\nrepresents a first step towards separation of concerns. The intention is that\nelements of a type `p : Prop` should play no role in computation, and so the\nparticular construction of a term `t : p` is "irrelevant" in that sense. One\ncan still define computational objects that incorporate elements of type\n`Prop`; the point is that these elements can help us reason about the effects\nof the computation, but can be ignored when we extract "code" from the term.\nElements of type `Prop` are not entirely innocuous, however. They include\nequations `s = t : α` for any type `α`, and such equations can be used as\ncasts, to type check terms. Below, we will see examples of how such casts can\nblock computation in the system. However, computation is still possible under\nan evaluation scheme that erases propositional content, ignores intermediate\ntyping constraints, and reduces terms until they reach a normal form. This is\nprecisely what Lean\'s virtual machine does.\n\nHaving adopted a proof-irrelevant `Prop`, one might consider it legitimate to\nuse, for example, the law of the excluded middle, `p ∨ ¬p`, where `p` is any\nproposition. Of course, this, too, can block computation according to the\nrules of CIC, but it does not block bytecode evaluation, as described above.\nIt is only the choice principles discussed in :numref:`choice` that completely\nerase the distinction between the proof-irrelevant and data-relevant parts of\nthe theory.\n\n## Propositional Extensionality\n\nPropositional extensionality is the following axiom:\n\n    \n    \n    namespace Hidden\n    axiom propext {a b : Prop} : (a ↔ b) → a = b\n    end Hidden\n    \n\nIt asserts that when two propositions imply one another, they are actually\nequal. This is consistent with set-theoretic interpretations in which any\nelement `a : Prop` is either empty or the singleton set `{*}`, for some\ndistinguished element `*`. The axiom has the effect that equivalent\npropositions can be substituted for one another in any context:\n\n    \n    \n    theorem thm₁ (a b c d e : Prop) (h : a ↔ b) : (c ∧ a ∧ d → e) ↔ (c ∧ b ∧ d → e) :=\n      propext h ▸ Iff.refl _\n    \n    theorem thm₂ (a b : Prop) (p : Prop → Prop) (h : a ↔ b) (h₁ : p a) : p b :=\n      propext h ▸ h₁\n    \n\n## Function Extensionality\n\nSimilar to propositional extensionality, function extensionality asserts that\nany two functions of type `(x : α) → β x` that agree on all their inputs are\nequal:\n\n    \n    \n    universe u v\n    #check (@funext :\n               {α : Type u}\n             → {β : α → Type u}\n             → {f g : (x : α) → β x}\n             → (∀ (x : α), f x = g x)\n             → f = g)\n    \n    #print funext\n    \n\nFrom a classical, set-theoretic perspective, this is exactly what it means for\ntwo functions to be equal. This is known as an "extensional" view of\nfunctions. From a constructive perspective, however, it is sometimes more\nnatural to think of functions as algorithms, or computer programs, that are\npresented in some explicit way. It is certainly the case that two computer\nprograms can compute the same answer for every input despite the fact that\nthey are syntactically quite different. In much the same way, you might want\nto maintain a view of functions that does not force you to identify two\nfunctions that have the same input / output behavior. This is known as an\n"intensional" view of functions.\n\nIn fact, function extensionality follows from the existence of quotients,\nwhich we describe in the next section. In the Lean standard library,\ntherefore, `funext` is thus [proved from the quotient\nconstruction](https://github.com/leanprover/lean4/blob/master/src/Init/Core.lean).\n\nSuppose that for `α : Type` we define the `Set α := α → Prop` to denote the\ntype of subsets of `α`, essentially identifying subsets with predicates. By\ncombining `funext` and `propext`, we obtain an extensional theory of such\nsets:\n\n    \n    \n    def Set (α : Type u) := α → Prop\n    \n    namespace Set\n    \n    def mem (x : α) (a : Set α) := a x\n    \n    infix:50 (priority := high) "∈" => mem\n    \n    theorem setext {a b : Set α} (h : ∀ x, x ∈ a ↔ x ∈ b) : a = b :=\n      funext (fun x => propext (h x))\n    \n    end Set\n    \n\nWe can then proceed to define the empty set and set intersection, for example,\nand prove set identities:\n\n    \n    \n    def Set (α : Type u) := α → Prop\n    namespace Set\n    def mem (x : α) (a : Set α) := a x\n    infix:50 (priority := high) "∈" => mem\n    theorem setext {a b : Set α} (h : ∀ x, x ∈ a ↔ x ∈ b) : a = b :=\n      funext (fun x => propext (h x))\n    def empty : Set α := fun x => False\n    \n    notation (priority := high) "∅" => empty\n    \n    def inter (a b : Set α) : Set α :=\n      fun x => x ∈ a ∧ x ∈ b\n    \n    infix:70 " ∩ " => inter\n    \n    theorem inter_self (a : Set α) : a ∩ a = a :=\n      setext fun x => Iff.intro\n        (fun ⟨h, _⟩ => h)\n        (fun h => ⟨h, h⟩)\n    \n    theorem inter_empty (a : Set α) : a ∩ ∅ = ∅ :=\n      setext fun x => Iff.intro\n        (fun ⟨_, h⟩ => h)\n        (fun h => False.elim h)\n    \n    theorem empty_inter (a : Set α) : ∅ ∩ a = ∅ :=\n      setext fun x => Iff.intro\n        (fun ⟨h, _⟩ => h)\n        (fun h => False.elim h)\n    \n    theorem inter.comm (a b : Set α) : a ∩ b = b ∩ a :=\n      setext fun x => Iff.intro\n        (fun ⟨h₁, h₂⟩ => ⟨h₂, h₁⟩)\n        (fun ⟨h₁, h₂⟩ => ⟨h₂, h₁⟩)\n    end Set\n    \n\nThe following is an example of how function extensionality blocks computation\ninside the Lean kernel:\n\n    \n    \n    def f (x : Nat) := x\n    def g (x : Nat) := 0 + x\n    \n    theorem f_eq_g : f = g :=\n      funext fun x => (Nat.zero_add x).symm\n    \n    def val : Nat :=\n      Eq.recOn (motive := fun _ _ => Nat) f_eq_g 0\n    \n    -- does not reduce to 0\n    #reduce val\n    \n    -- evaluates to 0\n    #eval val\n    \n\nFirst, we show that the two functions `f` and `g` are equal using function\nextensionality, and then we cast `0` of type `Nat` by replacing `f` by `g` in\nthe type. Of course, the cast is vacuous, because `Nat` does not depend on\n`f`. But that is enough to do the damage: under the computational rules of the\nsystem, we now have a closed term of `Nat` that does not reduce to a numeral.\nIn this case, we may be tempted to reduce the expression to `0`. But in\nnontrivial examples, eliminating cast changes the type of the term, which\nmight make an ambient expression type incorrect. The virtual machine, however,\nhas no trouble evaluating the expression to `0`. Here is a similarly contrived\nexample that shows how `propext` can get in the way:\n\n    \n    \n    theorem tteq : (True ∧ True) = True :=\n      propext (Iff.intro (fun ⟨h, _⟩ => h) (fun h => ⟨h, h⟩))\n    \n    def val : Nat :=\n      Eq.recOn (motive := fun _ _ => Nat) tteq 0\n    \n    -- does not reduce to 0\n    #reduce val\n    \n    -- evaluates to 0\n    #eval val\n    \n\nCurrent research programs, including work on _observational type theory_ and\n_cubical type theory_ , aim to extend type theory in ways that permit\nreductions for casts involving function extensionality, quotients, and more.\nBut the solutions are not so clear-cut, and the rules of Lean\'s underlying\ncalculus do not sanction such reductions.\n\nIn a sense, however, a cast does not change the meaning of an expression.\nRather, it is a mechanism to reason about the expression\'s type. Given an\nappropriate semantics, it then makes sense to reduce terms in ways that\npreserve their meaning, ignoring the intermediate bookkeeping needed to make\nthe reductions type-correct. In that case, adding new axioms in `Prop` does\nnot matter; by proof irrelevance, an expression in `Prop` carries no\ninformation, and can be safely ignored by the reduction procedures.\n\n## Quotients\n\nLet `α` be any type, and let `r` be an equivalence relation on `α`. It is\nmathematically common to form the "quotient" `α / r`, that is, the type of\nelements of `α` "modulo" `r`. Set theoretically, one can view `α / r` as the\nset of equivalence classes of `α` modulo `r`. If `f : α → β` is any function\nthat respects the equivalence relation in the sense that for every `x y : α`,\n`r x y` implies `f x = f y`, then `f` "lifts" to a function `f\' : α / r → β`\ndefined on each equivalence class `⟦x⟧` by `f\' ⟦x⟧ = f x`. Lean\'s standard\nlibrary extends the Calculus of Constructions with additional constants that\nperform exactly these constructions, and installs this last equation as a\ndefinitional reduction rule.\n\nIn its most basic form, the quotient construction does not even require `r` to\nbe an equivalence relation. The following constants are built into Lean:\n\n    \n    \n    namespace Hidden\n    universe u v\n    \n    axiom Quot : {α : Sort u} → (α → α → Prop) → Sort u\n    \n    axiom Quot.mk : {α : Sort u} → (r : α → α → Prop) → α → Quot r\n    \n    axiom Quot.ind :\n        ∀ {α : Sort u} {r : α → α → Prop} {β : Quot r → Prop},\n          (∀ a, β (Quot.mk r a)) → (q : Quot r) → β q\n    \n    axiom Quot.lift :\n        {α : Sort u} → {r : α → α → Prop} → {β : Sort u} → (f : α → β)\n        → (∀ a b, r a b → f a = f b) → Quot r → β\n    end Hidden\n    \n\nThe first one forms a type `Quot r` given a type `α` by any binary relation\n`r` on `α`. The second maps `α` to `Quot α`, so that if `r : α → α → Prop` and\n`a : α`, then `Quot.mk r a` is an element of `Quot r`. The third principle,\n`Quot.ind`, says that every element of `Quot.mk r a` is of this form. As for\n`Quot.lift`, given a function `f : α → β`, if `h` is a proof that `f` respects\nthe relation `r`, then `Quot.lift f h` is the corresponding function on `Quot\nr`. The idea is that for each element `a` in `α`, the function `Quot.lift f h`\nmaps `Quot.mk r a` (the `r`-class containing `a`) to `f a`, wherein `h` shows\nthat this function is well defined. In fact, the computation principle is\ndeclared as a reduction rule, as the proof below makes clear.\n\n    \n    \n    def mod7Rel (x y : Nat) : Prop :=\n      x % 7 = y % 7\n    \n    -- the quotient type\n    #check (Quot mod7Rel : Type)\n    \n    -- the class of a\n    #check (Quot.mk mod7Rel 4 : Quot mod7Rel)\n    \n    def f (x : Nat) : Bool :=\n      x % 7 = 0\n    \n    theorem f_respects (a b : Nat) (h : mod7Rel a b) : f a = f b := by\n      simp [mod7Rel, f] at *\n      rw [h]\n    \n    #check (Quot.lift f f_respects : Quot mod7Rel → Bool)\n    \n    -- the computation principle\n    example (a : Nat) : Quot.lift f f_respects (Quot.mk mod7Rel a) = f a :=\n      rfl\n    \n\nThe four constants, `Quot`, `Quot.mk`, `Quot.ind`, and `Quot.lift` in and of\nthemselves are not very strong. You can check that the `Quot.ind` is satisfied\nif we take `Quot r` to be simply `α`, and take `Quot.lift` to be the identity\nfunction (ignoring `h`). For that reason, these four constants are not viewed\nas additional axioms.\n\nThey are, like inductively defined types and the associated constructors and\nrecursors, viewed as part of the logical framework.\n\nWhat makes the `Quot` construction into a bona fide quotient is the following\nadditional axiom:\n\n    \n    \n    namespace Hidden\n    universe u v\n    axiom Quot.sound :\n          ∀ {α : Type u} {r : α → α → Prop} {a b : α},\n            r a b → Quot.mk r a = Quot.mk r b\n    end Hidden\n    \n\nThis is the axiom that asserts that any two elements of `α` that are related\nby `r` become identified in the quotient. If a theorem or definition makes use\nof `Quot.sound`, it will show up in the `#print axioms` command.\n\nOf course, the quotient construction is most commonly used in situations when\n`r` is an equivalence relation. Given `r` as above, if we define `r\'`\naccording to the rule `r\' a b` iff `Quot.mk r a = Quot.mk r b`, then it\'s\nclear that `r\'` is an equivalence relation. Indeed, `r\'` is the _kernel_ of\nthe function `a ↦ quot.mk r a`. The axiom `Quot.sound` says that `r a b`\nimplies `r\' a b`. Using `Quot.lift` and `Quot.ind`, we can show that `r\'` is\nthe smallest equivalence relation containing `r`, in the sense that if `r\'\'`\nis any equivalence relation containing `r`, then `r\' a b` implies `r\'\' a b`.\nIn particular, if `r` was an equivalence relation to start with, then for all\n`a` and `b` we have `r a b` iff `r\' a b`.\n\nTo support this common use case, the standard library defines the notion of a\n_setoid_ , which is simply a type with an associated equivalence relation:\n\n    \n    \n    namespace Hidden\n    class Setoid (α : Sort u) where\n      r : α → α → Prop\n      iseqv : Equivalence r\n    \n    instance {α : Sort u} [Setoid α] : HasEquiv α :=\n      ⟨Setoid.r⟩\n    \n    namespace Setoid\n    \n    variable {α : Sort u} [Setoid α]\n    \n    theorem refl (a : α) : a ≈ a :=\n      iseqv.refl a\n    \n    theorem symm {a b : α} (hab : a ≈ b) : b ≈ a :=\n      iseqv.symm hab\n    \n    theorem trans {a b c : α} (hab : a ≈ b) (hbc : b ≈ c) : a ≈ c :=\n      iseqv.trans hab hbc\n    \n    end Setoid\n    end Hidden\n    \n\nGiven a type `α`, a relation `r` on `α`, and a proof `p` that `r` is an\nequivalence relation, we can define `Setoid.mk r p` as an instance of the\nsetoid class.\n\n    \n    \n    namespace Hidden\n    def Quotient {α : Sort u} (s : Setoid α) :=\n      @Quot α Setoid.r\n    end Hidden\n    \n\nThe constants `Quotient.mk`, `Quotient.ind`, `Quotient.lift`, and\n`Quotient.sound` are nothing more than the specializations of the\ncorresponding elements of `Quot`. The fact that type class inference can find\nthe setoid associated to a type `α` brings a number of benefits. First, we can\nuse the notation `a ≈ b` (entered with `\\approx`) for `Setoid.r a b`, where\nthe instance of `Setoid` is implicit in the notation `Setoid.r`. We can use\nthe generic theorems `Setoid.refl`, `Setoid.symm`, `Setoid.trans` to reason\nabout the relation. Specifically with quotients we can use the generic\nnotation `⟦a⟧` for `Quot.mk Setoid.r` where the instance of `Setoid` is\nimplicit in the notation `Setoid.r`, as well as the theorem `Quotient.exact`:\n\n    \n    \n    universe u\n    #check (@Quotient.exact :\n             ∀ {α : Sort u} {s : Setoid α} {a b : α},\n               Quotient.mk s a = Quotient.mk s b → a ≈ b)\n    \n\nTogether with `Quotient.sound`, this implies that the elements of the quotient\ncorrespond exactly to the equivalence classes of elements in `α`.\n\nRecall that in the standard library, `α × β` represents the Cartesian product\nof the types `α` and `β`. To illustrate the use of quotients, let us define\nthe type of _unordered_ pairs of elements of a type `α` as a quotient of the\ntype `α × α`. First, we define the relevant equivalence relation:\n\n    \n    \n    private def eqv (p₁ p₂ : α × α) : Prop :=\n      (p₁.1 = p₂.1 ∧ p₁.2 = p₂.2) ∨ (p₁.1 = p₂.2 ∧ p₁.2 = p₂.1)\n    \n    infix:50 " ~ " => eqv\n    \n\nThe next step is to prove that `eqv` is in fact an equivalence relation, which\nis to say, it is reflexive, symmetric and transitive. We can prove these three\nfacts in a convenient and readable way by using dependent pattern matching to\nperform case-analysis and break the hypotheses into pieces that are then\nreassembled to produce the conclusion.\n\n    \n    \n    private def eqv (p₁ p₂ : α × α) : Prop :=\n      (p₁.1 = p₂.1 ∧ p₁.2 = p₂.2) ∨ (p₁.1 = p₂.2 ∧ p₁.2 = p₂.1)\n    infix:50 " ~ " => eqv\n    private theorem eqv.refl (p : α × α) : p ~ p :=\n      Or.inl ⟨rfl, rfl⟩\n    \n    private theorem eqv.symm : ∀ {p₁ p₂ : α × α}, p₁ ~ p₂ → p₂ ~ p₁\n      | (a₁, a₂), (b₁, b₂), (Or.inl ⟨a₁b₁, a₂b₂⟩) =>\n        Or.inl (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (Or.inr ⟨a₁b₂, a₂b₁⟩) =>\n        Or.inr (by simp_all)\n    \n    private theorem eqv.trans : ∀ {p₁ p₂ p₃ : α × α}, p₁ ~ p₂ → p₂ ~ p₃ → p₁ ~ p₃\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =>\n        Or.inl (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =>\n        Or.inr (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =>\n        Or.inr (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =>\n        Or.inl (by simp_all)\n    \n    private theorem is_equivalence : Equivalence (@eqv α) :=\n      { refl := eqv.refl, symm := eqv.symm, trans := eqv.trans }\n    \n\nNow that we have proved that `eqv` is an equivalence relation, we can\nconstruct a `Setoid (α × α)`, and use it to define the type `UProd α` of\nunordered pairs.\n\n    \n    \n    private def eqv (p₁ p₂ : α × α) : Prop :=\n      (p₁.1 = p₂.1 ∧ p₁.2 = p₂.2) ∨ (p₁.1 = p₂.2 ∧ p₁.2 = p₂.1)\n    infix:50 " ~ " => eqv\n    private theorem eqv.refl (p : α × α) : p ~ p :=\n      Or.inl ⟨rfl, rfl⟩\n    private theorem eqv.symm : ∀ {p₁ p₂ : α × α}, p₁ ~ p₂ → p₂ ~ p₁\n      | (a₁, a₂), (b₁, b₂), (Or.inl ⟨a₁b₁, a₂b₂⟩) =>\n        Or.inl (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (Or.inr ⟨a₁b₂, a₂b₁⟩) =>\n        Or.inr (by simp_all)\n    private theorem eqv.trans : ∀ {p₁ p₂ p₃ : α × α}, p₁ ~ p₂ → p₂ ~ p₃ → p₁ ~ p₃\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =>\n        Or.inl (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =>\n        Or.inr (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =>\n        Or.inr (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =>\n        Or.inl (by simp_all)\n    private theorem is_equivalence : Equivalence (@eqv α) :=\n      { refl := eqv.refl, symm := eqv.symm, trans := eqv.trans }\n    instance uprodSetoid (α : Type u) : Setoid (α × α) where\n      r     := eqv\n      iseqv := is_equivalence\n    \n    def UProd (α : Type u) : Type u :=\n      Quotient (uprodSetoid α)\n    \n    namespace UProd\n    \n    def mk {α : Type} (a₁ a₂ : α) : UProd α :=\n      Quotient.mk\' (a₁, a₂)\n    \n    notation "{ " a₁ ", " a₂ " }" => mk a₁ a₂\n    \n    end UProd\n    \n\nNotice that we locally define the notation `{a₁, a₂}` for unordered pairs as\n`Quotient.mk (a₁, a₂)`. This is useful for illustrative purposes, but it is\nnot a good idea in general, since the notation will shadow other uses of curly\nbrackets, such as for records and sets.\n\nWe can easily prove that `{a₁, a₂} = {a₂, a₁}` using `Quot.sound`, since we\nhave `(a₁, a₂) ~ (a₂, a₁)`.\n\n    \n    \n    private def eqv (p₁ p₂ : α × α) : Prop :=\n      (p₁.1 = p₂.1 ∧ p₁.2 = p₂.2) ∨ (p₁.1 = p₂.2 ∧ p₁.2 = p₂.1)\n    infix:50 " ~ " => eqv\n    private theorem eqv.refl (p : α × α) : p ~ p :=\n      Or.inl ⟨rfl, rfl⟩\n    private theorem eqv.symm : ∀ {p₁ p₂ : α × α}, p₁ ~ p₂ → p₂ ~ p₁\n      | (a₁, a₂), (b₁, b₂), (Or.inl ⟨a₁b₁, a₂b₂⟩) =>\n        Or.inl (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (Or.inr ⟨a₁b₂, a₂b₁⟩) =>\n        Or.inr (by simp_all)\n    private theorem eqv.trans : ∀ {p₁ p₂ p₃ : α × α}, p₁ ~ p₂ → p₂ ~ p₃ → p₁ ~ p₃\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =>\n        Or.inl (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =>\n        Or.inr (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =>\n        Or.inr (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =>\n        Or.inl (by simp_all)\n    private theorem is_equivalence : Equivalence (@eqv α) :=\n      { refl := eqv.refl, symm := eqv.symm, trans := eqv.trans }\n    instance uprodSetoid (α : Type u) : Setoid (α × α) where\n      r     := eqv\n      iseqv := is_equivalence\n    def UProd (α : Type u) : Type u :=\n      Quotient (uprodSetoid α)\n    namespace UProd\n    def mk {α : Type} (a₁ a₂ : α) : UProd α :=\n      Quotient.mk\' (a₁, a₂)\n    notation "{ " a₁ ", " a₂ " }" => mk a₁ a₂\n    theorem mk_eq_mk (a₁ a₂ : α) : {a₁, a₂} = {a₂, a₁} :=\n      Quot.sound (Or.inr ⟨rfl, rfl⟩)\n    end UProd\n    \n\nTo complete the example, given `a : α` and `u : uprod α`, we define the\nproposition `a ∈ u` which should hold if `a` is one of the elements of the\nunordered pair `u`. First, we define a similar proposition `mem_fn a u` on\n(ordered) pairs; then we show that `mem_fn` respects the equivalence relation\n`eqv` with the lemma `mem_respects`. This is an idiom that is used extensively\nin the Lean standard library.\n\n    \n    \n    private def eqv (p₁ p₂ : α × α) : Prop :=\n      (p₁.1 = p₂.1 ∧ p₁.2 = p₂.2) ∨ (p₁.1 = p₂.2 ∧ p₁.2 = p₂.1)\n    infix:50 " ~ " => eqv\n    private theorem eqv.refl (p : α × α) : p ~ p :=\n      Or.inl ⟨rfl, rfl⟩\n    private theorem eqv.symm : ∀ {p₁ p₂ : α × α}, p₁ ~ p₂ → p₂ ~ p₁\n      | (a₁, a₂), (b₁, b₂), (Or.inl ⟨a₁b₁, a₂b₂⟩) =>\n        Or.inl (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (Or.inr ⟨a₁b₂, a₂b₁⟩) =>\n        Or.inr (by simp_all)\n    private theorem eqv.trans : ∀ {p₁ p₂ p₃ : α', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:23,300 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:23,300 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:23,300 - DEBUG - send_request_headers.complete
2025-06-01 01:54:23,300 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:23,300 - DEBUG - send_request_body.complete
2025-06-01 01:54:23,300 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:24,058 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'195'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-786c6cd5df-gf2cl'), (b'x-envoy-upstream-service-time', b'198'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'992823'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'430ms'), (b'x-request-id', b'req_acbfd96100f8296b9e82922f850294f8'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b152fa86c3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:24,058 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:24,058 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:24,058 - DEBUG - receive_response_body.complete
2025-06-01 01:54:24,059 - DEBUG - response_closed.started
2025-06-01 01:54:24,059 - DEBUG - response_closed.complete
2025-06-01 01:54:24,059 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '195', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-786c6cd5df-gf2cl', 'x-envoy-upstream-service-time': '198', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '992823', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '430ms', 'x-request-id': 'req_acbfd96100f8296b9e82922f850294f8', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b152fa86c3bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:24,059 - DEBUG - request_id: req_acbfd96100f8296b9e82922f850294f8
2025-06-01 01:54:24,059 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': ' × α}, p₁ ~ p₂ → p₂ ~ p₃ → p₁ ~ p₃\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =>\n        Or.inl (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =>\n        Or.inr (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =>\n        Or.inr (by simp_all)\n      | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =>\n        Or.inl (by simp_all)\n    private theorem is_equivalence : Equivalence (@eqv α) :=\n      { refl := eqv.refl, symm := eqv.symm, trans := eqv.trans }\n    instance uprodSetoid (α : Type u) : Setoid (α × α) where\n      r     := eqv\n      iseqv := is_equivalence\n    def UProd (α : Type u) : Type u :=\n      Quotient (uprodSetoid α)\n    namespace UProd\n    def mk {α : Type} (a₁ a₂ : α) : UProd α :=\n      Quotient.mk\' (a₁, a₂)\n    notation "{ " a₁ ", " a₂ " }" => mk a₁ a₂\n    theorem mk_eq_mk (a₁ a₂ : α) : {a₁, a₂} = {a₂, a₁} :=\n      Quot.sound (Or.inr ⟨rfl, rfl⟩)\n    private def mem_fn (a : α) : α × α → Prop\n      | (a₁, a₂) => a = a₁ ∨ a = a₂\n    \n    -- auxiliary lemma for proving mem_respects\n    private theorem mem_swap {a : α} :\n          ∀ {p : α × α}, mem_fn a p = mem_fn a (⟨p.2, p.1⟩)\n      | (a₁, a₂) => by\n        apply propext\n        apply Iff.intro\n        . intro\n          | Or.inl h => exact Or.inr h\n          | Or.inr h => exact Or.inl h\n        . intro\n          | Or.inl h => exact Or.inr h\n          | Or.inr h => exact Or.inl h\n    \n    \n    private theorem mem_respects\n          : {p₁ p₂ : α × α} → (a : α) → p₁ ~ p₂ → mem_fn a p₁ = mem_fn a p₂\n      | (a₁, a₂), (b₁, b₂), a, Or.inl ⟨a₁b₁, a₂b₂⟩ => by simp_all\n      | (a₁, a₂), (b₁, b₂), a, Or.inr ⟨a₁b₂, a₂b₁⟩ => by simp_all; apply mem_swap\n    \n    def mem (a : α) (u : UProd α) : Prop :=\n      Quot.liftOn u (fun p => mem_fn a p) (fun p₁ p₂ e => mem_respects a e)\n    \n    infix:50 (priority := high) " ∈ " => mem\n    \n    theorem mem_mk_left (a b : α) : a ∈ {a, b} :=\n      Or.inl rfl\n    \n    theorem mem_mk_right (a b : α) : b ∈ {a, b} :=\n      Or.inr rfl\n    \n    theorem mem_or_mem_of_mem_mk {a b c : α} : c ∈ {a, b} → c = a ∨ c = b :=\n      fun h => h\n    end UProd\n    \n\nFor convenience, the standard library also defines `Quotient.lift₂` for\nlifting binary functions, and `Quotient.ind₂` for induction on two variables.\n\nWe close this section with some hints as to why the quotient construction\nimplies function extensionality. It is not hard to show that extensional\nequality on the `(x : α) → β x` is an equivalence relation, and so we can\nconsider the type `extfun α β` of functions "up to equivalence." Of course,\napplication respects that equivalence in the sense that if `f₁` is equivalent\nto `f₂`, then `f₁ a` is equal to `f₂ a`. Thus application gives rise to a\nfunction `extfun_app : extfun α β → (x : α) → β x`. But for every `f`,\n`extfun_app ⟦f⟧` is definitionally equal to `fun x => f x`, which is in turn\ndefinitionally equal to `f`. So, when `f₁` and `f₂` are extensionally equal,\nwe have the following chain of equalities:\n\n    \n    \n        f₁ = extfun_app ⟦f₁⟧ = extfun_app ⟦f₂⟧ = f₂\n    \n\nAs a result, `f₁` is equal to `f₂`.\n\n## Choice\n\nTo state the final axiom defined in the standard library, we need the\n`Nonempty` type, which is defined as follows:\n\n    \n    \n    namespace Hidden\n    class inductive Nonempty (α : Sort u) : Prop where\n      | intro (val : α) : Nonempty α\n    end Hidden\n    \n\nBecause `Nonempty α` has type `Prop` and its constructor contains data, it can\nonly eliminate to `Prop`. In fact, `Nonempty α` is equivalent to `∃ x : α,\nTrue`:\n\n    \n    \n    example (α : Type u) : Nonempty α ↔ ∃ x : α, True :=\n      Iff.intro (fun ⟨a⟩ => ⟨a, trivial⟩) (fun ⟨a, h⟩ => ⟨a⟩)\n    \n\nOur axiom of choice is now expressed simply as follows:\n\n    \n    \n    namespace Hidden\n    universe u\n    axiom choice {α : Sort u} : Nonempty α → α\n    end Hidden\n    \n\nGiven only the assertion `h` that `α` is nonempty, `choice h` magically\nproduces an element of `α`. Of course, this blocks any meaningful computation:\nby the interpretation of `Prop`, `h` contains no information at all as to how\nto find such an element.\n\nThis is found in the `Classical` namespace, so the full name of the theorem is\n`Classical.choice`. The choice principle is equivalent to the principle of\n_indefinite description_ , which can be expressed with subtypes as follows:\n\n    \n    \n    namespace Hidden\n    universe u\n    axiom choice {α : Sort u} : Nonempty α → α\n    noncomputable def indefiniteDescription {α : Sort u} (p : α → Prop)\n                                            (h : ∃ x, p x) : {x // p x} :=\n      choice <| let ⟨x, px⟩ := h; ⟨⟨x, px⟩⟩\n    end Hidden\n    \n\nBecause it depends on `choice`, Lean cannot generate bytecode for\n`indefiniteDescription`, and so requires us to mark the definition as\n`noncomputable`. Also in the `Classical` namespace, the function `choose` and\nthe property `choose_spec` decompose the two parts of the output of\n`indefiniteDescription`:\n\n    \n    \n    open Classical\n    namespace Hidden\n    noncomputable def choose {α : Sort u} {p : α → Prop} (h : ∃ x, p x) : α :=\n      (indefiniteDescription p h).val\n    \n    theorem choose_spec {α : Sort u} {p : α → Prop} (h : ∃ x, p x) : p (choose h) :=\n      (indefiniteDescription p h).property\n    end Hidden\n    \n\nThe `choice` principle also erases the distinction between the property of\nbeing `Nonempty` and the more constructive property of being `Inhabited`:\n\n    \n    \n    open Classical\n    theorem inhabited_of_nonempty : Nonempty α → Inhabited α :=\n      fun h => choice (let ⟨a⟩ := h; ⟨⟨a⟩⟩)\n    \n\nIn the next section, we will see that `propext`, `funext`, and `choice`, taken\ntogether, imply the law of the excluded middle and the decidability of all\npropositions. Using those, one can strengthen the principle of indefinite\ndescription as follows:\n\n    \n    \n    open Classical\n    universe u\n    #check (@strongIndefiniteDescription :\n             {α : Sort u} → (p : α → Prop)\n             → Nonempty α → {x // (∃ (y : α), p y) → p x})\n    \n\nAssuming the ambient type `α` is nonempty, `strongIndefiniteDescription p`\nproduces an element of `α` satisfying `p` if there is one. The data component\nof this definition is conventionally known as _Hilbert\'s epsilon function_ :\n\n    \n    \n    open Classical\n    universe u\n    #check (@epsilon :\n             {α : Sort u} → [Nonempty α]\n             → (α → Prop) → α)\n    \n    #check (@epsilon_spec :\n             ∀ {α : Sort u} {p : α → Prop} (hex : ∃ (y : α), p y),\n               p (@epsilon _ (nonempty_of_exists hex) p))\n    \n\n## The Law of the Excluded Middle\n\nThe law of the excluded middle is the following\n\n    \n    \n    open Classical\n    \n    #check (@em : ∀ (p : Prop), p ∨ ¬p)\n    \n\n[Diaconescu\'s theorem](https://en.wikipedia.org/wiki/Diaconescu%27s_theorem)\nstates that the axiom of choice is sufficient to derive the law of excluded\nmiddle. More precisely, it shows that the law of the excluded middle follows\nfrom `Classical.choice`, `propext`, and `funext`. We sketch the proof that is\nfound in the standard library.\n\nFirst, we import the necessary axioms, and define two predicates `U` and `V`:\n\n    \n    \n    namespace Hidden\n    open Classical\n    theorem em (p : Prop) : p ∨ ¬p :=\n      let U (x : Prop) : Prop := x = True ∨ p\n      let V (x : Prop) : Prop := x = False ∨ p\n    \n      have exU : ∃ x, U x := ⟨True, Or.inl rfl⟩\n      have exV : ∃ x, V x := ⟨False, Or.inl rfl⟩\n      sorry\n    end Hidden\n    \n\nIf `p` is true, then every element of `Prop` is in both `U` and `V`. If `p` is\nfalse, then `U` is the singleton `true`, and `V` is the singleton `false`.\n\nNext, we use `some` to choose an element from each of `U` and `V`:\n\n    \n    \n    namespace Hidden\n    open Classical\n    theorem em (p : Prop) : p ∨ ¬p :=\n      let U (x : Prop) : Prop := x = True ∨ p\n      let V (x : Prop) : Prop := x = False ∨ p\n      have exU : ∃ x, U x := ⟨True, Or.inl rfl⟩\n      have exV : ∃ x, V x := ⟨False, Or.inl rfl⟩\n      let u : Prop := choose exU\n      let v : Prop := choose exV\n    \n      have u_def : U u := choose_spec exU\n      have v_def : V v := choose_spec exV\n      sorry\n    end Hidden\n    \n\nEach of `U` and `V` is a disjunction, so `u_def` and `v_def` represent four\ncases. In one of these cases, `u = True` and `v = False`, and in all the other\ncases, `p` is true. Thus we have:\n\n    \n    \n    namespace Hidden\n    open Classical\n    theorem em (p : Prop) : p ∨ ¬p :=\n      let U (x : Prop) : Prop := x = True ∨ p\n      let V (x : Prop) : Prop := x = False ∨ p\n      have exU : ∃ x, U x := ⟨True, Or.inl rfl⟩\n      have exV : ∃ x, V x := ⟨False, Or.inl rfl⟩\n      let u : Prop := choose exU\n      let v : Prop := choose exV\n      have u_def : U u := choose_spec exU\n      have v_def : V v := choose_spec exV\n      have not_uv_or_p : u ≠ v ∨ p :=\n        match u_def, v_def with\n        | Or.inr h, _ => Or.inr h\n        | _, Or.inr h => Or.inr h\n        | Or.inl hut, Or.inl hvf =>\n          have hne : u ≠ v := by simp [hvf, hut, true_ne_false]\n          Or.inl hne\n      sorry\n    end Hidden\n    \n\nOn the other hand, if `p` is true, then, by function extensionality and\npropositional extensionality, `U` and `V` are equal. By the definition of `u`\nand `v`, this implies that they are equal as well.\n\n    \n    \n    namespace Hidden\n    open Classical\n    theorem em (p : Prop) : p ∨ ¬p :=\n      let U (x : Prop) : Prop := x = True ∨ p\n      let V (x : Prop) : Prop := x = False ∨ p\n      have exU : ∃ x, U x := ⟨True, Or.inl rfl⟩\n      have exV : ∃ x, V x := ⟨False, Or.inl rfl⟩\n      let u : Prop := choose exU\n      let v : Prop := choose exV\n      have u_def : U u := choose_spec exU\n      have v_def : V v := choose_spec exV\n      have not_uv_or_p : u ≠ v ∨ p :=\n        match u_def, v_def with\n        | Or.inr h, _ => Or.inr h\n        | _, Or.inr h => Or.inr h\n        | Or.inl hut, Or.inl hvf =>\n          have hne : u ≠ v := by simp [hvf, hut, true_ne_false]\n          Or.inl hne\n      have p_implies_uv : p → u = v :=\n        fun hp =>\n        have hpred : U = V :=\n          funext fun x =>\n            have hl : (x = True ∨ p) → (x = False ∨ p) :=\n              fun _ => Or.inr hp\n            have hr : (x = False ∨ p) → (x = True ∨ p) :=\n              fun _ => Or.inr hp\n            show (x = True ∨ p) = (x = False ∨ p) from\n              propext (Iff.intro hl hr)\n        have h₀ : ∀ exU exV, @choose _ U exU = @choose _ V exV := by\n          rw [hpred]; intros; rfl\n        show u = v from h₀ _ _\n      sorry\n    end Hidden\n    \n\nPutting these last two facts together yields the desired conclusion:\n\n    \n    \n    namespace Hidden\n    open Classical\n    theorem em (p : Prop) : p ∨ ¬p :=\n      let U (x : Prop) : Prop := x = True ∨ p\n      let V (x : Prop) : Prop := x = False ∨ p\n      have exU : ∃ x, U x := ⟨True, Or.inl rfl⟩\n      have exV : ∃ x, V x := ⟨False, Or.inl rfl⟩\n      let u : Prop := choose exU\n      let v : Prop := choose exV\n      have u_def : U u := choose_spec exU\n      have v_def : V v := choose_spec exV\n      have not_uv_or_p : u ≠ v ∨ p :=\n        match u_def, v_def with\n        | Or.inr h, _ => Or.inr h\n        | _, Or.inr h => Or.inr h\n        | Or.inl hut, Or.inl hvf =>\n          have hne : u ≠ v := by simp [hvf, hut, true_ne_false]\n          Or.inl hne\n      have p_implies_uv : p → u = v :=\n        fun hp =>\n        have hpred : U = V :=\n          funext fun x =>\n            have hl : (x = True ∨ p) → (x = False ∨ p) :=\n              fun _ => Or.inr hp\n            have hr : (x = False ∨ p) → (x = True ∨ p) :=\n              fun _ => Or.inr hp\n            show (x = True ∨ p) = (x = False ∨ p) from\n              propext (Iff.intro hl hr)\n        have h₀ : ∀ exU exV, @choose _ U exU = @choose _ V exV := by\n          rw [hpred]; intros; rfl\n        show u = v from h₀ _ _\n      match not_uv_or_p with\n      | Or.inl hne => Or.inr (mt p_implies_uv hne)\n      | Or.inr h   => Or.inl h\n    end Hidden\n    \n\nConsequences of excluded middle include double-negation elimination, proof by\ncases, and proof by contradiction, all of which are described in the [Section\nClassical Logic](./propositions_and_proofs.html#classical-logic). The law of\nthe excluded middle and propositional extensionality imply propositional\ncompleteness:\n\n    \n    \n    namespace Hidden\n    open Classical\n    theorem propComplete (a : Prop) : a = True ∨ a = False :=\n      match em a with\n      | Or.inl ha => Or.inl (propext (Iff.intro (fun _ => ⟨⟩) (fun _ => ha)))\n      | Or.inr hn => Or.inr (propext (Iff.intro (fun h => hn h) (fun h => False.elim h)))\n    end Hidden\n    \n\nTogether with choice, we also get the stronger principle that every\nproposition is decidable. Recall that the class of `Decidable` propositions is\ndefined as follows:\n\n    \n    \n    namespace Hidden\n    class inductive Decidable (p : Prop) where\n      | isFalse (h : ¬p) : Decidable p\n      | isTrue  (h : p)  : Decidable p\n    end Hidden\n    \n\nIn contrast to `p ∨ ¬ p`, which can only eliminate to `Prop`, the type\n`Decidable p` is equivalent to the sum type `Sum p (¬ p)`, which can eliminate\nto any type. It is this data that is needed to write an if-then-else\nexpression.\n\nAs an example of classical reasoning, we use `choose` to show that if `f : α →\nβ` is injective and `α` is inhabited, then `f` has a left inverse. To define\nthe left inverse `linv`, we use a dependent if-then-else expression. Recall\nthat `if h : c then t else e` is notation for `dite c (fun h : c => t) (fun h\n: ¬ c => e)`. In the definition of `linv`, choice is used twice: first, to\nshow that `(∃ a : A, f a = b)` is "decidable," and then to choose an `a` such\nthat `f a = b`. Notice that `propDecidable` is a scoped instance and is\nactivated by the `open Classical` command. We use this instance to justify the\nif-then-else expression. (See also the discussion in [Section Decidable\nPropositions](./type_classes.html#decidable-propositions)).\n\n    \n    \n    open Classical\n    \n    noncomputable def linv [Inhabited α] (f : α → β) : β → α :=\n      fun b : β => if ex : (∃ a : α, f a = b) then choose ex else default\n    \n    theorem linv_comp_self {f : α → β} [Inhabited α]\n                           (inj : ∀ {a b}, f a = f b → a = b)\n                           : linv f ∘ f = id :=\n      funext fun a =>\n        have ex  : ∃ a₁ : α, f a₁ = f a := ⟨a, rfl⟩\n        have feq : f (choose ex) = f a  := choose_spec ex\n        calc linv f (f a)\n          _ = choose ex := dif_pos ex\n          _ = a         := inj feq\n    \n\nFrom a classical point of view, `linv` is a function. From a constructive\npoint of view, it is unacceptable; because there is no way to implement such a\nfunction in general, the construction is not informative.\n\n[ __](conv.html "Previous chapter")\n\n[ __](conv.html "Previous chapter")', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:24,060 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:24,060 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:24,060 - DEBUG - send_request_headers.complete
2025-06-01 01:54:24,060 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:24,060 - DEBUG - send_request_body.complete
2025-06-01 01:54:24,061 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:24,811 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'156'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5f689c5f9d-qrjgp'), (b'x-envoy-upstream-service-time', b'162'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'996117'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'232ms'), (b'x-request-id', b'req_30bb20ad4ffcb9d17ee95556079f2747'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b15346ad23bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:24,811 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:24,811 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:24,811 - DEBUG - receive_response_body.complete
2025-06-01 01:54:24,812 - DEBUG - response_closed.started
2025-06-01 01:54:24,812 - DEBUG - response_closed.complete
2025-06-01 01:54:24,812 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '156', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-5f689c5f9d-qrjgp', 'x-envoy-upstream-service-time': '162', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '996117', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '232ms', 'x-request-id': 'req_30bb20ad4ffcb9d17ee95556079f2747', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b15346ad23bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:24,812 - DEBUG - request_id: req_30bb20ad4ffcb9d17ee95556079f2747
2025-06-01 01:54:24,812 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': 'Reinforcement learning can be used to solve tasks such as decision making and knowledge discovery. This is due to the exploration exploitation paradigm.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:24,813 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:24,813 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:24,813 - DEBUG - send_request_headers.complete
2025-06-01 01:54:24,813 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:24,813 - DEBUG - send_request_body.complete
2025-06-01 01:54:24,813 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:25,159 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'43'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-6b5d94d96-7zr68'), (b'x-envoy-upstream-service-time', b'46'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999961'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_2c715334c89810a63bb39ad0bc715132'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b15391ce43bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:25,160 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:25,160 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:25,160 - DEBUG - receive_response_body.complete
2025-06-01 01:54:25,160 - DEBUG - response_closed.started
2025-06-01 01:54:25,160 - DEBUG - response_closed.complete
2025-06-01 01:54:25,161 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '43', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-6b5d94d96-7zr68', 'x-envoy-upstream-service-time': '46', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999961', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '2ms', 'x-request-id': 'req_2c715334c89810a63bb39ad0bc715132', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b15391ce43bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:25,161 - DEBUG - request_id: req_2c715334c89810a63bb39ad0bc715132
2025-06-01 01:54:25,161 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': "Deep neural networks often use transformers. In today's world, has there been a lot of data being fed into these giant foundation models, which compress info about the world.", 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:25,162 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:25,162 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:25,162 - DEBUG - send_request_headers.complete
2025-06-01 01:54:25,162 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:25,162 - DEBUG - send_request_body.complete
2025-06-01 01:54:25,162 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:25,839 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'67'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5f689c5f9d-m5j5v'), (b'x-envoy-upstream-service-time', b'73'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999956'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_f76accec3327f37e15ba00e052f0e9a6'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b153b4de23bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:25,839 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:25,839 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:25,840 - DEBUG - receive_response_body.complete
2025-06-01 01:54:25,840 - DEBUG - response_closed.started
2025-06-01 01:54:25,840 - DEBUG - response_closed.complete
2025-06-01 01:54:25,840 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '67', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-5f689c5f9d-m5j5v', 'x-envoy-upstream-service-time': '73', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999956', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '2ms', 'x-request-id': 'req_f76accec3327f37e15ba00e052f0e9a6', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b153b4de23bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:25,840 - DEBUG - request_id: req_f76accec3327f37e15ba00e052f0e9a6
2025-06-01 01:54:25,840 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Structures and Records\n\nWe have seen that Lean\'s foundational system includes inductive types. We\nhave, moreover, noted that it is a remarkable fact that it is possible to\nconstruct a substantial edifice of mathematics based on nothing more than the\ntype universes, dependent arrow types, and inductive types; everything else\nfollows from those. The Lean standard library contains many instances of\ninductive types (e.g., `Nat`, `Prod`, `List`), and even the logical\nconnectives are defined using inductive types.\n\nRecall that a non-recursive inductive type that contains only one constructor\nis called a _structure_ or _record_. The product type is a structure, as is\nthe dependent product (Sigma) type. In general, whenever we define a structure\n`S`, we usually define _projection_ functions that allow us to "destruct" each\ninstance of `S` and retrieve the values that are stored in its fields. The\nfunctions `prod.fst` and `prod.snd`, which return the first and second\nelements of a pair, are examples of such projections.\n\nWhen writing programs or formalizing mathematics, it is not uncommon to define\nstructures containing many fields. The `structure` command, available in Lean,\nprovides infrastructure to support this process. When we define a structure\nusing this command, Lean automatically generates all the projection functions.\nThe `structure` command also allows us to define new structures based on\npreviously defined ones. Moreover, Lean provides convenient notation for\ndefining instances of a given structure.\n\n## Declaring Structures\n\nThe structure command is essentially a "front end" for defining inductive data\ntypes. Every `structure` declaration introduces a namespace with the same\nname. The general form is as follows:\n\n    \n    \n        structure <name> <parameters> <parent-structures> where\n          <constructor> :: <fields>\n    \n\nMost parts are optional. Here is an example:\n\n    \n    \n    structure Point (α : Type u) where\n      mk :: (x : α) (y : α)\n    \n\nValues of type `Point` are created using `Point.mk a b`, and the fields of a\npoint `p` are accessed using `Point.x p` and `Point.y p` (but `p.x` and `p.y`\nalso work, see below). The structure command also generates useful recursors\nand theorems. Here are some of the constructions generated for the declaration\nabove.\n\n    \n    \n    structure Point (α : Type u) where\n     mk :: (x : α) (y : α)\n    #check Point       -- a Type\n    #check @Point.rec  -- the eliminator\n    #check @Point.mk   -- the constructor\n    #check @Point.x    -- a projection\n    #check @Point.y    -- a projection\n    \n\nIf the constructor name is not provided, then a constructor is named `mk` by\ndefault. You can also avoid the parentheses around field names if you add a\nline break between each field.\n\n    \n    \n    structure Point (α : Type u) where\n      x : α\n      y : α\n    \n\nHere are some simple theorems and expressions that use the generated\nconstructions. As usual, you can avoid the prefix `Point` by using the command\n`open Point`.\n\n    \n    \n    structure Point (α : Type u) where\n     x : α\n     y : α\n    #eval Point.x (Point.mk 10 20)\n    #eval Point.y (Point.mk 10 20)\n    \n    open Point\n    \n    example (a b : α) : x (mk a b) = a :=\n      rfl\n    \n    example (a b : α) : y (mk a b) = b :=\n      rfl\n    \n\nGiven `p : Point Nat`, the dot notation `p.x` is shorthand for `Point.x p`.\nThis provides a convenient way of accessing the fields of a structure.\n\n    \n    \n    structure Point (α : Type u) where\n     x : α\n     y : α\n    def p := Point.mk 10 20\n    \n    #check p.x  -- Nat\n    #eval p.x   -- 10\n    #eval p.y   -- 20\n    \n\nThe dot notation is convenient not just for accessing the projections of a\nrecord, but also for applying functions defined in a namespace with the same\nname. Recall from the [Conjunction\nsection](./propositions_and_proofs.html#conjunction) if `p` has type `Point`,\nthe expression `p.foo` is interpreted as `Point.foo p`, assuming that the\nfirst non-implicit argument to `foo` has type `Point`. The expression `p.add\nq` is therefore shorthand for `Point.add p q` in the example below.\n\n    \n    \n    structure Point (α : Type u) where\n      x : α\n      y : α\n      deriving Repr\n    \n    def Point.add (p q : Point Nat) :=\n      mk (p.x + q.x) (p.y + q.y)\n    \n    def p : Point Nat := Point.mk 1 2\n    def q : Point Nat := Point.mk 3 4\n    \n    #eval p.add q  -- {x := 4, y := 6}\n    \n\nIn the next chapter, you will learn how to define a function like `add` so\nthat it works generically for elements of `Point α` rather than just `Point\nNat`, assuming `α` has an associated addition operation.\n\nMore generally, given an expression `p.foo x y z` where `p : Point`, Lean will\ninsert `p` at the first argument to `Point.foo` of type `Point`. For example,\nwith the definition of scalar multiplication below, `p.smul 3` is interpreted\nas `Point.smul 3 p`.\n\n    \n    \n    structure Point (α : Type u) where\n     x : α\n     y : α\n     deriving Repr\n    def Point.smul (n : Nat) (p : Point Nat) :=\n      Point.mk (n * p.x) (n * p.y)\n    \n    def p : Point Nat := Point.mk 1 2\n    \n    #eval p.smul 3  -- {x := 3, y := 6}\n    \n\nIt is common to use a similar trick with the `List.map` function, which takes\na list as its second non-implicit argument:\n\n    \n    \n    #check @List.map\n    \n    def xs : List Nat := [1, 2, 3]\n    def f : Nat → Nat := fun x => x * x\n    \n    #eval xs.map f  -- [1, 4, 9]\n    \n\nHere `xs.map f` is interpreted as `List.map f xs`.\n\n## Objects\n\nWe have been using constructors to create elements of a structure type. For\nstructures containing many fields, this is often inconvenient, because we have\nto remember the order in which the fields were defined. Lean therefore\nprovides the following alternative notations for defining elements of a\nstructure type.\n\n    \n    \n        { (<field-name> := <expr>)* : structure-type }\n        or\n        { (<field-name> := <expr>)* }\n    \n\nThe suffix `: structure-type` can be omitted whenever the name of the\nstructure can be inferred from the expected type. For example, we use this\nnotation to define "points." The order that the fields are specified does not\nmatter, so all the expressions below define the same point.\n\n    \n    \n    structure Point (α : Type u) where\n      x : α\n      y : α\n    \n    #check { x := 10, y := 20 : Point Nat }  -- Point ℕ\n    #check { y := 20, x := 10 : Point _ }\n    #check ({ x := 10, y := 20 } : Point Nat)\n    \n    example : Point Nat :=\n      { y := 20, x := 10 }\n    \n\nIf the value of a field is not specified, Lean tries to infer it. If the\nunspecified fields cannot be inferred, Lean flags an error indicating the\ncorresponding placeholder could not be synthesized.\n\n    \n    \n    structure MyStruct where\n        {α : Type u}\n        {β : Type v}\n        a : α\n        b : β\n    \n    #check { a := 10, b := true : MyStruct }\n    \n\n_Record update_ is another common operation which amounts to creating a new\nrecord object by modifying the value of one or more fields in an old one. Lean\nallows you to specify that unassigned fields in the specification of a record\nshould be taken from a previously defined structure object `s` by adding the\nannotation `s with` before the field assignments. If more than one record\nobject is provided, then they are visited in order until Lean finds one that\ncontains the unspecified field. Lean raises an error if any of the field names\nremain unspecified after all the objects are visited.\n\n    \n    \n    structure Point (α : Type u) where\n      x : α\n      y : α\n      deriving Repr\n    \n    def p : Point Nat :=\n      { x := 1, y := 2 }\n    \n    #eval { p with y := 3 }  -- { x := 1, y := 3 }\n    #eval { p with x := 4 }  -- { x := 4, y := 2 }\n    \n    structure Point3 (α : Type u) where\n      x : α\n      y : α\n      z : α\n    \n    def q : Point3 Nat :=\n      { x := 5, y := 5, z := 5 }\n    \n    def r : Point3 Nat :=\n      { p, q with x := 6 }\n    \n    example : r.x = 6 := rfl\n    example : r.y = 2 := rfl\n    example : r.z = 5 := rfl\n    \n\n## Inheritance\n\nWe can _extend_ existing structures by adding new fields. This feature allows\nus to simulate a form of _inheritance_.\n\n    \n    \n    structure Point (α : Type u) where\n      x : α\n      y : α\n    \n    inductive Color where\n      | red | green | blue\n    \n    structure ColorPoint (α : Type u) extends Point α where\n      c : Color\n    \n\nIn the next example, we define a structure using multiple inheritance, and\nthen define an object using objects of the parent structures.\n\n    \n    \n    structure Point (α : Type u) where\n      x : α\n      y : α\n      z : α\n    \n    structure RGBValue where\n      red : Nat\n      green : Nat\n      blue : Nat\n    \n    structure RedGreenPoint (α : Type u) extends Point α, RGBValue where\n      no_blue : blue = 0\n    \n    def p : Point Nat :=\n      { x := 10, y := 10, z := 20 }\n    \n    def rgp : RedGreenPoint Nat :=\n      { p with red := 200, green := 40, blue := 0, no_blue := rfl }\n    \n    example : rgp.x   = 10 := rfl\n    example : rgp.red = 200 := rfl\n    \n\n[ __](induction_and_recursion.html "Previous chapter") [ __](type_classes.html\n"Next chapter")\n\n[ __](induction_and_recursion.html "Previous chapter") [ __](type_classes.html\n"Next chapter")', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:25,841 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:25,841 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:25,841 - DEBUG - send_request_headers.complete
2025-06-01 01:54:25,841 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:25,842 - DEBUG - send_request_body.complete
2025-06-01 01:54:25,842 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:26,603 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'108'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7c4bf98c9f-xxbct'), (b'x-envoy-upstream-service-time', b'114'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'997442'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'153ms'), (b'x-request-id', b'req_1911a4574cadd0dcce627db34c57af8a'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b153f8fe03bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:26,603 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:26,603 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:26,604 - DEBUG - receive_response_body.complete
2025-06-01 01:54:26,604 - DEBUG - response_closed.started
2025-06-01 01:54:26,604 - DEBUG - response_closed.complete
2025-06-01 01:54:26,604 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '108', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-7c4bf98c9f-xxbct', 'x-envoy-upstream-service-time': '114', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '997442', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '153ms', 'x-request-id': 'req_1911a4574cadd0dcce627db34c57af8a', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b153f8fe03bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:26,604 - DEBUG - request_id: req_1911a4574cadd0dcce627db34c57af8a
2025-06-01 01:54:26,604 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Dependent Type Theory\n\nDependent type theory is a powerful and expressive language, allowing you to\nexpress complex mathematical assertions, write complex hardware and software\nspecifications, and reason about both of these in a natural and uniform way.\nLean is based on a version of dependent type theory known as the _Calculus of\nConstructions_ , with a countable hierarchy of non-cumulative universes and\ninductive types. By the end of this chapter, you will understand much of what\nthis means.\n\n## Simple Type Theory\n\n"Type theory" gets its name from the fact that every expression has an\nassociated _type_. For example, in a given context, `x + 0` may denote a\nnatural number and `f` may denote a function on the natural numbers. For those\nwho like precise definitions, a Lean natural number is an arbitrary-precision\nunsigned integer.\n\nHere are some examples of how you can declare objects in Lean and check their\ntypes.\n\n    \n    \n    /- Define some constants. -/\n    \n    def m : Nat := 1       -- m is a natural number\n    def n : Nat := 0\n    def b1 : Bool := true  -- b1 is a Boolean\n    def b2 : Bool := false\n    \n    /- Check their types. -/\n    \n    #check m            -- output: Nat\n    #check n\n    #check n + 0        -- Nat\n    #check m * (n + 0)  -- Nat\n    #check b1           -- Bool\n    #check b1 && b2     -- "&&" is the Boolean and\n    #check b1 || b2     -- Boolean or\n    #check true         -- Boolean "true"\n    \n    /- Evaluate -/\n    \n    #eval 5 * 4         -- 20\n    #eval m + 2         -- 3\n    #eval b1 && b2      -- false\n    \n\nAny text between `/-` and `-/` constitutes a comment block that is ignored by\nLean. Similarly, two dashes `--` indicate that the rest of the line contains a\ncomment that is also ignored. Comment blocks can be nested, making it possible\nto "comment out" chunks of code, just as in many programming languages.\n\nThe `def` keyword declares new constant symbols into the working environment.\nIn the example above, `def m : Nat := 1` defines a new constant `m` of type\n`Nat` whose value is `1`. The `#check` command asks Lean to report their\ntypes; in Lean, auxiliary commands that query the system for information\ntypically begin with the hash (#) symbol. The `#eval` command asks Lean to\nevaluate the given expression. You should try declaring some constants and\ntype checking some expressions on your own. Declaring new objects in this\nmanner is a good way to experiment with the system.\n\nWhat makes simple type theory powerful is that you can build new types out of\nothers. For example, if `a` and `b` are types, `a -> b` denotes the type of\nfunctions from `a` to `b`, and `a × b` denotes the type of pairs consisting of\nan element of `a` paired with an element of `b`, also known as the _Cartesian\nproduct_. Note that `×` is a Unicode symbol. The judicious use of Unicode\nimproves legibility, and all modern editors have great support for it. In the\nLean standard library, you often see Greek letters to denote types, and the\nUnicode symbol `→` as a more compact version of `->`.\n\n    \n    \n    #check Nat → Nat      -- type the arrow as "\\to" or "\\r"\n    #check Nat -> Nat     -- alternative ASCII notation\n    \n    #check Nat × Nat      -- type the product as "\\times"\n    #check Prod Nat Nat   -- alternative notation\n    \n    #check Nat → Nat → Nat\n    #check Nat → (Nat → Nat)  --  same type as above\n    \n    #check Nat × Nat → Nat\n    #check (Nat → Nat) → Nat -- a "functional"\n    \n    #check Nat.succ     -- Nat → Nat\n    #check (0, 1)       -- Nat × Nat\n    #check Nat.add      -- Nat → Nat → Nat\n    \n    #check Nat.succ 2   -- Nat\n    #check Nat.add 3    -- Nat → Nat\n    #check Nat.add 5 2  -- Nat\n    #check (5, 9).1     -- Nat\n    #check (5, 9).2     -- Nat\n    \n    #eval Nat.succ 2   -- 3\n    #eval Nat.add 5 2  -- 7\n    #eval (5, 9).1     -- 5\n    #eval (5, 9).2     -- 9\n    \n\nOnce again, you should try some examples on your own.\n\nLet\'s take a look at some basic syntax. You can enter the unicode arrow `→` by\ntyping `\\to` or `\\r` or `\\->`. You can also use the ASCII alternative `->`, so\nthe expressions `Nat -> Nat` and `Nat → Nat` mean the same thing. Both\nexpressions denote the type of functions that take a natural number as input\nand return a natural number as output. The unicode symbol `×` for the\nCartesian product is entered as `\\times`. You will generally use lower-case\nGreek letters like `α`, `β`, and `γ` to range over types. You can enter these\nparticular ones with `\\a`, `\\b`, and `\\g`.\n\nThere are a few more things to notice here. First, the application of a\nfunction `f` to a value `x` is denoted `f x` (e.g., `Nat.succ 2`). Second,\nwhen writing type expressions, arrows associate to the _right_ ; for example,\nthe type of `Nat.add` is `Nat → Nat → Nat` which is equivalent to `Nat → (Nat\n→ Nat)`. Thus you can view `Nat.add` as a function that takes a natural number\nand returns another function that takes a natural number and returns a natural\nnumber. In type theory, this is generally more convenient than writing\n`Nat.add` as a function that takes a pair of natural numbers as input and\nreturns a natural number as output. For example, it allows you to "partially\napply" the function `Nat.add`. The example above shows that `Nat.add 3` has\ntype `Nat → Nat`, that is, `Nat.add 3` returns a function that "waits" for a\nsecond argument, `n`, which is then equivalent to writing `Nat.add 3 n`.\n\nYou have seen that if you have `m : Nat` and `n : Nat`, then `(m, n)` denotes\nthe ordered pair of `m` and `n` which is of type `Nat × Nat`. This gives you a\nway of creating pairs of natural numbers. Conversely, if you have `p : Nat ×\nNat`, then you can write `p.1 : Nat` and `p.2 : Nat`. This gives you a way of\nextracting its two components.\n\n## Types as objects\n\nOne way in which Lean\'s dependent type theory extends simple type theory is\nthat types themselves --- entities like `Nat` and `Bool` \\--- are first-class\ncitizens, which is to say that they themselves are objects. For that to be the\ncase, each of them also has to have a type.\n\n    \n    \n    #check Nat               -- Type\n    #check Bool              -- Type\n    #check Nat → Bool        -- Type\n    #check Nat × Bool        -- Type\n    #check Nat → Nat         -- ...\n    #check Nat × Nat → Nat\n    #check Nat → Nat → Nat\n    #check Nat → (Nat → Nat)\n    #check Nat → Nat → Bool\n    #check (Nat → Nat) → Nat\n    \n\nYou can see that each one of the expressions above is an object of type\n`Type`. You can also declare new constants for types:\n\n    \n    \n    def α : Type := Nat\n    def β : Type := Bool\n    def F : Type → Type := List\n    def G : Type → Type → Type := Prod\n    \n    #check α        -- Type\n    #check F α      -- Type\n    #check F Nat    -- Type\n    #check G α      -- Type → Type\n    #check G α β    -- Type\n    #check G α Nat  -- Type\n    \n\nAs the example above suggests, you have already seen an example of a function\nof type `Type → Type → Type`, namely, the Cartesian product `Prod`:\n\n    \n    \n    def α : Type := Nat\n    def β : Type := Bool\n    \n    #check Prod α β       -- Type\n    #check α × β          -- Type\n    \n    #check Prod Nat Nat   -- Type\n    #check Nat × Nat      -- Type\n    \n\nHere is another example: given any type `α`, the type `List α` denotes the\ntype of lists of elements of type `α`.\n\n    \n    \n    def α : Type := Nat\n    \n    #check List α    -- Type\n    #check List Nat  -- Type\n    \n\nGiven that every expression in Lean has a type, it is natural to ask: what\ntype does `Type` itself have?\n\n    \n    \n    #check Type      -- Type 1\n    \n\nYou have actually come up against one of the most subtle aspects of Lean\'s\ntyping system. Lean\'s underlying foundation has an infinite hierarchy of\ntypes:\n\n    \n    \n    #check Type     -- Type 1\n    #check Type 1   -- Type 2\n    #check Type 2   -- Type 3\n    #check Type 3   -- Type 4\n    #check Type 4   -- Type 5\n    \n\nThink of `Type 0` as a universe of "small" or "ordinary" types. `Type 1` is\nthen a larger universe of types, which contains `Type 0` as an element, and\n`Type 2` is an even larger universe of types, which contains `Type 1` as an\nelement. The list is infinite: there is a `Type n` for every natural number\n`n`. `Type` is an abbreviation for `Type 0`:\n\n    \n    \n    #check Type\n    #check Type 0\n    \n\nThe following table may help concretize the relationships being discussed.\nMovement along the x-axis represents a change in the universe, while movement\nalong the y-axis represents a change in what is sometimes referred to as\n"degree".\n\n| | | | |   \n---|---|---|---|---|---  \nsort| Prop (Sort 0)| Type (Sort 1)| Type 1 (Sort 2)| Type 2 (Sort 3)| ...  \ntype| True| Bool| Nat -> Type| Type -> Type 1| ...  \nterm| trivial| true| fun n => Fin n| fun (_ : Type) => Type| ...  \n  \nSome operations, however, need to be _polymorphic_ over type universes. For\nexample, `List α` should make sense for any type `α`, no matter which type\nuniverse `α` lives in. This explains the type signature of the function\n`List`:\n\n    \n    \n    #check List    -- List.{u} (α : Type u) : Type u\n    \n\nHere `u` is a variable ranging over type levels. The output of the `#check`\ncommand means that whenever `α` has type `Type n`, `List α` also has type\n`Type n`. The function `Prod` is similarly polymorphic:\n\n    \n    \n    #check Prod    -- Prod.{u, v} (α : Type u) (β : Type v) : Type (max u v)\n    \n\nTo define polymorphic constants, Lean allows you to declare universe variables\nexplicitly using the `universe` command:\n\n    \n    \n    universe u\n    \n    def F (α : Type u) : Type u := Prod α α\n    \n    #check F    -- Type u → Type u\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `F`:\n\n    \n    \n    def F.{u} (α : Type u) : Type u := Prod α α\n    \n    #check F    -- Type u → Type u\n    \n\n## Function Abstraction and Evaluation\n\nLean provides a `fun` (or `λ`) keyword to create a function from an expression\nas follows:\n\n    \n    \n    #check fun (x : Nat) => x + 5   -- Nat → Nat\n    #check λ (x : Nat) => x + 5     -- λ and fun mean the same thing\n    #check fun x => x + 5     -- Nat inferred\n    #check λ x => x + 5       -- Nat inferred\n    \n\nYou can evaluate a lambda function by passing the required parameters:\n\n    \n    \n    #eval (λ x : Nat => x + 5) 10    -- 15\n    \n\nCreating a function from another expression is a process known as _lambda\nabstraction_. Suppose you have the variable `x : α` and you can construct an\nexpression `t : β`, then the expression `fun (x : α) => t`, or, equivalently,\n`λ (x : α) => t`, is an object of type `α → β`. Think of this as the function\nfrom `α` to `β` which maps any value `x` to the value `t`.\n\nHere are some more examples\n\n    \n    \n    #check fun x : Nat => fun y : Bool => if not y then x + 1 else x + 2\n    #check fun (x : Nat) (y : Bool) => if not y then x + 1 else x + 2\n    #check fun x y => if not y then x + 1 else x + 2   -- Nat → Bool → Nat\n    \n\nLean interprets the final three examples as the same expression; in the last\nexpression, Lean infers the type of `x` and `y` from the expression `if not y\nthen x + 1 else x + 2`.\n\nSome mathematically common examples of operations of functions can be\ndescribed in terms of lambda abstraction:\n\n    \n    \n    def f (n : Nat) : String := toString n\n    def g (s : String) : Bool := s.length > 0\n    \n    #check fun x : Nat => x        -- Nat → Nat\n    #check fun x : Nat => true     -- Nat → Bool\n    #check fun x : Nat => g (f x)  -- Nat → Bool\n    #check fun x => g (f x)        -- Nat → Bool\n    \n\nThink about what these expressions mean. The expression `fun x : Nat => x`\ndenotes the identity function on `Nat`, the expression `fun x : Nat => true`\ndenotes the constant function that always returns `true`, and `fun x : Nat =>\ng (f x)` denotes the composition of `f` and `g`. You can, in general, leave\noff the type annotation and let Lean infer it for you. So, for example, you\ncan write `fun x => g (f x)` instead of `fun x : Nat => g (f x)`.\n\nYou can pass functions as parameters and by giving them names `f` and `g` you\ncan then use those functions in the implementation:\n\n    \n    \n    #check fun (g : String → Bool) (f : Nat → String) (x : Nat) => g (f x)\n    -- (String → Bool) → (Nat → String) → Nat → Bool\n    \n\nYou can also pass types as parameters:\n\n    \n    \n    #check fun (α β γ : Type) (g : β → γ) (f : α → β) (x : α) => g (f x)\n    \n\nThe last expression, for example, denotes the function that takes three types,\n`α`, `β`, and `γ`, and two functions, `g : β → γ` and `f : α → β`, and returns\nthe composition of `g` and `f`. (Making sense of the type of this function\nrequires an understanding of _dependent products_ , which will be explained\nbelow.)\n\nThe general form of a lambda expression is `fun x : α => t`, where the\nvariable `x` is a "bound variable": it is really a placeholder, whose "scope"\ndoes not extend beyond the expression `t`. For example, the variable `b` in\nthe expression `fun (b : β) (x : α) => b` has nothing to do with the constant\n`b` declared earlier. In fact, the expression denotes the same function as\n`fun (u : β) (z : α) => u`.\n\nFormally, expressions that are the same up to a renaming of bound variables\nare called _alpha equivalent_ , and are considered "the same." Lean recognizes\nthis equivalence.\n\nNotice that applying a term `t : α → β` to a term `s : α` yields an expression\n`t s : β`. Returning to the previous example and renaming bound variables for\nclarity, notice the types of the following expressions:\n\n    \n    \n    #check (fun x : Nat => x) 1     -- Nat\n    #check (fun x : Nat => true) 1  -- Bool\n    \n    def f (n : Nat) : String := toString n\n    def g (s : String) : Bool := s.length > 0\n    \n    #check\n      (fun (α β γ : Type) (u : β → γ) (v : α → β) (x : α) => u (v x)) Nat String Bool g f 0\n      -- Bool\n    \n\nAs expected, the expression `(fun x : Nat => x) 1` has type `Nat`. In fact,\nmore should be true: applying the expression `(fun x : Nat => x)` to `1`\nshould "return" the value `1`. And, indeed, it does:\n\n    \n    \n    #eval (fun x : Nat => x) 1     -- 1\n    #eval (fun x : Nat => true) 1  -- true\n    \n\nYou will see later how these terms are evaluated. For now, notice that this is\nan important feature of dependent type theory: every term has a computational\nbehavior, and supports a notion of _normalization_. In principle, two terms\nthat reduce to the same value are called _definitionally equal_. They are\nconsidered "the same" by Lean\'s type checker, and Lean does its best to\nrecognize and support these identifications.\n\nLean is a complete programming language. It has a compiler that generates a\nbinary executable and an interactive interpreter. You can use the command\n`#eval` to execute expressions, and it is the preferred way of testing your\nfunctions.\n\n## Definitions\n\nRecall that the `def` keyword provides one important way of declaring new\nnamed objects.\n\n    \n    \n    def double (x : Nat) : Nat :=\n      x + x\n    \n\nThis might look more familiar to you if you know how functions work in other\nprogramming languages. The name `double` is defined as a function that takes\nan input parameter `x` of type `Nat`, where the result of the call is `x + x`,\nso it is returning type `Nat`. You can then invoke this function using:\n\n    \n    \n    def double (x : Nat) : Nat :=\n     x + x\n    #eval double 3    -- 6\n    \n\nIn this case you can think of `def` as a kind of named `lambda`. The following\nyields the same result:\n\n    \n    \n    def double : Nat → Nat :=\n      fun x => x + x\n    \n    #eval double 3    -- 6\n    \n\nYou can omit the type declarations when Lean has enough information to infer\nit. Type inference is an important part of Lean:\n\n    \n    \n    def double :=\n      fun (x : Nat) => x + x\n    \n\nThe general form of a definition is `def foo : α := bar` where `α` is the type\nreturned from the expression `bar`. Lean can usually infer the type `α`, but\nit is often a good idea to write it explicitly. This clarifies your intention,\nand Lean will flag an error if the right-hand side of the definition does not\nhave a matching type.\n\nThe right hand side `bar` can be any expression, not just a lambda. So `def`\ncan also be used to simply name a value like this:\n\n    \n    \n    def pi := 3.141592654\n    \n\n`def` can take multiple input parameters. Let\'s create one that adds two\nnatural numbers:\n\n    \n    \n    def add (x y : Nat) :=\n      x + y\n    \n    #eval add 3 2               -- 5\n    \n\nThe parameter list can be separated like this:\n\n    \n    \n    def double (x : Nat) : Nat :=\n     x + x\n    def add (x : Nat) (y : Nat) :=\n      x + y\n    \n    #eval add (double 3) (7 + 9)  -- 22\n    \n\nNotice here we called the `double` function to create the first parameter to\n`add`.\n\nYou can use other more interesting expressions inside a `def`:\n\n    \n    \n    def greater (x y : Nat) :=\n      if x > y then x\n      else y\n    \n\nYou can probably guess what this one will do.\n\nYou can also define a function that takes another function as input. The\nfollowing calls a given function twice passing the output of the first\ninvocation to the second:\n\n    \n    \n    def double (x : Nat) : Nat :=\n     x + x\n    def doTwice (f : Nat → Nat) (x : Nat) : Nat :=\n      f (f x)\n    \n    #eval doTwice double 2   -- 8\n    \n\nNow to get a bit more abstract, you can also specify arguments that are like\ntype parameters:\n\n    \n    \n    def compose (α β γ : Type) (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nThis means `compose` is a function that takes any two functions as input\narguments, so long as those functions each take only one input. The type\nalgebra `β → γ` and `α → β` means it is a requirement that the type of the\noutput of the second function must match the type of the input to the first\nfunction - which makes sense, otherwise the two functions would not be\ncomposable.\n\n`compose` also takes a 3rd argument of type `α` which it uses to invoke the\nsecond function (locally named `f`) and it passes the result of that function\n(which is type `β`) as input to the first function (locally named `g`). The\nfirst function returns a type `γ` so that is also the return type of the\n`compose` function.\n\n`compose` is also very general in that it works over any type `α β γ`. This\nmeans `compose` can compose just about any 2 functions so long as they each\ntake one parameter, and so long as the type of output of the second matches\nthe input of the first. For example:\n\n    \n    \n    def compose (α β γ : Type) (g : β → γ) (f : α → β) (x : α) : γ :=\n     g (f x)\n    def double (x : Nat) : Nat :=\n     x + x\n    def square (x : Nat) : Nat :=\n      x * x\n    \n    #eval compose Nat Nat Nat double square 3  -- 18\n    \n\n## Local Definitions\n\nLean also allows you to introduce "local" definitions using the `let` keyword.\nThe expression `let a := t1; t2` is definitionally equal to the result of\nreplacing every occurrence of `a` in `t2` by `t1`.\n\n    \n    \n    #check let y := 2 + 2; y * y   -- Nat\n    #eval  let y := 2 + 2; y * y   -- 16\n    \n    def twice_double (x : Nat) : Nat :=\n      let y := x + x; y * y\n    \n    #eval twice_double 2   -- 16\n    \n\nHere, `twice_double x` is definitionally equal to the term `(x + x) * (x +\nx)`.\n\nYou can combine multiple assignments by chaining `let` statements:\n\n    \n    \n    #check let y := 2 + 2; let z := y + y; z * z   -- Nat\n    #eval  let y := 2 + 2; let z := y + y; z * z   -- 64\n    \n\nThe `;` can be omitted when a line break is used.\n\n    \n    \n    def t (x : Nat) : Nat :=\n      let y := x + x\n      y * y\n    \n\nNotice that the meaning of the expression `let a := t1; t2` is very similar to\nthe meaning of `(fun a => t2) t1`, but the two are not the same. In the first\nexpression, you should think of every instance of `a` in `t2` as a syntactic\nabbreviation for `t1`. In the second expression, `a` is a variable, and the\nexpression `fun a => t2` has to make sense independently of the value of `a`.\nThe `let` construct is a stronger means of abbreviation, and there are\nexpressions of the form `let a := t1; t2` that cannot be expressed as `(fun a\n=> t2) t1`. As an exercise, try to understand why the definition of `foo`\nbelow type checks, but the definition of `bar` does not.\n\n    \n    \n    def foo := let a := Nat; fun x : a => x + 2\n    /-\n      def bar := (fun a => fun x : a => x + 2) Nat\n    -/\n    \n\n# Variables and Sections\n\nConsider the following three function definitions:\n\n    \n    \n    def compose (α β γ : Type) (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    def doTwice (α : Type) (h : α → α) (x : α) : α :=\n      h (h x)\n    \n    def doThrice (α : Type) (h : α → α) (x : α) : α :=\n      h (h (h x))\n    \n\nLean provides you with the `variable` command to make such declarations look\nmore compact:\n\n    \n    \n    variable (α β γ : Type)\n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    def doTwice (h : α → α) (x : α) : α :=\n      h (h x)\n    \n    def doThrice (h : α → α) (x : α) : α :=\n      h (h (h x))\n    \n\nYou can declare variables of any type, not just `Type` itself:\n\n    \n    \n    variable (α β γ : Type)\n    variable (g : β → γ) (f : α → β) (h : α → α)\n    variable (x : α)\n    \n    def compose := g (f x)\n    def doTwice := h (h x)\n    def doThrice := h (h (h x))\n    \n    #print compose\n    #print doTwice\n    #print doThrice\n    \n\nPrinting them out shows that all three groups of definitions have exactly the\nsame effect.\n\nThe `variable` command instructs Lean to insert the declared variables as\nbound variables in definitions that refer to them by name. Lean is smart\nenough to figure out which variables are used explicitly or implicitly in a\ndefinition. You can therefore proceed as though `α`, `β`, `γ`, `g`, `f`, `h`,\nand `x` are fixed objects when you write your definitions, and let Lean\nabstract the definitions for you automatically.\n\nWhen declared in this way, a variable stays in scope until the end of the file\nyou are working on. Sometimes, however, it is useful to limit the scope of a\nvariable. For that purpose, Lean provides the notion of a `section`:\n\n    \n    \n    section useful\n      variable (α β γ : Type)\n      variable (g : β → γ) (f : α → β) (h : α → α)\n      variable (x : α)\n    \n      def compose := g (f x)\n      def doTwice := h (h x)\n      def doThrice := h (h (h x))\n    end useful\n    \n\nWhen the section is closed, the variables go out of scope, and cannot be\nreferenced any more.\n\nYou do not have to indent the lines within a section. Nor do you have to name\na section, which is to say, you can use an anonymous `section` / `end` pair.\nIf you do name a section, however, you have to close it using the same name.\nSections can also be nested, which allows you to declare new variables\nincrementally.\n\n# Namespaces\n\nLean provides you with the ability to group definitions into nested,\nhierarchical _namespaces_ :\n\n    \n    \n    namespace Foo\n      def a : Nat := 5\n      def f (x : Nat) : Nat := x + 7\n    \n      def fa : Nat := f a\n      def ffa : Nat := f (f a)\n    \n      #check a\n      #check f\n      #check fa\n      #check ffa\n      #check Foo.fa\n    end Foo\n    \n    -- #check a  -- error\n    -- #check f  -- error\n    #check Foo.a\n    #check Foo.f\n    #check Foo.fa\n    #check Foo.ffa\n    \n    open Foo\n    \n    #check a\n    #check f\n    #check fa\n    #check Foo.fa\n    \n\nWhen you declare that you are working in the namespace `Foo`, every identifier\nyou declare has a full name with prefix "`Foo.`". Within the namespace, you\ncan refer to identifiers by their shorter names, but once you end the\nnamespace, you have to use the longer names. Unlike `section`, namespaces\nrequire a name. There is only one anonymous namespace at the root level.\n\nThe `open` command brings the shorter names into the current context. Often,\nwhen you import a module, you will want to open one or more of the namespaces\nit contains, to have access to the short identifiers. But sometimes you will\nwant to leave this information protected by a fully qualified name, for\nexample, when they conflict with identifiers in another namespace you want to\nuse. Thus namespaces give you a way to manage names in your working\nenvironment.\n\nFor example, Lean groups definitions and theorems involving lists into a\nnamespace `List`.\n\n    \n    \n    #check List.nil\n    #check List.cons\n    #check List.map\n    \n\nThe command `open List` allows you to use the shorter names:\n\n    \n    \n    open List\n    \n    #check nil\n    #check cons\n    #check map\n    \n\nLike sections, namespaces can be nested:\n\n    \n    \n    namespace Foo\n      def a : Nat := 5\n      def f (x : Nat) : Nat := x + 7\n    \n      def fa : Nat := f a\n    \n      namespace Bar\n        def ffa : Nat := f (f a)\n    \n        #check fa\n        #check ffa\n      end Bar\n    \n      #check fa\n      #check Bar.ffa\n    end Foo\n    \n    #check Foo.fa\n    #check Foo.Bar.ffa\n    \n    open Foo\n    \n    #check fa\n    #check Bar.ffa\n    \n\nNamespaces that have been closed can later be reopened, even in another file:\n\n    \n    \n    namespace Foo\n      def a : Nat := 5\n      def f (x : Nat) : Nat := x + 7\n    \n      def fa : Nat := f a\n    end Foo\n    \n    #check Foo.a\n    #check Foo.f\n    \n    namespace Foo\n      def ffa : Nat := f (f a)\n    end Foo\n    \n\nLike sections, nested namespaces have to be closed in the order they are\nopened. Namespaces and sections serve different purposes: namespaces organize\ndata and sections declare variables for insertion in definitions. Sections are\nalso useful for delimiting the scope of commands such as `set_option` and\n`open`.\n\nIn many respects, however, a `namespace ... end` block behaves the same as a\n`section ... end` block. In particular, if you use the `variable` command\nwithin a namespace, its scope is limited to the namespace. Similarly, if you\nuse an `open` command within a namespace, its effects disappear when the\nnamespace is closed.\n\n## What makes dependent type theory dependent?\n\nThe short explanation is that types can depend on parameters. You have already\nseen a nice example of this: the type `List α` depends on the argument `α`,\nand this dependence is what distinguishes `List Nat` and `List Bool`. For\nanother example, consider the type `Vector α n`, the type of vectors of\nelements of `α` of length `n`. This type depends on _two_ parameters: the type\nof the elements in the vector (`α : Type`) and the length of the vector `n :\nNat`.\n\nSuppose you wish to write a function `cons` which inserts a new element at the\nhead of a list. What type should `cons` have? Such a function is _polymorphic_\n: you expect the `cons` function for `Nat`, `Bool`, or an arbitrary type `α`\nto behave the same way. So it makes sense to take the type to be the first\nargument to `cons`, so that for any type, `α`, `cons α` is the insertion\nfunction for lists of type `α`. In other words, for every `α`, `cons α` is the\nfunction that takes an element `a : α` and a list `as : List α`, and returns a\nnew list, so you have `cons α a as : List α`.\n\nIt is clear that `cons α` should have type `α → List α → List α`. But what\ntype should `cons` have? A first guess might be `Type → α → List α → List α`,\nbut, on reflection, this does not make sense: the `α` in this expression does\nnot refer to anything, whereas it should refer to the argument of type `Type`.\nIn other words, _assuming_ `α : Type` is the first argument to the function,\nthe type of the next two elements are `α` and `List α`. These types vary\ndepending on the first argument, `α`.\n\n    \n    \n    def cons (α : Type) (a : α) (as : List α) : List α :=\n      List.cons a as\n    \n    #check cons Nat        -- Nat → List Nat → List Nat\n    #check cons Bool       -- Bool → List Bool → List Bool\n    #check cons            -- (α : Type) → α → List α → List α\n    \n\nThis is an instance of a _dependent function type_ , or _dependent arrow\ntype_. Given `α : Type` and `β : α → Type`, think of `β` as a family of types\nover `α`, that is, a type `β a` for each `a : α`. In that case, the type `(a :\nα) → β a` denotes the type of functions `f` with the property that, for each\n`a : α`, `f a` is an element of `β a`. In other words, the type of the value\nreturned by `f` depends on its input.\n\nNotice that `(a : α) → β` makes sense for any expression `β : Type`. When the\nvalue of `β` depends on `a` (as does, for example, the expression `β a` in the\nprevious paragraph), `(a : α) → β` denotes a dependent function type. When `β`\ndoesn\'t depend on `a`, `(a : α) → β` is no different from the type `α → β`.\nIndeed, in dependent type theory (and in Lean), `α → β` is just notation for\n`(a : α) → β` when `β` does not depend on `a`.\n\nReturning to the example of lists, you can use the command `#check` to inspect\nthe type of the following `List` functions. The `@` symbol and the difference\nbetween the round and curly braces will be explained momentarily.\n\n    \n    \n    #check @List.cons    -- {α : Type u_1} → α → List α → List α\n    #check @List.nil     -- {α : Type u_1} → List α\n    #check @', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:26,605 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:26,606 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:26,606 - DEBUG - send_request_headers.complete
2025-06-01 01:54:26,606 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:26,606 - DEBUG - send_request_body.complete
2025-06-01 01:54:26,606 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:27,757 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'227'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-6d88f968d4-fhw95'), (b'x-envoy-upstream-service-time', b'533'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'992414'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'455ms'), (b'x-request-id', b'req_69beeaf37ee4051b14ca79f092decb81'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b15444a393bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:27,758 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:27,758 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:27,758 - DEBUG - receive_response_body.complete
2025-06-01 01:54:27,758 - DEBUG - response_closed.started
2025-06-01 01:54:27,758 - DEBUG - response_closed.complete
2025-06-01 01:54:27,758 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '227', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-6d88f968d4-fhw95', 'x-envoy-upstream-service-time': '533', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '992414', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '455ms', 'x-request-id': 'req_69beeaf37ee4051b14ca79f092decb81', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b15444a393bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:27,758 - DEBUG - request_id: req_69beeaf37ee4051b14ca79f092decb81
2025-06-01 01:54:27,759 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': 'List.length  -- {α : Type u_1} → List α → Nat\n    #check @List.append  -- {α : Type u_1} → List α → List α → List α\n    \n\nJust as dependent function types `(a : α) → β a` generalize the notion of a\nfunction type `α → β` by allowing `β` to depend on `α`, dependent Cartesian\nproduct types `(a : α) × β a` generalize the Cartesian product `α × β` in the\nsame way. Dependent products are also called _sigma_ types, and you can also\nwrite them as `Σ a : α, β a`. You can use `⟨a, b⟩` or `Sigma.mk a b` to create\na dependent pair. The `⟨` and `⟩` characters may be typed with `\\langle` and\n`\\rangle` or `\\<` and `\\>`, respectively.\n\n    \n    \n    universe u v\n    \n    def f (α : Type u) (β : α → Type v) (a : α) (b : β a) : (a : α) × β a :=\n      ⟨a, b⟩\n    \n    def g (α : Type u) (β : α → Type v) (a : α) (b : β a) : Σ a : α, β a :=\n      Sigma.mk a b\n    \n    def h1 (x : Nat) : Nat :=\n      (f Type (fun α => α) Nat x).2\n    \n    #eval h1 5 -- 5\n    \n    def h2 (x : Nat) : Nat :=\n      (g Type (fun α => α) Nat x).2\n    \n    #eval h2 5 -- 5\n    \n\nThe functions `f` and `g` above denote the same function.\n\n## Implicit Arguments\n\nSuppose we have an implementation of lists as:\n\n    \n    \n    universe u\n    def Lst (α : Type u) : Type u := List α\n    def Lst.cons (α : Type u) (a : α) (as : Lst α) : Lst α := List.cons a as\n    def Lst.nil (α : Type u) : Lst α := List.nil\n    def Lst.append (α : Type u) (as bs : Lst α) : Lst α := List.append as bs\n    #check Lst          -- Lst.{u} (α : Type u) : Type u\n    #check Lst.cons     -- Lst.cons.{u} (α : Type u) (a : α) (as : Lst α) : Lst α\n    #check Lst.nil      -- Lst.nil.{u} (α : Type u) : Lst α\n    #check Lst.append   -- Lst.append.{u} (α : Type u) (as bs : Lst α) : Lst α\n    \n\nThen, you can construct lists of `Nat` as follows:\n\n    \n    \n    universe u\n    def Lst (α : Type u) : Type u := List α\n    def Lst.cons (α : Type u) (a : α) (as : Lst α) : Lst α := List.cons a as\n    def Lst.nil (α : Type u) : Lst α := List.nil\n    def Lst.append (α : Type u) (as bs : Lst α) : Lst α := List.append as bs\n    #check Lst          -- Type u_1 → Type u_1\n    #check Lst.cons     -- (α : Type u_1) → α → Lst α → Lst α\n    #check Lst.nil      -- (α : Type u_1) → Lst α\n    #check Lst.append   -- (α : Type u_1) → Lst α → Lst α → Lst α\n    #check Lst.cons Nat 0 (Lst.nil Nat)\n    \n    def as : Lst Nat := Lst.nil Nat\n    def bs : Lst Nat := Lst.cons Nat 5 (Lst.nil Nat)\n    \n    #check Lst.append Nat as bs\n    \n\nBecause the constructors are polymorphic over types, we have to insert the\ntype `Nat` as an argument repeatedly. But this information is redundant: one\ncan infer the argument `α` in `Lst.cons Nat 5 (Lst.nil Nat)` from the fact\nthat the second argument, `5`, has type `Nat`. One can similarly infer the\nargument in `Lst.nil Nat`, not from anything else in that expression, but from\nthe fact that it is sent as an argument to the function `Lst.cons`, which\nexpects an element of type `Lst α` in that position.\n\nThis is a central feature of dependent type theory: terms carry a lot of\ninformation, and often some of that information can be inferred from the\ncontext. In Lean, one uses an underscore, `_`, to specify that the system\nshould fill in the information automatically. This is known as an "implicit\nargument."\n\n    \n    \n    universe u\n    def Lst (α : Type u) : Type u := List α\n    def Lst.cons (α : Type u) (a : α) (as : Lst α) : Lst α := List.cons a as\n    def Lst.nil (α : Type u) : Lst α := List.nil\n    def Lst.append (α : Type u) (as bs : Lst α) : Lst α := List.append as bs\n    #check Lst          -- Type u_1 → Type u_1\n    #check Lst.cons     -- (α : Type u_1) → α → Lst α → Lst α\n    #check Lst.nil      -- (α : Type u_1) → Lst α\n    #check Lst.append   -- (α : Type u_1) → Lst α → Lst α → Lst α\n    #check Lst.cons _ 0 (Lst.nil _)\n    \n    def as : Lst Nat := Lst.nil _\n    def bs : Lst Nat := Lst.cons _ 5 (Lst.nil _)\n    \n    #check Lst.append _ as bs\n    \n\nIt is still tedious, however, to type all these underscores. When a function\ntakes an argument that can generally be inferred from context, Lean allows you\nto specify that this argument should, by default, be left implicit. This is\ndone by putting the arguments in curly braces, as follows:\n\n    \n    \n    universe u\n    def Lst (α : Type u) : Type u := List α\n    \n    def Lst.cons {α : Type u} (a : α) (as : Lst α) : Lst α := List.cons a as\n    def Lst.nil {α : Type u} : Lst α := List.nil\n    def Lst.append {α : Type u} (as bs : Lst α) : Lst α := List.append as bs\n    \n    #check Lst.cons 0 Lst.nil\n    \n    def as : Lst Nat := Lst.nil\n    def bs : Lst Nat := Lst.cons 5 Lst.nil\n    \n    #check Lst.append as bs\n    \n\nAll that has changed are the braces around `α : Type u` in the declaration of\nthe variables. We can also use this device in function definitions:\n\n    \n    \n    universe u\n    def ident {α : Type u} (x : α) := x\n    \n    #check ident         -- ?m → ?m\n    #check ident 1       -- Nat\n    #check ident "hello" -- String\n    #check @ident        -- {α : Type u_1} → α → α\n    \n\nThis makes the first argument to `ident` implicit. Notationally, this hides\nthe specification of the type, making it look as though `ident` simply takes\nan argument of any type. In fact, the function `id` is defined in the standard\nlibrary in exactly this way. We have chosen a nontraditional name here only to\navoid a clash of names.\n\nVariables can also be specified as implicit when they are declared with the\n`variable` command:\n\n    \n    \n    universe u\n    \n    section\n      variable {α : Type u}\n      variable (x : α)\n      def ident := x\n    end\n    \n    #check ident\n    #check ident 4\n    #check ident "hello"\n    \n\nThis definition of `ident` here has the same effect as the one above.\n\nLean has very complex mechanisms for instantiating implicit arguments, and we\nwill see that they can be used to infer function types, predicates, and even\nproofs. The process of instantiating these "holes," or "placeholders," in a\nterm is often known as _elaboration_. The presence of implicit arguments means\nthat at times there may be insufficient information to fix the meaning of an\nexpression precisely. An expression like `id` or `List.nil` is said to be\n_polymorphic_ , because it can take on different meanings in different\ncontexts.\n\nOne can always specify the type `T` of an expression `e` by writing `(e : T)`.\nThis instructs Lean\'s elaborator to use the value `T` as the type of `e` when\ntrying to resolve implicit arguments. In the second pair of examples below,\nthis mechanism is used to specify the desired types of the expressions `id`\nand `List.nil`:\n\n    \n    \n    #check List.nil               -- List ?m\n    #check id                     -- ?m → ?m\n    \n    #check (List.nil : List Nat)  -- List Nat\n    #check (id : Nat → Nat)       -- Nat → Nat\n    \n\nNumerals are overloaded in Lean, but when the type of a numeral cannot be\ninferred, Lean assumes, by default, that it is a natural number. So the\nexpressions in the first two `#check` commands below are elaborated in the\nsame way, whereas the third `#check` command interprets `2` as an integer.\n\n    \n    \n    #check 2            -- Nat\n    #check (2 : Nat)    -- Nat\n    #check (2 : Int)    -- Int\n    \n\nSometimes, however, we may find ourselves in a situation where we have\ndeclared an argument to a function to be implicit, but now want to provide the\nargument explicitly. If `foo` is such a function, the notation `@foo` denotes\nthe same function with all the arguments made explicit.\n\n    \n    \n    #check @id        -- {α : Sort u_1} → α → α\n    #check @id Nat    -- Nat → Nat\n    #check @id Bool   -- Bool → Bool\n    \n    #check @id Nat 1     -- Nat\n    #check @id Bool true -- Bool\n    \n\nNotice that now the first `#check` command gives the type of the identifier,\n`id`, without inserting any placeholders. Moreover, the output indicates that\nthe first argument is implicit.\n\n[ __](introduction.html "Previous chapter") [ __](propositions_and_proofs.html\n"Next chapter")\n\n[ __](introduction.html "Previous chapter") [ __](propositions_and_proofs.html\n"Next chapter")', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:27,759 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:27,760 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:27,760 - DEBUG - send_request_headers.complete
2025-06-01 01:54:27,760 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:27,760 - DEBUG - send_request_body.complete
2025-06-01 01:54:27,760 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:28,357 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'81'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-74c8894ff9-vdnpn'), (b'x-envoy-upstream-service-time', b'84'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'997927'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'124ms'), (b'x-request-id', b'req_4bf03f6166de653a8cb1d7dab968367b'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b154b8d2d3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:28,357 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:28,358 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:28,358 - DEBUG - receive_response_body.complete
2025-06-01 01:54:28,358 - DEBUG - response_closed.started
2025-06-01 01:54:28,358 - DEBUG - response_closed.complete
2025-06-01 01:54:28,358 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '81', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-74c8894ff9-vdnpn', 'x-envoy-upstream-service-time': '84', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '997927', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '124ms', 'x-request-id': 'req_4bf03f6166de653a8cb1d7dab968367b', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b154b8d2d3bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:28,358 - DEBUG - request_id: req_4bf03f6166de653a8cb1d7dab968367b
2025-06-01 01:54:28,359 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Type Classes\n\nType classes were introduced as a principled way of enabling ad-hoc\npolymorphism in functional programming languages. We first observe that it\nwould be easy to implement an ad-hoc polymorphic function (such as addition)\nif the function simply took the type-specific implementation of addition as an\nargument and then called that implementation on the remaining arguments. For\nexample, suppose we declare a structure in Lean to hold implementations of\naddition.\n\n    \n    \n    namespace Ex\n    structure Add (a : Type) where\n      add : a → a → a\n    \n    #check @Add.add\n    -- Add.add : {a : Type} → Add a → a → a → a\n    end Ex\n    \n\nIn the above Lean code, the field `add` has type `Add.add : {a : Type} → Add a\n→ a → a → a` where the curly braces around the type `a` mean that it is an\nimplicit argument. We could implement `double` by:\n\n    \n    \n    namespace Ex\n    structure Add (a : Type) where\n     add : a → a → a\n    def double (s : Add a) (x : a) : a :=\n      s.add x x\n    \n    #eval double { add := Nat.add } 10\n    -- 20\n    \n    #eval double { add := Nat.mul } 10\n    -- 100\n    \n    #eval double { add := Int.add } 10\n    -- 20\n    end Ex\n    \n\nNote that you can double a natural number `n` by `double { add := Nat.add }\nn`. Of course, it would be highly cumbersome for users to manually pass the\nimplementations around in this way. Indeed, it would defeat most of the\npotential benefits of ad-hoc polymorphism.\n\nThe main idea behind type classes is to make arguments such as `Add a`\nimplicit, and to use a database of user-defined instances to synthesize the\ndesired instances automatically through a process known as typeclass\nresolution. In Lean, by changing `structure` to `class` in the example above,\nthe type of `Add.add` becomes:\n\n    \n    \n    namespace Ex\n    class Add (a : Type) where\n      add : a → a → a\n    \n    #check @Add.add\n    -- Add.add : {a : Type} → [self : Add a] → a → a → a\n    end Ex\n    \n\nwhere the square brackets indicate that the argument of type `Add a` is\n_instance implicit_ , i.e. that it should be synthesized using typeclass\nresolution. This version of `add` is the Lean analogue of the Haskell term\n`add :: Add a => a -> a -> a`. Similarly, we can register instances by:\n\n    \n    \n    namespace Ex\n    class Add (a : Type) where\n     add : a → a → a\n    instance : Add Nat where\n      add := Nat.add\n    \n    instance : Add Int where\n      add := Int.add\n    \n    instance : Add Float where\n      add := Float.add\n    end Ex\n    \n\nThen for `n : Nat` and `m : Nat`, the term `Add.add n m` triggers typeclass\nresolution with the goal of `Add Nat`, and typeclass resolution will\nsynthesize the instance for `Nat` above. We can now reimplement `double` using\nan instance implicit by:\n\n    \n    \n    namespace Ex\n    class Add (a : Type) where\n      add : a → a → a\n    instance : Add Nat where\n     add := Nat.add\n    instance : Add Int where\n     add := Int.add\n    instance : Add Float where\n     add := Float.add\n    def double [Add a] (x : a) : a :=\n      Add.add x x\n    \n    #check @double\n    -- @double : {a : Type} → [inst : Add a] → a → a\n    \n    #eval double 10\n    -- 20\n    \n    #eval double (10 : Int)\n    -- 100\n    \n    #eval double (7 : Float)\n    -- 14.000000\n    \n    #eval double (239.0 + 2)\n    -- 482.000000\n    \n    end Ex\n    \n\nIn general, instances may depend on other instances in complicated ways. For\nexample, you can declare an (anonymous) instance stating that if `a` has\naddition, then `Array a` has addition:\n\n    \n    \n    instance [Add a] : Add (Array a) where\n      add x y := Array.zipWith x y (· + ·)\n    \n    #eval Add.add #[1, 2] #[3, 4]\n    -- #[4, 6]\n    \n    #eval #[1, 2] + #[3, 4]\n    -- #[4, 6]\n    \n\nNote that `(· + ·)` is notation for `fun x y => x + y` in Lean.\n\nThe example above demonstrates how type classes are used to overload notation.\nNow, we explore another application. We often need an arbitrary element of a\ngiven type. Recall that types may not have any elements in Lean. It often\nhappens that we would like a definition to return an arbitrary element in a\n"corner case." For example, we may like the expression `head xs` to be of type\n`a` when `xs` is of type `List a`. Similarly, many theorems hold under the\nadditional assumption that a type is not empty. For example, if `a` is a type,\n`exists x : a, x = x` is true only if `a` is not empty. The standard library\ndefines a type class `Inhabited` to enable type class inference to infer a\n"default" element of an inhabited type. Let us start with the first step of\nthe program above, declaring an appropriate class:\n\n    \n    \n    namespace Ex\n    class Inhabited (a : Type u) where\n      default : a\n    \n    #check @Inhabited.default\n    -- Inhabited.default : {a : Type u} → [self : Inhabited a] → a\n    end Ex\n    \n\nNote `Inhabited.default` doesn\'t have any explicit arguments.\n\nAn element of the class `Inhabited a` is simply an expression of the form\n`Inhabited.mk x`, for some element `x : a`. The projection `Inhabited.default`\nwill allow us to "extract" such an element of `a` from an element of\n`Inhabited a`. Now we populate the class with some instances:\n\n    \n    \n    namespace Ex\n    class Inhabited (a : Type _) where\n     default : a\n    instance : Inhabited Bool where\n      default := true\n    \n    instance : Inhabited Nat where\n      default := 0\n    \n    instance : Inhabited Unit where\n      default := ()\n    \n    instance : Inhabited Prop where\n      default := True\n    \n    #eval (Inhabited.default : Nat)\n    -- 0\n    \n    #eval (Inhabited.default : Bool)\n    -- true\n    end Ex\n    \n\nYou can use the command `export` to create the alias `default` for\n`Inhabited.default`\n\n    \n    \n    namespace Ex\n    class Inhabited (a : Type _) where\n     default : a\n    instance : Inhabited Bool where\n     default := true\n    instance : Inhabited Nat where\n     default := 0\n    instance : Inhabited Unit where\n     default := ()\n    instance : Inhabited Prop where\n     default := True\n    export Inhabited (default)\n    \n    #eval (default : Nat)\n    -- 0\n    \n    #eval (default : Bool)\n    -- true\n    end Ex\n    \n\n## Chaining Instances\n\nIf that were the extent of type class inference, it would not be all that\nimpressive; it would be simply a mechanism of storing a list of instances for\nthe elaborator to find in a lookup table. What makes type class inference\npowerful is that one can _chain_ instances. That is, an instance declaration\ncan in turn depend on an implicit instance of a type class. This causes class\ninference to chain through instances recursively, backtracking when necessary,\nin a Prolog-like search.\n\nFor example, the following definition shows that if two types `a` and `b` are\ninhabited, then so is their product:\n\n    \n    \n    instance [Inhabited a] [Inhabited b] : Inhabited (a × b) where\n      default := (default, default)\n    \n\nWith this added to the earlier instance declarations, type class instance can\ninfer, for example, a default element of `Nat × Bool`:\n\n    \n    \n    namespace Ex\n    class Inhabited (a : Type u) where\n     default : a\n    instance : Inhabited Bool where\n     default := true\n    instance : Inhabited Nat where\n     default := 0\n    opaque default [Inhabited a] : a :=\n     Inhabited.default\n    instance [Inhabited a] [Inhabited b] : Inhabited (a × b) where\n      default := (default, default)\n    \n    #eval (default : Nat × Bool)\n    -- (0, true)\n    end Ex\n    \n\nSimilarly, we can inhabit type function with suitable constant functions:\n\n    \n    \n    instance [Inhabited b] : Inhabited (a → b) where\n      default := fun _ => default\n    \n\nAs an exercise, try defining default instances for other types, such as `List`\nand `Sum` types.\n\nThe Lean standard library contains the definition `inferInstance`. It has type\n`{α : Sort u} → [i : α] → α`, and is useful for triggering the type class\nresolution procedure when the expected type is an instance.\n\n    \n    \n    #check (inferInstance : Inhabited Nat) -- Inhabited Nat\n    \n    def foo : Inhabited (Nat × Nat) :=\n      inferInstance\n    \n    theorem ex : foo.default = (default, default) :=\n      rfl\n    \n\nYou can use the command `#print` to inspect how simple `inferInstance` is.\n\n    \n    \n    #print inferInstance\n    \n\n## ToString\n\nThe polymorphic method `toString` has type `{α : Type u} → [ToString α] → α →\nString`. You implement the instance for your own types and use chaining to\nconvert complex values into strings. Lean comes with `ToString` instances for\nmost builtin types.\n\n    \n    \n    structure Person where\n      name : String\n      age  : Nat\n    \n    instance : ToString Person where\n      toString p := p.name ++ "@" ++ toString p.age\n    \n    #eval toString { name := "Leo", age := 542 : Person }\n    #eval toString ({ name := "Daniel", age := 18 : Person }, "hello")\n    \n\n## Numerals\n\nNumerals are polymorphic in Lean. You can use a numeral (e.g., `2`) to denote\nan element of any type that implements the type class `OfNat`.\n\n    \n    \n    structure Rational where\n      num : Int\n      den : Nat\n      inv : den ≠ 0\n    \n    instance : OfNat Rational n where\n      ofNat := { num := n, den := 1, inv := by decide }\n    \n    instance : ToString Rational where\n      toString r := s!"{r.num}/{r.den}"\n    \n    #eval (2 : Rational) -- 2/1\n    \n    #check (2 : Rational) -- Rational\n    #check (2 : Nat)      -- Nat\n    \n\nLean elaborates the terms `(2 : Nat)` and `(2 : Rational)` as `OfNat.ofNat Nat\n2 (instOfNatNat 2)` and `OfNat.ofNat Rational 2 (instOfNatRational 2)`\nrespectively. We say the numerals `2` occurring in the elaborated terms are\n_raw_ natural numbers. You can input the raw natural number `2` using the\nmacro `nat_lit 2`.\n\n    \n    \n    #check nat_lit 2  -- Nat\n    \n\nRaw natural numbers are _not_ polymorphic.\n\nThe `OfNat` instance is parametric on the numeral. So, you can define\ninstances for particular numerals. The second argument is often a variable as\nin the example above, or a _raw_ natural number.\n\n    \n    \n    class Monoid (α : Type u) where\n      unit : α\n      op   : α → α → α\n    \n    instance [s : Monoid α] : OfNat α (nat_lit 1) where\n      ofNat := s.unit\n    \n    def getUnit [Monoid α] : α :=\n      1\n    \n\n## Output Parameters\n\nBy default, Lean only tries to synthesize an instance `Inhabited T` when the\nterm `T` is known and does not contain missing parts. The following command\nproduces the error "typeclass instance problem is stuck, it is often due to\nmetavariables `?m.7`" because the type has a missing part (i.e., the `_`).\n\n    \n    \n    #check_failure (inferInstance : Inhabited (Nat × _))\n    \n\nYou can view the parameter of the type class `Inhabited` as an _input_ value\nfor the type class synthesizer. When a type class has multiple parameters, you\ncan mark some of them as output parameters. Lean will start type class\nsynthesizer even when these parameters have missing parts. In the following\nexample, we use output parameters to define a _heterogeneous_ polymorphic\nmultiplication.\n\n    \n    \n    namespace Ex\n    class HMul (α : Type u) (β : Type v) (γ : outParam (Type w)) where\n      hMul : α → β → γ\n    \n    export HMul (hMul)\n    \n    instance : HMul Nat Nat Nat where\n      hMul := Nat.mul\n    \n    instance : HMul Nat (Array Nat) (Array Nat) where\n      hMul a bs := bs.map (fun b => hMul a b)\n    \n    #eval hMul 4 3           -- 12\n    #eval hMul 4 #[2, 3, 4]  -- #[8, 12, 16]\n    end Ex\n    \n\nThe parameters `α` and `β` are considered input parameters and `γ` an output\none. Given an application `hMul a b`, after the types of `a` and `b` are\nknown, the type class synthesizer is invoked, and the resulting type is\nobtained from the output parameter `γ`. In the example above, we defined two\ninstances. The first one is the homogeneous multiplication for natural\nnumbers. The second is the scalar multiplication for arrays. Note that you\nchain instances and generalize the second instance.\n\n    \n    \n    namespace Ex\n    class HMul (α : Type u) (β : Type v) (γ : outParam (Type w)) where\n      hMul : α → β → γ\n    \n    export HMul (hMul)\n    \n    instance : HMul Nat Nat Nat where\n      hMul := Nat.mul\n    \n    instance : HMul Int Int Int where\n      hMul := Int.mul\n    \n    instance [HMul α β γ] : HMul α (Array β) (Array γ) where\n      hMul a bs := bs.map (fun b => hMul a b)\n    \n    #eval hMul 4 3                    -- 12\n    #eval hMul 4 #[2, 3, 4]           -- #[8, 12, 16]\n    #eval hMul (-2) #[3, -1, 4]       -- #[-6, 2, -8]\n    #eval hMul 2 #[#[2, 3], #[0, 4]]  -- #[#[4, 6], #[0, 8]]\n    end Ex\n    \n\nYou can use our new scalar array multiplication instance on arrays of type\n`Array β` with a scalar of type `α` whenever you have an instance `HMul α β\nγ`. In the last `#eval`, note that the instance was used twice on an array of\narrays.\n\n## Default Instances\n\nIn the class `HMul`, the parameters `α` and `β` are treated as input values.\nThus, type class synthesis only starts after these two types are known. This\nmay often be too restrictive.\n\n    \n    \n    namespace Ex\n    class HMul (α : Type u) (β : Type v) (γ : outParam (Type w)) where\n      hMul : α → β → γ\n    \n    export HMul (hMul)\n    \n    instance : HMul Int Int Int where\n      hMul := Int.mul\n    \n    def xs : List Int := [1, 2, 3]\n    \n    -- Error "typeclass instance problem is stuck, it is often due to metavariables HMul ?m.89 ?m.90 ?m.91"\n    #check_failure fun y => xs.map (fun x => hMul x y)\n    end Ex\n    \n\nThe instance `HMul` is not synthesized by Lean because the type of `y` has not\nbeen provided. However, it is natural to assume that the type of `y` and `x`\nshould be the same in this kind of situation. We can achieve exactly that\nusing _default instances_.\n\n    \n    \n    namespace Ex\n    class HMul (α : Type u) (β : Type v) (γ : outParam (Type w)) where\n      hMul : α → β → γ\n    \n    export HMul (hMul)\n    \n    @[default_instance]\n    instance : HMul Int Int Int where\n      hMul := Int.mul\n    \n    def xs : List Int := [1, 2, 3]\n    \n    #check fun y => xs.map (fun x => hMul x y)  -- Int → List Int\n    end Ex\n    \n\nBy tagging the instance above with the attribute `default_instance`, we are\ninstructing Lean to use this instance on pending type class synthesis\nproblems. The actual Lean implementation defines homogeneous and heterogeneous\nclasses for arithmetical operators. Moreover, `a+b`, `a*b`, `a-b`, `a/b`, and\n`a%b` are notations for the heterogeneous versions. The instance `OfNat Nat n`\nis the default instance (with priority 100) for the `OfNat` class. This is why\nthe numeral `2` has type `Nat` when the expected type is not known. You can\ndefine default instances with higher priority to override the builtin ones.\n\n    \n    \n    structure Rational where\n      num : Int\n      den : Nat\n      inv : den ≠ 0\n    \n    @[default_instance 200]\n    instance : OfNat Rational n where\n      ofNat := { num := n, den := 1, inv := by decide }\n    \n    instance : ToString Rational where\n      toString r := s!"{r.num}/{r.den}"\n    \n    #check 2 -- Rational\n    \n\nPriorities are also useful to control the interaction between different\ndefault instances. For example, suppose `xs` has type `List α`. When\nelaborating `xs.map (fun x => 2 * x)`, we want the homogeneous instance for\nmultiplication to have higher priority than the default instance for `OfNat`.\nThis is particularly important when we have implemented only the instance\n`HMul α α α`, and did not implement `HMul Nat α α`. Now, we reveal how the\nnotation `a*b` is defined in Lean.\n\n    \n    \n    namespace Ex\n    class OfNat (α : Type u) (n : Nat) where\n      ofNat : α\n    \n    @[default_instance]\n    instance (n : Nat) : OfNat Nat n where\n      ofNat := n\n    \n    class HMul (α : Type u) (β : Type v) (γ : outParam (Type w)) where\n      hMul : α → β → γ\n    \n    class Mul (α : Type u) where\n      mul : α → α → α\n    \n    @[default_instance 10]\n    instance [Mul α] : HMul α α α where\n      hMul a b := Mul.mul a b\n    \n    infixl:70 " * " => HMul.hMul\n    end Ex\n    \n\nThe `Mul` class is convenient for types that only implement the homogeneous\nmultiplication.\n\n## Local Instances\n\nType classes are implemented using attributes in Lean. Thus, you can use the\n`local` modifier to indicate that they only have effect until the current\n`section` or `namespace` is closed, or until the end of the current file.\n\n    \n    \n    structure Point where\n      x : Nat\n      y : Nat\n    \n    section\n    \n    local instance : Add Point where\n      add a b := { x := a.x + b.x, y := a.y + b.y }\n    \n    def double (p : Point) :=\n      p + p\n    \n    end -- instance `Add Point` is not active anymore\n    \n    -- def triple (p : Point) :=\n    --  p + p + p  -- Error: failed to synthesize instance\n    \n\nYou can also temporarily disable an instance using the `attribute` command\nuntil the current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\n    \n    \n    structure Point where\n      x : Nat\n      y : Nat\n    \n    instance addPoint : Add Point where\n      add a b := { x := a.x + b.x, y := a.y + b.y }\n    \n    def double (p : Point) :=\n      p + p\n    \n    attribute [-instance] addPoint\n    \n    -- def triple (p : Point) :=\n    --  p + p + p  -- Error: failed to synthesize instance\n    \n\nWe recommend you only use this command to diagnose problems.\n\n## Scoped Instances\n\nYou can also declare scoped instances in namespaces. This kind of instance is\nonly active when you are inside of the namespace or open the namespace.\n\n    \n    \n    structure Point where\n      x : Nat\n      y : Nat\n    \n    namespace Point\n    \n    scoped instance : Add Point where\n      add a b := { x := a.x + b.x, y := a.y + b.y }\n    \n    def double (p : Point) :=\n      p + p\n    \n    end Point\n    -- instance `Add Point` is not active anymore\n    \n    -- #check fun (p : Point) => p + p + p  -- Error\n    \n    namespace Point\n    -- instance `Add Point` is active again\n    #check fun (p : Point) => p + p + p\n    \n    end Point\n    \n    open Point -- activates instance `Add Point`\n    #check fun (p : Point) => p + p + p\n    \n\nYou can use the command `open scoped <namespace>` to activate scoped\nattributes but will not "open" the names from the namespace.\n\n    \n    \n    structure Point where\n      x : Nat\n      y : Nat\n    \n    namespace Point\n    \n    scoped instance : Add Point where\n      add a b := { x := a.x + b.x, y := a.y + b.y }\n    \n    def double (p : Point) :=\n      p + p\n    \n    end Point\n    \n    open scoped Point -- activates instance `Add Point`\n    #check fun (p : Point) => p + p + p\n    \n    -- #check fun (p : Point) => double p -- Error: unknown identifier \'double\'\n    \n\n## Decidable Propositions\n\nLet us consider another example of a type class defined in the standard\nlibrary, namely the type class of `Decidable` propositions. Roughly speaking,\nan element of `Prop` is said to be decidable if we can decide whether it is\ntrue or false. The distinction is only useful in constructive mathematics;\nclassically, every proposition is decidable. But if we use the classical\nprinciple, say, to define a function by cases, that function will not be\ncomputable. Algorithmically speaking, the `Decidable` type class can be used\nto infer a procedure that effectively determines whether or not the\nproposition is true. As a result, the type class supports such computational\ndefinitions when they are possible while at the same time allowing a smooth\ntransition to the use of classical definitions and classical reasoning.\n\nIn the standard library, `Decidable` is defined formally as follows:\n\n    \n    \n    namespace Hidden\n    class inductive Decidable (p : Prop) where\n      | isFalse (h : ¬p) : Decidable p\n      | isTrue  (h : p)  : Decidable p\n    end Hidden\n    \n\nLogically speaking, having an element `t : Decidable p` is stronger than\nhaving an element `t : p ∨ ¬p`; it enables us to define values of an arbitrary\ntype depending on the truth value of `p`. For example, for the expression `if\np then a else b` to make sense, we need to know that `p` is decidable. That\nexpression is syntactic sugar for `ite p a b`, where `ite` is defined as\nfollows:\n\n    \n    \n    namespace Hidden\n    def ite {α : Sort u} (c : Prop) [h : Decidable c] (t e : α) : α :=\n      Decidable.casesOn (motive := fun _ => α) h (fun _ => e) (fun _ => t)\n    end Hidden\n    \n\nThe standard library also contains a variant of `ite` called `dite`, the\ndependent if-then-else expression. It is defined as follows:\n\n    \n    \n    namespace Hidden\n    def dite {α : Sort u} (c : Prop) [h : Decidable c] (t : c → α) (e : Not c → α) : α :=\n      Decidable.casesOn (motive := fun _ => α) h e t\n    end Hidden\n    \n\nThat is, in `dite c t e`, we can assume `hc : c` in the "then" branch, and\n`hnc : ¬ c` in the "else" branch. To make `dite` more convenient to use, Lean\nallows us to write `if h : c then t else e` instead of `dite c (λ h : c => t)\n(λ h : ¬ c => e)`.\n\nWithout classical logic, we cannot prove that every proposition is decidable.\nBut we can prove that _certain_ propositions are decidable. For example, we\ncan prove the decidability of basic operations like equality and comparisons\non the natural numbers and the integers. Moreover, decidability is preserved\nunder propositional connectives:\n\n    \n    \n    #check @instDecidableAnd\n      -- {p q : Prop} → [Decidable p] → [Decidable q] → Decidable (And p q)\n    \n    #check @instDecidableOr\n    #check @instDecidableNot\n    \n\nThus we can carry out definitions by cases on decidable predicates on the\nnatural numbers:\n\n    \n    \n    def step (a b x : Nat) : Nat :=\n      if x < a ∨ x > b then 0 else 1\n    \n    set_option pp.explicit true\n    #print step\n    \n\nTurning on implicit arguments shows that the elaborator has inferred the\ndecidability of the proposition `x < a ∨ x > b`, simply by applying\nappropriate instances.\n\nWith the classical axioms, we can prove that every proposition is decidable.\nYou can import the classical axioms and make the generic instance of\ndecidability available by opening the `Classical` namespace.\n\n    \n    \n    open Classical\n    \n\nThereafter `Decidable p` has an instance for every `p`. Thus all theorems in\nthe library that rely on decidability assumptions are freely available when\nyou want to reason classically. In [Chapter Axioms and\nComputation](./axioms_and_computation.html), we will see that using the law of\nthe excluded middle to define functions can prevent them from being used\ncomputationally. Thus, the standard library assigns a low priority to the\n`propDecidable` instance.\n\n    \n    \n    namespace Hidden\n    open Classical\n    noncomputable scoped\n    instance (priority := low) propDecidable (a : Prop) : Decidable a :=\n      choice <| match em a with\n        | Or.inl h => ⟨isTrue h⟩\n        | Or.inr h => ⟨isFalse h⟩\n    end Hidden\n    \n\nThis guarantees that Lean will favor other instances and fall back on\n`propDecidable` only after other attempts to infer decidability have failed.\n\nThe `Decidable` type class also provides a bit of small-scale automation for\nproving theorems. The standard library introduces the tactic `decide` that\nuses the `Decidable` instance to solve simple goals.\n\n    \n    \n    example : 10 < 5 ∨ 1 > 0 := by\n      decide\n    \n    example : ¬ (True ∧ False) := by\n      decide\n    \n    example : 10 * 20 = 200 := by\n      decide\n    \n    theorem ex : True ∧ 2 = 1+1 := by\n      decide\n    \n    #print ex\n    -- theorem ex : True ∧ 2 = 1 + 1 :=\n    -- of_decide_eq_true (Eq.refl true)\n    \n    #check @of_decide_eq_true\n    -- ∀ {p : Prop} [Decidable p], decide p = true → p\n    \n    #check @decide\n    -- (p : Prop) → [Decidable p] → Bool\n    \n\nThey work as follows. The expression `decide p` tries to infer a decision\nprocedure for `p`, and, if it is successful, evaluates to either `true` or\n`false`. In particular, if `p` is a true closed expression, `decide p` will\nreduce definitionally to the Boolean `true`. On the assumption that `decide p\n= true` holds, `of_decide_eq_true` produces a proof of `p`. The tactic\n`decide` puts it all together to prove a target `p`. By the previous\nobservations, `decide` will succeed any time the inferred decision procedure\nfor `c` has enough information to evaluate, definitionally, to the `isTrue`\ncase.\n\n## Managing Type Class Inference\n\nIf you are ever in a situation where you need to supply an expression that\nLean can infer by type class inference, you can ask Lean to carry out the\ninference using `inferInstance`:\n\n    \n    \n    def foo : Add Nat := inferInstance\n    def bar : Inhabited (Nat → Nat) := inferInstance\n    \n    #check @inferInstance\n    -- {α : Sort u} → [α] → α\n    \n\nIn fact, you can use Lean\'s `(t : T)` notation to specify the class whose\ninstance you are looking for, in a concise manner:\n\n    \n    \n    #check (inferInstance : Add Nat)\n    \n\nYou can also use the auxiliary definition `inferInstanceAs`:\n\n    \n    \n    #check inferInstanceAs (Add Nat)\n    \n    #check @inferInstanceAs\n    -- (α : Sort u) → [α] → α\n    \n\nSometimes Lean can\'t find an instance because the class is buried under a\ndefinition. For example, Lean cannot find an instance of `Inhabited (Set α)`.\nWe can declare one explicitly:\n\n    \n    \n    def Set (α : Type u) := α → Prop\n    \n    -- fails\n    -- example : Inhabited (Set α) :=\n    --  inferInstance\n    \n    instance : Inhabited (Set α) :=\n      inferInstanceAs (Inhabited (α → Prop))\n    \n\nAt times, you may find that the type class inference fails to find an expected\ninstance, or, worse, falls into an infinite loop and times out. To help debug\nin these situations, Lean enables you to request a trace of the search:\n\n    \n    \n    set_option trace.Meta.synthInstance true\n    \n\nIf you are using VS Code, you can read the results by hovering over the\nrelevant theorem or definition, or opening the messages window with `Ctrl-\nShift-Enter`. In Emacs, you can use `C-c C-x` to run an independent Lean\nprocess on your file, and the output buffer will show a trace every time the\ntype class resolution procedure is subsequently triggered.\n\nYou can also limit the search using the following options:\n\n    \n    \n    set_option synthInstance.maxHeartbeats 10000\n    set_option synthInstance.maxSize 400\n    \n\nOption `synthInstance.maxHeartbeats` specifies the maximum amount of\nheartbeats per typeclass resolution problem. A heartbeat is the number of\n(small) memory allocations (in thousands), 0 means there is no limit. Option\n`synthInstance.maxSize` is the maximum number of instances used to construct a\nsolution in the type class instance synthesis procedure.\n\nRemember also that in both the VS Code and Emacs editor modes, tab completion\nworks in `set_option`, to help you find suitable options.\n\nAs noted above, the type class instances in a given context represent a\nProlog-like program, which gives rise to a backtracking search. Both the\nefficiency of the program and the solutions that are found can depend on the\norder in which the system tries the instance. Instances which are declared\nlast are tried first. Moreover, if instances are declared in other modules,\nthe order in which they are tried depends on the order in which namespaces are\nopened. Instances declared in namespaces which are opened later are tried\nearlier.\n\nYou can change the order that type class instances are tried by assigning them\na _priority_. When an instance is declared, it is assigned a default priority\nvalue. You can assign other priorities when defining an instance. The\nfollowing example illustrates how this is done:\n\n    \n    \n    class Foo where\n      a : Nat\n      b : Nat\n    \n    instance (priority := default+1) i1 : Foo where\n      a := 1\n      b := 1\n    \n    instance i2 : Foo where\n      a := 2\n      b := 2\n    \n    example : Foo.a = 1 :=\n      rfl\n    \n    instance (priority := default+2) i3 : Foo where\n      a := 3\n      b := 3\n    \n    example : Foo.a = 3 :=\n      rfl\n    \n\n## Coercions using Type Classes\n\nThe most basic type of coercion maps elements of one type to another. For\nexample, a coercion from `Nat` to `Int` allows us to view any element `n :\nNat` as an element of `Int`. But some coercions depend on parameters; for\nexample, for any type `α`, we can view any element `as : List α` as an element\nof `Set α`, namely, the set of elements occurring in the list. The\ncorresponding coercion is defined on the "family" of types `List α`,\nparameterized by `α`.\n\nLean allows us to declare three kinds of coercions:\n\n  * from a family of types to another family of types\n  * from a family of types to the class of sorts\n  * from a family of types to the class of function types\n\nThe first kind of coercion allows us to view any element of a member of the\nsource family as an element of a corresponding member of the target family.\nThe second kind of coercion allows us to view any element of a member of the\nsource family as a type. The third kind of coercion allows us to view any\nelement of the source family as a function. Let us consider each of these in\nturn.\n\nIn Lean, coercions are implemented on top of the type class resolution\nframework. We define a coercion from `α` to `β` by declaring an instance of\n`Coe α β`. For example, we can define a coercion from `Bool` to `Prop` as\nfollows:\n\n    \n    \n    instance : Coe Bool Prop where\n      coe b := b = true\n    \n\nThis enables us to use boolean terms in if-then-else expressions:\n\n    \n    \n    #eval if true then 5 else 3\n    #eval if false then 5 else 3\n    \n\nWe can define a coercion from `List α` to `Set α` as follows:\n\n    \n    \n    def Set (α : Type u) := α → Prop\n    def Set.empty {α : Type u} : Set α := fun _ => False\n    def Set.mem (a : α) (s : Set α) : Prop := s a\n    def Set.singleton (a : α) : Set α := fun x => x = a\n    def Set.union (a b : Set α) : Set α := fun x => a x ∨ b x\n    notation "{ " a " }" => Set.singleton a\n    infix:55 " ∪ " => Set.union\n    def List.toSet : List α → Set α\n      | []    => Set.empty\n      | a::as => {a} ∪ as.toSet\n    \n    instance : Coe (List α) (Set α) where\n      coe a := a.toSet\n    \n    def s : Set Nat := {1}\n    #check s ∪ [2, ', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:28,360 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:28,360 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:28,360 - DEBUG - send_request_headers.complete
2025-06-01 01:54:28,360 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:28,360 - DEBUG - send_request_body.complete
2025-06-01 01:54:28,360 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:28,799 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'200'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7fbbd4cf65-j9pf5'), (b'x-envoy-upstream-service-time', b'204'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'992180'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'469ms'), (b'x-request-id', b'req_1d2a41d76eb852ef343326f87ecabd45'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b154f4ee93bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:28,800 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:28,800 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:28,800 - DEBUG - receive_response_body.complete
2025-06-01 01:54:28,800 - DEBUG - response_closed.started
2025-06-01 01:54:28,800 - DEBUG - response_closed.complete
2025-06-01 01:54:28,800 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '200', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-7fbbd4cf65-j9pf5', 'x-envoy-upstream-service-time': '204', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '992180', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '469ms', 'x-request-id': 'req_1d2a41d76eb852ef343326f87ecabd45', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b154f4ee93bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:28,801 - DEBUG - request_id: req_1d2a41d76eb852ef343326f87ecabd45
2025-06-01 01:54:28,801 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '3]\n    -- s ∪ List.toSet [2, 3] : Set Nat\n    \n\nWe can use the notation `↑` to force a coercion to be introduced in a\nparticular place. It is also helpful to make our intent clear, and work around\nlimitations of the coercion resolution system.\n\n    \n    \n    def Set (α : Type u) := α → Prop\n    def Set.empty {α : Type u} : Set α := fun _ => False\n    def Set.mem (a : α) (s : Set α) : Prop := s a\n    def Set.singleton (a : α) : Set α := fun x => x = a\n    def Set.union (a b : Set α) : Set α := fun x => a x ∨ b x\n    notation "{ " a " }" => Set.singleton a\n    infix:55 " ∪ " => Set.union\n    def List.toSet : List α → Set α\n      | []    => Set.empty\n      | a::as => {a} ∪ as.toSet\n    instance : Coe (List α) (Set α) where\n      coe a := a.toSet\n    def s : Set Nat := {1}\n    \n    #check let x := ↑[2, 3]; s ∪ x\n    -- let x := List.toSet [2, 3]; s ∪ x : Set Nat\n    #check let x := [2, 3]; s ∪ x\n    -- let x := [2, 3]; s ∪ List.toSet x : Set Nat\n    \n\nLean also supports dependent coercions using the type class `CoeDep`. For\nexample, we cannot coerce arbitrary propositions to `Bool`, only the ones that\nimplement the `Decidable` typeclass.\n\n    \n    \n    instance (p : Prop) [Decidable p] : CoeDep Prop p Bool where\n      coe := decide p\n    \n\nLean will also chain (non-dependent) coercions as necessary. Actually, the\ntype class `CoeT` is the transitive closure of `Coe`.\n\nLet us now consider the second kind of coercion. By the _class of sorts_ , we\nmean the collection of universes `Type u`. A coercion of the second kind is of\nthe form:\n\n    \n    \n        c : (x1 : A1) → ... → (xn : An) → F x1 ... xn → Type u\n    \n\nwhere `F` is a family of types as above. This allows us to write `s : t`\nwhenever `t` is of type `F a1 ... an`. In other words, the coercion allows us\nto view the elements of `F a1 ... an` as types. This is very useful when\ndefining algebraic structures in which one component, the carrier of the\nstructure, is a `Type`. For example, we can define a semigroup as follows:\n\n    \n    \n    structure Semigroup where\n      carrier : Type u\n      mul : carrier → carrier → carrier\n      mul_assoc (a b c : carrier) : mul (mul a b) c = mul a (mul b c)\n    \n    instance (S : Semigroup) : Mul S.carrier where\n      mul a b := S.mul a b\n    \n\nIn other words, a semigroup consists of a type, `carrier`, and a\nmultiplication, `mul`, with the property that the multiplication is\nassociative. The `instance` command allows us to write `a * b` instead of\n`Semigroup.mul S a b` whenever we have `a b : S.carrier`; notice that Lean can\ninfer the argument `S` from the types of `a` and `b`. The function\n`Semigroup.carrier` maps the class `Semigroup` to the sort `Type u`:\n\n    \n    \n    structure Semigroup where\n      carrier : Type u\n      mul : carrier → carrier → carrier\n      mul_assoc (a b c : carrier) : mul (mul a b) c = mul a (mul b c)\n    instance (S : Semigroup) : Mul S.carrier where\n      mul a b := S.mul a b\n    #check Semigroup.carrier\n    \n\nIf we declare this function to be a coercion, then whenever we have a\nsemigroup `S : Semigroup`, we can write `a : S` instead of `a : S.carrier`:\n\n    \n    \n    structure Semigroup where\n      carrier : Type u\n      mul : carrier → carrier → carrier\n      mul_assoc (a b c : carrier) : mul (mul a b) c = mul a (mul b c)\n    instance (S : Semigroup) : Mul S.carrier where\n      mul a b := S.mul a b\n    instance : CoeSort Semigroup (Type u) where\n      coe s := s.carrier\n    \n    example (S : Semigroup) (a b c : S) : (a * b) * c = a * (b * c) :=\n      Semigroup.mul_assoc _ a b c\n    \n\nIt is the coercion that makes it possible to write `(a b c : S)`. Note that,\nwe define an instance of `CoeSort Semigroup (Type u)` instead of `Coe\nSemigroup (Type u)`.\n\nBy the _class of function types_ , we mean the collection of Pi types `(z : B)\n→ C`. The third kind of coercion has the form:\n\n    \n    \n        c : (x1 : A1) → ... → (xn : An) → (y : F x1 ... xn) → (z : B) → C\n    \n\nwhere `F` is again a family of types and `B` and `C` can depend on `x1, ...,\nxn, y`. This makes it possible to write `t s` whenever `t` is an element of `F\na1 ... an`. In other words, the coercion enables us to view elements of `F a1\n... an` as functions. Continuing the example above, we can define the notion\nof a morphism between semigroups `S1` and `S2`. That is, a function from the\ncarrier of `S1` to the carrier of `S2` (note the implicit coercion) that\nrespects the multiplication. The projection `morphism.mor` takes a morphism to\nthe underlying function:\n\n    \n    \n    structure Semigroup where\n      carrier : Type u\n      mul : carrier → carrier → carrier\n      mul_assoc (a b c : carrier) : mul (mul a b) c = mul a (mul b c)\n    instance (S : Semigroup) : Mul S.carrier where\n      mul a b := S.mul a b\n    instance : CoeSort Semigroup (Type u) where\n      coe s := s.carrier\n    structure Morphism (S1 S2 : Semigroup) where\n      mor : S1 → S2\n      resp_mul : ∀ a b : S1, mor (a * b) = (mor a) * (mor b)\n    \n    #check @Morphism.mor\n    \n\nAs a result, it is a prime candidate for the third type of coercion.\n\n    \n    \n    structure Semigroup where\n      carrier : Type u\n      mul : carrier → carrier → carrier\n      mul_assoc (a b c : carrier) : mul (mul a b) c = mul a (mul b c)\n    instance (S : Semigroup) : Mul S.carrier where\n      mul a b := S.mul a b\n    instance : CoeSort Semigroup (Type u) where\n      coe s := s.carrier\n    structure Morphism (S1 S2 : Semigroup) where\n      mor : S1 → S2\n      resp_mul : ∀ a b : S1, mor (a * b) = (mor a) * (mor b)\n    instance (S1 S2 : Semigroup) : CoeFun (Morphism S1 S2) (fun _ => S1 → S2) where\n      coe m := m.mor\n    \n    theorem resp_mul {S1 S2 : Semigroup} (f : Morphism S1 S2) (a b : S1)\n            : f (a * b) = f a * f b :=\n      f.resp_mul a b\n    \n    example (S1 S2 : Semigroup) (f : Morphism S1 S2) (a : S1) :\n          f (a * a * a) = f a * f a * f a :=\n      calc f (a * a * a)\n        _ = f (a * a) * f a := by rw [resp_mul f]\n        _ = f a * f a * f a := by rw [resp_mul f]\n    \n\nWith the coercion in place, we can write `f (a * a * a)` instead of `f.mor (a\n* a * a)`. When the `Morphism`, `f`, is used where a function is expected,\nLean inserts the coercion. Similar to `CoeSort`, we have yet another class\n`CoeFun` for this class of coercions. The field `F` is used to specify the\nfunction type we are coercing to. This type may depend on the type we are\ncoercing from.\n\n[ __](structures_and_records.html "Previous chapter") [ __](conv.html "Next\nchapter")\n\n[ __](structures_and_records.html "Previous chapter") [ __](conv.html "Next\nchapter")', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:28,802 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:28,802 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:28,802 - DEBUG - send_request_headers.complete
2025-06-01 01:54:28,802 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:28,802 - DEBUG - send_request_body.complete
2025-06-01 01:54:28,802 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:29,763 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'96'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7c4c8df9b7-7rdt2'), (b'x-envoy-upstream-service-time', b'100'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'998332'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'100ms'), (b'x-request-id', b'req_c3caeb3fd6c7b33ad67bd2a5e0fc4477'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1552080f3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:29,763 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:29,763 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:29,764 - DEBUG - receive_response_body.complete
2025-06-01 01:54:29,764 - DEBUG - response_closed.started
2025-06-01 01:54:29,764 - DEBUG - response_closed.complete
2025-06-01 01:54:29,764 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '96', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-7c4c8df9b7-7rdt2', 'x-envoy-upstream-service-time': '100', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '998332', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '100ms', 'x-request-id': 'req_c3caeb3fd6c7b33ad67bd2a5e0fc4477', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1552080f3bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:29,764 - DEBUG - request_id: req_c3caeb3fd6c7b33ad67bd2a5e0fc4477
2025-06-01 01:54:29,764 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:29,765 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:29,766 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:29,766 - DEBUG - send_request_headers.complete
2025-06-01 01:54:29,766 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:29,766 - DEBUG - send_request_body.complete
2025-06-01 01:54:29,766 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:30,363 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'158'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7ffd9cff7b-92vjk'), (b'x-envoy-upstream-service-time', b'161'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'992040'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'477ms'), (b'x-request-id', b'req_b30db85096a4b3ace87506650e81a84f'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b15580ad53bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:30,363 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:30,363 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:30,363 - DEBUG - receive_response_body.complete
2025-06-01 01:54:30,363 - DEBUG - response_closed.started
2025-06-01 01:54:30,364 - DEBUG - response_closed.complete
2025-06-01 01:54:30,364 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '158', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-7ffd9cff7b-92vjk', 'x-envoy-upstream-service-time': '161', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '992040', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '477ms', 'x-request-id': 'req_b30db85096a4b3ace87506650e81a84f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b15580ad53bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:30,364 - DEBUG - request_id: req_b30db85096a4b3ace87506650e81a84f
2025-06-01 01:54:30,364 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': ' Lean failed to infer it. Named arguments also improve\nthe readability of your code by identifying what each argument represents.\n\n    \n    \n    def sum (xs : List Nat) :=\n      xs.foldl (init := 0) (·+·)\n    \n    #eval sum [1, 2, 3, 4]\n    -- 10\n    \n    example {a b : Nat} {p : Nat → Nat → Nat → Prop} (h₁ : p a b b) (h₂ : b = a)\n        : p a a b :=\n      Eq.subst (motive := fun x => p a x b) h₂ h₁\n    \n\nIn the following examples, we illustrate the interaction between named and\ndefault arguments.\n\n    \n    \n    def f (x : Nat) (y : Nat := 1) (w : Nat := 2) (z : Nat) :=\n      x + y + w - z\n    \n    example (x z : Nat) : f (z := z) x = x + 1 + 2 - z := rfl\n    \n    example (x z : Nat) : f x (z := z) = x + 1 + 2 - z := rfl\n    \n    example (x y : Nat) : f x y = fun z => x + y + 2 - z := rfl\n    \n    example : f = (fun x z => x + 1 + 2 - z) := rfl\n    \n    example (x : Nat) : f x = fun z => x + 1 + 2 - z := rfl\n    \n    example (y : Nat) : f (y := 5) = fun x z => x + 5 + 2 - z := rfl\n    \n    def g {α} [Add α] (a : α) (b? : Option α := none) (c : α) : α :=\n      match b? with\n      | none   => a + c\n      | some b => a + b + c\n    \n    variable {α} [Add α]\n    \n    example : g = fun (a c : α) => a + c := rfl\n    \n    example (x : α) : g (c := x) = fun (a : α) => a + x := rfl\n    \n    example (x : α) : g (b? := some x) = fun (a c : α) => a + x + c := rfl\n    \n    example (x : α) : g x = fun (c : α) => x + c := rfl\n    \n    example (x y : α) : g x y = fun (c : α) => x + y + c := rfl\n    \n\nYou can use `..` to provide missing explicit arguments as `_`. This feature\ncombined with named arguments is useful for writing patterns. Here is an\nexample:\n\n    \n    \n    inductive Term where\n      | var    (name : String)\n      | num    (val : Nat)\n      | app    (fn : Term) (arg : Term)\n      | lambda (name : String) (type : Term) (body : Term)\n    \n    def getBinderName : Term → Option String\n      | Term.lambda (name := n) .. => some n\n      | _ => none\n    \n    def getBinderType : Term → Option Term\n      | Term.lambda (type := t) .. => some t\n      | _ => none\n    \n\nEllipses are also useful when explicit arguments can be automatically inferred\nby Lean, and we want to avoid a sequence of `_`s.\n\n    \n    \n    example (f : Nat → Nat) (a b c : Nat) : f (a + b + c) = f (a + (b + c)) :=\n      congrArg f (Nat.add_assoc ..)\n    \n\n[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next\nchapter")\n\n[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next\nchapter")', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:30,365 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:30,365 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:30,365 - DEBUG - send_request_headers.complete
2025-06-01 01:54:30,365 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:30,365 - DEBUG - send_request_body.complete
2025-06-01 01:54:30,365 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:30,857 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'50'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5c589d798-bqx48'), (b'x-envoy-upstream-service-time', b'52'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999361'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'38ms'), (b'x-request-id', b'req_bdc04a1cbddd18e897e32f45a5d1af49'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b155bccb83bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:30,858 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:30,858 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:30,858 - DEBUG - receive_response_body.complete
2025-06-01 01:54:30,858 - DEBUG - response_closed.started
2025-06-01 01:54:30,858 - DEBUG - response_closed.complete
2025-06-01 01:54:30,858 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '50', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-5c589d798-bqx48', 'x-envoy-upstream-service-time': '52', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999361', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '38ms', 'x-request-id': 'req_bdc04a1cbddd18e897e32f45a5d1af49', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b155bccb83bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:30,859 - DEBUG - request_id: req_bdc04a1cbddd18e897e32f45a5d1af49
2025-06-01 01:54:30,859 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Propositions and Proofs\n\nBy now, you have seen some ways of defining objects and functions in Lean. In\nthis chapter, we will begin to explain how to write mathematical assertions\nand proofs in the language of dependent type theory as well.\n\n## Propositions as Types\n\nOne strategy for proving assertions about objects defined in the language of\ndependent type theory is to layer an assertion language and a proof language\non top of the definition language. But there is no reason to multiply\nlanguages in this way: dependent type theory is flexible and expressive, and\nthere is no reason we cannot represent assertions and proofs in the same\ngeneral framework.\n\nFor example, we could introduce a new type, `Prop`, to represent propositions,\nand introduce constructors to build new propositions from others.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    #check And     -- Prop → Prop → Prop\n    #check Or      -- Prop → Prop → Prop\n    #check Not     -- Prop → Prop\n    #check Implies -- Prop → Prop → Prop\n    \n    variable (p q r : Prop)\n    #check And p q                      -- Prop\n    #check Or (And p q) r               -- Prop\n    #check Implies (And p q) (And q p)  -- Prop\n    \n\nWe could then introduce, for each element `p : Prop`, another type `Proof p`,\nfor the type of proofs of `p`. An "axiom" would be a constant of such a type.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    #check Proof   -- Proof : Prop → Type\n    \n    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))\n    \n    variable (p q : Prop)\n    #check and_comm p q     -- Proof (Implies (And p q) (And q p))\n    \n\nIn addition to axioms, however, we would also need rules to build new proofs\nfrom old ones. For example, in many proof systems for propositional logic, we\nhave the rule of _modus ponens_ :\n\n> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.\n\nWe could represent this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q\n    \n\nSystems of natural deduction for propositional logic also typically rely on\nthe following rule:\n\n> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we\n> can "cancel" the hypothesis and obtain a proof of `Implies p q`.\n\nWe could render this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)\n    \n\nThis approach would provide us with a reasonable way of building assertions\nand proofs. Determining that an expression `t` is a correct proof of assertion\n`p` would then simply be a matter of checking that `t` has type `Proof p`.\n\nSome simplifications are possible, however. To start with, we can avoid\nwriting the term `Proof` repeatedly by conflating `Proof p` with `p` itself.\nIn other words, whenever we have `p : Prop`, we can interpret `p` as a type,\nnamely, the type of its proofs. We can then read `t : p` as the assertion that\n`t` is a proof of `p`.\n\nMoreover, once we make this identification, the rules for implication show\nthat we can pass back and forth between `Implies p q` and `p → q`. In other\nwords, implication between propositions `p` and `q` corresponds to having a\nfunction that takes any element of `p` to an element of `q`. As a result, the\nintroduction of the connective `Implies` is entirely redundant: we can use the\nusual function space constructor `p → q` from dependent type theory as our\nnotion of implication.\n\nThis is the approach followed in the Calculus of Constructions, and hence in\nLean as well. The fact that the rules for implication in a proof system for\nnatural deduction correspond exactly to the rules governing abstraction and\napplication for functions is an instance of the _Curry-Howard isomorphism_ ,\nsometimes known as the _propositions-as-types_ paradigm. In fact, the type\n`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy\ndescribed in the last chapter. Moreover, `Type u` is also just syntactic sugar\nfor `Sort (u+1)`. `Prop` has some special features, but like the other type\nuniverses, it is closed under the arrow constructor: if we have `p q : Prop`,\nthen `p → q : Prop`.\n\nThere are at least two ways of thinking about propositions as types. To some\nwho take a constructive view of logic and mathematics, this is a faithful\nrendering of what it means to be a proposition: a proposition `p` represents a\nsort of data type, namely, a specification of the type of data that\nconstitutes a proof. A proof of `p` is then simply an object `t : p` of the\nright type.\n\nThose not inclined to this ideology can view it, rather, as a simple coding\ntrick. To each proposition `p` we associate a type that is empty if `p` is\nfalse and has a single element, say `*`, if `p` is true. In the latter case,\nlet us say that (the type associated with) `p` is _inhabited_. It just so\nhappens that the rules for function application and abstraction can\nconveniently help us keep track of which elements of `Prop` are inhabited. So\nconstructing an element `t : p` tells us that `p` is indeed true. You can\nthink of the inhabitant of `p` as being the "fact that `p` is true." A proof\nof `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is\ntrue."\n\nIndeed, if `p : Prop` is any proposition, Lean\'s kernel treats any two\nelements `t1 t2 : p` as being definitionally equal, much the same way as it\ntreats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as\n_proof irrelevance,_ and is consistent with the interpretation in the last\nparagraph. It means that even though we can treat proofs `t : p` as ordinary\nobjects in the language of dependent type theory, they carry no information\nbeyond the fact that `p` is true.\n\nThe two ways we have suggested thinking about the propositions-as-types\nparadigm differ in a fundamental way. From the constructive point of view,\nproofs are abstract mathematical objects that are _denoted_ by suitable\nexpressions in dependent type theory. In contrast, if we think in terms of the\ncoding trick described above, then the expressions themselves do not denote\nanything interesting. Rather, it is the fact that we can write them down and\ncheck that they are well-typed that ensures that the proposition in question\nis true. In other words, the expressions _themselves_ are the proofs.\n\nIn the exposition below, we will slip back and forth between these two ways of\ntalking, at times saying that an expression "constructs" or "produces" or\n"returns" a proof of a proposition, and at other times simply saying that it\n"is" such a proof. This is similar to the way that computer scientists\noccasionally blur the distinction between syntax and semantics by saying, at\ntimes, that a program "computes" a certain function, and at other times\nspeaking as though the program "is" the function in question.\n\nIn any case, all that really matters is the bottom line. To formally express a\nmathematical assertion in the language of dependent type theory, we need to\nexhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a\nterm `t : p`. Lean\'s task, as a proof assistant, is to help us to construct\nsuch a term, `t`, and to verify that it is well-formed and has the correct\ntype.\n\n## Working with Propositions as Types\n\nIn the propositions-as-types paradigm, theorems involving only `→` can be\nproved using lambda abstraction and application. In Lean, the `theorem`\ncommand introduces a new theorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    \n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n\nCompare this proof to the expression `fun x : α => fun y : β => x` of type `α\n→ β → α`, where `α` and `β` are data types. This describes the function that\ntakes arguments `x` and `y` of type `α` and `β`, respectively, and returns\n`x`. The proof of `t1` has the same form, the only difference being that `p`\nand `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of\n`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis\n(trivially) to establish that the conclusion, `p`, is true.\n\nNote that the `theorem` command is really a version of the `def` command:\nunder the propositions and types correspondence, proving the theorem `p → q →\np` is really the same as defining an element of the associated type. To the\nkernel type checker, there is no difference between the two.\n\nThere are a few pragmatic differences between definitions and theorems,\nhowever. In normal circumstances, it is never necessary to unfold the\n"definition" of a theorem; by proof irrelevance, any two proofs of that\ntheorem are definitionally equal. Once the proof of a theorem is complete,\ntypically we only need to know that the proof exists; it doesn\'t matter what\nthe proof is. In light of that fact, Lean tags proofs as _irreducible_ , which\nserves as a hint to the parser (more precisely, the _elaborator_) that there\nis generally no need to unfold them when processing a file. In fact, Lean is\ngenerally able to process and check proofs in parallel, since assessing the\ncorrectness of one proof does not require knowing the details of another.\n\nAs with definitions, the `#print` command will show you the proof of a\ntheorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n    #print t1\n    \n\nNotice that the lambda abstractions `hp : p` and `hq : q` can be viewed as\ntemporary assumptions in the proof of `t1`. Lean also allows us to specify the\ntype of the final term `hp`, explicitly, with a `show` statement:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p :=\n      fun hp : p =>\n      fun hq : q =>\n      show p from hp\n    \n\nAdding such extra information can improve the clarity of a proof and help\ndetect errors when writing a proof. The `show` command does nothing more than\nannotate the type, and, internally, all the presentations of `t1` that we have\nseen produce the same term.\n\nAs with ordinary definitions, we can move the lambda-abstracted variables to\nthe left of the colon:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    #print t1    -- p → q → p\n    \n\nWe can use the theorem `t1` just as a function application:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    axiom hp : p\n    \n    theorem t2 : q → p := t1 hp\n    \n\nThe `axiom` declaration postulates the existence of an element of the given\ntype and may compromise logical consistency. For example, we can use it to\npostulate that the empty type `False` has an element:\n\n    \n    \n    axiom unsound : False\n    -- Everything follows from false\n    theorem ex : 1 = 0 :=\n      False.elim unsound\n    \n\nDeclaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as\nwitnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`\nthat `p` is true yields the theorem `t1 hp : q → p`.\n\nRecall that we can also write theorem `t1` as follows:\n\n    \n    \n    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp\n    \n    #print t1\n    \n\nThe type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the\nassertion "for every pair of propositions `p q`, we have `p → q → p`." For\nexample, we can move all parameters to the right of the colon:\n\n    \n    \n    theorem t1 : ∀ {p q : Prop}, p → q → p :=\n      fun {p q : Prop} (hp : p) (hq : q) => hp\n    \n\nIf `p` and `q` have been declared as variables, Lean will generalize them for\nus automatically:\n\n    \n    \n    variable {p q : Prop}\n    \n    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp\n    \n\nIn fact, by the propositions-as-types correspondence, we can declare the\nassumption `hp` that `p` holds, as another variable:\n\n    \n    \n    variable {p q : Prop}\n    variable (hp : p)\n    \n    theorem t1 : q → p := fun (hq : q) => hp\n    \n\nLean detects that the proof uses `hp` and automatically adds `hp : p` as a\npremise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →\nq → p`. Remember that this type can just as well be written `∀ (p q : Prop)\n(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type\nin which the target does not depend on the bound variable.\n\nWhen we generalize `t1` in such a way, we can then apply it to different pairs\nof propositions, to obtain different instances of the general theorem.\n\n    \n    \n    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp\n    \n    variable (p q r s : Prop)\n    \n    #check t1 p q                -- p → q → p\n    #check t1 r s                -- r → s → r\n    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s\n    \n    variable (h : r → s)\n    #check t1 (r → s) (s → r) h  -- (s → r) → r → s\n    \n\nOnce again, using the propositions-as-types correspondence, the variable `h`\nof type `r → s` can be viewed as the hypothesis, or premise, that `r → s`\nholds.\n\nAs another example, let us consider the composition function discussed in the\nlast chapter, now with propositions instead of types.\n\n    \n    \n    variable (p q r s : Prop)\n    \n    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=\n      fun h₃ : p =>\n      show r from h₁ (h₂ h₃)\n    \n\nAs a theorem of propositional logic, what does `t2` say?\n\nNote that it is often useful to use numeric unicode subscripts, entered as\n`\\0`, `\\1`, `\\2`, ..., for hypotheses, as we did in this example.\n\n## Propositional Logic\n\nLean defines all the standard logical connectives and notation. The\npropositional connectives come with the following notation:\n\nAscii| Unicode| Editor shortcut| Definition  \n---|---|---|---  \nTrue| | | True  \nFalse| | | False  \nNot| ¬| `\\not`, `\\neg`| Not  \n/\\| ∧| `\\and`| And  \n\\/| ∨| `\\or`| Or  \n->| →| `\\to`, `\\r`, `\\imp`|   \n<->| ↔| `\\iff`, `\\lr`| Iff  \n  \nThey all take values in `Prop`.\n\n    \n    \n    variable (p q : Prop)\n    \n    #check p → q → p ∧ q\n    #check ¬p → p ↔ False\n    #check p ∨ q → q ∨ p\n    \n\nThe order of operations is as follows: unary negation `¬` binds most strongly,\nthen `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧\ne` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right\n(nothing changes now that the arguments are elements of `Prop`, instead of\nsome other `Type`), as do the other binary connectives. So if we have `p q r :\nProp`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This\nis just the "curried" form of `p ∧ q → r`.\n\nIn the last chapter we observed that lambda abstraction can be viewed as an\n"introduction rule" for `→`. In the current setting, it shows how to\n"introduce" or establish an implication. Application can be viewed as an\n"elimination rule," showing how to "eliminate" or use an implication in a\nproof. The other propositional connectives are defined in Lean\'s library in\nthe file `Prelude.core` (see [importing\nfiles](./interacting_with_lean.html#importing-files) for more information on\nthe library hierarchy), and each connective comes with its canonical\nintroduction and elimination rules.\n\n### Conjunction\n\nThe expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :\np` and `h2 : q`. It is common to describe `And.intro` as the _and-\nintroduction_ rule. In the next example we use `And.intro` to create a proof\nof `p → q → p ∧ q`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq\n    \n    #check fun (hp : p) (hq : q) => And.intro hp hq\n    \n\nThe `example` command states a theorem without naming it or storing it in the\npermanent context. Essentially, it just checks that the given term has the\nindicated type. It is convenient for illustration, and we will use it often.\n\nThe expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.\nSimilarly, `And.right h` is a proof of `q`. They are commonly known as the\nleft and right _and-elimination_ rules.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : p := And.left h\n    example (h : p ∧ q) : q := And.right h\n    \n\nWe can now prove `p ∧ q → q ∧ p` with the following proof term.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      And.intro (And.right h) (And.left h)\n    \n\nNotice that and-introduction and and-elimination are similar to the pairing\nand projection operations for the Cartesian product. The difference is that\ngiven `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while\n`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is\nanother instance of the Curry-Howard isomorphism, but in contrast to\nimplication and the function space constructor, `∧` and `×` are treated\nseparately in Lean. With the analogy, however, the proof we have just\nconstructed is similar to a function that swaps the elements of a pair.\n\nWe will see in [Chapter Structures and Records](./structures_and_records.html)\nthat certain types in Lean are _structures_ , which is to say, the type is\ndefined with a single canonical _constructor_ which builds an element of the\ntype from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is\nan example: the canonical way to construct an element is to apply `And.intro`\nto suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous\nconstructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the\nrelevant type is an inductive type and can be inferred from the context. In\nparticular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:\n\n    \n    \n    variable (p q : Prop)\n    variable (hp : p) (hq : q)\n    \n    #check (⟨hp, hq⟩ : p ∧ q)\n    \n\nThese angle brackets are obtained by typing `\\<` and `\\>`, respectively.\n\nLean provides another useful syntactic gadget. Given an expression `e` of an\ninductive type `Foo` (possibly applied to some arguments), the notation\n`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of\naccessing functions without opening a namespace. For example, the following\ntwo expressions mean the same thing:\n\n    \n    \n    variable (xs : List Nat)\n    \n    #check List.length xs\n    #check xs.length\n    \n\nAs a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and\n`h.right` for `And.right h`. We can therefore rewrite the sample proof above\nconveniently as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      ⟨h.right, h.left⟩\n    \n\nThere is a fine line between brevity and obfuscation, and omitting information\nin this way can sometimes make a proof harder to read. But for straightforward\nconstructions like the one above, when the type of `h` and the goal of the\nconstruction are salient, the notation is clean and effective.\n\nIt is common to iterate constructions like "And." Lean also allows you to\nflatten nested constructors that associate to the right, so that these two\nproofs are equivalent:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, ⟨h.left, h.right⟩⟩\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, h.left, h.right⟩\n    \n\nThis is often useful as well.\n\n### Disjunction\n\nThe expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof\n`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a\nproof `hq : q`. These are the left and right _or-introduction_ rules.\n\n    \n    \n    variable (p q : Prop)\n    example (hp : p) : p ∨ q := Or.intro_left q hp\n    example (hq : q) : p ∨ q := Or.intro_right p hq\n    \n\nThe _or-elimination_ rule is slightly more complicated. The idea is that we\ncan prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`\nfollows from `q`. In other words, it is a proof by cases. In the expression\n`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :\np → r` and `hqr : q → r`, and produces a proof of `r`. In the following\nexample, we use `Or.elim` to prove `p ∨ q → q ∨ p`.\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h\n        (fun hp : p =>\n          show q ∨ p from Or.intro_right q hp)\n        (fun hq : q =>\n          show q ∨ p from Or.intro_left p hq)\n    \n\nIn most cases, the first argument of `Or.intro_right` and `Or.intro_left` can\nbe inferred automatically by Lean. Lean therefore provides `Or.inr` and\n`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and\n`Or.intro_left _`. Thus the proof term above could be written more concisely:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nNotice that there is enough information in the full expression for Lean to\ninfer the types of `hp` and `hq` as well. But using the type annotations in\nthe longer version makes the proof more readable, and can help catch and debug\nerrors.\n\nBecause `Or` has two constructors, we cannot use anonymous constructor\nnotation. But we can still write `h.elim` instead of `Or.elim h`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nOnce again, you should exercise judgment as to whether such abbreviations\nenhance or diminish readability.\n\n### Negation and Falsity\n\nNegation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by\nderiving a contradiction from `p`. Similarly, the expression `hnp hp` produces\na proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both\nthese rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is\nproduced by typing `\\not` or `\\neg`.)\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hpq : p → q) (hnq : ¬q) : ¬p :=\n      fun hp : p =>\n      show False from hnq (hpq hp)\n    \n\nThe connective `False` has a single elimination rule, `False.elim`, which\nexpresses the fact that anything follows from a contradiction. This rule is\nsometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the\n_principle of explosion_.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)\n    \n\nThe arbitrary fact, `q`, that follows from falsity is an implicit argument in\n`False.elim` and is inferred automatically. This pattern, deriving an\narbitrary fact from contradictory hypotheses, is quite common, and is\nrepresented by `absurd`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := absurd hp hnp\n    \n\nHere, for example, is a proof of `¬p → q → (q → p) → r`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=\n      absurd (hqp hq) hnp\n    \n\nIncidentally, just as `False` has only an elimination rule, `True` has only an\nintroduction rule, `True.intro : true`. In other words, `True` is simply true,\nand has a canonical proof, `True.intro`.\n\n### Logical Equivalence\n\nThe expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`\nand `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from\n`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔\nq`. Here is a proof of `p ∧ q ↔ q ∧ p`:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      Iff.intro\n        (fun h : p ∧ q =>\n         show q ∧ p from And.intro (And.right h) (And.left h))\n        (fun h : q ∧ p =>\n         show p ∧ q from And.intro (And.right h) (And.left h))\n    \n    #check and_swap p q    -- p ∧ q ↔ q ∧ p\n    \n    variable (h : p ∧ q)\n    example : q ∧ p := Iff.mp (and_swap p q) h\n    \n\nWe can use the anonymous constructor notation to construct a proof of `p ↔ q`\nfrom proofs of the forward and backward directions, and we can also use `.`\nnotation with `mp` and `mpr`. The previous examples can therefore be written\nconcisely as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩\n    \n    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h\n    \n\n## Introducing Auxiliary Subgoals\n\nThis is a good place to introduce another device Lean offers to help structure\nlong proofs, namely, the `have` construct, which introduces an auxiliary\nsubgoal in a proof. Here is a small example, adapted from the last section:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      have hq : q := h.right\n      show q ∧ p from And.intro hq hp\n    \n\nInternally, the expression `have h : p := s; t` produces the term `(fun (h :\np) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the\ndesired conclusion assuming `h : p`, and the two are combined by a lambda\nabstraction and application. This simple device is extremely useful when it\ncomes to structuring long proofs, since we can use intermediate `have`\'s as\nstepping stones leading to the final goal.\n\nLean also supports a structured way of reasoning backwards from a goal, which\nmodels the "suffices to show" construction in ordinary mathematics. The next\nexample simply permutes the last two lines in the previous proof.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      suffices hq : q from And.intro hq hp\n      show q from And.right h\n    \n\nWriting `suffices hq : q` leaves us with two goals. First, we have to show\nthat it indeed suffices to show `q`, by proving the original goal of `q ∧ p`\nwith the additional hypothesis `hq : q`. Finally, we have to show `q`.\n\n## Classical Logic\n\nThe introduction and elimination rules we have seen so far are all\nconstructive, which is to say, they reflect a computational understanding of\nthe logical connectives based on the propositions-as-types correspondence.\nOrdinary classical logic adds to this the law of the excluded middle, `p ∨\n¬p`. To use this principle, you have to open the classical namespace.\n\n    \n    \n    open Classical\n    \n    variable (p : Prop)\n    #check em p\n    \n\nIntuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts\nto knowing which is the case. If `RH` represents the Riemann hypothesis, a\nclassical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot\nyet assert either disjunct.\n\nOne consequence of the law of the excluded middle is the principle of double-\nnegation elimination:\n\n    \n    \n    open Classical\n    \n    theorem dne {p : Prop} (h : ¬¬p) : p :=\n      Or.elim (em p)\n        (fun hp : p => hp)\n        (fun hnp : ¬p => absurd hnp h)\n    \n\nDouble-negation elimination allows one to prove any proposition, `p`, by\nassuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In\nother words, double-negation elimination allows one to carry out a proof by\ncontradiction, something which is not generally possible in constructive\nlogic. As an exercise, you might try proving the converse, that is, showing\nthat `em` can be proved from `dne`.\n\nThe classical axioms also give you access to additional patterns of proof that\ncan be justified by appeal to `em`. For example, one can carry out a proof by\ncases:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byCases\n        (fun h1 : p => h1)\n        (fun h1 : ¬p => absurd h1 h)\n    \n\nOr you can carry out a proof by contradiction:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byContradiction\n        (fun h1 : ¬p =>\n         show False from h h1)\n    \n\nIf you are not used to thinking constructively, it may take some time for you\nto get a sense of where classical reasoning is used. It is needed in the\nfollowing example because, from a constructive standpoint, knowing that `p`\nand `q` are not both true does not necessarily tell you which one is false:\n\n    \n    \n    open Classical\n    variable (p q : Prop)\n    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=\n      Or.elim (em p)\n        (fun hp : p =>\n          Or.inr\n            (show ¬q from\n              fun hq : q =>\n              h ⟨hp, hq⟩))\n        (fun hp : ¬p =>\n          Or.inl hp)\n    \n\nWe will see later that there _are_ situations in constructive logic where\nprinciples like excluded middle and double-negation elimination are\npermissible, and Lean supports the use of classical reasoning in such contexts\nwithout relying on excluded middle.\n\nThe full list of axioms that are used in Lean to support classical reasoning\nare discussed in [Axioms and Computation](./axioms_and_computation.html).\n\n## Examples of Propositional Validities\n\nLean\'s standard library contains proofs of many valid statements of\npropositional logic, all of which you are free to use in proofs of your own.\nThe following list includes a number of common identities.\n\nCommutativity:\n\n  1. `p ∧ q ↔ q ∧ p`\n  2. `p ∨ q ↔ q ∨ p`\n\nAssociativity:\n\n  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`\n  4. `(p ∨ q) ∨ r ↔ p ∨ (q �', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:30,860 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:30,860 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:30,860 - DEBUG - send_request_headers.complete
2025-06-01 01:54:30,861 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:30,861 - DEBUG - send_request_body.complete
2025-06-01 01:54:30,861 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:31,528 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'183'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-canary-8445c47868-j978m'), (b'x-envoy-upstream-service-time', b'186'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'992336'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'459ms'), (b'x-request-id', b'req_0c2fab521fc14c35165f25d1b82b938f'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b155eee213bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:31,529 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:31,529 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:31,529 - DEBUG - receive_response_body.complete
2025-06-01 01:54:31,529 - DEBUG - response_closed.started
2025-06-01 01:54:31,529 - DEBUG - response_closed.complete
2025-06-01 01:54:31,529 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '183', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-canary-8445c47868-j978m', 'x-envoy-upstream-service-time': '186', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '992336', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '459ms', 'x-request-id': 'req_0c2fab521fc14c35165f25d1b82b938f', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b155eee213bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:31,530 - DEBUG - request_id: req_0c2fab521fc14c35165f25d1b82b938f
2025-06-01 01:54:31,530 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '� r)`\n\nDistributivity:\n\n  5. `p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)`\n  6. `p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)`\n\nOther properties:\n\n  7. `(p → (q → r)) ↔ (p ∧ q → r)`\n  8. `((p ∨ q) → r) ↔ (p → r) ∧ (q → r)`\n  9. `¬(p ∨ q) ↔ ¬p ∧ ¬q`\n  10. `¬p ∨ ¬q → ¬(p ∧ q)`\n  11. `¬(p ∧ ¬p)`\n  12. `p ∧ ¬q → ¬(p → q)`\n  13. `¬p → (p → q)`\n  14. `(¬p ∨ q) → (p → q)`\n  15. `p ∨ False ↔ p`\n  16. `p ∧ False ↔ False`\n  17. `¬(p ↔ ¬p)`\n  18. `(p → q) → (¬q → ¬p)`\n\nThese require classical reasoning:\n\n  19. `(p → r ∨ s) → ((p → r) ∨ (p → s))`\n  20. `¬(p ∧ q) → ¬p ∨ ¬q`\n  21. `¬(p → q) → p ∧ ¬q`\n  22. `(p → q) → (¬p ∨ q)`\n  23. `(¬q → ¬p) → (p → q)`\n  24. `p ∨ ¬p`\n  25. `(((p → q) → p) → p)`\n\nThe `sorry` identifier magically produces a proof of anything, or provides an\nobject of any data type at all. Of course, it is unsound as a proof method --\nfor example, you can use it to prove `False` \\-- and Lean produces severe\nwarnings when files use or import theorems which depend on it. But it is very\nuseful for building long proofs incrementally. Start writing the proof from\nthe top down, using `sorry` to fill in subproofs. Make sure Lean accepts the\nterm with all the `sorry`\'s; if not, there are errors that you need to\ncorrect. Then go back and replace each `sorry` with an actual proof, until no\nmore remain.\n\nHere is another useful trick. Instead of using `sorry`, you can use an\nunderscore `_` as a placeholder. Recall this tells Lean that the argument is\nimplicit, and should be filled in automatically. If Lean tries to do so and\nfails, it returns with an error message "don\'t know how to synthesize\nplaceholder," followed by the type of the term it is expecting, and all the\nobjects and hypotheses available in the context. In other words, for each\nunresolved placeholder, Lean reports the subgoal that needs to be filled at\nthat point. You can then construct a proof by incrementally filling in these\nplaceholders.\n\nFor reference, here are two sample proofs of validities taken from the list\nabove.\n\n    \n    \n    open Classical\n    \n    -- distributivity\n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=\n      Iff.intro\n        (fun h : p ∧ (q ∨ r) =>\n          have hp : p := h.left\n          Or.elim (h.right)\n            (fun hq : q =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)\n            (fun hr : r =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))\n        (fun h : (p ∧ q) ∨ (p ∧ r) =>\n          Or.elim h\n            (fun hpq : p ∧ q =>\n              have hp : p := hpq.left\n              have hq : q := hpq.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)\n            (fun hpr : p ∧ r =>\n              have hp : p := hpr.left\n              have hr : r := hpr.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))\n    \n    -- an example that requires classical reasoning\n    example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=\n      fun h : ¬(p ∧ ¬q) =>\n      fun hp : p =>\n      show q from\n        Or.elim (em q)\n          (fun hq : q => hq)\n          (fun hnq : ¬q => absurd (And.intro hp hnq) h)\n    \n\n## Exercises\n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs.\n\n    \n    \n    variable (p q r : Prop)\n    \n    -- commutativity of ∧ and ∨\n    example : p ∧ q ↔ q ∧ p := sorry\n    example : p ∨ q ↔ q ∨ p := sorry\n    \n    -- associativity of ∧ and ∨\n    example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry\n    example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry\n    \n    -- distributivity\n    example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry\n    example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry\n    \n    -- other properties\n    example : (p → (q → r)) ↔ (p ∧ q → r) := sorry\n    example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry\n    example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry\n    example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry\n    example : ¬(p ∧ ¬p) := sorry\n    example : p ∧ ¬q → ¬(p → q) := sorry\n    example : ¬p → (p → q) := sorry\n    example : (¬p ∨ q) → (p → q) := sorry\n    example : p ∨ False ↔ p := sorry\n    example : p ∧ False ↔ False := sorry\n    example : (p → q) → (¬q → ¬p) := sorry\n    \n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs. These require classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (p q r : Prop)\n    \n    example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry\n    example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry\n    example : ¬(p → q) → p ∧ ¬q := sorry\n    example : (p → q) → (¬p ∨ q) := sorry\n    example : (¬q → ¬p) → (p → q) := sorry\n    example : p ∨ ¬p := sorry\n    example : (((p → q) → p) → p) := sorry\n    \n\nProve `¬(p ↔ ¬p)` without using classical logic.\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:31,531 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:31,531 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:31,531 - DEBUG - send_request_headers.complete
2025-06-01 01:54:31,531 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:31,531 - DEBUG - send_request_body.complete
2025-06-01 01:54:31,531 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:31,943 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5f689c5f9d-m5j5v'), (b'x-envoy-upstream-service-time', b'117'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'998681'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'79ms'), (b'x-request-id', b'req_baf51328fdbce81798a6edafcf9e047b'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b15631fdd3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:31,944 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:31,944 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:31,944 - DEBUG - receive_response_body.complete
2025-06-01 01:54:31,944 - DEBUG - response_closed.started
2025-06-01 01:54:31,944 - DEBUG - response_closed.complete
2025-06-01 01:54:31,944 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '113', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-5f689c5f9d-m5j5v', 'x-envoy-upstream-service-time': '117', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '998681', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '79ms', 'x-request-id': 'req_baf51328fdbce81798a6edafcf9e047b', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b15631fdd3bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:31,944 - DEBUG - request_id: req_baf51328fdbce81798a6edafcf9e047b
2025-06-01 01:54:31,945 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:31,946 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:31,946 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:31,946 - DEBUG - send_request_headers.complete
2025-06-01 01:54:31,946 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:31,946 - DEBUG - send_request_body.complete
2025-06-01 01:54:31,947 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:32,417 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'176'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5c589d798-4wv9z'), (b'x-envoy-upstream-service-time', b'178'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'992444'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'453ms'), (b'x-request-id', b'req_ed4daa9133ec7cad81209197f68fc935'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1565a9463bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:32,417 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:32,417 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:32,418 - DEBUG - receive_response_body.complete
2025-06-01 01:54:32,418 - DEBUG - response_closed.started
2025-06-01 01:54:32,418 - DEBUG - response_closed.complete
2025-06-01 01:54:32,418 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '176', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-5c589d798-4wv9z', 'x-envoy-upstream-service-time': '178', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '992444', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '453ms', 'x-request-id': 'req_ed4daa9133ec7cad81209197f68fc935', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1565a9463bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:32,418 - DEBUG - request_id: req_ed4daa9133ec7cad81209197f68fc935
2025-06-01 01:54:32,419 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': ' modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:32,419 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:32,420 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:32,420 - DEBUG - send_request_headers.complete
2025-06-01 01:54:32,420 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:32,420 - DEBUG - send_request_body.complete
2025-06-01 01:54:32,420 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:33,171 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'149'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5d97677bdb-8h7rd'), (b'x-envoy-upstream-service-time', b'152'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'993231'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'406ms'), (b'x-request-id', b'req_9e8f7d3128a2c70356e5e710130898f1'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1568aac33bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:33,171 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:33,171 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:33,172 - DEBUG - receive_response_body.complete
2025-06-01 01:54:33,172 - DEBUG - response_closed.started
2025-06-01 01:54:33,172 - DEBUG - response_closed.complete
2025-06-01 01:54:33,172 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '149', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-5d97677bdb-8h7rd', 'x-envoy-upstream-service-time': '152', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '993231', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '406ms', 'x-request-id': 'req_9e8f7d3128a2c70356e5e710130898f1', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1568aac33bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:33,172 - DEBUG - request_id: req_9e8f7d3128a2c70356e5e710130898f1
2025-06-01 01:54:33,172 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Tactics\n\nIn this chapter, we describe an alternative approach to constructing proofs,\nusing _tactics_. A proof term is a representation of a mathematical proof;\ntactics are commands, or instructions, that describe how to build such a\nproof. Informally, you might begin a mathematical proof by saying "to prove\nthe forward direction, unfold the definition, apply the previous lemma, and\nsimplify." Just as these are instructions that tell the reader how to find the\nrelevant proof, tactics are instructions that tell Lean how to construct a\nproof term. They naturally support an incremental style of writing proofs, in\nwhich you decompose a proof and work on goals one step at a time.\n\nWe will describe proofs that consist of sequences of tactics as "tactic-style"\nproofs, to contrast with the ways of writing proof terms we have seen so far,\nwhich we will call "term-style" proofs. Each style has its own advantages and\ndisadvantages. For example, tactic-style proofs can be harder to read, because\nthey require the reader to predict or guess the results of each instruction.\nBut they can also be shorter and easier to write. Moreover, tactics offer a\ngateway to using Lean\'s automation, since automated procedures are themselves\ntactics.\n\n## Entering Tactic Mode\n\nConceptually, stating a theorem or introducing a `have` statement creates a\ngoal, namely, the goal of constructing a term with the expected type. For\nexample, the following creates the goal of constructing a term of type `p ∧ q\n∧ p`, in a context with constants `p q : Prop`, `hp : p` and `hq : q`:\n\n    \n    \n    theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p :=\n      sorry\n    \n\nYou can write this goal as follows:\n\n    \n    \n        p : Prop, q : Prop, hp : p, hq : q ⊢ p ∧ q ∧ p\n    \n\nIndeed, if you replace the "sorry" by an underscore in the example above, Lean\nwill report that it is exactly this goal that has been left unsolved.\n\nOrdinarily, you meet such a goal by writing an explicit term. But wherever a\nterm is expected, Lean allows us to insert instead a `by <tactics>` block,\nwhere `<tactics>` is a sequence of commands, separated by semicolons or line\nbreaks. You can prove the theorem above in that way:\n\n    \n    \n    theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p :=\n      by apply And.intro\n         exact hp\n         apply And.intro\n         exact hq\n         exact hp\n    \n\nWe often put the `by` keyword on the preceding line, and write the example\nabove as:\n\n    \n    \n    theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by\n      apply And.intro\n      exact hp\n      apply And.intro\n      exact hq\n      exact hp\n    \n\nThe `apply` tactic applies an expression, viewed as denoting a function with\nzero or more arguments. It unifies the conclusion with the expression in the\ncurrent goal, and creates new goals for the remaining arguments, provided that\nno later arguments depend on them. In the example above, the command `apply\nAnd.intro` yields two subgoals:\n\n    \n    \n        case left\n        p q : Prop\n        hp : p\n        hq : q\n        ⊢ p\n    \n        case right\n        p q : Prop\n        hp : p\n        hq : q\n        ⊢ q ∧ p\n    \n\nThe first goal is met with the command `exact hp`. The `exact` command is just\na variant of `apply` which signals that the expression given should fill the\ngoal exactly. It is good form to use it in a tactic proof, since its failure\nsignals that something has gone wrong. It is also more robust than `apply`,\nsince the elaborator takes the expected type, given by the target of the goal,\ninto account when processing the expression that is being applied. In this\ncase, however, `apply` would work just as well.\n\nYou can see the resulting proof term with the `#print` command:\n\n    \n    \n    theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by\n     apply And.intro\n     exact hp\n     apply And.intro\n     exact hq\n     exact hp\n    #print test\n    \n\nYou can write a tactic script incrementally. In VS Code, you can open a window\nto display messages by pressing `Ctrl-Shift-Enter`, and that window will then\nshow you the current goal whenever the cursor is in a tactic block. In Emacs,\nyou can see the goal at the end of any line by pressing `C-c C-g`, or see the\nremaining goal in an incomplete proof by putting the cursor after the first\ncharacter of the last tactic. If the proof is incomplete, the token `by` is\ndecorated with a red squiggly line, and the error message contains the\nremaining goals.\n\nTactic commands can take compound expressions, not just single identifiers.\nThe following is a shorter version of the preceding proof:\n\n    \n    \n    theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by\n      apply And.intro hp\n      exact And.intro hq hp\n    \n\nUnsurprisingly, it produces exactly the same proof term:\n\n    \n    \n    theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by\n     apply And.intro hp\n     exact And.intro hq hp\n    #print test\n    \n\nMultiple tactic applications can be written in a single line by concatenating\nwith a semicolon.\n\n    \n    \n    theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by\n      apply And.intro hp; exact And.intro hq hp\n    \n\nTactics that may produce multiple subgoals often tag them. For example, the\ntactic `apply And.intro` tagged the first subgoal as `left`, and the second as\n`right`. In the case of the `apply` tactic, the tags are inferred from the\nparameters\' names used in the `And.intro` declaration. You can structure your\ntactics using the notation `case <tag> => <tactics>`. The following is a\nstructured version of our first tactic proof in this chapter.\n\n    \n    \n    theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by\n      apply And.intro\n      case left => exact hp\n      case right =>\n        apply And.intro\n        case left => exact hq\n        case right => exact hp\n    \n\nYou can solve the subgoal `right` before `left` using the `case` notation:\n\n    \n    \n    theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by\n      apply And.intro\n      case right =>\n        apply And.intro\n        case left => exact hq\n        case right => exact hp\n      case left => exact hp\n    \n\nNote that Lean hides the other goals inside the `case` block. We say it is\n"focusing" on the selected goal. Moreover, Lean flags an error if the selected\ngoal is not fully solved at the end of the `case` block.\n\nFor simple subgoals, it may not be worth selecting a subgoal using its tag,\nbut you may still want to structure the proof. Lean also provides the "bullet"\nnotation `. <tactics>` (or `· <tactics>`) for structuring proofs:\n\n    \n    \n    theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by\n      apply And.intro\n      . exact hp\n      . apply And.intro\n        . exact hq\n        . exact hp\n    \n\n## Basic Tactics\n\nIn addition to `apply` and `exact`, another useful tactic is `intro`, which\nintroduces a hypothesis. What follows is an example of an identity from\npropositional logic that we proved in a previous chapter, now proved using\ntactics.\n\n    \n    \n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by\n      apply Iff.intro\n      . intro h\n        apply Or.elim (And.right h)\n        . intro hq\n          apply Or.inl\n          apply And.intro\n          . exact And.left h\n          . exact hq\n        . intro hr\n          apply Or.inr\n          apply And.intro\n          . exact And.left h\n          . exact hr\n      . intro h\n        apply Or.elim h\n        . intro hpq\n          apply And.intro\n          . exact And.left hpq\n          . apply Or.inl\n            exact And.right hpq\n        . intro hpr\n          apply And.intro\n          . exact And.left hpr\n          . apply Or.inr\n            exact And.right hpr\n    \n\nThe `intro` command can more generally be used to introduce a variable of any\ntype:\n\n    \n    \n    example (α : Type) : α → α := by\n      intro a\n      exact a\n    \n    example (α : Type) : ∀ x : α, x = x := by\n      intro x\n      exact Eq.refl x\n    \n\nYou can use it to introduce several variables:\n\n    \n    \n    example : ∀ a b c : Nat, a = b → a = c → c = b := by\n      intro a b c h₁ h₂\n      exact Eq.trans (Eq.symm h₂) h₁\n    \n\nAs the `apply` tactic is a command for constructing function applications\ninteractively, the `intro` tactic is a command for constructing function\nabstractions interactively (i.e., terms of the form `fun x => e`). As with\nlambda abstraction notation, the `intro` tactic allows us to use an implicit\n`match`.\n\n    \n    \n    example (α : Type) (p q : α → Prop) : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x := by\n      intro ⟨w, hpw, hqw⟩\n      exact ⟨w, hqw, hpw⟩\n    \n\nYou can also provide multiple alternatives like in the `match` expression.\n\n    \n    \n    example (α : Type) (p q : α → Prop) : (∃ x, p x ∨ q x) → ∃ x, q x ∨ p x := by\n      intro\n      | ⟨w, Or.inl h⟩ => exact ⟨w, Or.inr h⟩\n      | ⟨w, Or.inr h⟩ => exact ⟨w, Or.inl h⟩\n    \n\nThe `intros` tactic can be used without any arguments, in which case, it\nchooses names and introduces as many variables as it can. You will see an\nexample of this in a moment.\n\nThe `assumption` tactic looks through the assumptions in context of the\ncurrent goal, and if there is one matching the conclusion, it applies it.\n\n    \n    \n    example (x y z w : Nat) (h₁ : x = y) (h₂ : y = z) (h₃ : z = w) : x = w := by\n      apply Eq.trans h₁\n      apply Eq.trans h₂\n      assumption   -- applied h₃\n    \n\nIt will unify metavariables in the conclusion if necessary:\n\n    \n    \n    example (x y z w : Nat) (h₁ : x = y) (h₂ : y = z) (h₃ : z = w) : x = w := by\n      apply Eq.trans\n      assumption      -- solves x = ?b with h₁\n      apply Eq.trans\n      assumption      -- solves y = ?h₂.b with h₂\n      assumption      -- solves z = w with h₃\n    \n\nThe following example uses the `intros` command to introduce the three\nvariables and two hypotheses automatically:\n\n    \n    \n    example : ∀ a b c : Nat, a = b → a = c → c = b := by\n      intros\n      apply Eq.trans\n      apply Eq.symm\n      assumption\n      assumption\n    \n\nNote that names automatically generated by Lean are inaccessible by default.\nThe motivation is to ensure your tactic proofs do not rely on automatically\ngenerated names, and are consequently more robust. However, you can use the\ncombinator `unhygienic` to disable this restriction.\n\n    \n    \n    example : ∀ a b c : Nat, a = b → a = c → c = b := by unhygienic\n      intros\n      apply Eq.trans\n      apply Eq.symm\n      exact a_2\n      exact a_1\n    \n\nYou can also use the `rename_i` tactic to rename the most recent inaccessible\nnames in your context. In the following example, the tactic `rename_i h1 _ h2`\nrenames two of the last three hypotheses in your context.\n\n    \n    \n    example : ∀ a b c d : Nat, a = b → a = d → a = c → c = b := by\n      intros\n      rename_i h1 _ h2\n      apply Eq.trans\n      apply Eq.symm\n      exact h2\n      exact h1\n    \n\nThe `rfl` tactic is syntactic sugar for `exact rfl`:\n\n    \n    \n    example (y : Nat) : (fun x : Nat => 0) y = 0 :=\n      by rfl\n    \n\nThe `repeat` combinator can be used to apply a tactic several times:\n\n    \n    \n    example : ∀ a b c : Nat, a = b → a = c → c = b := by\n      intros\n      apply Eq.trans\n      apply Eq.symm\n      repeat assumption\n    \n\nAnother tactic that is sometimes useful is the `revert` tactic, which is, in a\nsense, an inverse to `intro`:\n\n    \n    \n    example (x : Nat) : x = x := by\n      revert x\n      -- goal is ⊢ ∀ (x : Nat), x = x\n      intro y\n      -- goal is y : Nat ⊢ y = y\n      rfl\n    \n\nMoving a hypothesis into the goal yields an implication:\n\n    \n    \n    example (x y : Nat) (h : x = y) : y = x := by\n      revert h\n      -- goal is x y : Nat ⊢ x = y → y = x\n      intro h₁\n      -- goal is x y : Nat, h₁ : x = y ⊢ y = x\n      apply Eq.symm\n      assumption\n    \n\nBut `revert` is even more clever, in that it will revert not only an element\nof the context but also all the subsequent elements of the context that depend\non it. For example, reverting `x` in the example above brings `h` along with\nit:\n\n    \n    \n    example (x y : Nat) (h : x = y) : y = x := by\n      revert x\n      -- goal is y : Nat ⊢ ∀ (x : Nat), x = y → y = x\n      intros\n      apply Eq.symm\n      assumption\n    \n\nYou can also revert multiple elements of the context at once:\n\n    \n    \n    example (x y : Nat) (h : x = y) : y = x := by\n      revert x y\n      -- goal is ⊢ ∀ (x y : Nat), x = y → y = x\n      intros\n      apply Eq.symm\n      assumption\n    \n\nYou can only `revert` an element of the local context, that is, a local\nvariable or hypothesis. But you can replace an arbitrary expression in the\ngoal by a fresh variable using the `generalize` tactic:\n\n    \n    \n    example : 3 = 3 := by\n      generalize 3 = x\n      -- goal is x : Nat ⊢ x = x\n      revert x\n      -- goal is ⊢ ∀ (x : Nat), x = x\n      intro y\n      -- goal is y : Nat ⊢ y = y\n      rfl\n    \n\nThe mnemonic in the notation above is that you are generalizing the goal by\nsetting `3` to an arbitrary variable `x`. Be careful: not every generalization\npreserves the validity of the goal. Here, `generalize` replaces a goal that\ncould be proved using `rfl` with one that is not provable:\n\n    \n    \n    example : 2 + 3 = 5 := by\n      generalize 3 = x\n      -- goal is x : Nat ⊢ 2 + x = 5\n      admit\n    \n\nIn this example, the `admit` tactic is the analogue of the `sorry` proof term.\nIt closes the current goal, producing the usual warning that `sorry` has been\nused. To preserve the validity of the previous goal, the `generalize` tactic\nallows us to record the fact that `3` has been replaced by `x`. All you need\nto do is to provide a label, and `generalize` uses it to store the assignment\nin the local context:\n\n    \n    \n    example : 2 + 3 = 5 := by\n      generalize h : 3 = x\n      -- goal is x : Nat, h : 3 = x ⊢ 2 + x = 5\n      rw [← h]\n    \n\nHere the `rewrite` tactic, abbreviated `rw`, uses `h` to replace `x` by `3`\nagain. The `rewrite` tactic will be discussed below.\n\n## More Tactics\n\nSome additional tactics are useful for constructing and destructing\npropositions and data. For example, when applied to a goal of the form `p ∨\nq`, you use tactics such as `apply Or.inl` and `apply Or.inr`. Conversely, the\n`cases` tactic can be used to decompose a disjunction:\n\n    \n    \n    example (p q : Prop) : p ∨ q → q ∨ p := by\n      intro h\n      cases h with\n      | inl hp => apply Or.inr; exact hp\n      | inr hq => apply Or.inl; exact hq\n    \n\nNote that the syntax is similar to the one used in `match` expressions. The\nnew subgoals can be solved in any order:\n\n    \n    \n    example (p q : Prop) : p ∨ q → q ∨ p := by\n      intro h\n      cases h with\n      | inr hq => apply Or.inl; exact hq\n      | inl hp => apply Or.inr; exact hp\n    \n\nYou can also use a (unstructured) `cases` without the `with` and a tactic for\neach alternative:\n\n    \n    \n    example (p q : Prop) : p ∨ q → q ∨ p := by\n      intro h\n      cases h\n      apply Or.inr\n      assumption\n      apply Or.inl\n      assumption\n    \n\nThe (unstructured) `cases` is particularly useful when you can close several\nsubgoals using the same tactic:\n\n    \n    \n    example (p : Prop) : p ∨ p → p := by\n      intro h\n      cases h\n      repeat assumption\n    \n\nYou can also use the combinator `tac1 <;> tac2` to apply `tac2` to each\nsubgoal produced by tactic `tac1`:\n\n    \n    \n    example (p : Prop) : p ∨ p → p := by\n      intro h\n      cases h <;> assumption\n    \n\nYou can combine the unstructured `cases` tactic with the `case` and `.`\nnotation:\n\n    \n    \n    example (p q : Prop) : p ∨ q → q ∨ p := by\n      intro h\n      cases h\n      . apply Or.inr\n        assumption\n      . apply Or.inl\n        assumption\n    \n    example (p q : Prop) : p ∨ q → q ∨ p := by\n      intro h\n      cases h\n      case inr h =>\n        apply Or.inl\n        assumption\n      case inl h =>\n        apply Or.inr\n        assumption\n    \n    example (p q : Prop) : p ∨ q → q ∨ p := by\n      intro h\n      cases h\n      case inr h =>\n        apply Or.inl\n        assumption\n      . apply Or.inr\n        assumption\n    \n\nThe `cases` tactic can also be used to decompose a conjunction:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p := by\n      intro h\n      cases h with\n      | intro hp hq => constructor; exact hq; exact hp\n    \n\nIn this example, there is only one goal after the `cases` tactic is applied,\nwith `h : p ∧ q` replaced by a pair of assumptions, `hp : p` and `hq : q`. The\n`constructor` tactic applies the unique constructor for conjunction,\n`And.intro`.\n\nWith these tactics, an example from the previous section can be rewritten as\nfollows:\n\n    \n    \n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by\n      apply Iff.intro\n      . intro h\n        cases h with\n        | intro hp hqr =>\n          cases hqr\n          . apply Or.inl; constructor <;> assumption\n          . apply Or.inr; constructor <;> assumption\n      . intro h\n        cases h with\n        | inl hpq =>\n          cases hpq with\n          | intro hp hq => constructor; exact hp; apply Or.inl; exact hq\n        | inr hpr =>\n          cases hpr with\n          | intro hp hr => constructor; exact hp; apply Or.inr; exact hr\n    \n\nYou will see in [Chapter Inductive Types](./inductive_types.html) that these\ntactics are quite general. The `cases` tactic can be used to decompose any\nelement of an inductively defined type; `constructor` always applies the first\napplicable constructor of an inductively defined type. For example, you can\nuse `cases` and `constructor` with an existential quantifier:\n\n    \n    \n    example (p q : Nat → Prop) : (∃ x, p x) → ∃ x, p x ∨ q x := by\n      intro h\n      cases h with\n      | intro x px => constructor; apply Or.inl; exact px\n    \n\nHere, the `constructor` tactic leaves the first component of the existential\nassertion, the value of `x`, implicit. It is represented by a metavariable,\nwhich should be instantiated later on. In the previous example, the proper\nvalue of the metavariable is determined by the tactic `exact px`, since `px`\nhas type `p x`. If you want to specify a witness to the existential quantifier\nexplicitly, you can use the `exists` tactic instead:\n\n    \n    \n    example (p q : Nat → Prop) : (∃ x, p x) → ∃ x, p x ∨ q x := by\n      intro h\n      cases h with\n      | intro x px => exists x; apply Or.inl; exact px\n    \n\nHere is another example:\n\n    \n    \n    example (p q : Nat → Prop) : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x := by\n      intro h\n      cases h with\n      | intro x hpq =>\n        cases hpq with\n        | intro hp hq =>\n          exists x\n    \n\nThese tactics can be used on data just as well as propositions. In the next\nexample, they are used to define functions which swap the components of the\nproduct and sum types:\n\n    \n    \n    def swap_pair : α × β → β × α := by\n      intro p\n      cases p\n      constructor <;> assumption\n    \n    def swap_sum : Sum α β → Sum β α := by\n      intro p\n      cases p\n      . apply Sum.inr; assumption\n      . apply Sum.inl; assumption\n    \n\nNote that up to the names we have chosen for the variables, the definitions\nare identical to the proofs of the analogous propositions for conjunction and\ndisjunction. The `cases` tactic will also do a case distinction on a natural\nnumber:\n\n    \n    \n    open Nat\n    example (P : Nat → Prop) (h₀ : P 0) (h₁ : ∀ n, P (succ n)) (m : Nat) : P m := by\n      cases m with\n      | zero    => exact h₀\n      | succ m\' => exact h₁ m\'\n    \n\nThe `cases` tactic, and its companion, the `induction` tactic, are discussed\nin greater detail in the [Tactics for Inductive\nTypes](./inductive_types.html#tactics-for-inductive-types) section.\n\nThe `contradiction` tactic searches for a contradiction among the hypotheses\nof the current goal:\n\n    \n    \n    example (p q : Prop) : p ∧ ¬ p → q := by\n      intro h\n      cases h\n      contradiction\n    \n\nYou can also use `match` in tactic blocks.\n\n    \n    \n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by\n      apply Iff.intro\n      . intro h\n        match h with\n        | ⟨_, Or.inl _⟩ => apply Or.inl; constructor <;> assumption\n        | ⟨_, Or.inr _⟩ => apply Or.inr; constructor <;> assumption\n      . intro h\n        match h with\n        | Or.inl ⟨hp, hq⟩ => constructor; exact hp; apply Or.inl; exact hq\n        | Or.inr ⟨hp, hr⟩ => constructor; exact hp; apply Or.inr; exact hr\n    \n\nYou can "combine" `intro h` with `match h ...` and write the previous examples\nas follows:\n\n    \n    \n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by\n      apply Iff.intro\n      . intro\n        | ⟨hp, Or.inl hq⟩ => apply Or.inl; constructor <;> assumption\n        | ⟨hp, Or.inr hr⟩ => apply Or.inr; constructor <;> assumption\n      . intro\n        | Or.inl ⟨hp, hq⟩ => constructor; assumption; apply Or.inl; assumption\n        | Or.inr ⟨hp, hr⟩ => constructor; assumption; apply Or.inr; assumption\n    \n\n## Structuring Tactic Proofs\n\nTactics often provide an efficient way of building a proof, but long sequences\nof instructions can obscure the structure of the argument. In this section, we\ndescribe some means that help provide structure to a tactic-style proof,\nmaking such proofs more readable and robust.\n\nOne thing that is nice about Lean\'s proof-writing syntax is that it is\npossible to mix term-style and tactic-style proofs, and pass between the two\nfreely. For example, the tactics `apply` and `exact` expect arbitrary terms,\nwhich you can write using `have`, `show`, and so on. Conversely, when writing\nan arbitrary Lean term, you can always invoke the tactic mode by inserting a\n`by` block. The following is a somewhat toy example:\n\n    \n    \n    example (p q r : Prop) : p ∧ (q ∨ r) → (p ∧ q) ∨ (p ∧ r) := by\n      intro h\n      exact\n        have hp : p := h.left\n        have hqr : q ∨ r := h.right\n        show (p ∧ q) ∨ (p ∧ r) by\n          cases hqr with\n          | inl hq => exact Or.inl ⟨hp, hq⟩\n          | inr hr => exact Or.inr ⟨hp, hr⟩\n    \n\nThe following is a more natural example:\n\n    \n    \n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by\n      apply Iff.intro\n      . intro h\n        cases h.right with\n        | inl hq => exact Or.inl ⟨h.left, hq⟩\n        | inr hr => exact Or.inr ⟨h.left, hr⟩\n      . intro h\n        cases h with\n        | inl hpq => exact ⟨hpq.left, Or.inl hpq.right⟩\n        | inr hpr => exact ⟨hpr.left, Or.inr hpr.right⟩\n    \n\nIn fact, there is a `show` tactic, which is similar to the `show` expression\nin a proof term. It simply declares the type of the goal that is about to be\nsolved, while remaining in tactic mode.\n\n    \n    \n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by\n      apply Iff.intro\n      . intro h\n        cases h.right with\n        | inl hq =>\n          show (p ∧ q) ∨ (p ∧ r)\n          exact Or.inl ⟨h.left, hq⟩\n        | inr hr =>\n          show (p ∧ q) ∨ (p ∧ r)\n          exact Or.inr ⟨h.left, hr⟩\n      . intro h\n        cases h with\n        | inl hpq =>\n          show p ∧ (q ∨ r)\n          exact ⟨hpq.left, Or.inl hpq.right⟩\n        | inr hpr =>\n          show p ∧ (q ∨ r)\n          exact ⟨hpr.left, Or.inr hpr.right⟩\n    \n\nThe `show` tactic can actually be used to rewrite a goal to something\ndefinitionally equivalent:\n\n    \n    \n    example (n : Nat) : n + 1 = Nat.succ n := by\n      show Nat.succ n = Nat.succ n\n      rfl\n    \n\nThere is also a `have` tactic, which introduces a new subgoal, just as when\nwriting proof terms:\n\n    \n    \n    example (p q r : Prop) : p ∧ (q ∨ r) → (p ∧ q) ∨ (p ∧ r) := by\n      intro ⟨hp, hqr⟩\n      show (p ∧ q) ∨ (p ∧ r)\n      cases hqr with\n      | inl hq =>\n        have hpq : p ∧ q := And.intro hp hq\n        apply Or.inl\n        exact hpq\n      | inr hr =>\n        have hpr : p ∧ r := And.intro hp hr\n        apply Or.inr\n        exact hpr\n    \n\nAs with proof terms, you can omit the label in the `have` tactic, in which\ncase, the default label `this` is used:\n\n    \n    \n    example (p q r : Prop) : p ∧ (q ∨ r) → (p ∧ q) ∨ (p ∧ r) := by\n      intro ⟨hp, hqr⟩\n      show (p ∧ q) ∨ (p ∧ r)\n      cases hqr with\n      | inl hq =>\n        have : p ∧ q := And.intro hp hq\n        apply Or.inl\n        exact this\n      | inr hr =>\n        have : p ∧ r := And.intro hp hr\n        apply Or.inr\n        exact this\n    \n\nThe types in a `have` tactic can be omitted, so you can write `have hp :=\nh.left` and `have hqr := h.right`. In fact, with this notation, you can even\nomit both the type and the label, in which case the new fact is introduced\nwith the label `this`:\n\n    \n    \n    example (p q r : Prop) : p ∧ (q ∨ r) → (p ∧ q) ∨ (p ∧ r) := by\n      intro ⟨hp, hqr⟩\n      cases hqr with\n      | inl hq =>\n        have := And.intro hp hq\n        apply Or.inl; exact this\n      | inr hr =>\n        have := And.intro hp hr\n        apply Or.inr; exact this\n    \n\nLean also has a `let` tactic, which is similar to the `have` tactic, but is\nused to introduce local definitions instead of auxiliary facts. It is the\ntactic analogue of a `let` in a proof term:\n\n    \n    \n    example : ∃ x, x + 2 = 8 := by\n      let a : Nat := 3 * 2\n      exists a\n    \n\nAs with `have`, you can leave the type implicit by writing `let a := 3 * 2`.\nThe difference between `let` and `have` is that `let` introduces a local\ndefinition in the context, so that the definition of the local declaration can\nbe unfolded in the proof.\n\nWe have used `.` to create nested tactic blocks. In a nested block, Lean\nfocuses on the first goal, and generates an error if it has not been fully\nsolved at the end of the block. This can be helpful in indicating the separate\nproofs of multiple subgoals introduced by a tactic. The notation `.` is\nwhitespace sensitive and relies on the indentation to detect whether the\ntactic block ends. Alternatively, you can define tactic blocks using curly\nbraces and semicolons:\n\n    \n    \n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by\n      apply Iff.intro\n      { intro h;\n        cases h.right;\n        { show (p ∧ q) ∨ (p ∧ r);\n          exact Or.inl ⟨h.left, ‹q›⟩ }\n        { show (p ∧ q) ∨ (p ∧ r);\n          exact Or.inr ⟨h.left, ‹r›⟩ } }\n      { intro h;\n        cases h;\n        { show p ∧ (q ∨ r);\n          rename_i hpq;\n          exact ⟨hpq.left, Or.inl hpq.right⟩ }\n        { show p ∧ (q ∨ r);\n          rename_i hpr;\n          exact ⟨hpr.left, Or.inr hpr.right⟩ } }\n    \n\nIt is useful to use indentation to structure proof: every time a tactic leaves\nmore than one subgoal, we separate the remaining subgoals by enclosing them in\nblocks and indenting. Thus if the application of theorem `foo` to a single\ngoal produces four subgoals, one would expect the proof to look like this:\n\n    \n    \n      apply foo\n      . <proof of first goal>\n      . <proof of second goal>\n      . <proof of third goal>\n      . <proof of final goal>\n    \n\nor\n\n    \n    \n      apply foo\n      case <tag of first goal>  => <proof of first goal>\n      case <tag of second goal> => <proof of second goal>\n      case <tag of third goal>  => <proof of third goal>\n      case <tag of final goal>  => <proof of final goal>\n    \n\nor\n\n    \n    \n      apply foo\n      { <proof of first goal>  }\n      { <proof of second goal> }\n      { <proof of third goal>  }\n      { <proof of final goal>  }\n    \n\n## Tactic Combinators\n\n_Tactic combinators_ are operations that form new tactics from old ones. A\nsequencing combinator is already implicit in the `by` block:\n\n    \n    \n    example (p q : Prop) (hp : p) : p ∨ q :=\n      by apply Or.inl; assumption\n    \n\nHere, `apply Or.inl; assumption` is functionally equivalent to a single tactic\nwhich first applies `apply Or.inl` and then applies `assumption`.\n\nIn `t₁ <;> t₂`, the `<;>` operator provides a _parallel_ version of the\nsequencing operation: `t₁` is applied to the current goal, and then `t₂` is\napplied to _all_ the resulting subgoals:\n\n    \n    \n    example (p q : Prop) (hp : p) (hq : q) : p ∧ q :=\n      by constructor <;> assumption\n    \n\nThis is especially useful when the resulting goals can be finished off in a\nuniform way, or, at least, when it is possible to make progress on all of them\nuniformly.\n\nThe `first | t₁ | t₂ | ... | tₙ` applies each `tᵢ` until one succeeds, or else fails:\n    \n    \n    example (p q : Prop) (hp : p) : p ∨ q := by\n      first | apply Or.inl; assumption | apply Or.inr; assumption\n    \n    example (p q : Prop) (hq : q) : p ∨ q := by\n      first | apply Or.inl; assumption | apply Or.inr; assumption\n    \n\nIn the first example, the left', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:33,173 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:33,173 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:33,174 - DEBUG - send_request_headers.complete
2025-06-01 01:54:33,174 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:33,174 - DEBUG - send_request_body.complete
2025-06-01 01:54:33,174 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:33,869 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'179'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-78456c78d9-mmt9t'), (b'x-envoy-upstream-service-time', b'182'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'992478'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'451ms'), (b'x-request-id', b'req_191fa4350c4c2501889507dde386da79'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b156d5ce93bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:33,870 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:33,870 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:33,870 - DEBUG - receive_response_body.complete
2025-06-01 01:54:33,870 - DEBUG - response_closed.started
2025-06-01 01:54:33,870 - DEBUG - response_closed.complete
2025-06-01 01:54:33,870 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '179', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-78456c78d9-mmt9t', 'x-envoy-upstream-service-time': '182', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '992478', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '451ms', 'x-request-id': 'req_191fa4350c4c2501889507dde386da79', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b156d5ce93bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:33,870 - DEBUG - request_id: req_191fa4350c4c2501889507dde386da79
2025-06-01 01:54:33,871 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': ' branch succeeds, whereas in the second one, it\nis the right one that succeeds. In the next three examples, the same compound\ntactic succeeds in each case:\n\n    \n    \n    example (p q r : Prop) (hp : p) : p ∨ q ∨ r :=\n      by repeat (first | apply Or.inl; assumption | apply Or.inr | assumption)\n    \n    example (p q r : Prop) (hq : q) : p ∨ q ∨ r :=\n      by repeat (first | apply Or.inl; assumption | apply Or.inr | assumption)\n    \n    example (p q r : Prop) (hr : r) : p ∨ q ∨ r :=\n      by repeat (first | apply Or.inl; assumption | apply Or.inr | assumption)\n    \n\nThe tactic tries to solve the left disjunct immediately by assumption; if that\nfails, it tries to focus on the right disjunct; and if that doesn\'t work, it\ninvokes the assumption tactic.\n\nYou will have no doubt noticed by now that tactics can fail. Indeed, it is the "failure" state that causes the _first_ combinator to backtrack and try the next tactic. The `try` combinator builds a tactic that always succeeds, though possibly in a trivial way: `try t` executes `t` and reports success, even if `t` fails. It is equivalent to `first | t | skip`, where `skip` is a tactic that does nothing (and succeeds in doing so). In the next example, the second `constructor` succeeds on the right conjunct `q ∧ r` (remember that disjunction and conjunction associate to the right) but fails on the first. The `try` tactic ensures that the sequential composition succeeds:\n    \n    \n    example (p q r : Prop) (hp : p) (hq : q) (hr : r) : p ∧ q ∧ r := by\n      constructor <;> (try constructor) <;> assumption\n    \n\nBe careful: `repeat (try t)` will loop forever, because the inner tactic never\nfails.\n\nIn a proof, there are often multiple goals outstanding. Parallel sequencing is\none way to arrange it so that a single tactic is applied to multiple goals,\nbut there are other ways to do this. For example, `all_goals t` applies `t` to\nall open goals:\n\n    \n    \n    example (p q r : Prop) (hp : p) (hq : q) (hr : r) : p ∧ q ∧ r := by\n      constructor\n      all_goals (try constructor)\n      all_goals assumption\n    \n\nIn this case, the `any_goals` tactic provides a more robust solution. It is\nsimilar to `all_goals`, except it succeeds if its argument succeeds on at\nleast one goal:\n\n    \n    \n    example (p q r : Prop) (hp : p) (hq : q) (hr : r) : p ∧ q ∧ r := by\n      constructor\n      any_goals constructor\n      any_goals assumption\n    \n\nThe first tactic in the `by` block below repeatedly splits conjunctions:\n\n    \n    \n    example (p q r : Prop) (hp : p) (hq : q) (hr : r) :\n          p ∧ ((p ∧ q) ∧ r) ∧ (q ∧ r ∧ p) := by\n      repeat (any_goals constructor)\n      all_goals assumption\n    \n\nIn fact, we can compress the full tactic down to one line:\n\n    \n    \n    example (p q r : Prop) (hp : p) (hq : q) (hr : r) :\n          p ∧ ((p ∧ q) ∧ r) ∧ (q ∧ r ∧ p) := by\n      repeat (any_goals (first | constructor | assumption))\n    \n\nThe combinator `focus t` ensures that `t` only effects the current goal,\ntemporarily hiding the others from the scope. So, if `t` ordinarily only\neffects the current goal, `focus (all_goals t)` has the same effect as `t`.\n\n## Rewriting\n\nThe `rewrite` tactic (abbreviated `rw`) and the `simp` tactic were introduced\nbriefly in [Calculational\nProofs](./quantifiers_and_equality.html#calculational-proofs). In this section\nand the next, we discuss them in greater detail.\n\nThe `rewrite` tactic provides a basic mechanism for applying substitutions to\ngoals and hypotheses, providing a convenient and efficient way of working with\nequality. The most basic form of the tactic is `rewrite [t]`, where `t` is a\nterm whose type asserts an equality. For example, `t` can be a hypothesis `h :\nx = y` in the context; it can be a general lemma, like `add_comm : ∀ x y, x +\ny = y + x`, in which the rewrite tactic tries to find suitable instantiations\nof `x` and `y`; or it can be any compound term asserting a concrete or general\nequation. In the following example, we use this basic form to rewrite the goal\nusing a hypothesis.\n\n    \n    \n    example (f : Nat → Nat) (k : Nat) (h₁ : f 0 = 0) (h₂ : k = 0) : f k = 0 := by\n      rw [h₂] -- replace k with 0\n      rw [h₁] -- replace f 0 with 0\n    \n\nIn the example above, the first use of `rw` replaces `k` with `0` in the goal\n`f k = 0`. Then, the second one replaces `f 0` with `0`. The tactic\nautomatically closes any goal of the form `t = t`. Here is an example of\nrewriting using a compound expression:\n\n    \n    \n    example (x y : Nat) (p : Nat → Prop) (q : Prop) (h : q → x = y)\n            (h\' : p y) (hq : q) : p x := by\n      rw [h hq]; assumption\n    \n\nHere, `h hq` establishes the equation `x = y`.\n\nMultiple rewrites can be combined using the notation `rw [t_1, ..., t_n]`,\nwhich is just shorthand for `rw [t_1]; ...; rw [t_n]`. The previous example\ncan be written as follows:\n\n    \n    \n    example (f : Nat → Nat) (k : Nat) (h₁ : f 0 = 0) (h₂ : k = 0) : f k = 0 := by\n      rw [h₂, h₁]\n    \n\nBy default, `rw` uses an equation in the forward direction, matching the left-\nhand side with an expression, and replacing it with the right-hand side. The\nnotation `←t` can be used to instruct the tactic to use the equality `t` in\nthe reverse direction.\n\n    \n    \n    example (f : Nat → Nat) (a b : Nat) (h₁ : a = b) (h₂ : f a = 0) : f b = 0 := by\n      rw [←h₁, h₂]\n    \n\nIn this example, the term `←h₁` instructs the rewriter to replace `b` with\n`a`. In the editors, you can type the backwards arrow as `\\l`. You can also\nuse the ascii equivalent, `<-`.\n\nSometimes the left-hand side of an identity can match more than one subterm in\nthe pattern, in which case the `rw` tactic chooses the first match it finds\nwhen traversing the term. If that is not the one you want, you can use\nadditional arguments to specify the appropriate subterm.\n\n    \n    \n    example (a b c : Nat) : a + b + c = a + c + b := by\n      rw [Nat.add_assoc, Nat.add_comm b, ← Nat.add_assoc]\n    \n    example (a b c : Nat) : a + b + c = a + c + b := by\n      rw [Nat.add_assoc, Nat.add_assoc, Nat.add_comm b]\n    \n    example (a b c : Nat) : a + b + c = a + c + b := by\n      rw [Nat.add_assoc, Nat.add_assoc, Nat.add_comm _ b]\n    \n\nIn the first example above, the first step rewrites `a + b + c` to `a + (b +\nc)`. The next step applies commutativity to the term `b + c`; without\nspecifying the argument, the tactic would instead rewrite `a + (b + c)` to `(b\n+ c) + a`. Finally, the last step applies associativity in the reverse\ndirection, rewriting `a + (c + b)` to `a + c + b`. The next two examples\ninstead apply associativity to move the parenthesis to the right on both\nsides, and then switch `b` and `c`. Notice that the last example specifies\nthat the rewrite should take place on the right-hand side by specifying the\nsecond argument to `Nat.add_comm`.\n\nBy default, the `rewrite` tactic affects only the goal. The notation `rw [t]\nat h` applies the rewrite `t` at hypothesis `h`.\n\n    \n    \n    example (f : Nat → Nat) (a : Nat) (h : a + 0 = 0) : f a = f 0 := by\n      rw [Nat.add_zero] at h\n      rw [h]\n    \n\nThe first step, `rw [Nat.add_zero] at h`, rewrites the hypothesis `a + 0 = 0`\nto `a = 0`. Then the new hypothesis `a = 0` is used to rewrite the goal to `f\n0 = f 0`.\n\nThe `rewrite` tactic is not restricted to propositions. In the following\nexample, we use `rw [h] at t` to rewrite the hypothesis `t : Tuple α n` to `t\n: Tuple α 0`.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    example (n : Nat) (h : n = 0) (t : Tuple α n) : Tuple α 0 := by\n      rw [h] at t\n      exact t\n    \n\n## Using the Simplifier\n\nWhereas `rewrite` is designed as a surgical tool for manipulating a goal, the\nsimplifier offers a more powerful form of automation. A number of identities\nin Lean\'s library have been tagged with the `[simp]` attribute, and the `simp`\ntactic uses them to iteratively rewrite subterms in an expression.\n\n    \n    \n    example (x y z : Nat) : (x + 0) * (0 + y * 1 + z * 0) = x * y := by\n      simp\n    \n    example (x y z : Nat) (p : Nat → Prop) (h : p (x * y))\n            : p ((x + 0) * (0 + y * 1 + z * 0)) := by\n      simp; assumption\n    \n\nIn the first example, the left-hand side of the equality in the goal is\nsimplified using the usual identities involving 0 and 1, reducing the goal to\n`x * y = x * y`. At that point, `simp` applies reflexivity to finish it off.\nIn the second example, `simp` reduces the goal to `p (x * y)`, at which point\nthe assumption `h` finishes it off. Here are some more examples with lists:\n\n    \n    \n    open List\n    \n    example (xs : List Nat)\n            : reverse (xs ++ [1, 2, 3]) = [3, 2, 1] ++ reverse xs := by\n      simp\n    \n    example (xs ys : List α)\n            : length (reverse (xs ++ ys)) = length xs + length ys := by\n      simp [Nat.add_comm]\n    \n\nAs with `rw`, you can use the keyword `at` to simplify a hypothesis:\n\n    \n    \n    example (x y z : Nat) (p : Nat → Prop)\n            (h : p ((x + 0) * (0 + y * 1 + z * 0))) : p (x * y) := by\n      simp at h; assumption\n    \n\nMoreover, you can use a "wildcard" asterisk to simplify all the hypotheses and\nthe goal:\n\n    \n    \n    attribute [local simp] Nat.mul_comm Nat.mul_assoc Nat.mul_left_comm\n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    example (w x y z : Nat) (p : Nat → Prop)\n            (h : p (x * y + z * w * x)) : p (x * w * z + y * x) := by\n      simp at *; assumption\n    \n    example (x y z : Nat) (p : Nat → Prop)\n            (h₁ : p (1 * x + y)) (h₂ : p (x * z * 1))\n            : p (y + 0 + x) ∧ p (z * x) := by\n      simp at * <;> constructor <;> assumption\n    \n\nFor operations that are commutative and associative, like multiplication on\nthe natural numbers, the simplifier uses these two facts to rewrite an\nexpression, as well as _left commutativity_. In the case of multiplication the\nlatter is expressed as follows: `x * (y * z) = y * (x * z)`. The `local`\nmodifier tells the simplifier to use these rules in the current file (or\nsection or namespace, as the case may be). It may seem that commutativity and\nleft-commutativity are problematic, in that repeated application of either\ncauses looping. But the simplifier detects identities that permute their\narguments, and uses a technique known as _ordered rewriting_. This means that\nthe system maintains an internal ordering of terms, and only applies the\nidentity if doing so decreases the order. With the three identities mentioned\nabove, this has the effect that all the parentheses in an expression are\nassociated to the right, and the expressions are ordered in a canonical\n(though somewhat arbitrary) way. Two expressions that are equivalent up to\nassociativity and commutativity are then rewritten to the same canonical form.\n\n    \n    \n    attribute [local simp] Nat.mul_comm Nat.mul_assoc Nat.mul_left_comm\n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    example (w x y z : Nat) (p : Nat → Prop)\n            : x * y + z * w * x = x * w * z + y * x := by\n      simp\n    \n    example (w x y z : Nat) (p : Nat → Prop)\n            (h : p (x * y + z * w * x)) : p (x * w * z + y * x) := by\n      simp; simp at h; assumption\n    \n\nAs with `rewrite`, you can send `simp` a list of facts to use, including\ngeneral lemmas, local hypotheses, definitions to unfold, and compound\nexpressions. The `simp` tactic also recognizes the `←t` syntax that `rewrite`\ndoes. In any case, the additional rules are added to the collection of\nidentities that are used to simplify a term.\n\n    \n    \n    def f (m n : Nat) : Nat :=\n      m + n + m\n    \n    example {m n : Nat} (h : n = 1) (h\' : 0 = m) : (f m n) = n := by\n      simp [h, ←h\', f]\n    \n\nA common idiom is to simplify a goal using local hypotheses:\n\n    \n    \n    example (f : Nat → Nat) (k : Nat) (h₁ : f 0 = 0) (h₂ : k = 0) : f k = 0 := by\n      simp [h₁, h₂]\n    \n\nTo use all the hypotheses present in the local context when simplifying, we\ncan use the wildcard symbol, `*`:\n\n    \n    \n    example (f : Nat → Nat) (k : Nat) (h₁ : f 0 = 0) (h₂ : k = 0) : f k = 0 := by\n      simp [*]\n    \n\nHere is another example:\n\n    \n    \n    example (u w x y z : Nat) (h₁ : x = y + z) (h₂ : w = u + x)\n            : w = z + y + u := by\n      simp [*, Nat.add_assoc, Nat.add_comm, Nat.add_left_comm]\n    \n\nThe simplifier will also do propositional rewriting. For example, using the\nhypothesis `p`, it rewrites `p ∧ q` to `q` and `p ∨ q` to `true`, which it\nthen proves trivially. Iterating such rewrites produces nontrivial\npropositional reasoning.\n\n    \n    \n    example (p q : Prop) (hp : p) : p ∧ q ↔ q := by\n      simp [*]\n    \n    example (p q : Prop) (hp : p) : p ∨ q := by\n      simp [*]\n    \n    example (p q r : Prop) (hp : p) (hq : q) : p ∧ (q ∨ r) := by\n      simp [*]\n    \n\nThe next example simplifies all the hypotheses, and then uses them to prove\nthe goal.\n\n    \n    \n    example (u w x x\' y y\' z : Nat) (p : Nat → Prop)\n            (h₁ : x + 0 = x\') (h₂ : y + 0 = y\')\n            : x + y + 0 = x\' + y\' := by\n      simp at *\n      simp [*]\n    \n\nOne thing that makes the simplifier especially useful is that its capabilities\ncan grow as a library develops. For example, suppose we define a list\noperation that symmetrizes its input by appending its reversal:\n\n    \n    \n    def mk_symm (xs : List α) :=\n      xs ++ xs.reverse\n    \n\nThen for any list `xs`, `reverse (mk_symm xs)` is equal to `mk_symm xs`, which\ncan easily be proved by unfolding the definition:\n\n    \n    \n    def mk_symm (xs : List α) :=\n     xs ++ xs.reverse\n    theorem reverse_mk_symm (xs : List α)\n            : (mk_symm xs).reverse = mk_symm xs := by\n      simp [mk_symm]\n    \n\nWe can now use this theorem to prove new results:\n\n    \n    \n    def mk_symm (xs : List α) :=\n     xs ++ xs.reverse\n    theorem reverse_mk_symm (xs : List α)\n           : (mk_symm xs).reverse = mk_symm xs := by\n     simp [mk_symm]\n    example (xs ys : List Nat)\n            : (xs ++ mk_symm ys).reverse = mk_symm ys ++ xs.reverse := by\n      simp [reverse_mk_symm]\n    \n    example (xs ys : List Nat) (p : List Nat → Prop)\n            (h : p (xs ++ mk_symm ys).reverse)\n            : p (mk_symm ys ++ xs.reverse) := by\n      simp [reverse_mk_symm] at h; assumption\n    \n\nBut using `reverse_mk_symm` is generally the right thing to do, and it would\nbe nice if users did not have to invoke it explicitly. You can achieve that by\nmarking it as a simplification rule when the theorem is defined:\n\n    \n    \n    def mk_symm (xs : List α) :=\n     xs ++ xs.reverse\n    @[simp] theorem reverse_mk_symm (xs : List α)\n            : (mk_symm xs).reverse = mk_symm xs := by\n      simp [mk_symm]\n    \n    example (xs ys : List Nat)\n            : (xs ++ mk_symm ys).reverse = mk_symm ys ++ xs.reverse := by\n      simp\n    \n    example (xs ys : List Nat) (p : List Nat → Prop)\n            (h : p (xs ++ mk_symm ys).reverse)\n            : p (mk_symm ys ++ xs.reverse) := by\n      simp at h; assumption\n    \n\nThe notation `@[simp]` declares `reverse_mk_symm` to have the `[simp]`\nattribute, and can be spelled out more explicitly:\n\n    \n    \n    def mk_symm (xs : List α) :=\n     xs ++ xs.reverse\n    theorem reverse_mk_symm (xs : List α)\n            : (mk_symm xs).reverse = mk_symm xs := by\n      simp [mk_symm]\n    \n    attribute [simp] reverse_mk_symm\n    \n    example (xs ys : List Nat)\n            : (xs ++ mk_symm ys).reverse = mk_symm ys ++ xs.reverse := by\n      simp\n    \n    example (xs ys : List Nat) (p : List Nat → Prop)\n            (h : p (xs ++ mk_symm ys).reverse)\n            : p (mk_symm ys ++ xs.reverse) := by\n      simp at h; assumption\n    \n\nThe attribute can also be applied any time after the theorem is declared:\n\n    \n    \n    def mk_symm (xs : List α) :=\n     xs ++ xs.reverse\n    theorem reverse_mk_symm (xs : List α)\n            : (mk_symm xs).reverse = mk_symm xs := by\n      simp [mk_symm]\n    \n    example (xs ys : List Nat)\n            : (xs ++ mk_symm ys).reverse = mk_symm ys ++ xs.reverse := by\n      simp [reverse_mk_symm]\n    \n    attribute [simp] reverse_mk_symm\n    \n    example (xs ys : List Nat) (p : List Nat → Prop)\n            (h : p (xs ++ mk_symm ys).reverse)\n            : p (mk_symm ys ++ xs.reverse) := by\n      simp at h; assumption\n    \n\nOnce the attribute is applied, however, there is no way to permanently remove\nit; it persists in any file that imports the one where the attribute is\nassigned. As we will discuss further in\n[Attributes](./interacting_with_lean.html#attributes), one can limit the scope\nof an attribute to the current file or section using the `local` modifier:\n\n    \n    \n    def mk_symm (xs : List α) :=\n     xs ++ xs.reverse\n    theorem reverse_mk_symm (xs : List α)\n            : (mk_symm xs).reverse = mk_symm xs := by\n      simp [mk_symm]\n    \n    section\n    attribute [local simp] reverse_mk_symm\n    \n    example (xs ys : List Nat)\n            : (xs ++ mk_symm ys).reverse = mk_symm ys ++ xs.reverse := by\n      simp\n    \n    example (xs ys : List Nat) (p : List Nat → Prop)\n            (h : p (xs ++ mk_symm ys).reverse)\n            : p (mk_symm ys ++ xs.reverse) := by\n      simp at h; assumption\n    end\n    \n\nOutside the section, the simplifier will no longer use `reverse_mk_symm` by\ndefault.\n\nNote that the various `simp` options we have discussed --- giving an explicit\nlist of rules, and using `at` to specify the location --- can be combined, but\nthe order they are listed is rigid. You can see the correct order in an editor\nby placing the cursor on the `simp` identifier to see the documentation string\nthat is associated with it.\n\nThere are two additional modifiers that are useful. By default, `simp`\nincludes all theorems that have been marked with the attribute `[simp]`.\nWriting `simp only` excludes these defaults, allowing you to use a more\nexplicitly crafted list of rules. In the examples below, the minus sign and\n`only` are used to block the application of `reverse_mk_symm`.\n\n    \n    \n    def mk_symm (xs : List α) :=\n      xs ++ xs.reverse\n    @[simp] theorem reverse_mk_symm (xs : List α)\n            : (mk_symm xs).reverse = mk_symm xs := by\n      simp [mk_symm]\n    \n    example (xs ys : List Nat) (p : List Nat → Prop)\n            (h : p (xs ++ mk_symm ys).reverse)\n            : p (mk_symm ys ++ xs.reverse) := by\n      simp at h; assumption\n    \n    example (xs ys : List Nat) (p : List Nat → Prop)\n            (h : p (xs ++ mk_symm ys).reverse)\n            : p ((mk_symm ys).reverse ++ xs.reverse) := by\n      simp [-reverse_mk_symm] at h; assumption\n    \n    example (xs ys : List Nat) (p : List Nat → Prop)\n            (h : p (xs ++ mk_symm ys).reverse)\n            : p ((mk_symm ys).reverse ++ xs.reverse) := by\n      simp only [List.reverse_append] at h; assumption\n    \n\nThe `simp` tactic has many configuration options. For example, we can enable\ncontextual simplifications as follows:\n\n    \n    \n    example : if x = 0 then y + x = y else x ≠ 0 := by\n      simp (config := { contextual := true })\n    \n\nWith `contextual := true`, the `simp` tactic uses the fact that `x = 0` when\nsimplifying `y + x = y`, and `x ≠ 0` when simplifying the other branch. Here\nis another example:\n\n    \n    \n    example : ∀ (x : Nat) (h : x = 0), y + x = y := by\n      simp (config := { contextual := true })\n    \n\nAnother useful configuration option is `arith := true` which enables\narithmetical simplifications. It is so useful that `simp_arith` is a shorthand\nfor `simp (config := { arith := true })`:\n\n    \n    \n    example : 0 < 1 + x ∧ x + y + 2 ≥ y + 1 := by\n      simp_arith\n    \n\n## Split Tactic\n\nThe `split` tactic is useful for breaking nested `if-then-else` and `match`\nexpressions in cases. For a `match` expression with `n` cases, the `split`\ntactic generates at most `n` subgoals. Here is an example:\n\n    \n    \n    def f (x y z : Nat) : Nat :=\n      match x, y, z with\n      | 5, _, _ => y\n      | _, 5, _ => y\n      | _, _, 5 => y\n      | _, _, _ => 1\n    \n    example (x y z : Nat) : x ≠ 5 → y ≠ 5 → z ≠ 5 → z = w → f x y w = 1 := by\n      intros\n      simp [f]\n      split\n      . contradiction\n      . contradiction\n      . contradiction\n      . rfl\n    \n\nWe can compress the tactic proof above as follows.\n\n    \n    \n    def f (x y z : Nat) : Nat :=\n     match x, y, z with\n     | 5, _, _ => y\n     | _, 5, _ => y\n     | _, _, 5 => y\n     | _, _, _ => 1\n    example (x y z : Nat) : x ≠ 5 → y ≠ 5 → z ≠ 5 → z = w → f x y w = 1 := by\n      intros; simp [f]; split <;> first | contradiction | rfl\n    \n\nThe tactic `split <;> first | contradiction | rfl` first applies the `split` tactic, and then for each generated goal it tries `contradiction`, and then `rfl` if `contradiction` fails. Like `simp`, we can apply `split` to a particular hypothesis:\n    \n    \n    def g (xs ys : List Nat) : Nat :=\n      match xs, ys with\n      | [a, b], _ => a+b+1\n      | _, [b, c] => b+1\n      | _, _      => 1\n    \n    example (xs ys : List Nat) (h : g xs ys = 0) : False := by\n      simp [g] at h; split at h <;> simp_arith at h\n    \n\n## Extensible Tactics\n\nIn the following example, we define the notation `triv` using the command\n`syntax`. Then, we use the command `macro_rules` to specify what should be\ndone when `triv` is used. You can provide different expansions, and the tactic\ninterpreter will try all of them until one succeeds:\n\n    \n    \n    -- Define a new tactic notation\n    syntax "triv" : tactic\n    \n    macro_rules\n      | `(tactic| triv) => `(tactic| assumption)\n    \n    example (h : p) : p := by\n      triv\n    \n    -- You cannot prove the following theorem using `triv`\n    -- example (x : α) : x = x := by\n    --  triv\n    \n    -- Let\'s extend `triv`. The tactic interpreter\n    -- tries all possible macro extensions for `triv` until one succeeds\n    macro_rules\n      | `(tactic| triv) => `(tactic| rfl)\n    \n    example (x : α) : x = x := by\n      triv\n    \n    example (x : α) (h : p) : x = x ∧ p := by\n      apply And.intro <;> triv\n    \n    -- We now add a (recursive) extension\n    macro_rules | `(tactic| triv) => `(tactic| apply And.intro <;> triv)\n    \n    example (x : α) (h : p) : x = x ∧ p := by\n      triv\n    \n\n## Exercises\n\n  1. Go back to the exercises in [Chapter Propositions and Proofs](./propositions_and_proofs.html) and [Chapter Quantifiers and Equality](./quantifiers_and_equality.html) and redo as many as you can now with tactic proofs, using also `rw` and `simp` as appropriate.\n\n  2. Use tactic combinators to obtain a one line proof of the following:\n\n    \n    \n    example (p q r : Prop) (hp : p)\n            : (p ∨ q ∨ r) ∧ (q ∨ p ∨ r) ∧ (q ∨ r ∨ p) := by\n      admit\n    \n\n[ __](quantifiers_and_equality.html "Previous chapter") [\n__](interacting_with_lean.html "Next chapter")\n\n[ __](quantifiers_and_equality.html "Previous chapter") [\n__](interacting_with_lean.html "Next chapter")', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:33,872 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:33,872 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:33,872 - DEBUG - send_request_headers.complete
2025-06-01 01:54:33,872 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:33,873 - DEBUG - send_request_body.complete
2025-06-01 01:54:33,873 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:34,681 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'195'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-b5646b449-j9wx6'), (b'x-envoy-upstream-service-time', b'226'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'994240'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'345ms'), (b'x-request-id', b'req_d3274757fdbe58218ddf03b992a88fc2'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1571bf573bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:34,682 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:34,682 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:34,682 - DEBUG - receive_response_body.complete
2025-06-01 01:54:34,682 - DEBUG - response_closed.started
2025-06-01 01:54:34,682 - DEBUG - response_closed.complete
2025-06-01 01:54:34,682 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:34 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '195', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-b5646b449-j9wx6', 'x-envoy-upstream-service-time': '226', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '994240', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '345ms', 'x-request-id': 'req_d3274757fdbe58218ddf03b992a88fc2', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1571bf573bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:34,682 - DEBUG - request_id: req_d3274757fdbe58218ddf03b992a88fc2
2025-06-01 01:54:34,683 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': 'One of the most common methods in aMachine learning is a branch of artificial intelligence that focuses on developing algorithms capable of learning from and making decisions based on data. These algorithms identify patterns within data, enabling systems to improve their performance over time without explicit programming. Applications of machine learning span various domains, including image recognition, natural language processing, and predictive analytics, making it a cornerstone of modern technological advancements.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:34,684 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:34,684 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:34,684 - DEBUG - send_request_headers.complete
2025-06-01 01:54:34,684 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:34,684 - DEBUG - send_request_body.complete
2025-06-01 01:54:34,684 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:35,033 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'54'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5c589d798-5ds54'), (b'x-envoy-upstream-service-time', b'57'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999869'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_3ea3fc52a945f7ffb3f60a12b7730e79'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1576c9f93bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:35,034 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:35,034 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:35,034 - DEBUG - receive_response_body.complete
2025-06-01 01:54:35,034 - DEBUG - response_closed.started
2025-06-01 01:54:35,034 - DEBUG - response_closed.complete
2025-06-01 01:54:35,034 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '54', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-5c589d798-5ds54', 'x-envoy-upstream-service-time': '57', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999869', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '7ms', 'x-request-id': 'req_3ea3fc52a945f7ffb3f60a12b7730e79', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1576c9f93bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:35,035 - DEBUG - request_id: req_3ea3fc52a945f7ffb3f60a12b7730e79
2025-06-01 01:54:35,035 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '\u200b\n\nDeep learning, a subset of machine learning, utilizes neural networks with multiple layers to model complex patterns in data. By processing information through these interconnected layers, deep learning systems can perform tasks such as image classification, speech recognition, and language translation with remarkable accuracy. This approach has significantly advanced fields like computer vision and autonomous systems, where understanding intricate data representations is crucial.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:35,036 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:35,036 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:35,036 - DEBUG - send_request_headers.complete
2025-06-01 01:54:35,036 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:35,036 - DEBUG - send_request_body.complete
2025-06-01 01:54:35,036 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:35,536 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'50'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-678485f6b9-h26jl'), (b'x-envoy-upstream-service-time', b'52'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999877'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_bccfb703ebe603f9dab63aa9c2436443'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1578facf3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:35,536 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:35,537 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:35,537 - DEBUG - receive_response_body.complete
2025-06-01 01:54:35,537 - DEBUG - response_closed.started
2025-06-01 01:54:35,537 - DEBUG - response_closed.complete
2025-06-01 01:54:35,537 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '50', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-678485f6b9-h26jl', 'x-envoy-upstream-service-time': '52', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999877', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '7ms', 'x-request-id': 'req_bccfb703ebe603f9dab63aa9c2436443', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1578facf3bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:35,537 - DEBUG - request_id: req_bccfb703ebe603f9dab63aa9c2436443
2025-06-01 01:54:35,538 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '\u200b\n\nControl systems are integral to engineering, ensuring that machines and processes operate within desired parameters. They monitor and adjust system behavior to maintain stability, performance, and safety. In the context of autonomous vehicles, control systems process sensor data to make real-time decisions, such as steering adjustments and speed regulation, ensuring safe navigation through dynamic environments.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:35,538 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:35,538 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:35,539 - DEBUG - send_request_headers.complete
2025-06-01 01:54:35,539 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:35,539 - DEBUG - send_request_body.complete
2025-06-01 01:54:35,539 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:35,887 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'40'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7c4bf98c9f-zw9qq'), (b'x-envoy-upstream-service-time', b'43'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999896'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_5189a8a872b8464932bff1e04b8aede0'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b157c1c143bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:35,887 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:35,888 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:35,888 - DEBUG - receive_response_body.complete
2025-06-01 01:54:35,888 - DEBUG - response_closed.started
2025-06-01 01:54:35,888 - DEBUG - response_closed.complete
2025-06-01 01:54:35,888 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '40', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-7c4bf98c9f-zw9qq', 'x-envoy-upstream-service-time': '43', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999896', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '6ms', 'x-request-id': 'req_5189a8a872b8464932bff1e04b8aede0', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b157c1c143bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:35,888 - DEBUG - request_id: req_5189a8a872b8464932bff1e04b8aede0
2025-06-01 01:54:35,889 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': "\u200b\n\nAutonomous vehicles rely heavily on machine learning and deep learning to interpret their surroundings and make informed decisions. These technologies enable vehicles to recognize objects, predict movements, and plan optimal paths without human intervention. Continuous learning from diverse driving scenarios enhances the system's ability to handle complex situations, paving the way for safer and more efficient transportation.", 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:35,889 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:35,890 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:35,890 - DEBUG - send_request_headers.complete
2025-06-01 01:54:35,890 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:35,890 - DEBUG - send_request_body.complete
2025-06-01 01:54:35,890 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:36,237 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'102'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-678485f6b9-8vtdx'), (b'x-envoy-upstream-service-time', b'127'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999892'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_82773a6793244f2c165c39d743174efa'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b157e5cfd3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:36,238 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:36,238 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:36,238 - DEBUG - receive_response_body.complete
2025-06-01 01:54:36,238 - DEBUG - response_closed.started
2025-06-01 01:54:36,238 - DEBUG - response_closed.complete
2025-06-01 01:54:36,238 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '102', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-678485f6b9-8vtdx', 'x-envoy-upstream-service-time': '127', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999892', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '6ms', 'x-request-id': 'req_82773a6793244f2c165c39d743174efa', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b157e5cfd3bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:36,238 - DEBUG - request_id: req_82773a6793244f2c165c39d743174efa
2025-06-01 01:54:36,239 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': 'The attention mechanism is a crucial innovation in deep learning, especially in natural language processing (NLP). It allows models to focus on specific parts of the input data while ignoring irrelevant information. For example, in machine translation, attention helps the model focus on the relevant words of the source sentence when generating a translation. The self-attention mechanism, popularized by models like Transformers, has made it possible to process sequences in parallel, drastically improving performance over earlier models like RNNs.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:36,239 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:36,240 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:36,240 - DEBUG - send_request_headers.complete
2025-06-01 01:54:36,240 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:36,240 - DEBUG - send_request_body.complete
2025-06-01 01:54:36,240 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:36,562 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'67'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-678485f6b9-46h27'), (b'x-envoy-upstream-service-time', b'70'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999863'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_c191c2a3ec625ae7e184afba4cebcee3'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b15808def3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:36,562 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:36,562 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:36,563 - DEBUG - receive_response_body.complete
2025-06-01 01:54:36,563 - DEBUG - response_closed.started
2025-06-01 01:54:36,563 - DEBUG - response_closed.complete
2025-06-01 01:54:36,563 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '67', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-678485f6b9-46h27', 'x-envoy-upstream-service-time': '70', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999863', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_c191c2a3ec625ae7e184afba4cebcee3', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b15808def3bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:36,563 - DEBUG - request_id: req_c191c2a3ec625ae7e184afba4cebcee3
2025-06-01 01:54:36,564 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': 'Overfitting is a common problem in machine learning where a model becomes too complex and learns not only the true patterns in the data but also the noise or random fluctuations. This results in poor generalization to unseen data. Techniques like cross-validation, regularization, and pruning are often used to prevent overfitting. Regularization methods, like L2 (Ridge) or L1 (Lasso), add a penalty term to the loss function to constrain model complexity.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:36,564 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:36,564 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:36,565 - DEBUG - send_request_headers.complete
2025-06-01 01:54:36,565 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:36,565 - DEBUG - send_request_body.complete
2025-06-01 01:54:36,565 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:36,954 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'69'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5d97677bdb-7kzxw'), (b'x-envoy-upstream-service-time', b'73'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999885'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_3d8a4294e0d3af7c602fb7a6a6d60d40'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b15828ec43bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:36,954 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:36,954 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:36,955 - DEBUG - receive_response_body.complete
2025-06-01 01:54:36,955 - DEBUG - response_closed.started
2025-06-01 01:54:36,955 - DEBUG - response_closed.complete
2025-06-01 01:54:36,955 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '69', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-5d97677bdb-7kzxw', 'x-envoy-upstream-service-time': '73', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999885', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '6ms', 'x-request-id': 'req_3d8a4294e0d3af7c602fb7a6a6d60d40', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b15828ec43bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:36,955 - DEBUG - request_id: req_3d8a4294e0d3af7c602fb7a6a6d60d40
2025-06-01 01:54:36,956 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': 'GPT-3 (Generative Pretrained Transformer 3) is one of the largest language models ever created, with 175 billion parameters. It utilizes unsupervised learning, where the model is trained on a vast amount of text data to predict the next word in a sentence. By doing so, it learns intricate patterns in language, including grammar, context, and meaning. This model can generate human-like text, complete sentences, and even answer questions, making it a powerful tool for a wide range of applications, from content creation to virtual assistants.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:36,956 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:36,956 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:36,956 - DEBUG - send_request_headers.complete
2025-06-01 01:54:36,956 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:36,957 - DEBUG - send_request_body.complete
2025-06-01 01:54:36,957 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:37,914 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'655'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-78998c59cd-78cvr'), (b'x-envoy-upstream-service-time', b'657'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999863'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_6376d327ccb49e8c0cb585a032fefd00'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1584ffd53bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:37,914 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:37,915 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:37,915 - DEBUG - receive_response_body.complete
2025-06-01 01:54:37,915 - DEBUG - response_closed.started
2025-06-01 01:54:37,915 - DEBUG - response_closed.complete
2025-06-01 01:54:37,915 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '655', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-78998c59cd-78cvr', 'x-envoy-upstream-service-time': '657', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999863', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_6376d327ccb49e8c0cb585a032fefd00', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1584ffd53bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:37,915 - DEBUG - request_id: req_6376d327ccb49e8c0cb585a032fefd00
2025-06-01 01:54:37,916 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': 'Super long chunk on purpose. This paragraph during chunking will be evenly split based on the token length. Lorem ipsum dolor sit amet. Quo vitae veritatis qui sequi vitae qui incidunt rerum non enim voluptas ea soluta consequuntur. Aut iusto expedita sed veniam sunt et omnis illum et quaerat quidem ad repellendus dolores? </p><p>Ea reiciendis voluptatem qui dolore repellat qui excepturi repellat sed accusamus laboriosam. Aut quod laborum aut quia aspernatur in velit dolorum vel rerum consequatur et dicta impedit ut natus quibusdam 33 omnis incidunt? </p><p>Qui rerum internos vel dolor beatae sed quos eveniet ut delectus nulla sit voluptatem necessitatibus est molestiae omnis aut necessitatibus impedit? Ut vitae minima aut voluptatum animi eum sunt sapiente qui consequuntur voluptatibus. Sed perspiciatis nemo ut unde omnis ad debitis itaque eos quia omnis est aliquid aliquid et repudiandae mollitia. </p><p>Quo omnis aliquam ut incidunt maiores a saepe nisi 33 nemo incidunt ut sint corporis aut officiis fugit. Et excepturi laborum hic repellendus enim et consequuntur quia quo esse sint est velit dolores est nemo molestiae. </p><p>Eum iusto officiis eum similique internos qui facere dolorem qui beatae rerum a architecto exercitationem. Sed quia unde et cupiditate ullam vel quis culpa aut cupiditate voluptatem est explicabo veritatis sed autem voluptatem.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:37,916 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:37,916 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:37,917 - DEBUG - send_request_headers.complete
2025-06-01 01:54:37,917 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:37,917 - DEBUG - send_request_body.complete
2025-06-01 01:54:37,917 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:38,268 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'56'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-78998c59cd-dhdz8'), (b'x-envoy-upstream-service-time', b'59'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999656'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'20ms'), (b'x-request-id', b'req_9fc42d5a538e3c144eb40e565c60580c'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b158afaa33bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:38,268 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:38,268 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:38,269 - DEBUG - receive_response_body.complete
2025-06-01 01:54:38,269 - DEBUG - response_closed.started
2025-06-01 01:54:38,269 - DEBUG - response_closed.complete
2025-06-01 01:54:38,269 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '56', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-78998c59cd-dhdz8', 'x-envoy-upstream-service-time': '59', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999656', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '20ms', 'x-request-id': 'req_9fc42d5a538e3c144eb40e565c60580c', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b158afaa33bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:38,269 - DEBUG - request_id: req_9fc42d5a538e3c144eb40e565c60580c
2025-06-01 01:54:38,269 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:38,270 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:38,270 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:38,270 - DEBUG - send_request_headers.complete
2025-06-01 01:54:38,271 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:38,271 - DEBUG - send_request_body.complete
2025-06-01 01:54:38,271 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:38,833 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'67'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-dc9d5f6f7-tp2fk'), (b'x-envoy-upstream-service-time', b'70'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'997690'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'138ms'), (b'x-request-id', b'req_13b311b704db02d2ee1f728203c50f23'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b158d3bbf3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:38,833 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:38,833 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:38,833 - DEBUG - receive_response_body.complete
2025-06-01 01:54:38,833 - DEBUG - response_closed.started
2025-06-01 01:54:38,834 - DEBUG - response_closed.complete
2025-06-01 01:54:38,834 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '67', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-dc9d5f6f7-tp2fk', 'x-envoy-upstream-service-time': '70', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '997690', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '138ms', 'x-request-id': 'req_13b311b704db02d2ee1f728203c50f23', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b158d3bbf3bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:38,834 - DEBUG - request_id: req_13b311b704db02d2ee1f728203c50f23
2025-06-01 01:54:38,834 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Quantifiers and Equality\n\nThe last chapter introduced you to methods that construct proofs of statements\ninvolving the propositional connectives. In this chapter, we extend the\nrepertoire of logical constructions to include the universal and existential\nquantifiers, and the equality relation.\n\n## The Universal Quantifier\n\nNotice that if `α` is any type, we can represent a unary predicate `p` on `α`\nas an object of type `α → Prop`. In that case, given `x : α`, `p x` denotes\nthe assertion that `p` holds of `x`. Similarly, an object `r : α → α → Prop`\ndenotes a binary relation on `α`: given `x y : α`, `r x y` denotes the\nassertion that `x` is related to `y`.\n\nThe universal quantifier, `∀ x : α, p x` is supposed to denote the assertion\nthat "for every `x : α`, `p x`" holds. As with the propositional connectives,\nin systems of natural deduction, "forall" is governed by an introduction and\nelimination rule. Informally, the introduction rule states:\n\n> Given a proof of `p x`, in a context where `x : α` is arbitrary, we obtain a\n> proof `∀ x : α, p x`.\n\nThe elimination rule states:\n\n> Given a proof `∀ x : α, p x` and any term `t : α`, we obtain a proof of `p\n> t`.\n\nAs was the case for implication, the propositions-as-types interpretation now\ncomes into play. Remember the introduction and elimination rules for dependent\narrow types:\n\n> Given a term `t` of type `β x`, in a context where `x : α` is arbitrary, we\n> have `(fun x : α => t) : (x : α) → β x`.\n\nThe elimination rule states:\n\n> Given a term `s : (x : α) → β x` and any term `t : α`, we have `s t : β t`.\n\nIn the case where `p x` has type `Prop`, if we replace `(x : α) → β x` with `∀\nx : α, p x`, we can read these as the correct rules for building proofs\ninvolving the universal quantifier.\n\nThe Calculus of Constructions therefore identifies dependent arrow types with\nforall-expressions in this way. If `p` is any expression, `∀ x : α, p` is\nnothing more than alternative notation for `(x : α) → p`, with the idea that\nthe former is more natural than the latter in cases where `p` is a\nproposition. Typically, the expression `p` will depend on `x : α`. Recall\nthat, in the case of ordinary function spaces, we could interpret `α → β` as\nthe special case of `(x : α) → β` in which `β` does not depend on `x`.\nSimilarly, we can think of an implication `p → q` between propositions as the\nspecial case of `∀ x : p, q` in which the expression `q` does not depend on\n`x`.\n\nHere is an example of how the propositions-as-types correspondence gets put\ninto practice.\n\n    \n    \n    example (α : Type) (p q : α → Prop) : (∀ x : α, p x ∧ q x) → ∀ y : α, p y :=\n      fun h : ∀ x : α, p x ∧ q x =>\n      fun y : α =>\n      show p y from (h y).left\n    \n\nAs a notational convention, we give the universal quantifier the widest scope\npossible, so parentheses are needed to limit the quantifier over `x` to the\nhypothesis in the example above. The canonical way to prove `∀ y : α, p y` is\nto take an arbitrary `y`, and prove `p y`. This is the introduction rule. Now,\ngiven that `h` has type `∀ x : α, p x ∧ q x`, the expression `h y` has type `p\ny ∧ q y`. This is the elimination rule. Taking the left conjunct gives the\ndesired conclusion, `p y`.\n\nRemember that expressions which differ up to renaming of bound variables are\nconsidered to be equivalent. So, for example, we could have used the same\nvariable, `x`, in both the hypothesis and conclusion, and instantiated it by a\ndifferent variable, `z`, in the proof:\n\n    \n    \n    example (α : Type) (p q : α → Prop) : (∀ x : α, p x ∧ q x) → ∀ x : α, p x :=\n      fun h : ∀ x : α, p x ∧ q x =>\n      fun z : α =>\n      show p z from And.left (h z)\n    \n\nAs another example, here is how we can express the fact that a relation, `r`,\nis transitive:\n\n    \n    \n    variable (α : Type) (r : α → α → Prop)\n    variable (trans_r : ∀ x y z, r x y → r y z → r x z)\n    \n    variable (a b c : α)\n    variable (hab : r a b) (hbc : r b c)\n    \n    #check trans_r    -- ∀ (x y z : α), r x y → r y z → r x z\n    #check trans_r a b c -- r a b → r b c → r a c\n    #check trans_r a b c hab -- r b c → r a c\n    #check trans_r a b c hab hbc -- r a c\n    \n\nThink about what is going on here. When we instantiate `trans_r` at the values\n`a b c`, we end up with a proof of `r a b → r b c → r a c`. Applying this to\nthe "hypothesis" `hab : r a b`, we get a proof of the implication `r b c → r a\nc`. Finally, applying it to the hypothesis `hbc` yields a proof of the\nconclusion `r a c`.\n\nIn situations like this, it can be tedious to supply the arguments `a b c`,\nwhen they can be inferred from `hab hbc`. For that reason, it is common to\nmake these arguments implicit:\n\n    \n    \n    variable (α : Type) (r : α → α → Prop)\n    variable (trans_r : ∀ {x y z}, r x y → r y z → r x z)\n    \n    variable (a b c : α)\n    variable (hab : r a b) (hbc : r b c)\n    \n    #check trans_r\n    #check trans_r hab\n    #check trans_r hab hbc\n    \n\nThe advantage is that we can simply write `trans_r hab hbc` as a proof of `r a\nc`. A disadvantage is that Lean does not have enough information to infer the\ntypes of the arguments in the expressions `trans_r` and `trans_r hab`. The\noutput of the first `#check` command is `r ?m.1 ?m.2 → r ?m.2 ?m.3 → r ?m.1\n?m.3`, indicating that the implicit arguments are unspecified in this case.\n\nHere is an example of how we can carry out elementary reasoning with an\nequivalence relation:\n\n    \n    \n    variable (α : Type) (r : α → α → Prop)\n    \n    variable (refl_r : ∀ x, r x x)\n    variable (symm_r : ∀ {x y}, r x y → r y x)\n    variable (trans_r : ∀ {x y z}, r x y → r y z → r x z)\n    \n    example (a b c d : α) (hab : r a b) (hcb : r c b) (hcd : r c d) : r a d :=\n      trans_r (trans_r hab (symm_r hcb)) hcd\n    \n\nTo get used to using universal quantifiers, you should try some of the\nexercises at the end of this section.\n\nIt is the typing rule for dependent arrow types, and the universal quantifier\nin particular, that distinguishes `Prop` from other types. Suppose we have `α\n: Sort i` and `β : Sort j`, where the expression `β` may depend on a variable\n`x : α`. Then `(x : α) → β` is an element of `Sort (imax i j)`, where `imax i\nj` is the maximum of `i` and `j` if `j` is not 0, and 0 otherwise.\n\nThe idea is as follows. If `j` is not `0`, then `(x : α) → β` is an element of\n`Sort (max i j)`. In other words, the type of dependent functions from `α` to\n`β` "lives" in the universe whose index is the maximum of `i` and `j`.\nSuppose, however, that `β` is of `Sort 0`, that is, an element of `Prop`. In\nthat case, `(x : α) → β` is an element of `Sort 0` as well, no matter which\ntype universe `α` lives in. In other words, if `β` is a proposition depending\non `α`, then `∀ x : α, β` is again a proposition. This reflects the\ninterpretation of `Prop` as the type of propositions rather than data, and it\nis what makes `Prop` _impredicative_.\n\nThe term "predicative" stems from foundational developments around the turn of\nthe twentieth century, when logicians such as Poincaré and Russell blamed set-\ntheoretic paradoxes on the "vicious circles" that arise when we define a\nproperty by quantifying over a collection that includes the very property\nbeing defined. Notice that if `α` is any type, we can form the type `α → Prop`\nof all predicates on `α` (the "power type of `α`"). The impredicativity of\n`Prop` means that we can form propositions that quantify over `α → Prop`. In\nparticular, we can define predicates on `α` by quantifying over all predicates\non `α`, which is exactly the type of circularity that was once considered\nproblematic.\n\n## Equality\n\nLet us now turn to one of the most fundamental relations defined in Lean\'s\nlibrary, namely, the equality relation. In [Chapter Inductive\nTypes](inductive_types.html), we will explain _how_ equality is defined from\nthe primitives of Lean\'s logical framework. In the meanwhile, here we explain\nhow to use it.\n\nOf course, a fundamental property of equality is that it is an equivalence\nrelation:\n\n    \n    \n    #check Eq.refl    -- Eq.refl.{u_1} {α : Sort u_1} (a : α) : a = a\n    #check Eq.symm    -- Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a\n    #check Eq.trans   -- Eq.trans.{u} {α : Sort u} {a b c : α} (h₁ : a = b) (h₂ : b = c) : a = c\n    \n\nWe can make the output easier to read by telling Lean not to insert the\nimplicit arguments (which are displayed here as metavariables).\n\n    \n    \n    universe u\n    \n    #check @Eq.refl.{u}   -- @Eq.refl : ∀ {α : Sort u} (a : α), a = a\n    #check @Eq.symm.{u}   -- @Eq.symm : ∀ {α : Sort u} {a b : α}, a = b → b = a\n    #check @Eq.trans.{u}  -- @Eq.trans : ∀ {α : Sort u} {a b c : α}, a = b → b = c → a = c\n    \n\nThe inscription `.{u}` tells Lean to instantiate the constants at the universe\n`u`.\n\nThus, for example, we can specialize the example from the previous section to\nthe equality relation:\n\n    \n    \n    variable (α : Type) (a b c d : α)\n    variable (hab : a = b) (hcb : c = b) (hcd : c = d)\n    \n    example : a = d :=\n      Eq.trans (Eq.trans hab (Eq.symm hcb)) hcd\n    \n\nWe can also use the projection notation:\n\n    \n    \n    variable (α : Type) (a b c d : α)\n    variable (hab : a = b) (hcb : c = b) (hcd : c = d)\n    example : a = d := (hab.trans hcb.symm).trans hcd\n    \n\nReflexivity is more powerful than it looks. Recall that terms in the Calculus\nof Constructions have a computational interpretation, and that the logical\nframework treats terms with a common reduct as the same. As a result, some\nnontrivial identities can be proved by reflexivity:\n\n    \n    \n    variable (α β : Type)\n    \n    example (f : α → β) (a : α) : (fun x => f x) a = f a := Eq.refl _\n    example (a : α) (b : β) : (a, b).1 = a := Eq.refl _\n    example : 2 + 3 = 5 := Eq.refl _\n    \n\nThis feature of the framework is so important that the library defines a\nnotation `rfl` for `Eq.refl _`:\n\n    \n    \n    variable (α β : Type)\n    example (f : α → β) (a : α) : (fun x => f x) a = f a := rfl\n    example (a : α) (b : β) : (a, b).1 = a := rfl\n    example : 2 + 3 = 5 := rfl\n    \n\nEquality is much more than an equivalence relation, however. It has the\nimportant property that every assertion respects the equivalence, in the sense\nthat we can substitute equal expressions without changing the truth value.\nThat is, given `h1 : a = b` and `h2 : p a`, we can construct a proof for `p b`\nusing substitution: `Eq.subst h1 h2`.\n\n    \n    \n    example (α : Type) (a b : α) (p : α → Prop)\n            (h1 : a = b) (h2 : p a) : p b :=\n      Eq.subst h1 h2\n    \n    example (α : Type) (a b : α) (p : α → Prop)\n        (h1 : a = b) (h2 : p a) : p b :=\n      h1 ▸ h2\n    \n\nThe triangle in the second presentation is a macro built on top of `Eq.subst`\nand `Eq.symm`, and you can enter it by typing `\\t`.\n\nThe rule `Eq.subst` is used to define the following auxiliary rules, which\ncarry out more explicit substitutions. They are designed to deal with\napplicative terms, that is, terms of form `s t`. Specifically, `congrArg` can\nbe used to replace the argument, `congrFun` can be used to replace the term\nthat is being applied, and `congr` can be used to replace both at once.\n\n    \n    \n    variable (α : Type)\n    variable (a b : α)\n    variable (f g : α → Nat)\n    variable (h₁ : a = b)\n    variable (h₂ : f = g)\n    \n    example : f a = f b := congrArg f h₁\n    example : f a = g a := congrFun h₂ a\n    example : f a = g b := congr h₂ h₁\n    \n\nLean\'s library contains a large number of common identities, such as these:\n\n    \n    \n    variable (a b c : Nat)\n    \n    example : a + 0 = a := Nat.add_zero a\n    example : 0 + a = a := Nat.zero_add a\n    example : a * 1 = a := Nat.mul_one a\n    example : 1 * a = a := Nat.one_mul a\n    example : a + b = b + a := Nat.add_comm a b\n    example : a + b + c = a + (b + c) := Nat.add_assoc a b c\n    example : a * b = b * a := Nat.mul_comm a b\n    example : a * b * c = a * (b * c) := Nat.mul_assoc a b c\n    example : a * (b + c) = a * b + a * c := Nat.mul_add a b c\n    example : a * (b + c) = a * b + a * c := Nat.left_distrib a b c\n    example : (a + b) * c = a * c + b * c := Nat.add_mul a b c\n    example : (a + b) * c = a * c + b * c := Nat.right_distrib a b c\n    \n\nNote that `Nat.mul_add` and `Nat.add_mul` are alternative names for\n`Nat.left_distrib` and `Nat.right_distrib`, respectively. The properties above\nare stated for the natural numbers (type `Nat`).\n\nHere is an example of a calculation in the natural numbers that uses\nsubstitution combined with associativity and distributivity.\n\n    \n    \n    example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n      have h1 : (x + y) * (x + y) = (x + y) * x + (x + y) * y :=\n        Nat.mul_add (x + y) x y\n      have h2 : (x + y) * (x + y) = x * x + y * x + (x * y + y * y) :=\n        (Nat.add_mul x y x) ▸ (Nat.add_mul x y y) ▸ h1\n      h2.trans (Nat.add_assoc (x * x + y * x) (x * y) (y * y)).symm\n    \n\nNotice that the second implicit parameter to `Eq.subst`, which provides the\ncontext in which the substitution is to occur, has type `α → Prop`. Inferring\nthis predicate therefore requires an instance of _higher-order unification_.\nIn full generality, the problem of determining whether a higher-order unifier\nexists is undecidable, and Lean can at best provide imperfect and approximate\nsolutions to the problem. As a result, `Eq.subst` doesn\'t always do what you\nwant it to. The macro `h ▸ e` uses more effective heuristics for computing\nthis implicit parameter, and often succeeds in situations where applying\n`Eq.subst` fails.\n\nBecause equational reasoning is so common and important, Lean provides a\nnumber of mechanisms to carry it out more effectively. The next section offers\nsyntax that allow you to write calculational proofs in a more natural and\nperspicuous way. But, more importantly, equational reasoning is supported by a\nterm rewriter, a simplifier, and other kinds of automation. The term rewriter\nand simplifier are described briefly in the next section, and then in greater\ndetail in the next chapter.\n\n## Calculational Proofs\n\nA calculational proof is just a chain of intermediate results that are meant\nto be composed by basic principles such as the transitivity of equality. In\nLean, a calculational proof starts with the keyword `calc`, and has the\nfollowing syntax:\n\n    \n    \n    calc\n      <expr>_0  \'op_1\'  <expr>_1  \':=\'  <proof>_1\n      \'_\'       \'op_2\'  <expr>_2  \':=\'  <proof>_2\n      ...\n      \'_\'       \'op_n\'  <expr>_n  \':=\'  <proof>_n\n    \n\nNote that the `calc` relations all have the same indentation. Each `<proof>_i`\nis a proof for `<expr>_{i-1} op_i <expr>_i`.\n\nWe can also use `_` in the first relation (right after `<expr>_0`) which is\nuseful to align the sequence of relation/proof pairs:\n\n    \n    \n    calc <expr>_0 \n        \'_\' \'op_1\' <expr>_1 \':=\' <proof>_1\n        \'_\' \'op_2\' <expr>_2 \':=\' <proof>_2\n        ...\n        \'_\' \'op_n\' <expr>_n \':=\' <proof>_n\n    \n\nHere is an example:\n\n    \n    \n    variable (a b c d e : Nat)\n    variable (h1 : a = b)\n    variable (h2 : b = c + 1)\n    variable (h3 : c = d)\n    variable (h4 : e = 1 + d)\n    \n    theorem T : a = e :=\n      calc\n        a = b      := h1\n        _ = c + 1  := h2\n        _ = d + 1  := congrArg Nat.succ h3\n        _ = 1 + d  := Nat.add_comm d 1\n        _ = e      := Eq.symm h4\n    \n\nThis style of writing proofs is most effective when it is used in conjunction\nwith the `simp` and `rewrite` tactics, which are discussed in greater detail\nin the next chapter. For example, using the abbreviation `rw` for rewrite, the\nproof above could be written as follows:\n\n    \n    \n    variable (a b c d e : Nat)\n    variable (h1 : a = b)\n    variable (h2 : b = c + 1)\n    variable (h3 : c = d)\n    variable (h4 : e = 1 + d)\n    theorem T : a = e :=\n      calc\n        a = b      := by rw [h1]\n        _ = c + 1  := by rw [h2]\n        _ = d + 1  := by rw [h3]\n        _ = 1 + d  := by rw [Nat.add_comm]\n        _ = e      := by rw [h4]\n    \n\nEssentially, the `rw` tactic uses a given equality (which can be a hypothesis,\na theorem name, or a complex term) to "rewrite" the goal. If doing so reduces\nthe goal to an identity `t = t`, the tactic applies reflexivity to prove it.\n\nRewrites can be applied sequentially, so that the proof above can be shortened\nto this:\n\n    \n    \n    variable (a b c d e : Nat)\n    variable (h1 : a = b)\n    variable (h2 : b = c + 1)\n    variable (h3 : c = d)\n    variable (h4 : e = 1 + d)\n    theorem T : a = e :=\n      calc\n        a = d + 1  := by rw [h1, h2, h3]\n        _ = 1 + d  := by rw [Nat.add_comm]\n        _ = e      := by rw [h4]\n    \n\nOr even this:\n\n    \n    \n    variable (a b c d e : Nat)\n    variable (h1 : a = b)\n    variable (h2 : b = c + 1)\n    variable (h3 : c = d)\n    variable (h4 : e = 1 + d)\n    theorem T : a = e :=\n      by rw [h1, h2, h3, Nat.add_comm, h4]\n    \n\nThe `simp` tactic, instead, rewrites the goal by applying the given identities\nrepeatedly, in any order, anywhere they are applicable in a term. It also uses\nother rules that have been previously declared to the system, and applies\ncommutativity wisely to avoid looping. As a result, we can also prove the\ntheorem as follows:\n\n    \n    \n    variable (a b c d e : Nat)\n    variable (h1 : a = b)\n    variable (h2 : b = c + 1)\n    variable (h3 : c = d)\n    variable (h4 : e = 1 + d)\n    theorem T : a = e :=\n      by simp [h1, h2, h3, Nat.add_comm, h4]\n    \n\nWe will discuss variations of `rw` and `simp` in the next chapter.\n\nThe `calc` command can be configured for any relation that supports some form\nof transitivity. It can even combine different relations.\n\n    \n    \n    example (a b c d : Nat) (h1 : a = b) (h2 : b ≤ c) (h3 : c + 1 < d) : a < d :=\n      calc\n        a = b     := h1\n        _ < b + 1 := Nat.lt_succ_self b\n        _ ≤ c + 1 := Nat.succ_le_succ h2\n        _ < d     := h3\n    \n\nYou can "teach" `calc` new transitivity theorems by adding new instances of\nthe `Trans` type class. Type classes are introduced later, but the following\nsmall example demonstrates how to extend the `calc` notation using new `Trans`\ninstances.\n\n    \n    \n    def divides (x y : Nat) : Prop :=\n      ∃ k, k*x = y\n    \n    def divides_trans (h₁ : divides x y) (h₂ : divides y z) : divides x z :=\n      let ⟨k₁, d₁⟩ := h₁\n      let ⟨k₂, d₂⟩ := h₂\n      ⟨k₁ * k₂, by rw [Nat.mul_comm k₁ k₂, Nat.mul_assoc, d₁, d₂]⟩\n    \n    def divides_mul (x : Nat) (k : Nat) : divides x (k*x) :=\n      ⟨k, rfl⟩\n    \n    instance : Trans divides divides divides where\n      trans := divides_trans\n    \n    example (h₁ : divides x y) (h₂ : y = z) : divides x (2*z) :=\n      calc\n        divides x y     := h₁\n        _ = z           := h₂\n        divides _ (2*z) := divides_mul ..\n    \n    infix:50 " ∣ " => divides\n    \n    example (h₁ : divides x y) (h₂ : y = z) : divides x (2*z) :=\n      calc\n        x ∣ y   := h₁\n        _ = z   := h₂\n        _ ∣ 2*z := divides_mul ..\n    \n\nThe example above also makes it clear that you can use `calc` even if you do\nnot have an infix notation for your relation. Finally we remark that the\nvertical bar `∣` in the example above is the unicode one. We use unicode to\nmake sure we do not overload the ASCII `|` used in the `match .. with`\nexpression.\n\nWith `calc`, we can write the proof in the last section in a more natural and\nperspicuous way.\n\n    \n    \n    example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n      calc\n        (x + y) * (x + y) = (x + y) * x + (x + y) * y  := by rw [Nat.mul_add]\n        _ = x * x + y * x + (x + y) * y                := by rw [Nat.add_mul]\n        _ = x * x + y * x + (x * y + y * y)            := by rw [Nat.add_mul]\n        _ = x * x + y * x + x * y + y * y              := by rw [←Nat.add_assoc]\n    \n\nThe alternative `calc` notation is worth considering here. When the first\nexpression is taking this much space, using `_` in the first relation\nnaturally aligns all relations:\n\n    \n    \n    example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n      calc (x + y) * (x + y)\n        _ = (x + y) * x + (x + y) * y       := by rw [Nat.mul_add]\n        _ = x * x + y * x + (x + y) * y     := by rw [Nat.add_mul]\n        _ = x * x + y * x + (x * y + y * y) := by rw [Nat.add_mul]\n        _ = x * x + y * x + x * y + y * y   := by rw [←Nat.add_assoc]\n    \n\nHere the left arrow before `Nat.add_assoc` tells rewrite to use the identity\nin the opposite direction. (You can enter it with `\\l` or use the ascii\nequivalent, `<-`.) If brevity is what we are after, both `rw` and `simp` can\ndo the job on their own:\n\n    \n    \n    example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n      by rw [Nat.mul_add, Nat.add_mul, Nat.add_mul, ←Nat.add_assoc]\n    \n    example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n      by simp [Nat.mul_add, Nat.add_mul, Nat.add_assoc]\n    \n\n## The Existential Quantifier\n\nFinally, consider the existential quantifier, which can be written as either\n`exists x : α, p x` or `∃ x : α, p x`. Both versions are actually notationally\nconvenient abbreviations for a more long-winded expression, `Exists (fun x : α\n=> p x)`, defined in Lean\'s library.\n\nAs you should by now expect, the library includes both an introduction rule\nand an elimination rule. The introduction rule is straightforward: to prove `∃\nx : α, p x`, it suffices to provide a suitable term `t` and a proof of `p t`.\nHere are some examples:\n\n    \n    \n    example : ∃ x : Nat, x > 0 :=\n      have h : 1 > 0 := Nat.zero_lt_succ 0\n      Exists.intro 1 h\n    \n    example (x : Nat) (h : x > 0) : ∃ y, y < x :=\n      Exists.intro 0 h\n    \n    example (x y z : Nat) (hxy : x < y) (hyz : y < z) : ∃ w, x < w ∧ w < z :=\n      Exists.intro y (And.intro hxy hyz)\n    \n    #check @Exists.intro -- ∀ {α : Sort u_1} {p : α → Prop} (w : α), p w → Exists p\n    \n\nWe can use the anonymous constructor notation `⟨t, h⟩` for `Exists.intro t h`,\nwhen the type is clear from the context.\n\n    \n    \n    example : ∃ x : Nat, x > 0 :=\n      have h : 1 > 0 := Nat.zero_lt_succ 0\n      ⟨1, h⟩\n    \n    example (x : Nat) (h : x > 0) : ∃ y, y < x :=\n      ⟨0, h⟩\n    \n    example (x y z : Nat) (hxy : x < y) (hyz : y < z) : ∃ w, x < w ∧ w < z :=\n      ⟨y, hxy, hyz⟩\n    \n\nNote that `Exists.intro` has implicit arguments: Lean has to infer the\npredicate `p : α → Prop` in the conclusion `∃ x, p x`. This is not a trivial\naffair. For example, if we have `hg : g 0 0 = 0` and write `Exists.intro 0\nhg`, there are many possible values for the predicate `p`, corresponding to\nthe theorems `∃ x, g x x = x`, `∃ x, g x x = 0`, `∃ x, g x 0 = x`, etc. Lean\nuses the context to infer which one is appropriate. This is illustrated in the\nfollowing example, in which we set the option `pp.explicit` to true to ask\nLean\'s pretty-printer to show the implicit arguments.\n\n    \n    \n    variable (g : Nat → Nat → Nat)\n    variable (hg : g 0 0 = 0)\n    \n    theorem gex1 : ∃ x, g x x = x := ⟨0, hg⟩\n    theorem gex2 : ∃ x, g x 0 = x := ⟨0, hg⟩\n    theorem gex3 : ∃ x, g 0 0 = x := ⟨0, hg⟩\n    theorem gex4 : ∃ x, g x x = 0 := ⟨0, hg⟩\n    \n    set_option pp.explicit true  -- display implicit arguments\n    #print gex1\n    #print gex2\n    #print gex3\n    #print gex4\n    \n\nWe can view `Exists.intro` as an information-hiding operation, since it hides\nthe witness to the body of the assertion. The existential elimination rule,\n`Exists.elim`, performs the opposite operation. It allows us to prove a\nproposition `q` from `∃ x : α, p x`, by showing that `q` follows from `p w`\nfor an arbitrary value `w`. Roughly speaking, since we know there is an `x`\nsatisfying `p x`, we can give it a name, say, `w`. If `q` does not mention\n`w`, then showing that `q` follows from `p w` is tantamount to showing that\n`q` follows from the existence of any such `x`. Here is an example:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      Exists.elim h\n        (fun w =>\n         fun hw : p w ∧ q w =>\n         show ∃ x, q x ∧ p x from ⟨w, hw.right, hw.left⟩)\n    \n\nIt may be helpful to compare the exists-elimination rule to the or-elimination\nrule: the assertion `∃ x : α, p x` can be thought of as a big disjunction of\nthe propositions `p a`, as `a` ranges over all the elements of `α`. Note that\nthe anonymous constructor notation `⟨w, hw.right, hw.left⟩` abbreviates a\nnested constructor application; we could equally well have written `⟨w,\n⟨hw.right, hw.left⟩⟩`.\n\nNotice that an existential proposition is very similar to a sigma type, as\ndescribed in dependent types section. The difference is that given `a : α` and\n`h : p a`, the term `Exists.intro a h` has type `(∃ x : α, p x) : Prop` and\n`Sigma.mk a h` has type `(Σ x : α, p x) : Type`. The similarity between `∃`\nand `Σ` is another instance of the Curry-Howard isomorphism.\n\nLean provides a more convenient way to eliminate from an existential\nquantifier with the `match` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hw⟩ => ⟨w, hw.right, hw.left⟩\n    \n\nThe `match` expression is part of Lean\'s function definition system, which\nprovides convenient and expressive ways of defining complex functions. Once\nagain, it is the Curry-Howard isomorphism that allows us to co-opt this\nmechanism for writing proofs as well. The `match` statement "destructs" the\nexistential assertion into the components `w` and `hw`, which can then be used\nin the body of the statement to prove the proposition. We can annotate the\ntypes used in the match for greater clarity:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨(w : α), (hw : p w ∧ q w)⟩ => ⟨w, hw.right, hw.left⟩\n    \n\nWe can even use the match statement to decompose the conjunction at', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:38,835 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:38,835 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:38,836 - DEBUG - send_request_headers.complete
2025-06-01 01:54:38,836 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:38,836 - DEBUG - send_request_body.complete
2025-06-01 01:54:38,836 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:39,455 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'311'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5f689c5f9d-89jl4'), (b'x-envoy-upstream-service-time', b'315'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'993165'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'410ms'), (b'x-request-id', b'req_734714e04384bb1a63b1acff57c7c9c3'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1590bd9e3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:39,455 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:39,456 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:39,456 - DEBUG - receive_response_body.complete
2025-06-01 01:54:39,456 - DEBUG - response_closed.started
2025-06-01 01:54:39,456 - DEBUG - response_closed.complete
2025-06-01 01:54:39,456 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '311', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-5f689c5f9d-89jl4', 'x-envoy-upstream-service-time': '315', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '993165', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '410ms', 'x-request-id': 'req_734714e04384bb1a63b1acff57c7c9c3', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1590bd9e3bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:39,456 - DEBUG - request_id: req_734714e04384bb1a63b1acff57c7c9c3
2025-06-01 01:54:39,457 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': ' the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:39,457 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:39,458 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:39,458 - DEBUG - send_request_headers.complete
2025-06-01 01:54:39,458 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:39,458 - DEBUG - send_request_body.complete
2025-06-01 01:54:39,458 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:39,870 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'108'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-b5646b449-86z2p'), (b'x-envoy-upstream-service-time', b'112'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'997294'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'162ms'), (b'x-request-id', b'req_69ae4aaab29d23e235e1d26e7b9c591e'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b15949f523bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:39,871 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:39,871 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:39,871 - DEBUG - receive_response_body.complete
2025-06-01 01:54:39,871 - DEBUG - response_closed.started
2025-06-01 01:54:39,871 - DEBUG - response_closed.complete
2025-06-01 01:54:39,871 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '108', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-b5646b449-86z2p', 'x-envoy-upstream-service-time': '112', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '997294', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '162ms', 'x-request-id': 'req_69ae4aaab29d23e235e1d26e7b9c591e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b15949f523bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:39,871 - DEBUG - request_id: req_69ae4aaab29d23e235e1d26e7b9c591e
2025-06-01 01:54:39,872 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab72980>, 'json_data': {'input': '1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# The Conversion Tactic Mode\n\nInside a tactic block, one can use the keyword `conv` to enter _conversion\nmode_. This mode allows to travel inside assumptions and goals, even inside\nfunction abstractions and dependent arrows, to apply rewriting or simplifying\nsteps.\n\n## Basic navigation and rewriting\n\nAs a first example, let us prove example `(a b c : Nat) : a * (b * c) = a * (c\n* b)` (examples in this file are somewhat artificial since other tactics could\nfinish them immediately). The naive first attempt is to enter tactic mode and\ntry `rw [Nat.mul_comm]`. But this transforms the goal into `b * c * a = a * (c\n* b)`, after commuting the very first multiplication appearing in the term.\nThere are several ways to fix this issue, and one way is to use a more precise\ntool: the conversion mode. The following code block shows the current target\nafter each line.\n\n    \n    \n    example (a b c : Nat) : a * (b * c) = a * (c * b) := by\n      conv =>\n        -- ⊢ a * (b * c) = a * (c * b)\n        lhs\n        -- ⊢ a * (b * c)\n        congr\n        -- 2 goals: ⊢ a, ⊢ b * c\n        rfl\n        -- ⊢ b * c\n        rw [Nat.mul_comm]\n    \n\nThe above snippet shows three navigation commands:\n\n  * `lhs` navigates to the left-hand side of a relation (equality, in this case). There is also a `rhs` to navigate to the right-hand side.\n  * `congr` creates as many targets as there are (nondependent and explicit) arguments to the current head function (here the head function is multiplication).\n  * `rfl` closes target using reflexivity.\n\nOnce arrived at the relevant target, we can use `rw` as in normal tactic mode.\n\nThe second main reason to use conversion mode is to rewrite under binders.\nSuppose we want to prove example `(fun x : Nat => 0 + x) = (fun x => x)`. The\nnaive first attempt is to enter tactic mode and try `rw [Nat.zero_add]`. But\nthis fails with a frustrating\n\n    \n    \n    error: tactic \'rewrite\' failed, did not find instance of the pattern\n           in the target expression\n      0 + ?n\n    ⊢ (fun x => 0 + x) = fun x => x\n    \n\nThe solution is:\n\n    \n    \n    example : (fun x : Nat => 0 + x) = (fun x => x) := by\n      conv =>\n        lhs\n        intro x\n        rw [Nat.zero_add]\n    \n\nwhere `intro x` is the navigation command entering inside the `fun` binder.\nNote that this example is somewhat artificial, one could also do:\n\n    \n    \n    example : (fun x : Nat => 0 + x) = (fun x => x) := by\n      funext x; rw [Nat.zero_add]\n    \n\nor just\n\n    \n    \n    example : (fun x : Nat => 0 + x) = (fun x => x) := by\n      simp\n    \n\n`conv` can also rewrite a hypothesis `h` from the local context, using `conv\nat h`.\n\n## Pattern matching\n\nNavigation using the above commands can be tedious. One can shortcut it using\npattern matching as follows:\n\n    \n    \n    example (a b c : Nat) : a * (b * c) = a * (c * b) := by\n      conv in b * c => rw [Nat.mul_comm]\n    \n\nwhich is just syntax sugar for\n\n    \n    \n    example (a b c : Nat) : a * (b * c) = a * (c * b) := by\n      conv =>\n        pattern b * c\n        rw [Nat.mul_comm]\n    \n\nOf course, wildcards are allowed:\n\n    \n    \n    example (a b c : Nat) : a * (b * c) = a * (c * b) := by\n      conv in _ * c => rw [Nat.mul_comm]\n    \n\n## Structuring conversion tactics\n\nCurly brackets and `.` can also be used in `conv` mode to structure tactics:\n\n    \n    \n    example (a b c : Nat) : (0 + a) * (b * c) = a * (c * b) := by\n      conv =>\n        lhs\n        congr\n        . rw [Nat.zero_add]\n        . rw [Nat.mul_comm]\n    \n\n## Other tactics inside conversion mode\n\n  * `arg i` enter the `i`-th nondependent explicit argument of an application.\n\n    \n    \n    example (a b c : Nat) : a * (b * c) = a * (c * b) := by\n      conv =>\n        -- ⊢ a * (b * c) = a * (c * b)\n        lhs\n        -- ⊢ a * (b * c)\n        arg 2\n        -- ⊢ b * c\n        rw [Nat.mul_comm]\n    \n\n  * `args` alternative name for `congr`.\n\n  * `simp` applies the simplifier to the current goal. It supports the same options available in regular tactic mode.\n\n    \n    \n    def f (x : Nat) :=\n      if x > 0 then x + 1 else x + 2\n    \n    example (g : Nat → Nat) (h₁ : g x = x + 1) (h₂ : x > 0) : g x = f x := by\n      conv =>\n        rhs\n        simp [f, h₂]\n      exact h₁\n    \n\n  * `enter [1, x, 2, y]` iterate `arg` and `intro` with the given arguments. It is just the macro:\n\n    \n    \n    syntax enterArg := ident <|> group("@"? num)\n    syntax "enter " "[" (colGt enterArg),+ "]": conv\n    macro_rules\n      | `(conv| enter [$i:num]) => `(conv| arg $i)\n      | `(conv| enter [@$i:num]) => `(conv| arg @$i)\n      | `(conv| enter [$id:ident]) => `(conv| ext $id)\n      | `(conv| enter [$arg:enterArg, $args,*]) => `(conv| (enter [$arg]; enter [$args,*]))\n    \n\n  * `done` fail if there are unsolved goals.\n\n  * `trace_state` display the current tactic state.\n\n  * `whnf` put term in weak head normal form.\n\n  * `tactic => <tactic sequence>` go back to regular tactic mode. This is useful for discharging goals not supported by `conv` mode, and applying custom congruence and extensionality lemmas.\n\n    \n    \n    example (g : Nat → Nat → Nat)\n            (h₁ : ∀ x, x ≠ 0 → g x x = 1)\n            (h₂ : x ≠ 0)\n            : g x x + x = 1 + x := by\n      conv =>\n        lhs\n        -- ⊢ g x x + x\n        arg 1\n        -- ⊢ g x x\n        rw [h₁]\n        -- 2 goals: ⊢ 1, ⊢ x ≠ 0\n        . skip\n        . tactic => exact h₂\n    \n\n  * `apply <term>` is syntax sugar for `tactic => apply <term>`.\n\n    \n    \n    example (g : Nat → Nat → Nat)\n            (h₁ : ∀ x, x ≠ 0 → g x x = 1)\n            (h₂ : x ≠ 0)\n            : g x x + x = 1 + x := by\n      conv =>\n        lhs\n        arg 1\n        rw [h₁]\n        . skip\n        . apply h₂\n    \n\n[ __](type_classes.html "Previous chapter") [ __](axioms_and_computation.html\n"Next chapter")\n\n[ __](type_classes.html "Previous chapter") [ __](axioms_and_computation.html\n"Next chapter")', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:39,872 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:39,873 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:39,873 - DEBUG - send_request_headers.complete
2025-06-01 01:54:39,873 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:39,873 - DEBUG - send_request_body.complete
2025-06-01 01:54:39,873 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:40,401 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'78'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-6b84dbcf9f-xgzjk'), (b'x-envoy-upstream-service-time', b'82'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'998269'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'103ms'), (b'x-request-id', b'req_e8514100eb846aebd4da2b0a81f50f51'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1597388e3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:40,401 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:40,401 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:40,402 - DEBUG - receive_response_body.complete
2025-06-01 01:54:40,402 - DEBUG - response_closed.started
2025-06-01 01:54:40,402 - DEBUG - response_closed.complete
2025-06-01 01:54:40,402 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '78', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-6b84dbcf9f-xgzjk', 'x-envoy-upstream-service-time': '82', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '998269', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '103ms', 'x-request-id': 'req_e8514100eb846aebd4da2b0a81f50f51', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1597388e3bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:40,402 - DEBUG - request_id: req_e8514100eb846aebd4da2b0a81f50f51
2025-06-01 01:54:40,406 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab73c40>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:40,406 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:40,407 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:40,407 - DEBUG - send_request_headers.complete
2025-06-01 01:54:40,407 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:40,407 - DEBUG - send_request_body.complete
2025-06-01 01:54:40,407 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:40,761 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'51'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5f689c5f9d-btk9q'), (b'x-envoy-upstream-service-time', b'56'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999922'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'4ms'), (b'x-request-id', b'req_f638e68a0ce2c757a6d6c0fcbfd2bb29'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b159a8a433bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:40,761 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:40,761 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:40,762 - DEBUG - receive_response_body.complete
2025-06-01 01:54:40,762 - DEBUG - response_closed.started
2025-06-01 01:54:40,762 - DEBUG - response_closed.complete
2025-06-01 01:54:40,762 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '51', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-5f689c5f9d-btk9q', 'x-envoy-upstream-service-time': '56', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999922', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '4ms', 'x-request-id': 'req_f638e68a0ce2c757a6d6c0fcbfd2bb29', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b159a8a433bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:40,762 - DEBUG - request_id: req_f638e68a0ce2c757a6d6c0fcbfd2bb29
2025-06-01 01:54:40,770 - INFO - Retrieved context:  modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
 Lean failed to infer it. Named arguments also improve
the readability of your code by identifying what each argument represents.

    
    
    def sum (xs : List Nat) :=
      xs.foldl (init := 0) (·+·)
    
    #eval sum [1, 2, 3, 4]
    -- 10
    
    example {a b : Nat} {p : Nat → Nat → Nat → Prop} (h₁ : p a b b) (h₂ : b = a)
        : p a a b :=
      Eq.subst (motive := fun x => p a x b) h₂ h₁
    

In the following examples, we illustrate the interaction between named and
default arguments.

    
    
    def f (x : Nat) (y : Nat := 1) (w : Nat := 2) (z : Nat) :=
      x + y + w - z
    
    example (x z : Nat) : f (z := z) x = x + 1 + 2 - z := rfl
    
    example (x z : Nat) : f x (z := z) = x + 1 + 2 - z := rfl
    
    example (x y : Nat) : f x y = fun z => x + y + 2 - z := rfl
    
    example : f = (fun x z => x + 1 + 2 - z) := rfl
    
    example (x : Nat) : f x = fun z => x + 1 + 2 - z := rfl
    
    example (y : Nat) : f (y := 5) = fun x z => x + 5 + 2 - z := rfl
    
    def g {α} [Add α] (a : α) (b? : Option α := none) (c : α) : α :=
      match b? with
      | none   => a + c
      | some b => a + b + c
    
    variable {α} [Add α]
    
    example : g = fun (a c : α) => a + c := rfl
    
    example (x : α) : g (c := x) = fun (a : α) => a + x := rfl
    
    example (x : α) : g (b? := some x) = fun (a c : α) => a + x + c := rfl
    
    example (x : α) : g x = fun (c : α) => x + c := rfl
    
    example (x y : α) : g x y = fun (c : α) => x + y + c := rfl
    

You can use `..` to provide missing explicit arguments as `_`. This feature
combined with named arguments is useful for writing patterns. Here is an
example:

    
    
    inductive Term where
      | var    (name : String)
      | num    (val : Nat)
      | app    (fn : Term) (arg : Term)
      | lambda (name : String) (type : Term) (body : Term)
    
    def getBinderName : Term → Option String
      | Term.lambda (name := n) .. => some n
      | _ => none
    
    def getBinderType : Term → Option Term
      | Term.lambda (type := t) .. => some t
      | _ => none
    

Ellipses are also useful when explicit arguments can be automatically inferred
by Lean, and we want to avoid a sequence of `_`s.

    
    
    example (f : Nat → Nat) (a b c : Nat) : f (a + b + c) = f (a + (b + c)) :=
      congrArg f (Nat.add_assoc ..)
    

[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next
chapter")

[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next
chapter")
2025-06-01 01:54:40,775 - DEBUG - close.started
2025-06-01 01:54:40,775 - DEBUG - close.complete
2025-06-01 01:54:40,791 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.'}], 'model': 'o3-mini'}}
2025-06-01 01:54:40,791 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:54:40,792 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:54:40,800 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59a7a7050>
2025-06-01 01:54:40,801 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x75d682d9ff50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:54:40,809 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59a7a6930>
2025-06-01 01:54:40,810 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:40,810 - DEBUG - send_request_headers.complete
2025-06-01 01:54:40,810 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:40,810 - DEBUG - send_request_body.complete
2025-06-01 01:54:40,810 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:46,627 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4263'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5223'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199622'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'113ms'), (b'x-request-id', b'req_a447ac34f6e4cf02cbfc06822b4d8674'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=EouAjIIhlhpPNUqabLEvt3RjAZTL6Sr6nAoZ7L5k7xs-1748742886-1.0.1.1-siEImLm4jaIb.KgQoGLS8dfRnINmxHmJ7bwJpc4quccCdxa79ViZhH1BLbaEaasXtleOpe941qN2gl1HOgGtYYKIpMBvm_t9uwtzVDBmkFA; path=/; expires=Sun, 01-Jun-25 02:24:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=b5BT01SvW8E3R3x9XE8rn4HRS_vNfphpvQDbPaepzdw-1748742886629-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b159d1dc58fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:46,628 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:54:46,628 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:46,628 - DEBUG - receive_response_body.complete
2025-06-01 01:54:46,628 - DEBUG - response_closed.started
2025-06-01 01:54:46,629 - DEBUG - response_closed.complete
2025-06-01 01:54:46,629 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 01 Jun 2025 01:54:46 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '4263'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '5223'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '199622'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '113ms'), ('x-request-id', 'req_a447ac34f6e4cf02cbfc06822b4d8674'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=EouAjIIhlhpPNUqabLEvt3RjAZTL6Sr6nAoZ7L5k7xs-1748742886-1.0.1.1-siEImLm4jaIb.KgQoGLS8dfRnINmxHmJ7bwJpc4quccCdxa79ViZhH1BLbaEaasXtleOpe941qN2gl1HOgGtYYKIpMBvm_t9uwtzVDBmkFA; path=/; expires=Sun, 01-Jun-25 02:24:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=b5BT01SvW8E3R3x9XE8rn4HRS_vNfphpvQDbPaepzdw-1748742886629-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b159d1dc58fcd-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 01:54:46,629 - DEBUG - request_id: req_a447ac34f6e4cf02cbfc06822b4d8674
2025-06-01 01:54:46,632 - INFO - Attempt 1/3
2025-06-01 01:54:46,633 - INFO - Current plan: {
  "plan_summary": "Implement a simple identity function in Lean 4 that takes a natural number as input and returns the same number without any modifications.",
  "steps": [
    "Define the function with a natural number input and a natural number output using Lean's type 'Nat'.",
    "Inside the function body, simply return the input parameter.",
    "Optionally add a brief comment explaining that the function simply returns its input.",
    "Ensure that the function compiles and correctly type-checks in Lean 4."
  ],
  "code_keywords": ["Lean 4", "natural numbers", "identity function", "function definition"],
  "proof_keywords": ["inductive reasoning", "trivial proof", "reflexivity"],
  "assumptions": [
    "The function's purpose is solely to return the given input, with no additional computation.",
    "Lean 4's 'Nat' type and basic function definition syntax are available and correct."
  ],
  "retry_guidance": "If there are compilation or type-checking errors, ensure that the function's type signature accurately uses 'Nat' for both the input and output, and confirm that Lean 4's syntax for function definitions is correctly applied."
}
2025-06-01 01:54:46,633 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Implement a simple identity function in Lean 4 that takes a natural number as input and returns the same number without any modifications.",\n  "steps": [\n    "Define the function with a natural number input and a natural number output using Lean\'s type \'Nat\'.",\n    "Inside the function body, simply return the input parameter.",\n    "Optionally add a brief comment explaining that the function simply returns its input.",\n    "Ensure that the function compiles and correctly type-checks in Lean 4."\n  ],\n  "code_keywords": ["Lean 4", "natural numbers", "identity function", "function definition"],\n  "proof_keywords": ["inductive reasoning", "trivial proof", "reflexivity"],\n  "assumptions": [\n    "The function\'s purpose is solely to return the given input, with no additional computation.",\n    "Lean 4\'s \'Nat\' type and basic function definition syntax are available and correct."\n  ],\n  "retry_guidance": "If there are compilation or type-checking errors, ensure that the function\'s type signature accurately uses \'Nat\' for both the input and output, and confirm that Lean 4\'s syntax for function definitions is correctly applied."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef ident (x : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\ndef ident_spec (x : Nat) (result: Nat) : Prop :=\n  -- << SPEC START >>\n  result = x\n  -- << SPEC END >>\n\ntheorem ident_spec_satisfied (x : Nat) :\n  ident_spec x (ident x) := by\n  -- << PROOF START >>\n  unfold ident ident_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n Lean failed to infer it. Named arguments also improve\nthe readability of your code by identifying what each argument represents.\n\n    \n    \n    def sum (xs : List Nat) :=\n      xs.foldl (init := 0) (·+·)\n    \n    #eval sum [1, 2, 3, 4]\n    -- 10\n    \n    example {a b : Nat} {p : Nat → Nat → Nat → Prop} (h₁ : p a b b) (h₂ : b = a)\n        : p a a b :=\n      Eq.subst (motive := fun x => p a x b) h₂ h₁\n    \n\nIn the following examples, we illustrate the interaction between named and\ndefault arguments.\n\n    \n    \n    def f (x : Nat) (y : Nat := 1) (w : Nat := 2) (z : Nat) :=\n      x + y + w - z\n    \n    example (x z : Nat) : f (z := z) x = x + 1 + 2 - z := rfl\n    \n    example (x z : Nat) : f x (z := z) = x + 1 + 2 - z := rfl\n    \n    example (x y : Nat) : f x y = fun z => x + y + 2 - z := rfl\n    \n    example : f = (fun x z => x + 1 + 2 - z) := rfl\n    \n    example (x : Nat) : f x = fun z => x + 1 + 2 - z := rfl\n    \n    example (y : Nat) : f (y := 5) = fun x z => x + 5 + 2 - z := rfl\n    \n    def g {α} [Add α] (a : α) (b? : Option α := none) (c : α) : α :=\n      match b? with\n      | none   => a + c\n      | some b => a + b + c\n    \n    variable {α} [Add α]\n    \n    example : g = fun (a c : α) => a + c := rfl\n    \n    example (x : α) : g (c := x) = fun (a : α) => a + x := rfl\n    \n    example (x : α) : g (b? := some x) = fun (a c : α) => a + x + c := rfl\n    \n    example (x : α) : g x = fun (c : α) => x + c := rfl\n    \n    example (x y : α) : g x y = fun (c : α) => x + y + c := rfl\n    \n\nYou can use `..` to provide missing explicit arguments as `_`. This feature\ncombined with named arguments is useful for writing patterns. Here is an\nexample:\n\n    \n    \n    inductive Term where\n      | var    (name : String)\n      | num    (val : Nat)\n      | app    (fn : Term) (arg : Term)\n      | lambda (name : String) (type : Term) (body : Term)\n    \n    def getBinderName : Term → Option String\n      | Term.lambda (name := n) .. => some n\n      | _ => none\n    \n    def getBinderType : Term → Option Term\n      | Term.lambda (type := t) .. => some t\n      | _ => none\n    \n\nEllipses are also useful when explicit arguments can be automatically inferred\nby Lean, and we want to avoid a sequence of `_`s.\n\n    \n    \n    example (f : Nat → Nat) (a b c : Nat) : f (a + b + c) = f (a + (b + c)) :=\n      congrArg f (Nat.add_assoc ..)\n    \n\n[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next\nchapter")\n\n[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next\nchapter")'}], 'model': 'gpt-4o'}}
2025-06-01 01:54:46,635 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:54:46,635 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:46,635 - DEBUG - send_request_headers.complete
2025-06-01 01:54:46,635 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:46,639 - DEBUG - send_request_body.complete
2025-06-01 01:54:46,639 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:49,199 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'1739'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1743'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'13938'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'32.124s'), (b'x-request-id', b'req_370a697fa1816353658091e5a714bb06'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b15c18d9d8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:49,199 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:54:49,199 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:49,201 - DEBUG - receive_response_body.complete
2025-06-01 01:54:49,201 - DEBUG - response_closed.started
2025-06-01 01:54:49,201 - DEBUG - response_closed.complete
2025-06-01 01:54:49,201 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '1739', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1743', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '13938', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '32.124s', 'x-request-id': 'req_370a697fa1816353658091e5a714bb06', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b15c18d9d8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:49,201 - DEBUG - request_id: req_370a697fa1816353658091e5a714bb06
2025-06-01 01:54:49,201 - INFO - Raw solution received: ```json
{
  "code": "x",
  "proof": "trivial"
}
```
2025-06-01 01:54:49,201 - INFO - <class 'str'>
2025-06-01 01:54:49,201 - INFO - Generated solution: {'code': 'x', 'proof': 'trivial'}
2025-06-01 01:54:49,204 - INFO - Lean execution result: Error: Lean executable not found or temp_project directory doesn't exist.
2025-06-01 01:54:49,204 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef ident (x : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\ndef ident_spec (x : Nat) (result: Nat) : Prop :=\n  -- << SPEC START >>\n  result = x\n  -- << SPEC END >>\n\ntheorem ident_spec_satisfied (x : Nat) :\n  ident_spec x (ident x) := by\n  -- << PROOF START >>\n  unfold ident ident_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nx\n\nGenerated Proof:\ntrivial\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nError: Lean executable not found or temp_project directory doesn't exist."}], 'model': 'o3-mini'}}
2025-06-01 01:54:49,205 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:54:49,205 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:49,205 - DEBUG - send_request_headers.complete
2025-06-01 01:54:49,205 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:49,205 - DEBUG - send_request_body.complete
2025-06-01 01:54:49,205 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:54,197 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4374'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4378'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199413'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'175ms'), (b'x-request-id', b'req_80dc7ddffb21a3c30d1ffc8a97e0c81b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b15d19f298fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:54,198 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:54:54,198 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:54,198 - DEBUG - receive_response_body.complete
2025-06-01 01:54:54,198 - DEBUG - response_closed.started
2025-06-01 01:54:54,198 - DEBUG - response_closed.complete
2025-06-01 01:54:54,198 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:54:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4374', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4378', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199413', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '175ms', 'x-request-id': 'req_80dc7ddffb21a3c30d1ffc8a97e0c81b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b15d19f298fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:54:54,198 - DEBUG - request_id: req_80dc7ddffb21a3c30d1ffc8a97e0c81b
2025-06-01 01:54:54,199 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': 'The error message indicates that the Lean executable or the temporary project directory is missing. This is an environmental configuration issue rather than a problem with the code or proof logic.', 'error_type': 'unknown', 'suggested_fix': "Ensure that Lean is properly installed on your system and that the 'temp_project' directory (or an appropriate project directory) exists. Verify that the Lean executable is in your system's PATH or correctly specified in your environment configuration.", 'retry_strategy': 'Check your Lean installation and setup. Reconfigure your project workspace to ensure that the Lean executable is accessible, then try running the code again.'}
2025-06-01 01:54:54,199 - INFO - Solution generated in 32.84 seconds
2025-06-01 01:54:54,199 - INFO - Generated code length: 5 characters
2025-06-01 01:54:54,199 - INFO - Generated proof length: 5 characters
2025-06-01 01:54:54,199 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 01:54:54,199 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 01:54:54,200 - INFO - Implementation test result: FAIL
2025-06-01 01:54:54,200 - INFO - Executing Lean code with implementation and proof...
2025-06-01 01:54:54,201 - INFO - Full solution test result: FAIL
2025-06-01 01:54:54,201 - ERROR - ❌ Implementation fails unit tests
2025-06-01 01:54:54,201 - ERROR - ❌ Proof has errors
2025-06-01 01:54:54,201 - INFO - 
==================================================
2025-06-01 01:54:54,201 - INFO - Processing task task_id_58...
2025-06-01 01:54:54,201 - INFO - Reading problem description and code template from tasks/task_id_58...
2025-06-01 01:54:54,203 - INFO - Problem description length: 700 characters
2025-06-01 01:54:54,203 - INFO - Reading unit tests from tasks/task_id_58...
2025-06-01 01:54:54,204 - INFO - Unit tests length: 462 characters
2025-06-01 01:54:54,204 - INFO - Running main workflow to generate solution...
2025-06-01 01:54:54,204 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.

-----Input-----
The input consists of two integers:
a: An integer.
b: An integer.

-----Output-----
The output is a Boolean value:
Returns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).
Returns false if both integers are either non-negative or non-positive, or if one (or both) is zero.
2025-06-01 01:54:54,204 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def hasOppositeSign (a : Int) (b : Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result is true if a and b have opposite signs
def hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=
  -- << SPEC START >>
  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result
  -- << SPEC END >>

theorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :
  hasOppositeSign_spec a b (hasOppositeSign a b) := by
  -- << PROOF START >>
  unfold hasOppositeSign hasOppositeSign_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 01:54:54,237 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59ab48040>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:54:54,238 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:54:54,238 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:54:54,244 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59ab4deb0>
2025-06-01 01:54:54,244 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x75d59b04f5d0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:54:54,251 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59ab4e870>
2025-06-01 01:54:54,252 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:54,252 - DEBUG - send_request_headers.complete
2025-06-01 01:54:54,252 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:54,252 - DEBUG - send_request_body.complete
2025-06-01 01:54:54,252 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:54:54,622 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:54:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'74'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-dc9d5f6f7-vz88b'), (b'x-envoy-upstream-service-time', b'77'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999825'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_e8f6f82a0362b6f2e317e09a44377c31'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mL4ylbcjX6w.Uh7NJiIIT26q7DNfFEeZUDv2175i.gU-1748742894-1.0.1.1-6juBqGSqDwfGkQYguTBSeMSV2I3qpDLmhwoMMwpuPTvezNk4MYay2uHwXTQtEQY9A5tTNy3LRROTpN4I40c7aJ1Hwc7C7mQhRP85v_UJAwk; path=/; expires=Sun, 01-Jun-25 02:24:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=cpPfk67rmx1HxlMUU5ArmgW3OJAF4QoKn51XUuzHL7A-1748742894618-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b15f11e1c3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:54:54,623 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:54:54,623 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:54:54,623 - DEBUG - receive_response_body.complete
2025-06-01 01:54:54,623 - DEBUG - response_closed.started
2025-06-01 01:54:54,623 - DEBUG - response_closed.complete
2025-06-01 01:54:54,623 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 01:54:54 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '74'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-dc9d5f6f7-vz88b'), ('x-envoy-upstream-service-time', '77'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999825'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '10ms'), ('x-request-id', 'req_e8f6f82a0362b6f2e317e09a44377c31'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=mL4ylbcjX6w.Uh7NJiIIT26q7DNfFEeZUDv2175i.gU-1748742894-1.0.1.1-6juBqGSqDwfGkQYguTBSeMSV2I3qpDLmhwoMMwpuPTvezNk4MYay2uHwXTQtEQY9A5tTNy3LRROTpN4I40c7aJ1Hwc7C7mQhRP85v_UJAwk; path=/; expires=Sun, 01-Jun-25 02:24:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=cpPfk67rmx1HxlMUU5ArmgW3OJAF4QoKn51XUuzHL7A-1748742894618-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b15f11e1c3bfe-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 01:54:54,623 - DEBUG - request_id: req_e8f6f82a0362b6f2e317e09a44377c31
2025-06-01 01:54:54,628 - INFO - Retrieved context:  the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
� r)`

Distributivity:

  5. `p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)`
  6. `p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)`

Other properties:

  7. `(p → (q → r)) ↔ (p ∧ q → r)`
  8. `((p ∨ q) → r) ↔ (p → r) ∧ (q → r)`
  9. `¬(p ∨ q) ↔ ¬p ∧ ¬q`
  10. `¬p ∨ ¬q → ¬(p ∧ q)`
  11. `¬(p ∧ ¬p)`
  12. `p ∧ ¬q → ¬(p → q)`
  13. `¬p → (p → q)`
  14. `(¬p ∨ q) → (p → q)`
  15. `p ∨ False ↔ p`
  16. `p ∧ False ↔ False`
  17. `¬(p ↔ ¬p)`
  18. `(p → q) → (¬q → ¬p)`

These require classical reasoning:

  19. `(p → r ∨ s) → ((p → r) ∨ (p → s))`
  20. `¬(p ∧ q) → ¬p ∨ ¬q`
  21. `¬(p → q) → p ∧ ¬q`
  22. `(p → q) → (¬p ∨ q)`
  23. `(¬q → ¬p) → (p → q)`
  24. `p ∨ ¬p`
  25. `(((p → q) → p) → p)`

The `sorry` identifier magically produces a proof of anything, or provides an
object of any data type at all. Of course, it is unsound as a proof method --
for example, you can use it to prove `False` \-- and Lean produces severe
warnings when files use or import theorems which depend on it. But it is very
useful for building long proofs incrementally. Start writing the proof from
the top down, using `sorry` to fill in subproofs. Make sure Lean accepts the
term with all the `sorry`'s; if not, there are errors that you need to
correct. Then go back and replace each `sorry` with an actual proof, until no
more remain.

Here is another useful trick. Instead of using `sorry`, you can use an
underscore `_` as a placeholder. Recall this tells Lean that the argument is
implicit, and should be filled in automatically. If Lean tries to do so and
fails, it returns with an error message "don't know how to synthesize
placeholder," followed by the type of the term it is expecting, and all the
objects and hypotheses available in the context. In other words, for each
unresolved placeholder, Lean reports the subgoal that needs to be filled at
that point. You can then construct a proof by incrementally filling in these
placeholders.

For reference, here are two sample proofs of validities taken from the list
above.

    
    
    open Classical
    
    -- distributivity
    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
      Iff.intro
        (fun h : p ∧ (q ∨ r) =>
          have hp : p := h.left
          Or.elim (h.right)
            (fun hq : q =>
              show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)
            (fun hr : r =>
              show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))
        (fun h : (p ∧ q) ∨ (p ∧ r) =>
          Or.elim h
            (fun hpq : p ∧ q =>
              have hp : p := hpq.left
              have hq : q := hpq.right
              show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)
            (fun hpr : p ∧ r =>
              have hp : p := hpr.left
              have hr : r := hpr.right
              show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))
    
    -- an example that requires classical reasoning
    example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=
      fun h : ¬(p ∧ ¬q) =>
      fun hp : p =>
      show q from
        Or.elim (em q)
          (fun hq : q => hq)
          (fun hnq : ¬q => absurd (And.intro hp hnq) h)
    

## Exercises

Prove the following identities, replacing the "sorry" placeholders with actual
proofs.

    
    
    variable (p q r : Prop)
    
    -- commutativity of ∧ and ∨
    example : p ∧ q ↔ q ∧ p := sorry
    example : p ∨ q ↔ q ∨ p := sorry
    
    -- associativity of ∧ and ∨
    example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry
    example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry
    
    -- distributivity
    example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry
    example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry
    
    -- other properties
    example : (p → (q → r)) ↔ (p ∧ q → r) := sorry
    example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry
    example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry
    example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry
    example : ¬(p ∧ ¬p) := sorry
    example : p ∧ ¬q → ¬(p → q) := sorry
    example : ¬p → (p → q) := sorry
    example : (¬p ∨ q) → (p → q) := sorry
    example : p ∨ False ↔ p := sorry
    example : p ∧ False ↔ False := sorry
    example : (p → q) → (¬q → ¬p) := sorry
    

Prove the following identities, replacing the "sorry" placeholders with actual
proofs. These require classical reasoning.

    
    
    open Classical
    
    variable (p q r : Prop)
    
    example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry
    example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry
    example : ¬(p → q) → p ∧ ¬q := sorry
    example : (p → q) → (¬p ∨ q) := sorry
    example : (¬q → ¬p) → (p → q) := sorry
    example : p ∨ ¬p := sorry
    example : (((p → q) → p) → p) := sorry
    

Prove `¬(p ↔ ¬p)` without using classical logic.

[ __](dependent_type_theory.html "Previous chapter") [
__](quantifiers_and_equality.html "Next chapter")

[ __](dependent_type_theory.html "Previous chapter") [
__](quantifiers_and_equality.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Propositions and Proofs

By now, you have seen some ways of defining objects and functions in Lean. In
this chapter, we will begin to explain how to write mathematical assertions
and proofs in the language of dependent type theory as well.

## Propositions as Types

One strategy for proving assertions about objects defined in the language of
dependent type theory is to layer an assertion language and a proof language
on top of the definition language. But there is no reason to multiply
languages in this way: dependent type theory is flexible and expressive, and
there is no reason we cannot represent assertions and proofs in the same
general framework.

For example, we could introduce a new type, `Prop`, to represent propositions,
and introduce constructors to build new propositions from others.

    
    
    def Implies (p q : Prop) : Prop := p → q
    #check And     -- Prop → Prop → Prop
    #check Or      -- Prop → Prop → Prop
    #check Not     -- Prop → Prop
    #check Implies -- Prop → Prop → Prop
    
    variable (p q r : Prop)
    #check And p q                      -- Prop
    #check Or (And p q) r               -- Prop
    #check Implies (And p q) (And q p)  -- Prop
    

We could then introduce, for each element `p : Prop`, another type `Proof p`,
for the type of proofs of `p`. An "axiom" would be a constant of such a type.

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    #check Proof   -- Proof : Prop → Type
    
    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))
    
    variable (p q : Prop)
    #check and_comm p q     -- Proof (Implies (And p q) (And q p))
    

In addition to axioms, however, we would also need rules to build new proofs
from old ones. For example, in many proof systems for propositional logic, we
have the rule of _modus ponens_ :

> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.

We could represent this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q
    

Systems of natural deduction for propositional logic also typically rely on
the following rule:

> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we
> can "cancel" the hypothesis and obtain a proof of `Implies p q`.

We could render this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)
    

This approach would provide us with a reasonable way of building assertions
and proofs. Determining that an expression `t` is a correct proof of assertion
`p` would then simply be a matter of checking that `t` has type `Proof p`.

Some simplifications are possible, however. To start with, we can avoid
writing the term `Proof` repeatedly by conflating `Proof p` with `p` itself.
In other words, whenever we have `p : Prop`, we can interpret `p` as a type,
namely, the type of its proofs. We can then read `t : p` as the assertion that
`t` is a proof of `p`.

Moreover, once we make this identification, the rules for implication show
that we can pass back and forth between `Implies p q` and `p → q`. In other
words, implication between propositions `p` and `q` corresponds to having a
function that takes any element of `p` to an element of `q`. As a result, the
introduction of the connective `Implies` is entirely redundant: we can use the
usual function space constructor `p → q` from dependent type theory as our
notion of implication.

This is the approach followed in the Calculus of Constructions, and hence in
Lean as well. The fact that the rules for implication in a proof system for
natural deduction correspond exactly to the rules governing abstraction and
application for functions is an instance of the _Curry-Howard isomorphism_ ,
sometimes known as the _propositions-as-types_ paradigm. In fact, the type
`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy
described in the last chapter. Moreover, `Type u` is also just syntactic sugar
for `Sort (u+1)`. `Prop` has some special features, but like the other type
universes, it is closed under the arrow constructor: if we have `p q : Prop`,
then `p → q : Prop`.

There are at least two ways of thinking about propositions as types. To some
who take a constructive view of logic and mathematics, this is a faithful
rendering of what it means to be a proposition: a proposition `p` represents a
sort of data type, namely, a specification of the type of data that
constitutes a proof. A proof of `p` is then simply an object `t : p` of the
right type.

Those not inclined to this ideology can view it, rather, as a simple coding
trick. To each proposition `p` we associate a type that is empty if `p` is
false and has a single element, say `*`, if `p` is true. In the latter case,
let us say that (the type associated with) `p` is _inhabited_. It just so
happens that the rules for function application and abstraction can
conveniently help us keep track of which elements of `Prop` are inhabited. So
constructing an element `t : p` tells us that `p` is indeed true. You can
think of the inhabitant of `p` as being the "fact that `p` is true." A proof
of `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is
true."

Indeed, if `p : Prop` is any proposition, Lean's kernel treats any two
elements `t1 t2 : p` as being definitionally equal, much the same way as it
treats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as
_proof irrelevance,_ and is consistent with the interpretation in the last
paragraph. It means that even though we can treat proofs `t : p` as ordinary
objects in the language of dependent type theory, they carry no information
beyond the fact that `p` is true.

The two ways we have suggested thinking about the propositions-as-types
paradigm differ in a fundamental way. From the constructive point of view,
proofs are abstract mathematical objects that are _denoted_ by suitable
expressions in dependent type theory. In contrast, if we think in terms of the
coding trick described above, then the expressions themselves do not denote
anything interesting. Rather, it is the fact that we can write them down and
check that they are well-typed that ensures that the proposition in question
is true. In other words, the expressions _themselves_ are the proofs.

In the exposition below, we will slip back and forth between these two ways of
talking, at times saying that an expression "constructs" or "produces" or
"returns" a proof of a proposition, and at other times simply saying that it
"is" such a proof. This is similar to the way that computer scientists
occasionally blur the distinction between syntax and semantics by saying, at
times, that a program "computes" a certain function, and at other times
speaking as though the program "is" the function in question.

In any case, all that really matters is the bottom line. To formally express a
mathematical assertion in the language of dependent type theory, we need to
exhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a
term `t : p`. Lean's task, as a proof assistant, is to help us to construct
such a term, `t`, and to verify that it is well-formed and has the correct
type.

## Working with Propositions as Types

In the propositions-as-types paradigm, theorems involving only `→` can be
proved using lambda abstraction and application. In Lean, the `theorem`
command introduces a new theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    

Compare this proof to the expression `fun x : α => fun y : β => x` of type `α
→ β → α`, where `α` and `β` are data types. This describes the function that
takes arguments `x` and `y` of type `α` and `β`, respectively, and returns
`x`. The proof of `t1` has the same form, the only difference being that `p`
and `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of
`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis
(trivially) to establish that the conclusion, `p`, is true.

Note that the `theorem` command is really a version of the `def` command:
under the propositions and types correspondence, proving the theorem `p → q →
p` is really the same as defining an element of the associated type. To the
kernel type checker, there is no difference between the two.

There are a few pragmatic differences between definitions and theorems,
however. In normal circumstances, it is never necessary to unfold the
"definition" of a theorem; by proof irrelevance, any two proofs of that
theorem are definitionally equal. Once the proof of a theorem is complete,
typically we only need to know that the proof exists; it doesn't matter what
the proof is. In light of that fact, Lean tags proofs as _irreducible_ , which
serves as a hint to the parser (more precisely, the _elaborator_) that there
is generally no need to unfold them when processing a file. In fact, Lean is
generally able to process and check proofs in parallel, since assessing the
correctness of one proof does not require knowing the details of another.

As with definitions, the `#print` command will show you the proof of a
theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    
    #print t1
    

Notice that the lambda abstractions `hp : p` and `hq : q` can be viewed as
temporary assumptions in the proof of `t1`. Lean also allows us to specify the
type of the final term `hp`, explicitly, with a `show` statement:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p :=
      fun hp : p =>
      fun hq : q =>
      show p from hp
    

Adding such extra information can improve the clarity of a proof and help
detect errors when writing a proof. The `show` command does nothing more than
annotate the type, and, internally, all the presentations of `t1` that we have
seen produce the same term.

As with ordinary definitions, we can move the lambda-abstracted variables to
the left of the colon:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    #print t1    -- p → q → p
    

We can use the theorem `t1` just as a function application:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    axiom hp : p
    
    theorem t2 : q → p := t1 hp
    

The `axiom` declaration postulates the existence of an element of the given
type and may compromise logical consistency. For example, we can use it to
postulate that the empty type `False` has an element:

    
    
    axiom unsound : False
    -- Everything follows from false
    theorem ex : 1 = 0 :=
      False.elim unsound
    

Declaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as
witnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`
that `p` is true yields the theorem `t1 hp : q → p`.

Recall that we can also write theorem `t1` as follows:

    
    
    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp
    
    #print t1
    

The type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the
assertion "for every pair of propositions `p q`, we have `p → q → p`." For
example, we can move all parameters to the right of the colon:

    
    
    theorem t1 : ∀ {p q : Prop}, p → q → p :=
      fun {p q : Prop} (hp : p) (hq : q) => hp
    

If `p` and `q` have been declared as variables, Lean will generalize them for
us automatically:

    
    
    variable {p q : Prop}
    
    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp
    

In fact, by the propositions-as-types correspondence, we can declare the
assumption `hp` that `p` holds, as another variable:

    
    
    variable {p q : Prop}
    variable (hp : p)
    
    theorem t1 : q → p := fun (hq : q) => hp
    

Lean detects that the proof uses `hp` and automatically adds `hp : p` as a
premise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →
q → p`. Remember that this type can just as well be written `∀ (p q : Prop)
(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type
in which the target does not depend on the bound variable.

When we generalize `t1` in such a way, we can then apply it to different pairs
of propositions, to obtain different instances of the general theorem.

    
    
    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp
    
    variable (p q r s : Prop)
    
    #check t1 p q                -- p → q → p
    #check t1 r s                -- r → s → r
    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s
    
    variable (h : r → s)
    #check t1 (r → s) (s → r) h  -- (s → r) → r → s
    

Once again, using the propositions-as-types correspondence, the variable `h`
of type `r → s` can be viewed as the hypothesis, or premise, that `r → s`
holds.

As another example, let us consider the composition function discussed in the
last chapter, now with propositions instead of types.

    
    
    variable (p q r s : Prop)
    
    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=
      fun h₃ : p =>
      show r from h₁ (h₂ h₃)
    

As a theorem of propositional logic, what does `t2` say?

Note that it is often useful to use numeric unicode subscripts, entered as
`\0`, `\1`, `\2`, ..., for hypotheses, as we did in this example.

## Propositional Logic

Lean defines all the standard logical connectives and notation. The
propositional connectives come with the following notation:

Ascii| Unicode| Editor shortcut| Definition  
---|---|---|---  
True| | | True  
False| | | False  
Not| ¬| `\not`, `\neg`| Not  
/\| ∧| `\and`| And  
\/| ∨| `\or`| Or  
->| →| `\to`, `\r`, `\imp`|   
<->| ↔| `\iff`, `\lr`| Iff  
  
They all take values in `Prop`.

    
    
    variable (p q : Prop)
    
    #check p → q → p ∧ q
    #check ¬p → p ↔ False
    #check p ∨ q → q ∨ p
    

The order of operations is as follows: unary negation `¬` binds most strongly,
then `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧
e` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right
(nothing changes now that the arguments are elements of `Prop`, instead of
some other `Type`), as do the other binary connectives. So if we have `p q r :
Prop`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This
is just the "curried" form of `p ∧ q → r`.

In the last chapter we observed that lambda abstraction can be viewed as an
"introduction rule" for `→`. In the current setting, it shows how to
"introduce" or establish an implication. Application can be viewed as an
"elimination rule," showing how to "eliminate" or use an implication in a
proof. The other propositional connectives are defined in Lean's library in
the file `Prelude.core` (see [importing
files](./interacting_with_lean.html#importing-files) for more information on
the library hierarchy), and each connective comes with its canonical
introduction and elimination rules.

### Conjunction

The expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :
p` and `h2 : q`. It is common to describe `And.intro` as the _and-
introduction_ rule. In the next example we use `And.intro` to create a proof
of `p → q → p ∧ q`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq
    
    #check fun (hp : p) (hq : q) => And.intro hp hq
    

The `example` command states a theorem without naming it or storing it in the
permanent context. Essentially, it just checks that the given term has the
indicated type. It is convenient for illustration, and we will use it often.

The expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.
Similarly, `And.right h` is a proof of `q`. They are commonly known as the
left and right _and-elimination_ rules.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : p := And.left h
    example (h : p ∧ q) : q := And.right h
    

We can now prove `p ∧ q → q ∧ p` with the following proof term.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      And.intro (And.right h) (And.left h)
    

Notice that and-introduction and and-elimination are similar to the pairing
and projection operations for the Cartesian product. The difference is that
given `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while
`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is
another instance of the Curry-Howard isomorphism, but in contrast to
implication and the function space constructor, `∧` and `×` are treated
separately in Lean. With the analogy, however, the proof we have just
constructed is similar to a function that swaps the elements of a pair.

We will see in [Chapter Structures and Records](./structures_and_records.html)
that certain types in Lean are _structures_ , which is to say, the type is
defined with a single canonical _constructor_ which builds an element of the
type from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is
an example: the canonical way to construct an element is to apply `And.intro`
to suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous
constructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the
relevant type is an inductive type and can be inferred from the context. In
particular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:

    
    
    variable (p q : Prop)
    variable (hp : p) (hq : q)
    
    #check (⟨hp, hq⟩ : p ∧ q)
    

These angle brackets are obtained by typing `\<` and `\>`, respectively.

Lean provides another useful syntactic gadget. Given an expression `e` of an
inductive type `Foo` (possibly applied to some arguments), the notation
`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of
accessing functions without opening a namespace. For example, the following
two expressions mean the same thing:

    
    
    variable (xs : List Nat)
    
    #check List.length xs
    #check xs.length
    

As a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and
`h.right` for `And.right h`. We can therefore rewrite the sample proof above
conveniently as follows:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      ⟨h.right, h.left⟩
    

There is a fine line between brevity and obfuscation, and omitting information
in this way can sometimes make a proof harder to read. But for straightforward
constructions like the one above, when the type of `h` and the goal of the
construction are salient, the notation is clean and effective.

It is common to iterate constructions like "And." Lean also allows you to
flatten nested constructors that associate to the right, so that these two
proofs are equivalent:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, ⟨h.left, h.right⟩⟩
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, h.left, h.right⟩
    

This is often useful as well.

### Disjunction

The expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof
`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a
proof `hq : q`. These are the left and right _or-introduction_ rules.

    
    
    variable (p q : Prop)
    example (hp : p) : p ∨ q := Or.intro_left q hp
    example (hq : q) : p ∨ q := Or.intro_right p hq
    

The _or-elimination_ rule is slightly more complicated. The idea is that we
can prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`
follows from `q`. In other words, it is a proof by cases. In the expression
`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :
p → r` and `hqr : q → r`, and produces a proof of `r`. In the following
example, we use `Or.elim` to prove `p ∨ q → q ∨ p`.

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h
        (fun hp : p =>
          show q ∨ p from Or.intro_right q hp)
        (fun hq : q =>
          show q ∨ p from Or.intro_left p hq)
    

In most cases, the first argument of `Or.intro_right` and `Or.intro_left` can
be inferred automatically by Lean. Lean therefore provides `Or.inr` and
`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and
`Or.intro_left _`. Thus the proof term above could be written more concisely:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Notice that there is enough information in the full expression for Lean to
infer the types of `hp` and `hq` as well. But using the type annotations in
the longer version makes the proof more readable, and can help catch and debug
errors.

Because `Or` has two constructors, we cannot use anonymous constructor
notation. But we can still write `h.elim` instead of `Or.elim h`:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Once again, you should exercise judgment as to whether such abbreviations
enhance or diminish readability.

### Negation and Falsity

Negation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by
deriving a contradiction from `p`. Similarly, the expression `hnp hp` produces
a proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both
these rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is
produced by typing `\not` or `\neg`.)

    
    
    variable (p q : Prop)
    
    example (hpq : p → q) (hnq : ¬q) : ¬p :=
      fun hp : p =>
      show False from hnq (hpq hp)
    

The connective `False` has a single elimination rule, `False.elim`, which
expresses the fact that anything follows from a contradiction. This rule is
sometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the
_principle of explosion_.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)
    

The arbitrary fact, `q`, that follows from falsity is an implicit argument in
`False.elim` and is inferred automatically. This pattern, deriving an
arbitrary fact from contradictory hypotheses, is quite common, and is
represented by `absurd`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := absurd hp hnp
    

Here, for example, is a proof of `¬p → q → (q → p) → r`:

    
    
    variable (p q r : Prop)
    
    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=
      absurd (hqp hq) hnp
    

Incidentally, just as `False` has only an elimination rule, `True` has only an
introduction rule, `True.intro : true`. In other words, `True` is simply true,
and has a canonical proof, `True.intro`.

### Logical Equivalence

The expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`
and `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from
`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔
q`. Here is a proof of `p ∧ q ↔ q ∧ p`:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      Iff.intro
        (fun h : p ∧ q =>
         show q ∧ p from And.intro (And.right h) (And.left h))
        (fun h : q ∧ p =>
         show p ∧ q from And.intro (And.right h) (And.left h))
    
    #check and_swap p q    -- p ∧ q ↔ q ∧ p
    
    variable (h : p ∧ q)
    example : q ∧ p := Iff.mp (and_swap p q) h
    

We can use the anonymous constructor notation to construct a proof of `p ↔ q`
from proofs of the forward and backward directions, and we can also use `.`
notation with `mp` and `mpr`. The previous examples can therefore be written
concisely as follows:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩
    
    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h
    

## Introducing Auxiliary Subgoals

This is a good place to introduce another device Lean offers to help structure
long proofs, namely, the `have` construct, which introduces an auxiliary
subgoal in a proof. Here is a small example, adapted from the last section:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      have hq : q := h.right
      show q ∧ p from And.intro hq hp
    

Internally, the expression `have h : p := s; t` produces the term `(fun (h :
p) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the
desired conclusion assuming `h : p`, and the two are combined by a lambda
abstraction and application. This simple device is extremely useful when it
comes to structuring long proofs, since we can use intermediate `have`'s as
stepping stones leading to the final goal.

Lean also supports a structured way of reasoning backwards from a goal, which
models the "suffices to show" construction in ordinary mathematics. The next
example simply permutes the last two lines in the previous proof.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      suffices hq : q from And.intro hq hp
      show q from And.right h
    

Writing `suffices hq : q` leaves us with two goals. First, we have to show
that it indeed suffices to show `q`, by proving the original goal of `q ∧ p`
with the additional hypothesis `hq : q`. Finally, we have to show `q`.

## Classical Logic

The introduction and elimination rules we have seen so far are all
constructive, which is to say, they reflect a computational understanding of
the logical connectives based on the propositions-as-types correspondence.
Ordinary classical logic adds to this the law of the excluded middle, `p ∨
¬p`. To use this principle, you have to open the classical namespace.

    
    
    open Classical
    
    variable (p : Prop)
    #check em p
    

Intuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts
to knowing which is the case. If `RH` represents the Riemann hypothesis, a
classical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot
yet assert either disjunct.

One consequence of the law of the excluded middle is the principle of double-
negation elimination:

    
    
    open Classical
    
    theorem dne {p : Prop} (h : ¬¬p) : p :=
      Or.elim (em p)
        (fun hp : p => hp)
        (fun hnp : ¬p => absurd hnp h)
    

Double-negation elimination allows one to prove any proposition, `p`, by
assuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In
other words, double-negation elimination allows one to carry out a proof by
contradiction, something which is not generally possible in constructive
logic. As an exercise, you might try proving the converse, that is, showing
that `em` can be proved from `dne`.

The classical axioms also give you access to additional patterns of proof that
can be justified by appeal to `em`. For example, one can carry out a proof by
cases:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byCases
        (fun h1 : p => h1)
        (fun h1 : ¬p => absurd h1 h)
    

Or you can carry out a proof by contradiction:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byContradiction
        (fun h1 : ¬p =>
         show False from h h1)
    

If you are not used to thinking constructively, it may take some time for you
to get a sense of where classical reasoning is used. It is needed in the
following example because, from a constructive standpoint, knowing that `p`
and `q` are not both true does not necessarily tell you which one is false:

    
    
    open Classical
    variable (p q : Prop)
    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=
      Or.elim (em p)
        (fun hp : p =>
          Or.inr
            (show ¬q from
              fun hq : q =>
              h ⟨hp, hq⟩))
        (fun hp : ¬p =>
          Or.inl hp)
    

We will see later that there _are_ situations in constructive logic where
principles like excluded middle and double-negation elimination are
permissible, and Lean supports the use of classical reasoning in such contexts
without relying on excluded middle.

The full list of axioms that are used in Lean to support classical reasoning
are discussed in [Axioms and Computation](./axioms_and_computation.html).

## Examples of Propositional Validities

Lean's standard library contains proofs of many valid statements of
propositional logic, all of which you are free to use in proofs of your own.
The following list includes a number of common identities.

Commutativity:

  1. `p ∧ q ↔ q ∧ p`
  2. `p ∨ q ↔ q ∨ p`

Associativity:

  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`
  4. `(p ∨ q) ∨ r ↔ p ∨ (q �
2025-06-01 01:54:54,632 - DEBUG - close.started
2025-06-01 01:54:54,632 - DEBUG - close.complete
2025-06-01 01:54:54,644 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.'}], 'model': 'o3-mini'}}
2025-06-01 01:54:54,644 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:54:54,644 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:54:54,645 - DEBUG - send_request_headers.complete
2025-06-01 01:54:54,645 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:54:54,645 - DEBUG - send_request_body.complete
2025-06-01 01:54:54,645 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:55:01,773 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:55:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6903'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6905'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199523'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'142ms'), (b'x-request-id', b'req_b4ead48f6d901717464fce4d09436eaa'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b15f39d718fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:55:01,773 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:55:01,774 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:55:01,774 - DEBUG - receive_response_body.complete
2025-06-01 01:55:01,774 - DEBUG - response_closed.started
2025-06-01 01:55:01,774 - DEBUG - response_closed.complete
2025-06-01 01:55:01,774 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:55:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6903', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6905', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199523', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '142ms', 'x-request-id': 'req_b4ead48f6d901717464fce4d09436eaa', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b15f39d718fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:55:01,774 - DEBUG - request_id: req_b4ead48f6d901717464fce4d09436eaa
2025-06-01 01:55:01,775 - INFO - Attempt 1/3
2025-06-01 01:55:01,775 - INFO - Current plan: {
  "plan_summary": "We need to implement a Lean 4 function that takes two integers and returns true if one of them is positive and the other is negative, while returning false if either integer is zero or if both have the same sign. The strategy will be to first check for any zero input and then verify the sign difference by comparing each integer against zero.",
  "steps": [
    "Define the function with two integer parameters, a and b, returning a boolean.",
    "Check explicitly if either a or b is equal to zero. If yes, return false since zero is treated as neither positive nor negative.",
    "For non-zero integers, check the sign: determine if a > 0 and b < 0, or if a < 0 and b > 0.",
    "Return true when exactly one of the above conditions holds, indicating opposite signs. Otherwise, return false."
  ],
  "code_keywords": [
    "Lean4",
    "integer",
    "boolean",
    "if-else",
    "comparison"
  ],
  "proof_keywords": [
    "case analysis",
    "conditional reasoning",
    "exhaustive pattern matching"
  ],
  "assumptions": [
    "Zero is neither positive nor negative.",
    "Standard comparison and conditional constructs in Lean 4 can be used.",
    "The basic arithmetic and boolean operations behave as expected."
  ],
  "retry_guidance": "If the function isn't correctly handling the zero case or if the condition for checking sign differences fails, re-read the requirement ensuring that zeros yield false. Also, double-check the boundary conditions when testing the sign comparison to ensure that the condition covers both a > 0 and a < 0 cases correctly."
}
2025-06-01 01:55:01,775 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "We need to implement a Lean 4 function that takes two integers and returns true if one of them is positive and the other is negative, while returning false if either integer is zero or if both have the same sign. The strategy will be to first check for any zero input and then verify the sign difference by comparing each integer against zero.",\n  "steps": [\n    "Define the function with two integer parameters, a and b, returning a boolean.",\n    "Check explicitly if either a or b is equal to zero. If yes, return false since zero is treated as neither positive nor negative.",\n    "For non-zero integers, check the sign: determine if a > 0 and b < 0, or if a < 0 and b > 0.",\n    "Return true when exactly one of the above conditions holds, indicating opposite signs. Otherwise, return false."\n  ],\n  "code_keywords": [\n    "Lean4",\n    "integer",\n    "boolean",\n    "if-else",\n    "comparison"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "conditional reasoning",\n    "exhaustive pattern matching"\n  ],\n  "assumptions": [\n    "Zero is neither positive nor negative.",\n    "Standard comparison and conditional constructs in Lean 4 can be used.",\n    "The basic arithmetic and boolean operations behave as expected."\n  ],\n  "retry_guidance": "If the function isn\'t correctly handling the zero case or if the condition for checking sign differences fails, re-read the requirement ensuring that zeros yield false. Also, double-check the boundary conditions when testing the sign comparison to ensure that the condition covers both a > 0 and a < 0 cases correctly."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n� r)`\n\nDistributivity:\n\n  5. `p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)`\n  6. `p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)`\n\nOther properties:\n\n  7. `(p → (q → r)) ↔ (p ∧ q → r)`\n  8. `((p ∨ q) → r) ↔ (p → r) ∧ (q → r)`\n  9. `¬(p ∨ q) ↔ ¬p ∧ ¬q`\n  10. `¬p ∨ ¬q → ¬(p ∧ q)`\n  11. `¬(p ∧ ¬p)`\n  12. `p ∧ ¬q → ¬(p → q)`\n  13. `¬p → (p → q)`\n  14. `(¬p ∨ q) → (p → q)`\n  15. `p ∨ False ↔ p`\n  16. `p ∧ False ↔ False`\n  17. `¬(p ↔ ¬p)`\n  18. `(p → q) → (¬q → ¬p)`\n\nThese require classical reasoning:\n\n  19. `(p → r ∨ s) → ((p → r) ∨ (p → s))`\n  20. `¬(p ∧ q) → ¬p ∨ ¬q`\n  21. `¬(p → q) → p ∧ ¬q`\n  22. `(p → q) → (¬p ∨ q)`\n  23. `(¬q → ¬p) → (p → q)`\n  24. `p ∨ ¬p`\n  25. `(((p → q) → p) → p)`\n\nThe `sorry` identifier magically produces a proof of anything, or provides an\nobject of any data type at all. Of course, it is unsound as a proof method --\nfor example, you can use it to prove `False` \\-- and Lean produces severe\nwarnings when files use or import theorems which depend on it. But it is very\nuseful for building long proofs incrementally. Start writing the proof from\nthe top down, using `sorry` to fill in subproofs. Make sure Lean accepts the\nterm with all the `sorry`\'s; if not, there are errors that you need to\ncorrect. Then go back and replace each `sorry` with an actual proof, until no\nmore remain.\n\nHere is another useful trick. Instead of using `sorry`, you can use an\nunderscore `_` as a placeholder. Recall this tells Lean that the argument is\nimplicit, and should be filled in automatically. If Lean tries to do so and\nfails, it returns with an error message "don\'t know how to synthesize\nplaceholder," followed by the type of the term it is expecting, and all the\nobjects and hypotheses available in the context. In other words, for each\nunresolved placeholder, Lean reports the subgoal that needs to be filled at\nthat point. You can then construct a proof by incrementally filling in these\nplaceholders.\n\nFor reference, here are two sample proofs of validities taken from the list\nabove.\n\n    \n    \n    open Classical\n    \n    -- distributivity\n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=\n      Iff.intro\n        (fun h : p ∧ (q ∨ r) =>\n          have hp : p := h.left\n          Or.elim (h.right)\n            (fun hq : q =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)\n            (fun hr : r =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))\n        (fun h : (p ∧ q) ∨ (p ∧ r) =>\n          Or.elim h\n            (fun hpq : p ∧ q =>\n              have hp : p := hpq.left\n              have hq : q := hpq.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)\n            (fun hpr : p ∧ r =>\n              have hp : p := hpr.left\n              have hr : r := hpr.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))\n    \n    -- an example that requires classical reasoning\n    example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=\n      fun h : ¬(p ∧ ¬q) =>\n      fun hp : p =>\n      show q from\n        Or.elim (em q)\n          (fun hq : q => hq)\n          (fun hnq : ¬q => absurd (And.intro hp hnq) h)\n    \n\n## Exercises\n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs.\n\n    \n    \n    variable (p q r : Prop)\n    \n    -- commutativity of ∧ and ∨\n    example : p ∧ q ↔ q ∧ p := sorry\n    example : p ∨ q ↔ q ∨ p := sorry\n    \n    -- associativity of ∧ and ∨\n    example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry\n    example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry\n    \n    -- distributivity\n    example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry\n    example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry\n    \n    -- other properties\n    example : (p → (q → r)) ↔ (p ∧ q → r) := sorry\n    example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry\n    example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry\n    example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry\n    example : ¬(p ∧ ¬p) := sorry\n    example : p ∧ ¬q → ¬(p → q) := sorry\n    example : ¬p → (p → q) := sorry\n    example : (¬p ∨ q) → (p → q) := sorry\n    example : p ∨ False ↔ p := sorry\n    example : p ∧ False ↔ False := sorry\n    example : (p → q) → (¬q → ¬p) := sorry\n    \n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs. These require classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (p q r : Prop)\n    \n    example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry\n    example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry\n    example : ¬(p → q) → p ∧ ¬q := sorry\n    example : (p → q) → (¬p ∨ q) := sorry\n    example : (¬q → ¬p) → (p → q) := sorry\n    example : p ∨ ¬p := sorry\n    example : (((p → q) → p) → p) := sorry\n    \n\nProve `¬(p ↔ ¬p)` without using classical logic.\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Propositions and Proofs\n\nBy now, you have seen some ways of defining objects and functions in Lean. In\nthis chapter, we will begin to explain how to write mathematical assertions\nand proofs in the language of dependent type theory as well.\n\n## Propositions as Types\n\nOne strategy for proving assertions about objects defined in the language of\ndependent type theory is to layer an assertion language and a proof language\non top of the definition language. But there is no reason to multiply\nlanguages in this way: dependent type theory is flexible and expressive, and\nthere is no reason we cannot represent assertions and proofs in the same\ngeneral framework.\n\nFor example, we could introduce a new type, `Prop`, to represent propositions,\nand introduce constructors to build new propositions from others.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    #check And     -- Prop → Prop → Prop\n    #check Or      -- Prop → Prop → Prop\n    #check Not     -- Prop → Prop\n    #check Implies -- Prop → Prop → Prop\n    \n    variable (p q r : Prop)\n    #check And p q                      -- Prop\n    #check Or (And p q) r               -- Prop\n    #check Implies (And p q) (And q p)  -- Prop\n    \n\nWe could then introduce, for each element `p : Prop`, another type `Proof p`,\nfor the type of proofs of `p`. An "axiom" would be a constant of such a type.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    #check Proof   -- Proof : Prop → Type\n    \n    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))\n    \n    variable (p q : Prop)\n    #check and_comm p q     -- Proof (Implies (And p q) (And q p))\n    \n\nIn addition to axioms, however, we would also need rules to build new proofs\nfrom old ones. For example, in many proof systems for propositional logic, we\nhave the rule of _modus ponens_ :\n\n> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.\n\nWe could represent this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q\n    \n\nSystems of natural deduction for propositional logic also typically rely on\nthe following rule:\n\n> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we\n> can "cancel" the hypothesis and obtain a proof of `Implies p q`.\n\nWe could render this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)\n    \n\nThis approach would provide us with a reasonable way of building assertions\nand proofs. Determining that an expression `t` is a correct proof of assertion\n`p` would then simply be a matter of checking that `t` has type `Proof p`.\n\nSome simplifications are possible, however. To start with, we can avoid\nwriting the term `Proof` repeatedly by conflating `Proof p` with `p` itself.\nIn other words, whenever we have `p : Prop`, we can interpret `p` as a type,\nnamely, the type of its proofs. We can then read `t : p` as the assertion that\n`t` is a proof of `p`.\n\nMoreover, once we make this identification, the rules for implication show\nthat we can pass back and forth between `Implies p q` and `p → q`. In other\nwords, implication between propositions `p` and `q` corresponds to having a\nfunction that takes any element of `p` to an element of `q`. As a result, the\nintroduction of the connective `Implies` is entirely redundant: we can use the\nusual function space constructor `p → q` from dependent type theory as our\nnotion of implication.\n\nThis is the approach followed in the Calculus of Constructions, and hence in\nLean as well. The fact that the rules for implication in a proof system for\nnatural deduction correspond exactly to the rules governing abstraction and\napplication for functions is an instance of the _Curry-Howard isomorphism_ ,\nsometimes known as the _propositions-as-types_ paradigm. In fact, the type\n`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy\ndescribed in the last chapter. Moreover, `Type u` is also just syntactic sugar\nfor `Sort (u+1)`. `Prop` has some special features, but like the other type\nuniverses, it is closed under the arrow constructor: if we have `p q : Prop`,\nthen `p → q : Prop`.\n\nThere are at least two ways of thinking about propositions as types. To some\nwho take a constructive view of logic and mathematics, this is a faithful\nrendering of what it means to be a proposition: a proposition `p` represents a\nsort of data type, namely, a specification of the type of data that\nconstitutes a proof. A proof of `p` is then simply an object `t : p` of the\nright type.\n\nThose not inclined to this ideology can view it, rather, as a simple coding\ntrick. To each proposition `p` we associate a type that is empty if `p` is\nfalse and has a single element, say `*`, if `p` is true. In the latter case,\nlet us say that (the type associated with) `p` is _inhabited_. It just so\nhappens that the rules for function application and abstraction can\nconveniently help us keep track of which elements of `Prop` are inhabited. So\nconstructing an element `t : p` tells us that `p` is indeed true. You can\nthink of the inhabitant of `p` as being the "fact that `p` is true." A proof\nof `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is\ntrue."\n\nIndeed, if `p : Prop` is any proposition, Lean\'s kernel treats any two\nelements `t1 t2 : p` as being definitionally equal, much the same way as it\ntreats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as\n_proof irrelevance,_ and is consistent with the interpretation in the last\nparagraph. It means that even though we can treat proofs `t : p` as ordinary\nobjects in the language of dependent type theory, they carry no information\nbeyond the fact that `p` is true.\n\nThe two ways we have suggested thinking about the propositions-as-types\nparadigm differ in a fundamental way. From the constructive point of view,\nproofs are abstract mathematical objects that are _denoted_ by suitable\nexpressions in dependent type theory. In contrast, if we think in terms of the\ncoding trick described above, then the expressions themselves do not denote\nanything interesting. Rather, it is the fact that we can write them down and\ncheck that they are well-typed that ensures that the proposition in question\nis true. In other words, the expressions _themselves_ are the proofs.\n\nIn the exposition below, we will slip back and forth between these two ways of\ntalking, at times saying that an expression "constructs" or "produces" or\n"returns" a proof of a proposition, and at other times simply saying that it\n"is" such a proof. This is similar to the way that computer scientists\noccasionally blur the distinction between syntax and semantics by saying, at\ntimes, that a program "computes" a certain function, and at other times\nspeaking as though the program "is" the function in question.\n\nIn any case, all that really matters is the bottom line. To formally express a\nmathematical assertion in the language of dependent type theory, we need to\nexhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a\nterm `t : p`. Lean\'s task, as a proof assistant, is to help us to construct\nsuch a term, `t`, and to verify that it is well-formed and has the correct\ntype.\n\n## Working with Propositions as Types\n\nIn the propositions-as-types paradigm, theorems involving only `→` can be\nproved using lambda abstraction and application. In Lean, the `theorem`\ncommand introduces a new theorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    \n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n\nCompare this proof to the expression `fun x : α => fun y : β => x` of type `α\n→ β → α`, where `α` and `β` are data types. This describes the function that\ntakes arguments `x` and `y` of type `α` and `β`, respectively, and returns\n`x`. The proof of `t1` has the same form, the only difference being that `p`\nand `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of\n`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis\n(trivially) to establish that the conclusion, `p`, is true.\n\nNote that the `theorem` command is really a version of the `def` command:\nunder the propositions and types correspondence, proving the theorem `p → q →\np` is really the same as defining an element of the associated type. To the\nkernel type checker, there is no difference between the two.\n\nThere are a few pragmatic differences between definitions and theorems,\nhowever. In normal circumstances, it is never necessary to unfold the\n"definition" of a theorem; by proof irrelevance, any two proofs of that\ntheorem are definitionally equal. Once the proof of a theorem is complete,\ntypically we only need to know that the proof exists; it doesn\'t matter what\nthe proof is. In light of that fact, Lean tags proofs as _irreducible_ , which\nserves as a hint to the parser (more precisely, the _elaborator_) that there\nis generally no need to unfold them when processing a file. In fact, Lean is\ngenerally able to process and check proofs in parallel, since assessing the\ncorrectness of one proof does not require knowing the details of another.\n\nAs with definitions, the `#print` command will show you the proof of a\ntheorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n    #print t1\n    \n\nNotice that the lambda abstractions `hp : p` and `hq : q` can be viewed as\ntemporary assumptions in the proof of `t1`. Lean also allows us to specify the\ntype of the final term `hp`, explicitly, with a `show` statement:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p :=\n      fun hp : p =>\n      fun hq : q =>\n      show p from hp\n    \n\nAdding such extra information can improve the clarity of a proof and help\ndetect errors when writing a proof. The `show` command does nothing more than\nannotate the type, and, internally, all the presentations of `t1` that we have\nseen produce the same term.\n\nAs with ordinary definitions, we can move the lambda-abstracted variables to\nthe left of the colon:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    #print t1    -- p → q → p\n    \n\nWe can use the theorem `t1` just as a function application:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    axiom hp : p\n    \n    theorem t2 : q → p := t1 hp\n    \n\nThe `axiom` declaration postulates the existence of an element of the given\ntype and may compromise logical consistency. For example, we can use it to\npostulate that the empty type `False` has an element:\n\n    \n    \n    axiom unsound : False\n    -- Everything follows from false\n    theorem ex : 1 = 0 :=\n      False.elim unsound\n    \n\nDeclaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as\nwitnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`\nthat `p` is true yields the theorem `t1 hp : q → p`.\n\nRecall that we can also write theorem `t1` as follows:\n\n    \n    \n    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp\n    \n    #print t1\n    \n\nThe type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the\nassertion "for every pair of propositions `p q`, we have `p → q → p`." For\nexample, we can move all parameters to the right of the colon:\n\n    \n    \n    theorem t1 : ∀ {p q : Prop}, p → q → p :=\n      fun {p q : Prop} (hp : p) (hq : q) => hp\n    \n\nIf `p` and `q` have been declared as variables, Lean will generalize them for\nus automatically:\n\n    \n    \n    variable {p q : Prop}\n    \n    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp\n    \n\nIn fact, by the propositions-as-types correspondence, we can declare the\nassumption `hp` that `p` holds, as another variable:\n\n    \n    \n    variable {p q : Prop}\n    variable (hp : p)\n    \n    theorem t1 : q → p := fun (hq : q) => hp\n    \n\nLean detects that the proof uses `hp` and automatically adds `hp : p` as a\npremise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →\nq → p`. Remember that this type can just as well be written `∀ (p q : Prop)\n(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type\nin which the target does not depend on the bound variable.\n\nWhen we generalize `t1` in such a way, we can then apply it to different pairs\nof propositions, to obtain different instances of the general theorem.\n\n    \n    \n    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp\n    \n    variable (p q r s : Prop)\n    \n    #check t1 p q                -- p → q → p\n    #check t1 r s                -- r → s → r\n    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s\n    \n    variable (h : r → s)\n    #check t1 (r → s) (s → r) h  -- (s → r) → r → s\n    \n\nOnce again, using the propositions-as-types correspondence, the variable `h`\nof type `r → s` can be viewed as the hypothesis, or premise, that `r → s`\nholds.\n\nAs another example, let us consider the composition function discussed in the\nlast chapter, now with propositions instead of types.\n\n    \n    \n    variable (p q r s : Prop)\n    \n    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=\n      fun h₃ : p =>\n      show r from h₁ (h₂ h₃)\n    \n\nAs a theorem of propositional logic, what does `t2` say?\n\nNote that it is often useful to use numeric unicode subscripts, entered as\n`\\0`, `\\1`, `\\2`, ..., for hypotheses, as we did in this example.\n\n## Propositional Logic\n\nLean defines all the standard logical connectives and notation. The\npropositional connectives come with the following notation:\n\nAscii| Unicode| Editor shortcut| Definition  \n---|---|---|---  \nTrue| | | True  \nFalse| | | False  \nNot| ¬| `\\not`, `\\neg`| Not  \n/\\| ∧| `\\and`| And  \n\\/| ∨| `\\or`| Or  \n->| →| `\\to`, `\\r`, `\\imp`|   \n<->| ↔| `\\iff`, `\\lr`| Iff  \n  \nThey all take values in `Prop`.\n\n    \n    \n    variable (p q : Prop)\n    \n    #check p → q → p ∧ q\n    #check ¬p → p ↔ False\n    #check p ∨ q → q ∨ p\n    \n\nThe order of operations is as follows: unary negation `¬` binds most strongly,\nthen `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧\ne` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right\n(nothing changes now that the arguments are elements of `Prop`, instead of\nsome other `Type`), as do the other binary connectives. So if we have `p q r :\nProp`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This\nis just the "curried" form of `p ∧ q → r`.\n\nIn the last chapter we observed that lambda abstraction can be viewed as an\n"introduction rule" for `→`. In the current setting, it shows how to\n"introduce" or establish an implication. Application can be viewed as an\n"elimination rule," showing how to "eliminate" or use an implication in a\nproof. The other propositional connectives are defined in Lean\'s library in\nthe file `Prelude.core` (see [importing\nfiles](./interacting_with_lean.html#importing-files) for more information on\nthe library hierarchy), and each connective comes with its canonical\nintroduction and elimination rules.\n\n### Conjunction\n\nThe expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :\np` and `h2 : q`. It is common to describe `And.intro` as the _and-\nintroduction_ rule. In the next example we use `And.intro` to create a proof\nof `p → q → p ∧ q`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq\n    \n    #check fun (hp : p) (hq : q) => And.intro hp hq\n    \n\nThe `example` command states a theorem without naming it or storing it in the\npermanent context. Essentially, it just checks that the given term has the\nindicated type. It is convenient for illustration, and we will use it often.\n\nThe expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.\nSimilarly, `And.right h` is a proof of `q`. They are commonly known as the\nleft and right _and-elimination_ rules.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : p := And.left h\n    example (h : p ∧ q) : q := And.right h\n    \n\nWe can now prove `p ∧ q → q ∧ p` with the following proof term.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      And.intro (And.right h) (And.left h)\n    \n\nNotice that and-introduction and and-elimination are similar to the pairing\nand projection operations for the Cartesian product. The difference is that\ngiven `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while\n`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is\nanother instance of the Curry-Howard isomorphism, but in contrast to\nimplication and the function space constructor, `∧` and `×` are treated\nseparately in Lean. With the analogy, however, the proof we have just\nconstructed is similar to a function that swaps the elements of a pair.\n\nWe will see in [Chapter Structures and Records](./structures_and_records.html)\nthat certain types in Lean are _structures_ , which is to say, the type is\ndefined with a single canonical _constructor_ which builds an element of the\ntype from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is\nan example: the canonical way to construct an element is to apply `And.intro`\nto suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous\nconstructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the\nrelevant type is an inductive type and can be inferred from the context. In\nparticular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:\n\n    \n    \n    variable (p q : Prop)\n    variable (hp : p) (hq : q)\n    \n    #check (⟨hp, hq⟩ : p ∧ q)\n    \n\nThese angle brackets are obtained by typing `\\<` and `\\>`, respectively.\n\nLean provides another useful syntactic gadget. Given an expression `e` of an\ninductive type `Foo` (possibly applied to some arguments), the notation\n`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of\naccessing functions without opening a namespace. For example, the following\ntwo expressions mean the same thing:\n\n    \n    \n    variable (xs : List Nat)\n    \n    #check List.length xs\n    #check xs.length\n    \n\nAs a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and\n`h.right` for `And.right h`. We can therefore rewrite the sample proof above\nconveniently as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      ⟨h.right, h.left⟩\n    \n\nThere is a fine line between brevity and obfuscation, and omitting information\nin this way can sometimes make a proof harder to read. But for straightforward\nconstructions like the one above, when the type of `h` and the goal of the\nconstruction are salient, the notation is clean and effective.\n\nIt is common to iterate constructions like "And." Lean also allows you to\nflatten nested constructors that associate to the right, so that these two\nproofs are equivalent:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, ⟨h.left, h.right⟩⟩\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, h.left, h.right⟩\n    \n\nThis is often useful as well.\n\n### Disjunction\n\nThe expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof\n`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a\nproof `hq : q`. These are the left and right _or-introduction_ rules.\n\n    \n    \n    variable (p q : Prop)\n    example (hp : p) : p ∨ q := Or.intro_left q hp\n    example (hq : q) : p ∨ q := Or.intro_right p hq\n    \n\nThe _or-elimination_ rule is slightly more complicated. The idea is that we\ncan prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`\nfollows from `q`. In other words, it is a proof by cases. In the expression\n`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :\np → r` and `hqr : q → r`, and produces a proof of `r`. In the following\nexample, we use `Or.elim` to prove `p ∨ q → q ∨ p`.\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h\n        (fun hp : p =>\n          show q ∨ p from Or.intro_right q hp)\n        (fun hq : q =>\n          show q ∨ p from Or.intro_left p hq)\n    \n\nIn most cases, the first argument of `Or.intro_right` and `Or.intro_left` can\nbe inferred automatically by Lean. Lean therefore provides `Or.inr` and\n`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and\n`Or.intro_left _`. Thus the proof term above could be written more concisely:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nNotice that there is enough information in the full expression for Lean to\ninfer the types of `hp` and `hq` as well. But using the type annotations in\nthe longer version makes the proof more readable, and can help catch and debug\nerrors.\n\nBecause `Or` has two constructors, we cannot use anonymous constructor\nnotation. But we can still write `h.elim` instead of `Or.elim h`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nOnce again, you should exercise judgment as to whether such abbreviations\nenhance or diminish readability.\n\n### Negation and Falsity\n\nNegation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by\nderiving a contradiction from `p`. Similarly, the expression `hnp hp` produces\na proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both\nthese rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is\nproduced by typing `\\not` or `\\neg`.)\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hpq : p → q) (hnq : ¬q) : ¬p :=\n      fun hp : p =>\n      show False from hnq (hpq hp)\n    \n\nThe connective `False` has a single elimination rule, `False.elim`, which\nexpresses the fact that anything follows from a contradiction. This rule is\nsometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the\n_principle of explosion_.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)\n    \n\nThe arbitrary fact, `q`, that follows from falsity is an implicit argument in\n`False.elim` and is inferred automatically. This pattern, deriving an\narbitrary fact from contradictory hypotheses, is quite common, and is\nrepresented by `absurd`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := absurd hp hnp\n    \n\nHere, for example, is a proof of `¬p → q → (q → p) → r`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=\n      absurd (hqp hq) hnp\n    \n\nIncidentally, just as `False` has only an elimination rule, `True` has only an\nintroduction rule, `True.intro : true`. In other words, `True` is simply true,\nand has a canonical proof, `True.intro`.\n\n### Logical Equivalence\n\nThe expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`\nand `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from\n`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔\nq`. Here is a proof of `p ∧ q ↔ q ∧ p`:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      Iff.intro\n        (fun h : p ∧ q =>\n         show q ∧ p from And.intro (And.right h) (And.left h))\n        (fun h : q ∧ p =>\n         show p ∧ q from And.intro (And.right h) (And.left h))\n    \n    #check and_swap p q    -- p ∧ q ↔ q ∧ p\n    \n    variable (h : p ∧ q)\n    example : q ∧ p := Iff.mp (and_swap p q) h\n    \n\nWe can use the anonymous constructor notation to construct a proof of `p ↔ q`\nfrom proofs of the forward and backward directions, and we can also use `.`\nnotation with `mp` and `mpr`. The previous examples can therefore be written\nconcisely as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩\n    \n    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h\n    \n\n## Introducing Auxiliary Subgoals\n\nThis is a good place to introduce another device Lean offers to help structure\nlong proofs, namely, the `have` construct, which introduces an auxiliary\nsubgoal in a proof. Here is a small example, adapted from the last section:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      have hq : q := h.right\n      show q ∧ p from And.intro hq hp\n    \n\nInternally, the expression `have h : p := s; t` produces the term `(fun (h :\np) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the\ndesired conclusion assuming `h : p`, and the two are combined by a lambda\nabstraction and application. This simple device is extremely useful when it\ncomes to structuring long proofs, since we can use intermediate `have`\'s as\nstepping stones leading to the final goal.\n\nLean also supports a structured way of reasoning backwards from a goal, which\nmodels the "suffices to show" construction in ordinary mathematics. The next\nexample simply permutes the last two lines in the previous proof.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      suffices hq : q from And.intro hq hp\n      show q from And.right h\n    \n\nWriting `suffices hq : q` leaves us with two goals. First, we have to show\nthat it indeed suffices to show `q`, by proving the original goal of `q ∧ p`\nwith the additional hypothesis `hq : q`. Finally, we have to show `q`.\n\n## Classical Logic\n\nThe introduction and elimination rules we have seen so far are all\nconstructive, which is to say, they reflect a computational understanding of\nthe logical connectives based on the propositions-as-types correspondence.\nOrdinary classical logic adds to this the law of the excluded middle, `p ∨\n¬p`. To use this principle, you have to open the classical namespace.\n\n    \n    \n    open Classical\n    \n    variable (p : Prop)\n    #check em p\n    \n\nIntuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts\nto knowing which is the case. If `RH` represents the Riemann hypothesis, a\nclassical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot\nyet assert either disjunct.\n\nOne consequence of the law of the excluded middle is the principle of double-\nnegation elimination:\n\n    \n    \n    open Classical\n    \n    theorem dne {p : Prop} (h : ¬¬p) : p :=\n      Or.elim (em p)\n        (fun hp : p => hp)\n        (fun hnp : ¬p => absurd hnp h)\n    \n\nDouble-negation elimination allows one to prove any proposition, `p`, by\nassuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In\nother words, double-negation elimination allows one to carry out a proof by\ncontradiction, something which is not generally possible in constructive\nlogic. As an exercise, you might try proving the converse, that is, showing\nthat `em` can be proved from `dne`.\n\nThe classical axioms also give you access to additional patterns of proof that\ncan be justified by appeal to `em`. For example, one can carry out a proof by\ncases:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byCases\n        (fun h1 : p => h1)\n        (fun h1 : ¬p => absurd h1 h)\n    \n\nOr you can carry out a proof by contradiction:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byContradiction\n        (fun h1 : ¬p =>\n         show False from h h1)\n    \n\nIf you are not used to thinking constructively, it may take some time for you\nto get a sense of where classical reasoning is used. It is needed in the\nfollowing example because, from a constructive standpoint, knowing that `p`\nand `q` are not both true does not necessarily tell you which one is false:\n\n    \n    \n    open Classical\n    variable (p q : Prop)\n    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=\n      Or.elim (em p)\n        (fun hp : p =>\n          Or.inr\n            (show ¬q from\n              fun hq : q =>\n              h ⟨hp, hq⟩))\n        (fun hp : ¬p =>\n          Or.inl hp)\n    \n\nWe will see later that there _are_ situations in constructive logic where\nprinciples like excluded middle and double-negation elimination are\npermissible, and Lean supports the use of classical reasoning in such contexts\nwithout relying on excluded middle.\n\nThe full list of axioms that are used in Lean to support classical reasoning\nare discussed in [Axioms and Computation](./axioms_and_computation.html).\n\n## Examples of Propositional Validities\n\nLean\'s standard library contains proofs of many valid statements of\npropositional logic, all of which you are free to use in proofs of your own.\nThe following list includes a number of common identities.\n\nCommutativity:\n\n  1. `p ∧ q ↔ q ∧ p`\n  2. `p ∨ q ↔ q ∨ p`\n\nAssociativity:\n\n  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`\n  4. `(p ∨ q) ∨ r ↔ p ∨ (q �'}], 'model': 'gpt-4o'}}
2025-06-01 01:55:01,777 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:55:01,777 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:55:01,777 - DEBUG - send_request_headers.complete
2025-06-01 01:55:01,777 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:55:01,777 - DEBUG - send_request_body.complete
2025-06-01 01:55:01,777 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:55:06,184 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:55:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'3552'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'3555'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'6953'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'46.092s'), (b'x-request-id', b'req_17c3e94dd2d4483e89d84dbe54ea2a9c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1620295b8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:55:06,184 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:55:06,184 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:55:06,185 - DEBUG - receive_response_body.complete
2025-06-01 01:55:06,185 - DEBUG - response_closed.started
2025-06-01 01:55:06,185 - DEBUG - response_closed.complete
2025-06-01 01:55:06,185 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:55:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '3552', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '3555', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '6953', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '46.092s', 'x-request-id': 'req_17c3e94dd2d4483e89d84dbe54ea2a9c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1620295b8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:55:06,185 - DEBUG - request_id: req_17c3e94dd2d4483e89d84dbe54ea2a9c
2025-06-01 01:55:06,186 - INFO - Raw solution received: ```json
{
  "code": "if a = 0 ∨ b = 0 then false\nelse if (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0) then true\nelse false",
  "proof": "by_cases ha : a = 0\n  case pos.assumption =>\n    simp\n  case neg =>\n    by_cases hb : b = 0\n      case pos.assumption =>\n        simp\n      case neg =>\n        by_cases hab_pos : a > 0 ∧ b < 0\n          case pos.assumption =>\n            simp\n          case neg =>\n            by_cases hab_neg : a < 0 ∧ b > 0\n              case pos.assumption =>\n                simp\n              case neg =>\n                simp [hab_pos, hab_neg, ha, hb]"
}
```
2025-06-01 01:55:06,186 - INFO - <class 'str'>
2025-06-01 01:55:06,186 - INFO - Generated solution: {'code': 'if a = 0 ∨ b = 0 then false\nelse if (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0) then true\nelse false', 'proof': 'by_cases ha : a = 0\n  case pos.assumption =>\n    simp\n  case neg =>\n    by_cases hb : b = 0\n      case pos.assumption =>\n        simp\n      case neg =>\n        by_cases hab_pos : a > 0 ∧ b < 0\n          case pos.assumption =>\n            simp\n          case neg =>\n            by_cases hab_neg : a < 0 ∧ b > 0\n              case pos.assumption =>\n                simp\n              case neg =>\n                simp [hab_pos, hab_neg, ha, hb]'}
2025-06-01 01:55:06,186 - INFO - Lean execution result: Error: Lean executable not found or temp_project directory doesn't exist.
2025-06-01 01:55:06,187 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a = 0 ∨ b = 0 then false\nelse if (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0) then true\nelse false\n\nGenerated Proof:\nby_cases ha : a = 0\n  case pos.assumption =>\n    simp\n  case neg =>\n    by_cases hb : b = 0\n      case pos.assumption =>\n        simp\n      case neg =>\n        by_cases hab_pos : a > 0 ∧ b < 0\n          case pos.assumption =>\n            simp\n          case neg =>\n            by_cases hab_neg : a < 0 ∧ b > 0\n              case pos.assumption =>\n                simp\n              case neg =>\n                simp [hab_pos, hab_neg, ha, hb]\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nError: Lean executable not found or temp_project directory doesn't exist."}], 'model': 'o3-mini'}}
2025-06-01 01:55:06,188 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:55:06,188 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:55:06,188 - DEBUG - send_request_headers.complete
2025-06-01 01:55:06,188 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:55:06,188 - DEBUG - send_request_body.complete
2025-06-01 01:55:06,188 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:55:12,868 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:55:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6452'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6455'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199130'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'261ms'), (b'x-request-id', b'req_e457e564d083aadaba3e97183ddc18a9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b163bbb758fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:55:12,869 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:55:12,869 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:55:12,869 - DEBUG - receive_response_body.complete
2025-06-01 01:55:12,869 - DEBUG - response_closed.started
2025-06-01 01:55:12,869 - DEBUG - response_closed.complete
2025-06-01 01:55:12,870 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:55:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6452', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6455', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199130', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '261ms', 'x-request-id': 'req_e457e564d083aadaba3e97183ddc18a9', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b163bbb758fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:55:12,870 - DEBUG - request_id: req_e457e564d083aadaba3e97183ddc18a9
2025-06-01 01:55:12,870 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': 'The output indicates that the Lean executable could not be found or the temporary project directory is missing. This is typically an environment or configuration issue rather than a problem with the code or proof.', 'error_type': 'unknown', 'suggested_fix': 'Ensure that Lean 4 is properly installed and that your environment is correctly set up. Verify that the Lean executable is in your PATH and that the temp_project (or equivalent directory) exists and is accessible. Once the environment issues are resolved, re-run the code to confirm that the implementation and proof work as intended.', 'retry_strategy': 'Fix the Lean installation environment and make sure all necessary directories exist before retrying the execution of the code.'}
2025-06-01 01:55:12,870 - INFO - Solution generated in 18.67 seconds
2025-06-01 01:55:12,870 - INFO - Generated code length: 5 characters
2025-06-01 01:55:12,870 - INFO - Generated proof length: 5 characters
2025-06-01 01:55:12,870 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 01:55:12,871 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 01:55:12,871 - INFO - Implementation test result: FAIL
2025-06-01 01:55:12,871 - INFO - Executing Lean code with implementation and proof...
2025-06-01 01:55:12,872 - INFO - Full solution test result: FAIL
2025-06-01 01:55:12,872 - ERROR - ❌ Implementation fails unit tests
2025-06-01 01:55:12,872 - ERROR - ❌ Proof has errors
2025-06-01 01:55:12,872 - INFO - 
==================================================
2025-06-01 01:55:12,872 - INFO - Processing task task_id_77...
2025-06-01 01:55:12,872 - INFO - Reading problem description and code template from tasks/task_id_77...
2025-06-01 01:55:12,872 - INFO - Problem description length: 456 characters
2025-06-01 01:55:12,872 - INFO - Reading unit tests from tasks/task_id_77...
2025-06-01 01:55:12,873 - INFO - Unit tests length: 449 characters
2025-06-01 01:55:12,873 - INFO - Running main workflow to generate solution...
2025-06-01 01:55:12,873 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.

-----Input-----
The input consists of:
n: An integer to check for divisibility by 11.

-----Output-----
The output is a Boolean value:
Returns true if the input number is divisible by 11.
Returns false if the input number is not divisible by 11.
2025-06-01 01:55:12,873 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def isDivisibleBy11 (n : Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result is true if n is divisible by 11
def isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=
  -- << SPEC START >>
  n % 11 = 0 ↔ result
  -- << SPEC END >>

theorem isDivisibleBy11_spec_satisfied (n : Int) :
  isDivisibleBy11_spec n (isDivisibleBy11 n) := by
  -- << PROOF START >>
  unfold isDivisibleBy11 isDivisibleBy11_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 01:55:12,903 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59b053d80>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:55:12,903 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:55:12,903 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:55:12,909 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59a7a4fb0>
2025-06-01 01:55:12,909 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x75d59ab535d0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:55:12,917 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59a815220>
2025-06-01 01:55:12,917 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:55:12,917 - DEBUG - send_request_headers.complete
2025-06-01 01:55:12,917 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:55:12,917 - DEBUG - send_request_body.complete
2025-06-01 01:55:12,917 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:55:13,254 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:55:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'39'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5c589d798-652ls'), (b'x-envoy-upstream-service-time', b'42'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999885'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_1af5b489d53929867576bc2d42dbfff3'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Hfxv3_gsC9glJIPgNRZY3XOvmpG_8gn0j2ukE9kGC7U-1748742913-1.0.1.1-_.wUcuBOErdLYS_LtLUlzIirZbDeIA0qGePcLOugmWp6TVleLRS6ufM_tlLGtUxy8Pz4Xr97s4MXnWKzeGnn85QAF_mJiI6c6hq2zp0opIc; path=/; expires=Sun, 01-Jun-25 02:25:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=tUchYyExEVMhiqU04IubRSHmDiH8.FqQEPMa5ZUscg0-1748742913250-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1665bfc93bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:55:13,255 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:55:13,255 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:55:13,255 - DEBUG - receive_response_body.complete
2025-06-01 01:55:13,255 - DEBUG - response_closed.started
2025-06-01 01:55:13,255 - DEBUG - response_closed.complete
2025-06-01 01:55:13,255 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 01:55:13 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '39'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-5c589d798-652ls'), ('x-envoy-upstream-service-time', '42'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999885'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '6ms'), ('x-request-id', 'req_1af5b489d53929867576bc2d42dbfff3'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Hfxv3_gsC9glJIPgNRZY3XOvmpG_8gn0j2ukE9kGC7U-1748742913-1.0.1.1-_.wUcuBOErdLYS_LtLUlzIirZbDeIA0qGePcLOugmWp6TVleLRS6ufM_tlLGtUxy8Pz4Xr97s4MXnWKzeGnn85QAF_mJiI6c6hq2zp0opIc; path=/; expires=Sun, 01-Jun-25 02:25:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=tUchYyExEVMhiqU04IubRSHmDiH8.FqQEPMa5ZUscg0-1748742913250-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b1665bfc93bfe-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 01:55:13,256 - DEBUG - request_id: req_1af5b489d53929867576bc2d42dbfff3
2025-06-01 01:55:13,260 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
 the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
2025-06-01 01:55:13,264 - DEBUG - close.started
2025-06-01 01:55:13,264 - DEBUG - close.complete
2025-06-01 01:55:13,275 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.'}], 'model': 'o3-mini'}}
2025-06-01 01:55:13,276 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:55:13,276 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:55:13,276 - DEBUG - send_request_headers.complete
2025-06-01 01:55:13,276 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:55:13,276 - DEBUG - send_request_body.complete
2025-06-01 01:55:13,276 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:55:18,524 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:55:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5020'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5024'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199585'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'124ms'), (b'x-request-id', b'req_8142366c814f7799c6f1a82ef79e0820'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b16680fad8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:55:18,524 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:55:18,525 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:55:18,525 - DEBUG - receive_response_body.complete
2025-06-01 01:55:18,525 - DEBUG - response_closed.started
2025-06-01 01:55:18,525 - DEBUG - response_closed.complete
2025-06-01 01:55:18,525 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:55:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5020', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5024', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199585', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '124ms', 'x-request-id': 'req_8142366c814f7799c6f1a82ef79e0820', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b16680fad8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:55:18,525 - DEBUG - request_id: req_8142366c814f7799c6f1a82ef79e0820
2025-06-01 01:55:18,526 - INFO - Attempt 1/3
2025-06-01 01:55:18,526 - INFO - Current plan: {
  "plan_summary": "The task is to write a Lean 4 method that checks whether an integer is divisible by 11. The plan involves using Lean’s modulo operator to determine if the remainder when dividing by 11 is zero, which confirms divisibility. We will structure the solution as a Boolean function taking an integer and returning true if it is divisible by 11, otherwise false.",
  "steps": [
    "Define a function that takes an integer (n) as input.",
    "Utilize Lean's modulo operation (n % 11) to compute the remainder when n is divided by 11.",
    "Check if the computed remainder equals zero.",
    "Return true if the remainder is zero, meaning n is divisible by 11; otherwise, return false.",
    "Consider edge cases such as negative integers if needed."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "modulo operator",
    "integer arithmetic",
    "Boolean"
  ],
  "proof_keywords": [
    "divisibility proof",
    "modular arithmetic",
    "remainder",
    "inductive case for integers (if applicable)"
  ],
  "assumptions": [
    "The integer input is of type Int (or a similar integer type) in Lean.",
    "The modulo operation correctly computes remainders for both positive and negative integers.",
    "No additional error handling is required beyond the modulo check."
  ],
  "retry_guidance": "If errors occur regarding the use of the modulo operator or type mismatches, verify that the correct integer type and proper Lean syntax are used. Refine the type declarations and ensure that the modulo operation is valid for negative numbers if such cases need addressing."
}
2025-06-01 01:55:18,526 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "The task is to write a Lean 4 method that checks whether an integer is divisible by 11. The plan involves using Lean’s modulo operator to determine if the remainder when dividing by 11 is zero, which confirms divisibility. We will structure the solution as a Boolean function taking an integer and returning true if it is divisible by 11, otherwise false.",\n  "steps": [\n    "Define a function that takes an integer (n) as input.",\n    "Utilize Lean\'s modulo operation (n % 11) to compute the remainder when n is divided by 11.",\n    "Check if the computed remainder equals zero.",\n    "Return true if the remainder is zero, meaning n is divisible by 11; otherwise, return false.",\n    "Consider edge cases such as negative integers if needed."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "modulo operator",\n    "integer arithmetic",\n    "Boolean"\n  ],\n  "proof_keywords": [\n    "divisibility proof",\n    "modular arithmetic",\n    "remainder",\n    "inductive case for integers (if applicable)"\n  ],\n  "assumptions": [\n    "The integer input is of type Int (or a similar integer type) in Lean.",\n    "The modulo operation correctly computes remainders for both positive and negative integers.",\n    "No additional error handling is required beyond the modulo check."\n  ],\n  "retry_guidance": "If errors occur regarding the use of the modulo operator or type mismatches, verify that the correct integer type and proper Lean syntax are used. Refine the type declarations and ensure that the modulo operation is valid for negative numbers if such cases need addressing."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  n % 11 = 0 ↔ result\n  -- << SPEC END >>\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- << PROOF START >>\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The'}], 'model': 'gpt-4o'}}
2025-06-01 01:55:18,528 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:55:18,528 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:55:18,528 - DEBUG - send_request_headers.complete
2025-06-01 01:55:18,528 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:55:18,528 - DEBUG - send_request_body.complete
2025-06-01 01:55:18,528 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:55:18,939 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sun, 01 Jun 2025 01:55:18 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'373'), (b'Connection', b'keep-alive'), (b'retry-after', b'2'), (b'retry-after-ms', b'1284'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'13178'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'33.643s'), (b'x-request-id', b'req_dedda63e685357c5ae0a305dc06a0cf8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1688dc078fcd-BOM'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:55:18,939 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 01:55:18,939 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:55:18,939 - DEBUG - receive_response_body.complete
2025-06-01 01:55:18,939 - DEBUG - response_closed.started
2025-06-01 01:55:18,940 - DEBUG - response_closed.complete
2025-06-01 01:55:18,940 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sun, 01 Jun 2025 01:55:18 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '373', 'connection': 'keep-alive', 'retry-after': '2', 'retry-after-ms': '1284', 'vary': 'Origin', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '13178', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '33.643s', 'x-request-id': 'req_dedda63e685357c5ae0a305dc06a0cf8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1688dc078fcd-BOM', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:55:18,940 - DEBUG - request_id: req_dedda63e685357c5ae0a305dc06a0cf8
2025-06-01 01:55:18,940 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/openai/_base_client.py", line 1007, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.12/dist-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-06-01 01:55:18,941 - DEBUG - Retrying due to status code 429
2025-06-01 01:55:18,941 - DEBUG - 2 retries left
2025-06-01 01:55:18,941 - INFO - Retrying request to /chat/completions in 1.284000 seconds
2025-06-01 01:55:20,225 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "The task is to write a Lean 4 method that checks whether an integer is divisible by 11. The plan involves using Lean’s modulo operator to determine if the remainder when dividing by 11 is zero, which confirms divisibility. We will structure the solution as a Boolean function taking an integer and returning true if it is divisible by 11, otherwise false.",\n  "steps": [\n    "Define a function that takes an integer (n) as input.",\n    "Utilize Lean\'s modulo operation (n % 11) to compute the remainder when n is divided by 11.",\n    "Check if the computed remainder equals zero.",\n    "Return true if the remainder is zero, meaning n is divisible by 11; otherwise, return false.",\n    "Consider edge cases such as negative integers if needed."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "modulo operator",\n    "integer arithmetic",\n    "Boolean"\n  ],\n  "proof_keywords": [\n    "divisibility proof",\n    "modular arithmetic",\n    "remainder",\n    "inductive case for integers (if applicable)"\n  ],\n  "assumptions": [\n    "The integer input is of type Int (or a similar integer type) in Lean.",\n    "The modulo operation correctly computes remainders for both positive and negative integers.",\n    "No additional error handling is required beyond the modulo check."\n  ],\n  "retry_guidance": "If errors occur regarding the use of the modulo operator or type mismatches, verify that the correct integer type and proper Lean syntax are used. Refine the type declarations and ensure that the modulo operation is valid for negative numbers if such cases need addressing."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  n % 11 = 0 ↔ result\n  -- << SPEC END >>\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- << PROOF START >>\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The'}], 'model': 'gpt-4o'}}
2025-06-01 01:55:20,227 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:55:20,227 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:55:20,227 - DEBUG - send_request_headers.complete
2025-06-01 01:55:20,227 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:55:20,227 - DEBUG - send_request_body.complete
2025-06-01 01:55:20,227 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:55:22,871 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:55:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2338'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2342'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'150'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'59.698s'), (b'x-request-id', b'req_f63f6633df72cd33282a8430133ec172'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b16937b158fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:55:22,872 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:55:22,872 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:55:22,873 - DEBUG - receive_response_body.complete
2025-06-01 01:55:22,873 - DEBUG - response_closed.started
2025-06-01 01:55:22,873 - DEBUG - response_closed.complete
2025-06-01 01:55:22,873 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:55:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2338', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2342', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '150', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '59.698s', 'x-request-id': 'req_f63f6633df72cd33282a8430133ec172', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b16937b158fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:55:22,873 - DEBUG - request_id: req_f63f6633df72cd33282a8430133ec172
2025-06-01 01:55:22,873 - INFO - Raw solution received: ```json
{
  "code": "n % 11 == 0",
  "proof": "\n  by_cases h : n % 11 = 0\n  simp [h]\n  exact h\n  simp [h]",
  "proof": "\n\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  by_cases h : n % 11 = 0\n  simp [h]\n  exact h\n  simp [h]\n\n"
}
```
2025-06-01 01:55:22,873 - INFO - <class 'str'>
2025-06-01 01:55:22,873 - INFO - Generated solution: {'code': 'n % 11 == 0', 'proof': '\n\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  by_cases h : n % 11 = 0\n  simp [h]\n  exact h\n  simp [h]\n\n'}
2025-06-01 01:55:22,874 - INFO - Lean execution result: Error: Lean executable not found or temp_project directory doesn't exist.
2025-06-01 01:55:22,875 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  n % 11 = 0 ↔ result\n  -- << SPEC END >>\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- << PROOF START >>\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nn % 11 == 0\n\nGenerated Proof:\n\n\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  by_cases h : n % 11 = 0\n  simp [h]\n  exact h\n  simp [h]\n\n\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nError: Lean executable not found or temp_project directory doesn't exist."}], 'model': 'o3-mini'}}
2025-06-01 01:55:22,875 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:55:22,875 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:55:22,876 - DEBUG - send_request_headers.complete
2025-06-01 01:55:22,876 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:55:22,876 - DEBUG - send_request_body.complete
2025-06-01 01:55:22,876 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:55:27,884 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:55:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4791'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4794'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199315'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'205ms'), (b'x-request-id', b'req_c5bda051f869f710ddf5571fb3c883bc'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b16a40f388fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:55:27,884 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:55:27,884 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:55:27,885 - DEBUG - receive_response_body.complete
2025-06-01 01:55:27,885 - DEBUG - response_closed.started
2025-06-01 01:55:27,885 - DEBUG - response_closed.complete
2025-06-01 01:55:27,885 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:55:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4791', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4794', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199315', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '205ms', 'x-request-id': 'req_c5bda051f869f710ddf5571fb3c883bc', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b16a40f388fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:55:27,885 - DEBUG - request_id: req_c5bda051f869f710ddf5571fb3c883bc
2025-06-01 01:55:27,885 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': 'The error message indicates that the Lean executable or the temp_project directory was not found. This suggests that the Lean environment is not set up correctly rather than an issue with the generated code or proof. The provided implementation and proof might be correct, but they could not be executed due to the environment misconfiguration.', 'error_type': 'unknown', 'suggested_fix': 'Ensure that Lean 4 is properly installed and that the temp_project directory exists. Verify your environment settings and path configurations so that the Lean executable can be located and run.', 'retry_strategy': 'Set up and configure your Lean environment correctly, then re-run the proof verification. If further errors arise related to the code or proof itself, review the generated code and proof details.'}
2025-06-01 01:55:27,885 - INFO - Solution generated in 15.01 seconds
2025-06-01 01:55:27,886 - INFO - Generated code length: 5 characters
2025-06-01 01:55:27,886 - INFO - Generated proof length: 5 characters
2025-06-01 01:55:27,886 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 01:55:27,886 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 01:55:27,887 - INFO - Implementation test result: FAIL
2025-06-01 01:55:27,887 - INFO - Executing Lean code with implementation and proof...
2025-06-01 01:55:27,887 - INFO - Full solution test result: FAIL
2025-06-01 01:55:27,888 - ERROR - ❌ Implementation fails unit tests
2025-06-01 01:55:27,888 - ERROR - ❌ Proof has errors
2025-06-01 01:55:27,888 - INFO - 
==================================================
2025-06-01 01:55:27,888 - INFO - Processing task task_id_127...
2025-06-01 01:55:27,888 - INFO - Reading problem description and code template from tasks/task_id_127...
2025-06-01 01:55:27,888 - INFO - Problem description length: 342 characters
2025-06-01 01:55:27,888 - INFO - Reading unit tests from tasks/task_id_127...
2025-06-01 01:55:27,888 - INFO - Unit tests length: 219 characters
2025-06-01 01:55:27,889 - INFO - Running main workflow to generate solution...
2025-06-01 01:55:27,889 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.

-----Input-----
The input consists of:
a: The first integer.
b: The second integer.

-----Output-----
The output is an integer:
Returns the product of the two input integers (a * b).
2025-06-01 01:55:27,889 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def multiply (a : Int) (b : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result should be the product of the two input integers
def multiply_spec (a : Int) (b : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  result = a * b
  -- << SPEC END >>

theorem multiply_spec_satisfied (a : Int) (b : Int) :
  multiply_spec a b (multiply a b) := by
  -- << PROOF START >>
  unfold multiply multiply_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 01:55:27,919 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59a7c49a0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.\n\n-----Input-----\nThe input consists of:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the product of the two input integers (a * b).', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:55:27,920 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:55:27,920 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:55:27,926 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59b046990>
2025-06-01 01:55:27,926 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x75d59ac7b2d0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:55:27,934 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59ab4d280>
2025-06-01 01:55:27,934 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:55:27,934 - DEBUG - send_request_headers.complete
2025-06-01 01:55:27,935 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:55:27,935 - DEBUG - send_request_body.complete
2025-06-01 01:55:27,935 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:55:28,633 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:55:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'78'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-55694c5655-v5l7k'), (b'x-envoy-upstream-service-time', b'81'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999915'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'x-request-id', b'req_3baec76322fd0fe0a64f56a3887a39c1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PUq4y8jaYpPkPXUt.GUd_t30SVZAAmn0gMqQnUFyC1o-1748742928-1.0.1.1-w2SIvaSIbS_vrd0o4Ub2dNZBOguVMTAwGnEgLZgVmyUruuIYLz8hOMNgyOPT5tCVKUL3W6dvfQXcN7_tR4a4VYVzl7CviDq4QdB1sxvDaK0; path=/; expires=Sun, 01-Jun-25 02:25:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Qs21MiY19YkXn0PSM2Sv0ZzrLpP.13ECjWLGwFDDWXw-1748742928629-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b16c39f233bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:55:28,634 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:55:28,634 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:55:28,634 - DEBUG - receive_response_body.complete
2025-06-01 01:55:28,634 - DEBUG - response_closed.started
2025-06-01 01:55:28,634 - DEBUG - response_closed.complete
2025-06-01 01:55:28,635 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 01:55:28 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '78'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-55694c5655-v5l7k'), ('x-envoy-upstream-service-time', '81'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999915'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '5ms'), ('x-request-id', 'req_3baec76322fd0fe0a64f56a3887a39c1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=PUq4y8jaYpPkPXUt.GUd_t30SVZAAmn0gMqQnUFyC1o-1748742928-1.0.1.1-w2SIvaSIbS_vrd0o4Ub2dNZBOguVMTAwGnEgLZgVmyUruuIYLz8hOMNgyOPT5tCVKUL3W6dvfQXcN7_tR4a4VYVzl7CviDq4QdB1sxvDaK0; path=/; expires=Sun, 01-Jun-25 02:25:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Qs21MiY19YkXn0PSM2Sv0ZzrLpP.13ECjWLGwFDDWXw-1748742928629-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b16c39f233bfe-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 01:55:28,635 - DEBUG - request_id: req_3baec76322fd0fe0a64f56a3887a39c1
2025-06-01 01:55:28,642 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Interacting with Lean

You are now familiar with the fundamentals of dependent type theory, both as a
language for defining mathematical objects and a language for constructing
proofs. The one thing you are missing is a mechanism for defining new data
types. We will fill this gap in the next chapter, which introduces the notion
of an _inductive data type_. But first, in this chapter, we take a break from
the mechanics of type theory to explore some pragmatic aspects of interacting
with Lean.

Not all of the information found here will be useful to you right away. We
recommend skimming this section to get a sense of Lean's features, and then
returning to it as necessary.

## Importing Files

The goal of Lean's front end is to interpret user input, construct formal
expressions, and check that they are well-formed and type-correct. Lean also
supports the use of various editors, which provide continuous checking and
feedback. More information can be found on the Lean [documentation
pages](https://lean-lang.org/documentation/).

The definitions and theorems in Lean's standard library are spread across
multiple files. Users may also wish to make use of additional libraries, or
develop their own projects across multiple files. When Lean starts, it
automatically imports the contents of the library `Init` folder, which
includes a number of fundamental definitions and constructions. As a result,
most of the examples we present here work "out of the box."

If you want to use additional files, however, they need to be imported
manually, via an `import` statement at the beginning of a file. The command

    
    
    import Bar.Baz.Blah
    

imports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted
relative to the Lean _search path_. Information as to how the search path is
determined can be found on the [documentation pages](https://lean-
lang.org/documentation/). By default, it includes the standard library
directory, and (in some contexts) the root of the user's local project.

Importing is transitive. In other words, if you import `Foo` and `Foo` imports
`Bar`, then you also have access to the contents of `Bar`, and do not need to
import it explicitly.

## More on Sections

Lean provides various sectioning mechanisms to help structure a theory. You
saw in [Variables and Sections](./dependent_type_theory.html#variables-and-
sections) that the `section` command makes it possible not only to group
together elements of a theory that go together, but also to declare variables
that are inserted as arguments to theorems and definitions, as necessary.
Remember that the point of the `variable` command is to declare variables for
use in theorems, as in the following example:

    
    
    section
    variable (x y : Nat)
    
    def double := x + x
    
    #check double y
    #check double (2 * x)
    
    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm
    
    theorem t1 : double (x + y) = double x + double y := by
      simp [double]
    
    #check t1 y
    #check t1 (2 * x)
    
    theorem t2 : double (x * y) = double x * y := by
      simp [double, Nat.add_mul]
    
    end
    

The definition of `double` does not have to declare `x` as an argument; Lean
detects the dependence and inserts it automatically. Similarly, Lean detects
the occurrence of `x` in `t1` and `t2`, and inserts it automatically there,
too. Note that `double` does _not_ have `y` as argument. Variables are only
included in declarations where they are actually used.

## More on Namespaces

In Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We
saw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean
provides mechanisms for working with hierarchical names. The command
`namespace foo` causes `foo` to be prepended to the name of each definition
and theorem until `end foo` is encountered. The command `open foo` then
creates temporary _aliases_ to definitions and theorems that begin with prefix
`foo`.

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    
    open Foo
    
    #check bar
    #check Foo.bar
    

The following definition

    
    
    def Foo.bar : Nat := 1
    

is treated as a macro, and expands to

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    

Although the names of theorems and definitions have to be unique, the aliases
that identify them do not. When we open a namespace, an identifier may be
ambiguous. Lean tries to use type information to disambiguate the meaning in
context, but you can always disambiguate by giving the full name. To that end,
the string `_root_` is an explicit description of the empty prefix.

    
    
    def String.add (a b : String) : String :=
      a ++ b
    
    def Bool.add (a b : Bool) : Bool :=
      a != b
    
    def add (α β : Type) : Type := Sum α β
    
    open Bool
    open String
    -- #check add -- ambiguous
    #check String.add           -- String → String → String
    #check Bool.add             -- Bool → Bool → Bool
    #check _root_.add           -- Type → Type → Type
    
    #check add "hello" "world"  -- String
    #check add true false       -- Bool
    #check add Nat Nat          -- Type
    

We can prevent the shorter alias from being created by using the `protected`
keyword:

    
    
    protected def Foo.bar : Nat := 1
    
    open Foo
    
    -- #check bar -- error
    #check Foo.bar
    

This is often used for names like `Nat.rec` and `Nat.recOn`, to prevent
overloading of common names.

The `open` command admits variations. The command

    
    
    open Nat (succ zero gcd)
    #check zero     -- Nat
    #eval gcd 15 6  -- 3
    

creates aliases for only the identifiers listed. The command

    
    
    open Nat hiding succ gcd
    #check zero     -- Nat
    -- #eval gcd 15 6  -- error
    #eval Nat.gcd 15 6  -- 3
    

creates aliases for everything in the `Nat` namespace _except_ the identifiers
listed.

    
    
    open Nat renaming mul → times, add → plus
    #eval plus (times 2 2) 3  -- 7
    

creates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.

It is sometimes useful to `export` aliases from one namespace to another, or
to the top level. The command

    
    
    export Nat (succ add sub)
    

creates aliases for `succ`, `add`, and `sub` in the current namespace, so that
whenever the namespace is open, these aliases are available. If this command
is used outside a namespace, the aliases are exported to the top level.

## Attributes

The main function of Lean is to translate user input to formal expressions
that are checked by the kernel for correctness and then stored in the
environment for later use. But some commands have other effects on the
environment, either assigning attributes to objects in the environment,
defining notation, or declaring instances of type classes, as described in
[Chapter Type Classes](./type_classes.html). Most of these commands have
global effects, which is to say, they remain in effect not only in the current
file, but also in any file that imports it. However, such commands often
support the `local` modifier, which indicates that they only have effect until
the current `section` or `namespace` is closed, or until the end of the
current file.

In [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw
that theorems can be annotated with the `[simp]` attribute, which makes them
available for use by the simplifier. The following example defines the prefix
relation on lists, proves that this relation is reflexive, and assigns the
`[simp]` attribute to that theorem.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    

The simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to
`True`.

One can also assign the attribute any time after the definition takes place:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [simp] List.isPrefix_self
    

In all these cases, the attribute remains in effect in any file that imports
the one in which the declaration occurs. Adding the `local` modifier restricts
the scope:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    section
    
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [local simp] List.isPrefix_self
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    
    end
    
    -- Error:
    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by
    --  simp
    

For another example, we can use the `instance` command to assign the notation
`≤` to the `isPrefix` relation. That command, which will be explained in
[Chapter Type Classes](./type_classes.html), works by assigning an
`[instance]` attribute to the associated definition.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    instance : LE (List α) where
      le := isPrefix
    
    theorem List.isPrefix_self (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    

That assignment can also be made local:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    def instLe : LE (List α) :=
      { le := isPrefix }
    
    section
    attribute [local instance] instLe
    
    example (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    
    end
    
    -- Error:
    -- example (as : List α) : as ≤ as :=
    --  ⟨[], by simp⟩
    

In Section Notation below, we will discuss Lean's mechanisms for defining
notation, and see that they also support the `local` modifier. However, in
Section Setting Options, we will discuss Lean's mechanisms for setting
options, which does _not_ follow this pattern: options can _only_ be set
locally, which is to say, their scope is always restricted to the current
section or current file.

## More on Implicit Arguments

In [Section Implicit Arguments](./dependent_type_theory.html#implicit-
arguments), we saw that if Lean displays the type of a term `t` as `{x : α} →
β x`, then the curly brackets indicate that `x` has been marked as an
_implicit argument_ to `t`. This means that whenever you write `t`, a
placeholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you
don't want that to happen, you have to write `@t` instead.

Notice that implicit arguments are inserted eagerly. Suppose we define a
function `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,
when we write the expression `f 7` without further arguments, it is parsed as
`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that
a placeholder should only be added _before_ a subsequent explicit argument.
This annotation can also be written using as `⦃y : Nat⦄`, where the unicode
brackets are entered as `\{{` and `\}}`, respectively. With this annotation,
the expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as
`f 7 _ 3`, just as it would be with the strong annotation.

To illustrate the difference, consider the following example, which shows that
a reflexive euclidean relation is both symmetric and transitive.

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b : α}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
     th2 (th1 reflr @euclr) @euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3
    

The results are broken down into small steps: `th1` shows that a relation that
is reflexive and euclidean is symmetric, and `th2` shows that a relation that
is symmetric and euclidean is transitive. Then `th3` combines the two results.
But notice that we have to manually disable the implicit arguments in `euclr`,
because otherwise too many implicit arguments are inserted. The problem goes
away if we use weak implicit arguments:

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b : α}}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
      th2 (th1 reflr euclr) euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- euclidean r
    

There is a third kind of implicit argument that is denoted with square
brackets, `[` and `]`. These are used for type classes, as explained in
[Chapter Type Classes](./type_classes.html).

## Notation

Identifiers in Lean can include any alphanumeric characters, including Greek
characters (other than ∀ , Σ , and λ , which, as we have seen, have a special
meaning in the dependent type theory). They can also include subscripts, which
can be entered by typing `\_` followed by the desired subscripted character.

Lean's parser is extensible, which is to say, we can define new notation.

Lean's syntax can be extended and customized by users at every level, ranging
from basic "mixfix" notations to custom elaborators. In fact, all builtin
syntax is parsed and processed using the same mechanisms and APIs open to
users. In this section, we will describe and explain the various extension
points.

While introducing new notations is a relatively rare feature in programming
languages and sometimes even frowned upon because of its potential to obscure
code, it is an invaluable tool in formalization for expressing established
conventions and notations of the respective field succinctly in code. Going
beyond basic notations, Lean's ability to factor out common boilerplate code
into (well-behaved) macros and to embed entire custom domain specific
languages (DSLs) to textually encode subproblems efficiently and readably can
be of great benefit to both programmers and proof engineers alike.

### Notations and Precedence

The most basic syntax extension commands allow introducing new (or overloading
existing) prefix, infix, and postfix operators.

    
    
    infixl:65   " + " => HAdd.hAdd  -- left-associative
    infix:50    " = " => Eq         -- non-associative
    infixr:80   " ^ " => HPow.hPow  -- right-associative
    prefix:100  "-"   => Neg.neg
    set_option quotPrecheck false
    postfix:max "⁻¹"  => Inv.inv
    

After the initial command name describing the operator kind (its "fixity"), we
give the _parsing precedence_ of the operator preceded by a colon `:`, then a
new or existing token surrounded by double quotes (the whitespace is used for
pretty printing), then the function this operator should be translated to
after the arrow `=>`.

The precedence is a natural number describing how "tightly" an operator binds
to its arguments, encoding the order of operations. We can make this more
precise by looking at the commands the above unfold to:

    
    
    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs
    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs
    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs
    notation:100 "-" arg:100 => Neg.neg arg
    set_option quotPrecheck false
    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024
    

It turns out that all commands from the first code block are in fact command
_macros_ translating to the more general `notation` command. We will learn
about writing such macros below. Instead of a single token, the `notation`
command accepts a mixed sequence of tokens and named term placeholders with
precedences, which can be referenced on the right-hand side of `=>` and will
be replaced by the respective term parsed at that position. A placeholder with
precedence `p` accepts only notations with precedence at least `p` in that
place. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +
(b + c)` because the right-hand side operand of an `infixl` notation has
precedence one greater than the notation itself. In contrast, `infixr` reuses
the notation's precedence for the right-hand side operand, so `a ^ b ^ c`
_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to
introduce an infix notation like

    
    
    set_option quotPrecheck false
    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs
    

where the precedences do not sufficiently determine associativity, Lean's
parser will default to right associativity. More precisely, Lean's parser
follows a local _longest parse_ rule in the presence of ambiguous grammars:
when parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue
parsing as long as possible (as the current precedence allows), not stopping
after `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~
c)`.

As mentioned above, the `notation` command allows us to define arbitrary
_mixfix_ syntax freely mixing tokens and placeholders.

    
    
    set_option quotPrecheck false
    notation:max "(" e ")" => e
    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ
    

Placeholders without precedence default to `0`, i.e. they accept notations of
any precedence in their place. If two notations overlap, we again apply the
longest parse rule:

    
    
    notation:65 a " + " b:66 " + " c:66 => a + b - c
    #eval 1 + 2 + 3  -- 0
    

The new notation is preferred to the binary notation since the latter, before
chaining, would stop parsing after `1 + 2`. If there are multiple notations
accepting the same longest parse, the choice will be delayed until
elaboration, which will fail unless exactly one overload is type-correct.

## Coercions

In Lean, the type of natural numbers, `Nat`, is different from the type of
integers, `Int`. But there is a function `Int.ofNat` that embeds the natural
numbers in the integers, meaning that we can view any natural number as an
integer, when needed. Lean has mechanisms to detect and insert _coercions_ of
this sort.

    
    
    variable (m n : Nat)
    variable (i j : Int)
    
    #check i + m      -- i + Int.ofNat m : Int
    #check i + m + j  -- i + Int.ofNat m + j : Int
    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int
    

## Displaying Information

There are a number of ways in which you can query Lean for information about
its current state and the objects and theorems that are available in the
current context. You have already seen two of the most common ones, `#check`
and `#eval`. Remember that `#check` is often used in conjunction with the `@`
operator, which makes all of the arguments to a theorem or definition
explicit. In addition, you can use the `#print` command to get information
about any identifier. If the identifier denotes a definition or theorem, Lean
prints the type of the symbol, and its definition. If it is a constant or an
axiom, Lean indicates that fact, and shows the type.

    
    
    -- examples with equality
    #check Eq
    #check @Eq
    #check Eq.symm
    #check @Eq.symm
    
    #print Eq.symm
    
    -- examples with And
    #check And
    #check And.intro
    #check @And.intro
    
    -- a user-defined function
    def foo {α : Type u} (x : α) : α := x
    
    #check foo
    #check @foo
    #print foo
    

## Setting Options

Lean maintains a number of internal variables that can be set by users to
control its behavior. The syntax for doing so is as follows:

    
    
    set_option <name> <value>
    

One very useful family of options controls the way Lean's _pretty- printer_
displays terms. The following options take an input of true or false:

    
    
    pp.explicit  : display implicit arguments
    pp.universes : display hidden universe parameters
    pp.notation  : display output using defined notations
    

As an example, the following settings yield much longer output:

    
    
    set_option pp.explicit true
    set_option pp.universes true
    set_option pp.notation false
    
    #check 2 + 2 = 4
    #reduce (fun x => x + 2) = (fun x => x + 3)
    #check (fun x => x + 1) 1
    

The command `set_option pp.all true` carries out these settings all at once,
whereas `set_option pp.all false` reverts to the previous values. Pretty
printing additional information is often very useful when you are debugging a
proof, or trying to understand a cryptic error message. Too much information
can be overwhelming, though, and Lean's defaults are generally sufficient for
ordinary interactions.

## Using the Library

To use Lean effectively you will inevitably need to make use of definitions
and theorems in the library. Recall that the `import` command at the beginning
of a file imports previously compiled results from other files, and that
importing is transitive; if you import `Foo` and `Foo` imports `Bar`, then the
definitions and theorems from `Bar` are available to you as well. But the act
of opening a namespace, which provides shorter names, does not carry over. In
each file, you need to open the namespaces you wish to use.

In general, it is important for you to be familiar with the library and its
contents, so you know what theorems, definitions, notations, and resources are
available to you. Below we will see that Lean's editor modes can also help you
find things you need, but studying the contents of the library directly is
often unavoidable. Lean's standard library can be found online, on GitHub:

  * <https://github.com/leanprover/lean4/tree/master/src/Init>

  * <https://github.com/leanprover/std4/tree/main/Std>

You can see the contents of these directories and files using GitHub's browser
interface. If you have installed Lean on your own computer, you can find the
library in the `lean` folder, and explore it with your file manager. Comment
headers at the top of each file provide additional information.

Lean's library developers follow general naming guidelines to make it easier
to guess the name of a theorem you need, or to find it using tab completion in
editors with a Lean mode that supports this, which is discussed in the next
section. Identifiers are generally `camelCase`, and types are `CamelCase`. For
theorem names, we rely on descriptive names where the different components are
separated by `_`s. Often the name of theorem simply describes the conclusion:

    
    
    #check Nat.succ_ne_zero
    #check Nat.zero_add
    #check Nat.mul_one
    #check Nat.le_of_succ_le_succ
    

Remember that identifiers in Lean can be organized into hierarchical
namespaces. For example, the theorem named `le_of_succ_le_succ` in the
namespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name
is made available by the command `open Nat` (for names not marked as
`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)
and [Chapter Structures and Records](./structures_and_records.html) that
defining structures and inductive data types in Lean generates associated
operations, and these are stored in a namespace with the same name as the type
under definition. For example, the product type comes with the following
operations:

    
    
    #check @Prod.mk
    #check @Prod.fst
    #check @Prod.snd
    #check @Prod.rec
    

The first is used to construct a pair, whereas the next two, `Prod.fst` and
`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another
mechanism for defining functions on a product in terms of a function on the
two components. Names like `Prod.rec` are _protected_ , which means that one
has to use the full name even when the `Prod` namespace is open.

With the propositions as types correspondence, logical connectives are also
instances of inductive types, and so we tend to use dot notation for them as
well:

    
    
    #check @And.intro
    #check @And.casesOn
    #check @And.left
    #check @And.right
    #check @Or.inl
    #check @Or.inr
    #check @Or.elim
    #check @Exists.intro
    #check @Exists.elim
    #check @Eq.refl
    #check @Eq.subst
    

## Auto Bound Implicit Arguments

In the previous section, we have shown how implicit arguments make functions
more convenient to use. However, functions such as `compose` are still quite
verbose to define. Note that the universe polymorphic `compose` is even more
verbose than the one previously defined.

    
    
    universe u v w
    def compose {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

You can avoid the `universe` command by providing the universe parameters when
defining `compose`.

    
    
    def compose.{u, v, w}
                {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

Lean 4 supports a new feature called _auto bound implicit arguments_. It makes
functions such as `compose` much more convenient to write. When Lean processes
the header of a declaration, any unbound identifier is automatically added as
an implicit argument _if_ it is a single lower case or greek letter. With this
feature we can write `compose` as

    
    
    def compose (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    
    #check @compose
    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ
    

Note that Lean inferred a more general type using `Sort` instead of `Type`.

Although we love this feature and use it extensively when implementing Lean,
we realize some users may feel uncomfortable with it. Thus, you can disable it
using the command `set_option autoImplicit false`.

    
    
    set_option autoImplicit false
    /- The following definition produces `unknown identifier` errors -/
    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=
    --   g (f x)
    

## Implicit Lambdas

In Lean 3 stdlib, we find many
[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)
of the dreadful `@`+`_` idiom. It is often used when the expected type is a
function type with implicit arguments, and we have a constant (`reader_t.pure`
in the example) which also takes implicit arguments. In Lean 4, the elaborator
automatically introduces lambdas for consuming implicit arguments. We are
still exploring this feature and analyzing its impact, but the experience so
far has been very positive. Here is the example from the link above using Lean
4 implicit lambdas.

    
    
    variable (ρ : Type) (m : Type → Type) [Monad m]
    instance : Monad (ReaderT ρ m) where
      pure := ReaderT.pure
      bind := ReaderT.bind
    

Users can disable the implicit lambda feature by using `@` or writing a lambda
expression with `{}` or `[]` binder annotations. Here are few examples

    
    
    namespace ex2
    def id1 : {α : Type} → α → α :=
      fun x => x
    
    def listId : List ({α : Type} → α → α) :=
      (fun x => x) :: []
    
    -- In this example, implicit lambda introduction has been disabled because
    -- we use `@` before `fun`
    def id2 : {α : Type} → α → α :=
      @fun α (x : α) => id1 x
    
    def id3 : {α : Type} → α → α :=
      @fun α x => id1 x
    
    def id4 : {α : Type} → α → α :=
      fun x => id1 x
    
    -- In this example, implicit lambda introduction has been disabled
    -- because we used the binder annotation `{...}`
    def id5 : {α : Type} → α → α :=
      fun {α} x => id1 x
    end ex2
    

## Sugar for Simple Functions

In Lean 3, we can create simple functions from infix operators by using
parentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we
generalize this notation using `·` as a placeholder. Here are a few examples:

    
    
    namespace ex3
    #check (· + 1)
    -- fun a => a + 1
    #check (2 - ·)
    -- fun a => 2 - a
    #eval [1, 2, 3, 4, 5].foldl (·*·) 1
    -- 120
    
    def f (x y z : Nat) :=
      x + y + z
    
    #check (f · 1 ·)
    -- fun a b => f a 1 b
    
    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)
    -- [1, 3, 5]
    end ex3
    

As in Lean 3, the notation is activated using parentheses, and the lambda
abstraction is created by collecting the nested `·`s. The collection is
interrupted by nested parentheses. In the following example, two different
lambda expressions are created.

    
    
    #check (Prod.mk · (· + 1))
    -- fun a => (a, fun b => b + 1)
    

## Named Arguments

Named arguments enable you to specify an argument for a parameter by matching
the argument with its name rather than with its position in the parameter
list. If you don't remember the order of the parameters but know their names,
you can send the arguments in any order. You may also provide the value for an
implicit parameter when
 modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
2025-06-01 01:55:28,656 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.\n\n-----Input-----\nThe input consists of:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the product of the two input integers (a * b).'}], 'model': 'o3-mini'}}
2025-06-01 01:55:28,657 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:55:28,657 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:55:28,658 - DEBUG - send_request_headers.complete
2025-06-01 01:55:28,658 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:55:28,658 - DEBUG - send_request_body.complete
2025-06-01 01:55:28,658 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:55:32,845 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:55:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'3962'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'3968'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199613'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'115ms'), (b'x-request-id', b'req_790b6668a3d6cf8db6a8a3a1006d35b9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b16c82ee88fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:55:32,845 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:55:32,846 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:55:32,846 - DEBUG - receive_response_body.complete
2025-06-01 01:55:32,846 - DEBUG - response_closed.started
2025-06-01 01:55:32,846 - DEBUG - response_closed.complete
2025-06-01 01:55:32,846 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:55:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '3962', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '3968', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199613', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '115ms', 'x-request-id': 'req_790b6668a3d6cf8db6a8a3a1006d35b9', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b16c82ee88fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:55:32,846 - DEBUG - request_id: req_790b6668a3d6cf8db6a8a3a1006d35b9
2025-06-01 01:55:32,847 - INFO - Attempt 1/3
2025-06-01 01:55:32,847 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that takes two integers as input and returns their product using the built-in multiplication operator.",
  "steps": [
    "Define the function signature with two integer parameters and integer return type, for example: multiply : Int → Int → Int.",
    "Inside the function, use the built-in multiplication operator (*) to multiply the inputs.",
    "Return the computed product.",
    "(Optional) Add tests to verify the implementation works for positive and negative integers."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "multiplication",
    "Int",
    "operator *"
  ],
  "proof_keywords": [
    "basic arithmetic",
    "definition evaluation"
  ],
  "assumptions": [
    "The multiplication operator (*) is correctly defined for the Int type in Lean 4.",
    "No additional error handling is needed as the built-in operator manages all cases."
  ],
  "retry_guidance": "If errors occur, verify that the function signature correctly matches the intended types and review the operator usage for integer multiplication."
}
2025-06-01 01:55:32,848 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that takes two integers as input and returns their product using the built-in multiplication operator.",\n  "steps": [\n    "Define the function signature with two integer parameters and integer return type, for example: multiply : Int → Int → Int.",\n    "Inside the function, use the built-in multiplication operator (*) to multiply the inputs.",\n    "Return the computed product.",\n    "(Optional) Add tests to verify the implementation works for positive and negative integers."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "multiplication",\n    "Int",\n    "operator *"\n  ],\n  "proof_keywords": [\n    "basic arithmetic",\n    "definition evaluation"\n  ],\n  "assumptions": [\n    "The multiplication operator (*) is correctly defined for the Int type in Lean 4.",\n    "No additional error handling is needed as the built-in operator manages all cases."\n  ],\n  "retry_guidance": "If errors occur, verify that the function signature correctly matches the intended types and review the operator usage for integer multiplication."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef multiply (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result should be the product of the two input integers\ndef multiply_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = a * b\n  -- << SPEC END >>\n\ntheorem multiply_spec_satisfied (a : Int) (b : Int) :\n  multiply_spec a b (multiply a b) := by\n  -- << PROOF START >>\n  unfold multiply multiply_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 01:55:32,850 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:55:32,851 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:55:32,851 - DEBUG - send_request_headers.complete
2025-06-01 01:55:32,851 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:55:32,851 - DEBUG - send_request_body.complete
2025-06-01 01:55:32,851 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:55:33,260 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sun, 01 Jun 2025 01:55:33 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'374'), (b'Connection', b'keep-alive'), (b'retry-after', b'26'), (b'retry-after-ms', b'25536'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'5387'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'49.224s'), (b'x-request-id', b'req_4ca9bbc2e31750c06e1071cf2295548e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b16e25f9a8fcd-BOM'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:55:33,260 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 01:55:33,260 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:55:33,261 - DEBUG - receive_response_body.complete
2025-06-01 01:55:33,261 - DEBUG - response_closed.started
2025-06-01 01:55:33,261 - DEBUG - response_closed.complete
2025-06-01 01:55:33,261 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sun, 01 Jun 2025 01:55:33 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '374', 'connection': 'keep-alive', 'retry-after': '26', 'retry-after-ms': '25536', 'vary': 'Origin', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '5387', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '49.224s', 'x-request-id': 'req_4ca9bbc2e31750c06e1071cf2295548e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b16e25f9a8fcd-BOM', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:55:33,261 - DEBUG - request_id: req_4ca9bbc2e31750c06e1071cf2295548e
2025-06-01 01:55:33,261 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/openai/_base_client.py", line 1007, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.12/dist-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-06-01 01:55:33,261 - DEBUG - Retrying due to status code 429
2025-06-01 01:55:33,261 - DEBUG - 2 retries left
2025-06-01 01:55:33,261 - INFO - Retrying request to /chat/completions in 25.536000 seconds
2025-06-01 01:55:58,798 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that takes two integers as input and returns their product using the built-in multiplication operator.",\n  "steps": [\n    "Define the function signature with two integer parameters and integer return type, for example: multiply : Int → Int → Int.",\n    "Inside the function, use the built-in multiplication operator (*) to multiply the inputs.",\n    "Return the computed product.",\n    "(Optional) Add tests to verify the implementation works for positive and negative integers."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "multiplication",\n    "Int",\n    "operator *"\n  ],\n  "proof_keywords": [\n    "basic arithmetic",\n    "definition evaluation"\n  ],\n  "assumptions": [\n    "The multiplication operator (*) is correctly defined for the Int type in Lean 4.",\n    "No additional error handling is needed as the built-in operator manages all cases."\n  ],\n  "retry_guidance": "If errors occur, verify that the function signature correctly matches the intended types and review the operator usage for integer multiplication."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef multiply (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result should be the product of the two input integers\ndef multiply_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = a * b\n  -- << SPEC END >>\n\ntheorem multiply_spec_satisfied (a : Int) (b : Int) :\n  multiply_spec a b (multiply a b) := by\n  -- << PROOF START >>\n  unfold multiply multiply_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 01:55:58,799 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:55:58,800 - DEBUG - close.started
2025-06-01 01:55:58,800 - DEBUG - close.complete
2025-06-01 01:55:58,800 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:55:58,825 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59a7a54f0>
2025-06-01 01:55:58,825 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x75d682d9ff50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:55:58,852 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59a7a51f0>
2025-06-01 01:55:58,852 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:55:58,852 - DEBUG - send_request_headers.complete
2025-06-01 01:55:58,852 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:55:58,875 - DEBUG - send_request_body.complete
2025-06-01 01:55:58,875 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:56:01,205 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:56:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'1999'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2003'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'200'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'59.598s'), (b'x-request-id', b'req_f34b1a8f08dc5bdb8f9599f1ece317a2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1784faa34436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:56:01,206 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:56:01,206 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:56:01,211 - DEBUG - receive_response_body.complete
2025-06-01 01:56:01,211 - DEBUG - response_closed.started
2025-06-01 01:56:01,211 - DEBUG - response_closed.complete
2025-06-01 01:56:01,212 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:56:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '1999', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2003', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '200', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '59.598s', 'x-request-id': 'req_f34b1a8f08dc5bdb8f9599f1ece317a2', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1784faa34436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:56:01,212 - DEBUG - request_id: req_f34b1a8f08dc5bdb8f9599f1ece317a2
2025-06-01 01:56:01,212 - INFO - Raw solution received: ```json
{
  "code": "a * b",
  "proof": "exact rfl"
}
```
2025-06-01 01:56:01,212 - INFO - <class 'str'>
2025-06-01 01:56:01,212 - INFO - Generated solution: {'code': 'a * b', 'proof': 'exact rfl'}
2025-06-01 01:56:01,213 - INFO - Lean execution result: Error: Lean executable not found or temp_project directory doesn't exist.
2025-06-01 01:56:01,214 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.\n\n-----Input-----\nThe input consists of:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the product of the two input integers (a * b).\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef multiply (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result should be the product of the two input integers\ndef multiply_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = a * b\n  -- << SPEC END >>\n\ntheorem multiply_spec_satisfied (a : Int) (b : Int) :\n  multiply_spec a b (multiply a b) := by\n  -- << PROOF START >>\n  unfold multiply multiply_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na * b\n\nGenerated Proof:\nexact rfl\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nError: Lean executable not found or temp_project directory doesn't exist."}], 'model': 'o3-mini'}}
2025-06-01 01:56:01,214 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:56:01,214 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:56:01,215 - DEBUG - send_request_headers.complete
2025-06-01 01:56:01,215 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:56:01,215 - DEBUG - send_request_body.complete
2025-06-01 01:56:01,215 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:56:07,484 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:56:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6004'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6009'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199371'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'188ms'), (b'x-request-id', b'req_a155b7f88e6cbc911ce70534e70d53ae'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1793b9404436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:56:07,485 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:56:07,485 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:56:07,485 - DEBUG - receive_response_body.complete
2025-06-01 01:56:07,485 - DEBUG - response_closed.started
2025-06-01 01:56:07,485 - DEBUG - response_closed.complete
2025-06-01 01:56:07,485 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:56:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6004', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6009', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199371', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '188ms', 'x-request-id': 'req_a155b7f88e6cbc911ce70534e70d53ae', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1793b9404436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:56:07,485 - DEBUG - request_id: req_a155b7f88e6cbc911ce70534e70d53ae
2025-06-01 01:56:07,486 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The error 'Lean executable not found or temp_project directory doesn't exist' indicates that the environment is not properly set up rather than an issue with the code or proof. Ensure that Lean 4 is correctly installed and that the project directory is created.", 'error_type': 'unknown', 'suggested_fix': 'Verify that Lean 4 is installed and the executable is in your PATH. Create or configure the required temp_project directory or project workspace as needed for running Lean proofs.', 'retry_strategy': 'Set up the Lean 4 environment correctly and re-run the code. Ensure the Lean executable is accessible and the project directory is initialized.'}
2025-06-01 01:56:07,486 - INFO - Solution generated in 39.60 seconds
2025-06-01 01:56:07,486 - INFO - Generated code length: 5 characters
2025-06-01 01:56:07,486 - INFO - Generated proof length: 5 characters
2025-06-01 01:56:07,486 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 01:56:07,486 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 01:56:07,487 - INFO - Implementation test result: FAIL
2025-06-01 01:56:07,487 - INFO - Executing Lean code with implementation and proof...
2025-06-01 01:56:07,487 - INFO - Full solution test result: FAIL
2025-06-01 01:56:07,487 - ERROR - ❌ Implementation fails unit tests
2025-06-01 01:56:07,487 - ERROR - ❌ Proof has errors
2025-06-01 01:56:07,488 - INFO - 
==================================================
2025-06-01 01:56:07,488 - INFO - Processing task task_id_227...
2025-06-01 01:56:07,488 - INFO - Reading problem description and code template from tasks/task_id_227...
2025-06-01 01:56:07,488 - INFO - Problem description length: 608 characters
2025-06-01 01:56:07,488 - INFO - Reading unit tests from tasks/task_id_227...
2025-06-01 01:56:07,488 - INFO - Unit tests length: 339 characters
2025-06-01 01:56:07,488 - INFO - Running main workflow to generate solution...
2025-06-01 01:56:07,488 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.

-----Input-----
The input consists of three integers:
a: The first integer.
b: The second integer.
c: The third integer.

-----Output-----
The output is an integer:
Returns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.
2025-06-01 01:56:07,488 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def minOfThree (a : Int) (b : Int) (c : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The returned value is the minimum of the three input numbers
def minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  (result <= a ∧ result <= b ∧ result <= c) ∧
  (result = a ∨ result = b ∨ result = c)
  -- << SPEC END >>

theorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :
  minOfThree_spec a b c (minOfThree a b c) := by
  -- << PROOF START >>
  unfold minOfThree minOfThree_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 01:56:07,517 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x75d59a7c77e0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:56:07,518 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:56:07,518 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:56:07,524 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59a779b50>
2025-06-01 01:56:07,524 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x75d59ac7ba50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:56:07,534 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x75d59a779a30>
2025-06-01 01:56:07,534 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:56:07,534 - DEBUG - send_request_headers.complete
2025-06-01 01:56:07,534 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:56:07,534 - DEBUG - send_request_body.complete
2025-06-01 01:56:07,534 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:56:08,513 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:56:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7c4c8df9b7-jnb7x'), (b'x-envoy-upstream-service-time', b'117'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999847'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_f52d4ead0c535b68dcd3af0067278fcc'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=HNIt8b.mwK21spduCqk1iDzPhnvhiwCD1y907IvA54o-1748742968-1.0.1.1-dZPwMJ3wzGo5_.Djg27K35hr255v7U68u6MZZRjEW9kZAibhXyi1fGqLozYEZS43T3d_VsjihTUiIHVAX3xeqCn51j3w9BUncrhv4SN4JWs; path=/; expires=Sun, 01-Jun-25 02:26:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=IVDF00gwA297x4.kWq03nsKtPcOtN0ooj_hrwSjuTjE-1748742968515-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b17bb2b4a8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:56:08,514 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:56:08,514 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:56:08,515 - DEBUG - receive_response_body.complete
2025-06-01 01:56:08,515 - DEBUG - response_closed.started
2025-06-01 01:56:08,515 - DEBUG - response_closed.complete
2025-06-01 01:56:08,515 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 01:56:08 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '113'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-7c4c8df9b7-jnb7x'), ('x-envoy-upstream-service-time', '117'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999847'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '9ms'), ('x-request-id', 'req_f52d4ead0c535b68dcd3af0067278fcc'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=HNIt8b.mwK21spduCqk1iDzPhnvhiwCD1y907IvA54o-1748742968-1.0.1.1-dZPwMJ3wzGo5_.Djg27K35hr255v7U68u6MZZRjEW9kZAibhXyi1fGqLozYEZS43T3d_VsjihTUiIHVAX3xeqCn51j3w9BUncrhv4SN4JWs; path=/; expires=Sun, 01-Jun-25 02:26:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=IVDF00gwA297x4.kWq03nsKtPcOtN0ooj_hrwSjuTjE-1748742968515-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b17bb2b4a8fcd-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 01:56:08,515 - DEBUG - request_id: req_f52d4ead0c535b68dcd3af0067278fcc
2025-06-01 01:56:08,522 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Interacting with Lean

You are now familiar with the fundamentals of dependent type theory, both as a
language for defining mathematical objects and a language for constructing
proofs. The one thing you are missing is a mechanism for defining new data
types. We will fill this gap in the next chapter, which introduces the notion
of an _inductive data type_. But first, in this chapter, we take a break from
the mechanics of type theory to explore some pragmatic aspects of interacting
with Lean.

Not all of the information found here will be useful to you right away. We
recommend skimming this section to get a sense of Lean's features, and then
returning to it as necessary.

## Importing Files

The goal of Lean's front end is to interpret user input, construct formal
expressions, and check that they are well-formed and type-correct. Lean also
supports the use of various editors, which provide continuous checking and
feedback. More information can be found on the Lean [documentation
pages](https://lean-lang.org/documentation/).

The definitions and theorems in Lean's standard library are spread across
multiple files. Users may also wish to make use of additional libraries, or
develop their own projects across multiple files. When Lean starts, it
automatically imports the contents of the library `Init` folder, which
includes a number of fundamental definitions and constructions. As a result,
most of the examples we present here work "out of the box."

If you want to use additional files, however, they need to be imported
manually, via an `import` statement at the beginning of a file. The command

    
    
    import Bar.Baz.Blah
    

imports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted
relative to the Lean _search path_. Information as to how the search path is
determined can be found on the [documentation pages](https://lean-
lang.org/documentation/). By default, it includes the standard library
directory, and (in some contexts) the root of the user's local project.

Importing is transitive. In other words, if you import `Foo` and `Foo` imports
`Bar`, then you also have access to the contents of `Bar`, and do not need to
import it explicitly.

## More on Sections

Lean provides various sectioning mechanisms to help structure a theory. You
saw in [Variables and Sections](./dependent_type_theory.html#variables-and-
sections) that the `section` command makes it possible not only to group
together elements of a theory that go together, but also to declare variables
that are inserted as arguments to theorems and definitions, as necessary.
Remember that the point of the `variable` command is to declare variables for
use in theorems, as in the following example:

    
    
    section
    variable (x y : Nat)
    
    def double := x + x
    
    #check double y
    #check double (2 * x)
    
    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm
    
    theorem t1 : double (x + y) = double x + double y := by
      simp [double]
    
    #check t1 y
    #check t1 (2 * x)
    
    theorem t2 : double (x * y) = double x * y := by
      simp [double, Nat.add_mul]
    
    end
    

The definition of `double` does not have to declare `x` as an argument; Lean
detects the dependence and inserts it automatically. Similarly, Lean detects
the occurrence of `x` in `t1` and `t2`, and inserts it automatically there,
too. Note that `double` does _not_ have `y` as argument. Variables are only
included in declarations where they are actually used.

## More on Namespaces

In Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We
saw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean
provides mechanisms for working with hierarchical names. The command
`namespace foo` causes `foo` to be prepended to the name of each definition
and theorem until `end foo` is encountered. The command `open foo` then
creates temporary _aliases_ to definitions and theorems that begin with prefix
`foo`.

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    
    open Foo
    
    #check bar
    #check Foo.bar
    

The following definition

    
    
    def Foo.bar : Nat := 1
    

is treated as a macro, and expands to

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    

Although the names of theorems and definitions have to be unique, the aliases
that identify them do not. When we open a namespace, an identifier may be
ambiguous. Lean tries to use type information to disambiguate the meaning in
context, but you can always disambiguate by giving the full name. To that end,
the string `_root_` is an explicit description of the empty prefix.

    
    
    def String.add (a b : String) : String :=
      a ++ b
    
    def Bool.add (a b : Bool) : Bool :=
      a != b
    
    def add (α β : Type) : Type := Sum α β
    
    open Bool
    open String
    -- #check add -- ambiguous
    #check String.add           -- String → String → String
    #check Bool.add             -- Bool → Bool → Bool
    #check _root_.add           -- Type → Type → Type
    
    #check add "hello" "world"  -- String
    #check add true false       -- Bool
    #check add Nat Nat          -- Type
    

We can prevent the shorter alias from being created by using the `protected`
keyword:

    
    
    protected def Foo.bar : Nat := 1
    
    open Foo
    
    -- #check bar -- error
    #check Foo.bar
    

This is often used for names like `Nat.rec` and `Nat.recOn`, to prevent
overloading of common names.

The `open` command admits variations. The command

    
    
    open Nat (succ zero gcd)
    #check zero     -- Nat
    #eval gcd 15 6  -- 3
    

creates aliases for only the identifiers listed. The command

    
    
    open Nat hiding succ gcd
    #check zero     -- Nat
    -- #eval gcd 15 6  -- error
    #eval Nat.gcd 15 6  -- 3
    

creates aliases for everything in the `Nat` namespace _except_ the identifiers
listed.

    
    
    open Nat renaming mul → times, add → plus
    #eval plus (times 2 2) 3  -- 7
    

creates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.

It is sometimes useful to `export` aliases from one namespace to another, or
to the top level. The command

    
    
    export Nat (succ add sub)
    

creates aliases for `succ`, `add`, and `sub` in the current namespace, so that
whenever the namespace is open, these aliases are available. If this command
is used outside a namespace, the aliases are exported to the top level.

## Attributes

The main function of Lean is to translate user input to formal expressions
that are checked by the kernel for correctness and then stored in the
environment for later use. But some commands have other effects on the
environment, either assigning attributes to objects in the environment,
defining notation, or declaring instances of type classes, as described in
[Chapter Type Classes](./type_classes.html). Most of these commands have
global effects, which is to say, they remain in effect not only in the current
file, but also in any file that imports it. However, such commands often
support the `local` modifier, which indicates that they only have effect until
the current `section` or `namespace` is closed, or until the end of the
current file.

In [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw
that theorems can be annotated with the `[simp]` attribute, which makes them
available for use by the simplifier. The following example defines the prefix
relation on lists, proves that this relation is reflexive, and assigns the
`[simp]` attribute to that theorem.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    

The simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to
`True`.

One can also assign the attribute any time after the definition takes place:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [simp] List.isPrefix_self
    

In all these cases, the attribute remains in effect in any file that imports
the one in which the declaration occurs. Adding the `local` modifier restricts
the scope:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    section
    
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [local simp] List.isPrefix_self
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    
    end
    
    -- Error:
    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by
    --  simp
    

For another example, we can use the `instance` command to assign the notation
`≤` to the `isPrefix` relation. That command, which will be explained in
[Chapter Type Classes](./type_classes.html), works by assigning an
`[instance]` attribute to the associated definition.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    instance : LE (List α) where
      le := isPrefix
    
    theorem List.isPrefix_self (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    

That assignment can also be made local:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    def instLe : LE (List α) :=
      { le := isPrefix }
    
    section
    attribute [local instance] instLe
    
    example (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    
    end
    
    -- Error:
    -- example (as : List α) : as ≤ as :=
    --  ⟨[], by simp⟩
    

In Section Notation below, we will discuss Lean's mechanisms for defining
notation, and see that they also support the `local` modifier. However, in
Section Setting Options, we will discuss Lean's mechanisms for setting
options, which does _not_ follow this pattern: options can _only_ be set
locally, which is to say, their scope is always restricted to the current
section or current file.

## More on Implicit Arguments

In [Section Implicit Arguments](./dependent_type_theory.html#implicit-
arguments), we saw that if Lean displays the type of a term `t` as `{x : α} →
β x`, then the curly brackets indicate that `x` has been marked as an
_implicit argument_ to `t`. This means that whenever you write `t`, a
placeholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you
don't want that to happen, you have to write `@t` instead.

Notice that implicit arguments are inserted eagerly. Suppose we define a
function `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,
when we write the expression `f 7` without further arguments, it is parsed as
`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that
a placeholder should only be added _before_ a subsequent explicit argument.
This annotation can also be written using as `⦃y : Nat⦄`, where the unicode
brackets are entered as `\{{` and `\}}`, respectively. With this annotation,
the expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as
`f 7 _ 3`, just as it would be with the strong annotation.

To illustrate the difference, consider the following example, which shows that
a reflexive euclidean relation is both symmetric and transitive.

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b : α}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
     th2 (th1 reflr @euclr) @euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3
    

The results are broken down into small steps: `th1` shows that a relation that
is reflexive and euclidean is symmetric, and `th2` shows that a relation that
is symmetric and euclidean is transitive. Then `th3` combines the two results.
But notice that we have to manually disable the implicit arguments in `euclr`,
because otherwise too many implicit arguments are inserted. The problem goes
away if we use weak implicit arguments:

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b : α}}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
      th2 (th1 reflr euclr) euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- euclidean r
    

There is a third kind of implicit argument that is denoted with square
brackets, `[` and `]`. These are used for type classes, as explained in
[Chapter Type Classes](./type_classes.html).

## Notation

Identifiers in Lean can include any alphanumeric characters, including Greek
characters (other than ∀ , Σ , and λ , which, as we have seen, have a special
meaning in the dependent type theory). They can also include subscripts, which
can be entered by typing `\_` followed by the desired subscripted character.

Lean's parser is extensible, which is to say, we can define new notation.

Lean's syntax can be extended and customized by users at every level, ranging
from basic "mixfix" notations to custom elaborators. In fact, all builtin
syntax is parsed and processed using the same mechanisms and APIs open to
users. In this section, we will describe and explain the various extension
points.

While introducing new notations is a relatively rare feature in programming
languages and sometimes even frowned upon because of its potential to obscure
code, it is an invaluable tool in formalization for expressing established
conventions and notations of the respective field succinctly in code. Going
beyond basic notations, Lean's ability to factor out common boilerplate code
into (well-behaved) macros and to embed entire custom domain specific
languages (DSLs) to textually encode subproblems efficiently and readably can
be of great benefit to both programmers and proof engineers alike.

### Notations and Precedence

The most basic syntax extension commands allow introducing new (or overloading
existing) prefix, infix, and postfix operators.

    
    
    infixl:65   " + " => HAdd.hAdd  -- left-associative
    infix:50    " = " => Eq         -- non-associative
    infixr:80   " ^ " => HPow.hPow  -- right-associative
    prefix:100  "-"   => Neg.neg
    set_option quotPrecheck false
    postfix:max "⁻¹"  => Inv.inv
    

After the initial command name describing the operator kind (its "fixity"), we
give the _parsing precedence_ of the operator preceded by a colon `:`, then a
new or existing token surrounded by double quotes (the whitespace is used for
pretty printing), then the function this operator should be translated to
after the arrow `=>`.

The precedence is a natural number describing how "tightly" an operator binds
to its arguments, encoding the order of operations. We can make this more
precise by looking at the commands the above unfold to:

    
    
    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs
    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs
    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs
    notation:100 "-" arg:100 => Neg.neg arg
    set_option quotPrecheck false
    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024
    

It turns out that all commands from the first code block are in fact command
_macros_ translating to the more general `notation` command. We will learn
about writing such macros below. Instead of a single token, the `notation`
command accepts a mixed sequence of tokens and named term placeholders with
precedences, which can be referenced on the right-hand side of `=>` and will
be replaced by the respective term parsed at that position. A placeholder with
precedence `p` accepts only notations with precedence at least `p` in that
place. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +
(b + c)` because the right-hand side operand of an `infixl` notation has
precedence one greater than the notation itself. In contrast, `infixr` reuses
the notation's precedence for the right-hand side operand, so `a ^ b ^ c`
_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to
introduce an infix notation like

    
    
    set_option quotPrecheck false
    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs
    

where the precedences do not sufficiently determine associativity, Lean's
parser will default to right associativity. More precisely, Lean's parser
follows a local _longest parse_ rule in the presence of ambiguous grammars:
when parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue
parsing as long as possible (as the current precedence allows), not stopping
after `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~
c)`.

As mentioned above, the `notation` command allows us to define arbitrary
_mixfix_ syntax freely mixing tokens and placeholders.

    
    
    set_option quotPrecheck false
    notation:max "(" e ")" => e
    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ
    

Placeholders without precedence default to `0`, i.e. they accept notations of
any precedence in their place. If two notations overlap, we again apply the
longest parse rule:

    
    
    notation:65 a " + " b:66 " + " c:66 => a + b - c
    #eval 1 + 2 + 3  -- 0
    

The new notation is preferred to the binary notation since the latter, before
chaining, would stop parsing after `1 + 2`. If there are multiple notations
accepting the same longest parse, the choice will be delayed until
elaboration, which will fail unless exactly one overload is type-correct.

## Coercions

In Lean, the type of natural numbers, `Nat`, is different from the type of
integers, `Int`. But there is a function `Int.ofNat` that embeds the natural
numbers in the integers, meaning that we can view any natural number as an
integer, when needed. Lean has mechanisms to detect and insert _coercions_ of
this sort.

    
    
    variable (m n : Nat)
    variable (i j : Int)
    
    #check i + m      -- i + Int.ofNat m : Int
    #check i + m + j  -- i + Int.ofNat m + j : Int
    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int
    

## Displaying Information

There are a number of ways in which you can query Lean for information about
its current state and the objects and theorems that are available in the
current context. You have already seen two of the most common ones, `#check`
and `#eval`. Remember that `#check` is often used in conjunction with the `@`
operator, which makes all of the arguments to a theorem or definition
explicit. In addition, you can use the `#print` command to get information
about any identifier. If the identifier denotes a definition or theorem, Lean
prints the type of the symbol, and its definition. If it is a constant or an
axiom, Lean indicates that fact, and shows the type.

    
    
    -- examples with equality
    #check Eq
    #check @Eq
    #check Eq.symm
    #check @Eq.symm
    
    #print Eq.symm
    
    -- examples with And
    #check And
    #check And.intro
    #check @And.intro
    
    -- a user-defined function
    def foo {α : Type u} (x : α) : α := x
    
    #check foo
    #check @foo
    #print foo
    

## Setting Options

Lean maintains a number of internal variables that can be set by users to
control its behavior. The syntax for doing so is as follows:

    
    
    set_option <name> <value>
    

One very useful family of options controls the way Lean's _pretty- printer_
displays terms. The following options take an input of true or false:

    
    
    pp.explicit  : display implicit arguments
    pp.universes : display hidden universe parameters
    pp.notation  : display output using defined notations
    

As an example, the following settings yield much longer output:

    
    
    set_option pp.explicit true
    set_option pp.universes true
    set_option pp.notation false
    
    #check 2 + 2 = 4
    #reduce (fun x => x + 2) = (fun x => x + 3)
    #check (fun x => x + 1) 1
    

The command `set_option pp.all true` carries out these settings all at once,
whereas `set_option pp.all false` reverts to the previous values. Pretty
printing additional information is often very useful when you are debugging a
proof, or trying to understand a cryptic error message. Too much information
can be overwhelming, though, and Lean's defaults are generally sufficient for
ordinary interactions.

## Using the Library

To use Lean effectively you will inevitably need to make use of definitions
and theorems in the library. Recall that the `import` command at the beginning
of a file imports previously compiled results from other files, and that
importing is transitive; if you import `Foo` and `Foo` imports `Bar`, then the
definitions and theorems from `Bar` are available to you as well. But the act
of opening a namespace, which provides shorter names, does not carry over. In
each file, you need to open the namespaces you wish to use.

In general, it is important for you to be familiar with the library and its
contents, so you know what theorems, definitions, notations, and resources are
available to you. Below we will see that Lean's editor modes can also help you
find things you need, but studying the contents of the library directly is
often unavoidable. Lean's standard library can be found online, on GitHub:

  * <https://github.com/leanprover/lean4/tree/master/src/Init>

  * <https://github.com/leanprover/std4/tree/main/Std>

You can see the contents of these directories and files using GitHub's browser
interface. If you have installed Lean on your own computer, you can find the
library in the `lean` folder, and explore it with your file manager. Comment
headers at the top of each file provide additional information.

Lean's library developers follow general naming guidelines to make it easier
to guess the name of a theorem you need, or to find it using tab completion in
editors with a Lean mode that supports this, which is discussed in the next
section. Identifiers are generally `camelCase`, and types are `CamelCase`. For
theorem names, we rely on descriptive names where the different components are
separated by `_`s. Often the name of theorem simply describes the conclusion:

    
    
    #check Nat.succ_ne_zero
    #check Nat.zero_add
    #check Nat.mul_one
    #check Nat.le_of_succ_le_succ
    

Remember that identifiers in Lean can be organized into hierarchical
namespaces. For example, the theorem named `le_of_succ_le_succ` in the
namespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name
is made available by the command `open Nat` (for names not marked as
`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)
and [Chapter Structures and Records](./structures_and_records.html) that
defining structures and inductive data types in Lean generates associated
operations, and these are stored in a namespace with the same name as the type
under definition. For example, the product type comes with the following
operations:

    
    
    #check @Prod.mk
    #check @Prod.fst
    #check @Prod.snd
    #check @Prod.rec
    

The first is used to construct a pair, whereas the next two, `Prod.fst` and
`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another
mechanism for defining functions on a product in terms of a function on the
two components. Names like `Prod.rec` are _protected_ , which means that one
has to use the full name even when the `Prod` namespace is open.

With the propositions as types correspondence, logical connectives are also
instances of inductive types, and so we tend to use dot notation for them as
well:

    
    
    #check @And.intro
    #check @And.casesOn
    #check @And.left
    #check @And.right
    #check @Or.inl
    #check @Or.inr
    #check @Or.elim
    #check @Exists.intro
    #check @Exists.elim
    #check @Eq.refl
    #check @Eq.subst
    

## Auto Bound Implicit Arguments

In the previous section, we have shown how implicit arguments make functions
more convenient to use. However, functions such as `compose` are still quite
verbose to define. Note that the universe polymorphic `compose` is even more
verbose than the one previously defined.

    
    
    universe u v w
    def compose {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

You can avoid the `universe` command by providing the universe parameters when
defining `compose`.

    
    
    def compose.{u, v, w}
                {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

Lean 4 supports a new feature called _auto bound implicit arguments_. It makes
functions such as `compose` much more convenient to write. When Lean processes
the header of a declaration, any unbound identifier is automatically added as
an implicit argument _if_ it is a single lower case or greek letter. With this
feature we can write `compose` as

    
    
    def compose (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    
    #check @compose
    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ
    

Note that Lean inferred a more general type using `Sort` instead of `Type`.

Although we love this feature and use it extensively when implementing Lean,
we realize some users may feel uncomfortable with it. Thus, you can disable it
using the command `set_option autoImplicit false`.

    
    
    set_option autoImplicit false
    /- The following definition produces `unknown identifier` errors -/
    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=
    --   g (f x)
    

## Implicit Lambdas

In Lean 3 stdlib, we find many
[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)
of the dreadful `@`+`_` idiom. It is often used when the expected type is a
function type with implicit arguments, and we have a constant (`reader_t.pure`
in the example) which also takes implicit arguments. In Lean 4, the elaborator
automatically introduces lambdas for consuming implicit arguments. We are
still exploring this feature and analyzing its impact, but the experience so
far has been very positive. Here is the example from the link above using Lean
4 implicit lambdas.

    
    
    variable (ρ : Type) (m : Type → Type) [Monad m]
    instance : Monad (ReaderT ρ m) where
      pure := ReaderT.pure
      bind := ReaderT.bind
    

Users can disable the implicit lambda feature by using `@` or writing a lambda
expression with `{}` or `[]` binder annotations. Here are few examples

    
    
    namespace ex2
    def id1 : {α : Type} → α → α :=
      fun x => x
    
    def listId : List ({α : Type} → α → α) :=
      (fun x => x) :: []
    
    -- In this example, implicit lambda introduction has been disabled because
    -- we use `@` before `fun`
    def id2 : {α : Type} → α → α :=
      @fun α (x : α) => id1 x
    
    def id3 : {α : Type} → α → α :=
      @fun α x => id1 x
    
    def id4 : {α : Type} → α → α :=
      fun x => id1 x
    
    -- In this example, implicit lambda introduction has been disabled
    -- because we used the binder annotation `{...}`
    def id5 : {α : Type} → α → α :=
      fun {α} x => id1 x
    end ex2
    

## Sugar for Simple Functions

In Lean 3, we can create simple functions from infix operators by using
parentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we
generalize this notation using `·` as a placeholder. Here are a few examples:

    
    
    namespace ex3
    #check (· + 1)
    -- fun a => a + 1
    #check (2 - ·)
    -- fun a => 2 - a
    #eval [1, 2, 3, 4, 5].foldl (·*·) 1
    -- 120
    
    def f (x y z : Nat) :=
      x + y + z
    
    #check (f · 1 ·)
    -- fun a b => f a 1 b
    
    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)
    -- [1, 3, 5]
    end ex3
    

As in Lean 3, the notation is activated using parentheses, and the lambda
abstraction is created by collecting the nested `·`s. The collection is
interrupted by nested parentheses. In the following example, two different
lambda expressions are created.

    
    
    #check (Prod.mk · (· + 1))
    -- fun a => (a, fun b => b + 1)
    

## Named Arguments

Named arguments enable you to specify an argument for a parameter by matching
the argument with its name rather than with its position in the parameter
list. If you don't remember the order of the parameters but know their names,
you can send the arguments in any order. You may also provide the value for an
implicit parameter when
2025-06-01 01:56:08,536 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.'}], 'model': 'o3-mini'}}
2025-06-01 01:56:08,537 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:56:08,537 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:56:08,537 - DEBUG - send_request_headers.complete
2025-06-01 01:56:08,537 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:56:08,537 - DEBUG - send_request_body.complete
2025-06-01 01:56:08,538 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:56:11,484 - DEBUG - receive_response_headers.failed exception=KeyboardInterrupt()
2025-06-01 01:56:11,484 - DEBUG - response_closed.started
2025-06-01 01:56:11,484 - DEBUG - response_closed.complete
2025-06-01 01:56:11,623 - DEBUG - close.started
2025-06-01 01:56:11,623 - DEBUG - close.complete
2025-06-01 01:56:11,624 - DEBUG - close.started
2025-06-01 01:56:11,624 - DEBUG - close.complete
