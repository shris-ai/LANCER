2025-05-31 17:55:44,652 - INFO - Starting test of 11 tasks: task_id_0, task_id_58, task_id_77, task_id_127, task_id_227, task_id_404, task_id_431, task_id_433, task_id_435, task_id_441, task_id_447
2025-05-31 17:55:44,652 - INFO - 
==================================================
2025-05-31 17:55:44,652 - INFO - Processing task task_id_0...
2025-05-31 17:55:44,652 - INFO - Reading problem description and code template from tasks/task_id_0...
2025-05-31 17:55:44,652 - INFO - Problem description length: 310 characters
2025-05-31 17:55:44,652 - INFO - Reading unit tests from tasks/task_id_0...
2025-05-31 17:55:44,652 - INFO - Unit tests length: 69 characters
2025-05-31 17:55:44,652 - INFO - Running main workflow to generate solution...
2025-05-31 17:55:44,653 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.

-----Input-----
The input consists of one natural number:
x: An natural number.

-----Output-----
The output is a natural number which the value equals to x.
2025-05-31 17:55:44,653 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def ident (x : Nat) : Nat :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


def ident_spec (x : Nat) (result: Nat) : Prop :=
  -- << SPEC START >>
  result = x
  -- << SPEC END >>

theorem ident_spec_satisfied (x : Nat) :
  ident_spec x (ident x) := by
  -- << PROOF START >>
  unfold ident ident_spec
  {{proof}}
  -- << PROOF END >>

2025-05-31 17:55:44,968 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7a6c34d57ce0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-05-31 17:55:44,970 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-05-31 17:55:44,970 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-05-31 17:55:44,978 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a6c374e1e20>
2025-05-31 17:55:44,978 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7a6c37ed6ad0> server_hostname='api.openai.com' timeout=5.0
2025-05-31 17:55:44,988 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a6c37ecc890>
2025-05-31 17:55:44,988 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-31 17:55:44,988 - DEBUG - send_request_headers.complete
2025-05-31 17:55:44,988 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-31 17:55:44,988 - DEBUG - send_request_body.complete
2025-05-31 17:55:44,988 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-31 17:55:45,783 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 31 May 2025 17:55:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'75'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-6d88f968d4-ng5dg'), (b'x-envoy-upstream-service-time', b'80'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999923'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'4ms'), (b'x-request-id', b'req_a8498214481989c161244b959e04162a'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ZkAGfh2qs6a97nAgB5ocwBdUf7olPBzP0Cy8HekCeic-1748714145-1.0.1.1-7n7fzMbRPsuZjD4OUOL39GtaegY3zeFSl.2SamtcEkfOahToYPQVV3mCVt8nKb20izRdffLXr8vMu2kFetgxB1z7CkAyKX8DwXEJ5eHGy3o; path=/; expires=Sat, 31-May-25 18:25:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=SIb46B_r6gdVzA2esEG9tRrLmeR75rU78H5ooVdo7Oo-1748714145815-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9488580e6e59470a-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-05-31 17:55:45,784 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-05-31 17:55:45,784 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-31 17:55:45,784 - DEBUG - receive_response_body.complete
2025-05-31 17:55:45,785 - DEBUG - response_closed.started
2025-05-31 17:55:45,785 - DEBUG - response_closed.complete
2025-05-31 17:55:45,785 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sat, 31 May 2025 17:55:45 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '75'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-6d88f968d4-ng5dg'), ('x-envoy-upstream-service-time', '80'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999923'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '4ms'), ('x-request-id', 'req_a8498214481989c161244b959e04162a'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=ZkAGfh2qs6a97nAgB5ocwBdUf7olPBzP0Cy8HekCeic-1748714145-1.0.1.1-7n7fzMbRPsuZjD4OUOL39GtaegY3zeFSl.2SamtcEkfOahToYPQVV3mCVt8nKb20izRdffLXr8vMu2kFetgxB1z7CkAyKX8DwXEJ5eHGy3o; path=/; expires=Sat, 31-May-25 18:25:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=SIb46B_r6gdVzA2esEG9tRrLmeR75rU78H5ooVdo7Oo-1748714145815-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9488580e6e59470a-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-05-31 17:55:45,785 - DEBUG - request_id: req_a8498214481989c161244b959e04162a
2025-05-31 17:55:45,827 - INFO - Retrieved context: Induction and Recursion - Theorem Proving in Lean 4
Theorem Proving in Lean 4
1.
Introduction
2.
Dependent Type Theory
3.
Propositions and Proofs
4.
Quantifiers and Equality
5.
Tactics
6.
Interacting with Lean
7.
Inductive Types
8.
Induction and Recursion
9.
Structures and Records
10.
Type Classes
11.
The Conversion Tactic Mode
12.
Axioms and Computation
Light (default)
Rust
Coal
Navy
Ayu
Theorem Proving in Lean 4
Induction and Recursion
In the previous chapter, we saw that inductive definitions provide a
powerful means of introducing new types in Lean. Moreover, the
constructors and the recursors provide the only means of defining
functions on these types. By the propositions-as-types correspondence,
this means that induction is the fundamental method of proof.
Lean provides natural ways of defining recursive functions, performing
pattern matching, and writing inductive proofs. It allows you to
define a function by specifying equations that it should satisfy, and
it allows you to prove a theorem by specifying how to handle various
cases that can arise. Behind the scenes, these descriptions are
"compiled" down to primitive recursors, using a procedure that we
refer to as the "equation compiler." The equation compiler is not part
of the trusted code base; its output consists of terms that are
checked independently by the kernel.
Pattern Matching
The interpretation of schematic patterns is the first step of the
compilation process. We have seen that the
casesOn
recursor can
be used to define functions and prove theorems by cases, according to
the constructors involved in an inductively defined type. But
complicated definitions may use several nested
casesOn
applications, and may be hard to read and understand. Pattern matching
provides an approach that is more convenient, and familiar to users of
functional programming languages.
Consider the inductively defined type of natural numbers. Every
natural number is either
zero
or
succ x
, and so you can define
a function from the natural numbers to an arbitrary type by specifying
a value in each of those cases:
open Nat

def sub1 : Nat → Nat
  | zero   => zero
  | succ x => x

def isZero : Nat → Bool
  | zero   => true
  | succ x => false
The equations used to define these functions hold definitionally:
open Nat
def sub1 : Nat → Nat
| zero   => zero
| succ x => x
def isZero : Nat → Bool
| zero   => true
| succ x => false
example : sub1 0 = 0 := rfl
example (x : Nat) : sub1 (succ x) = x := rfl

example : isZero 0 = true := rfl
example (x : Nat) : isZero (succ x) = false := rfl

example : sub1 7 = 6 := rfl
example (x : Nat) : isZero (x + 3) = false := rfl
Instead of
zero
and
succ
, we can use more familiar notation:
def sub1 : Nat → Nat
  | 0   => 0
  | x+1 => x

def isZero : Nat → Bool
  | 0   => true
  | x+1 => false
Because addition and the zero notation have been assigned the
[match_pattern]
attribute, they can be used in pattern matching. Lean
simply normalizes these expressions until the constructors
zero
and
succ
are exposed.
Pattern matching works with any inductive type, such as products and option types:
def swap : α × β → β × α
  | (a, b) => (b, a)

def foo : Nat × Nat → Nat
  | (m, n) => m + n

def bar : Option Nat → Nat
  | some n => n + 1
  | none   => 0
Here we use it not only to define a function, but also to carry out a
proof by cases:
namespace Hidden
def not : Bool → Bool
  | true  => false
  | false => true

theorem not_not : ∀ (b : Bool), not (not b) = b
  | true  => rfl  -- proof that not (not true) = true
  | false => rfl  -- proof that not (not false) = false
end Hidden
Pattern matching can also be used to destruct inductively defined propositions:
example (p q : Prop) : p ∧ q → q ∧ p
  | And.intro h₁ h₂ => And.intro h₂ h₁

example (p q : Prop) : p ∨ q → q ∨ p
  | Or.inl hp => Or.inr hp
  | Or.inr hq => Or.inl hq
This provides a compact way of unpacking hypotheses that make use of logical connectives.
In all these examples, pattern matching was used to carry out a single
case distinction. More interestingly, patterns can involve nested
constructors, as in the following examples.
def sub2 : Nat → Nat
  | 0   => 0
  | 1   => 0
  | x+2 => x
The equation compiler first splits on cases as to whether the input is
zero
or of the form
succ x
.  It then does a case split on
whether
x
is of the form
zero
or
succ x
.  It determines
the necessary case splits from the patterns that are presented to it,
and raises an error if the patterns fail to exhaust the cases. Once
again, we can use arithmetic notation, as in the version below. In
either case, the defining equations hold definitionally.
def sub2 : Nat → Nat
| 0   => 0
| 1   => 0
| x+2 => x
example : sub2 0 = 0 := rfl
example : sub2 1 = 0 := rfl
example : sub2 (x+2) = x := rfl

example : sub2 5 = 3 := rfl
You can write
#print sub2
to see how the function was compiled to
recursors. (Lean will tell you that
sub2
has been defined in terms
of an internal auxiliary function,
sub2.match_1
, but you can print
that out too.) Lean uses these auxiliary functions to compile
match
expressions.
Actually, the definition above is expanded to
def sub2 : Nat → Nat :=
  fun x =>
    match x with
    | 0   => 0
    | 1   => 0
    | x+2 => x
Here are some more examples of nested pattern matching:
example (p q : α → Prop)
        : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
  | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
  | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)

def foo : Nat × Nat → Nat
  | (0, n)     => 0
  | (m+1, 0)   => 1
  | (m+1, n+1) => 2
The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a
function of two arguments:
def foo : Nat → Nat → Nat
  | 0,   n   => 0
  | m+1, 0   => 1
  | m+1, n+1 => 2
Here is another example:
def bar : List Nat → List Nat → Nat
  | [],      []      => 0
  | a :: as, []      => a
  | [],      b :: bs => b
  | a :: as, b :: bs => a + b
Note that the patterns are separated by commas.
In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of
patterns.
namespace Hidden
def and : Bool → Bool → Bool
  | true,  a => a
  | false, _ => false

def or : Bool → Bool → Bool
  | true,  _ => true
  | false, a => a

def cond : Bool → α → α → α
  | true,  x, y => x
  | false, x, y => y
end Hidden
Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is
known as a
wildcard pattern
, or an
anonymous variable
. In contrast
to usage outside the equation compiler, here the underscore does
not
indicate an implicit argument. The use of underscores for wildcards is
common in functional programming languages, and so Lean adopts that
notation.
Section Wildcards and Overlapping Patterns
expands on the notion of a wildcard, and
Section Inaccessible Patterns
explains how
you can use implicit arguments in patterns as well.
As described in
Chapter Inductive Types
,
inductive data types can depend on parameters. The following example defines
the
tail
function using pattern matching. The argument
α : Type u
is a parameter and occurs before the colon to indicate it does not participate in the pattern matching.
Lean also allows parameters to occur after
:
, but it cannot pattern match on them.
def tail1 {α : Type u} : List α → List α
  | []      => []
  | a :: as => as

def tail2 : {α : Type u} → List α → List α
  | α, []      => []
  | α, a :: as => as
Despite the different placement of the parameter
α
in these two
examples, in both cases it is treated in the same way, in that it does
not participate in a case split.
Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the
various cases. Such examples of
dependent pattern matching
are
considered in the
Section Dependent Pattern Matching
.
Wildcards and Overlapping Patterns
Consider one of the examples from the last section:
def foo : Nat → Nat → Nat
  | 0,   n   => 0
  | m+1, 0   => 1
  | m+1, n+1 => 2
An alternative presentation is:
def foo : Nat → Nat → Nat
  | 0, n => 0
  | m, 0 => 1
  | m, n => 2
In the second presentation, the patterns overlap; for example, the
pair of arguments
0 0
matches all three cases. But Lean handles
the ambiguity by using the first applicable equation, so in this example
the net result is the same. In particular, the following equations hold
definitionally:
def foo : Nat → Nat → Nat
| 0, n => 0
| m, 0 => 1
| m, n => 2
example : foo 0     0     = 0 := rfl
example : foo 0     (n+1) = 0 := rfl
example : foo (m+1) 0     = 1 := rfl
example : foo (m+1) (n+1) = 2 := rfl
Since the values of
m
and
n
are not needed, we can just as well use wildcard patterns instead.
def foo : Nat → Nat → Nat
  | 0, _ => 0
  | _, 0 => 1
  | _, _ => 2
You can check that this definition of
foo
satisfies the same
definitional identities as before.
Some functional programming languages support
incomplete
patterns
. In these languages, the interpreter produces an exception
or returns an arbitrary value for incomplete cases. We can simulate
the arbitrary value approach using the
Inhabited
type
class. Roughly, an element of
Inhabited α
is a witness to the fact
that there is an element of
α
; in the
Chapter Type Classes
we will see that Lean can be instructed that suitable
base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the
standard library provides a default element,
default
, of
any inhabited type.
We can also use the type
Option α
to simulate incomplete patterns.
The idea is to return
some a
for the provided patterns, and use
none
for the incomplete cases. The following example demonstrates
both approaches.
def f1 : Nat → Nat → Nat
  | 0, _  => 1
  | _, 0  => 2
  | _, _  => default  -- the "incomplete" case

example : f1 0     0     = 1       := rfl
example : f1 0     (a+1) = 1       := rfl
example : f1 (a+1) 0     = 2       := rfl
example : f1 (a+1) (b+1) = default := rfl

def f2 : Nat → Nat → Option Nat
  | 0, _  => some 1
  | _, 0  => some 2
  | _, _  => none     -- the "incomplete" case

example : f2 0     0     = some 1 := rfl
example : f2 0     (a+1) = some 1 := rfl
example : f2 (a+1) 0     = some 2 := rfl
example : f2 (a+1) (b+1) = none   := rfl
The equation compiler is clever. If you leave out any of the cases in
the following definition, the error message will let you know what has
not been covered.
def bar : Nat → List Nat → Bool → Nat
  | 0,   _,      false => 0
  | 0,   b :: _, _     => b
  | 0,   [],     true  => 7
  | a+1, [],     false => a
  | a+1, [],     true  => a + 1
  | a+1, b :: _, _     => a + b
It will also use an "if ... then ... else" instead of a
casesOn
in appropriate situations.
def foo : Char → Nat
  | 'A' => 1
  | 'B' => 2
  | _   => 3

#print foo.match_1
Structural Recursion and Induction
What makes the equation compiler powerful is that it also supports
recursive definitions. In the next three sections, we will describe,
respectively:
structurally recursive definitions
well-founded recursive definitions
mutually recursive definitions
Generally speaking, the equation compiler processes input of the following form:
def foo (a : α) : (b : β) → γ
  | [patterns₁] => t₁
  ...
  | [patternsₙ] => tₙ
Here
(a : α)
is a sequence of parameters,
(b : β)
is the
sequence of arguments on which pattern matching takes place, and
γ
is any type, which can depend on
a
and
b
. Each line should
contain the same number of patterns, one for each element of
β
. As we
have seen, a pattern is either a variable, a constructor applied to
other patterns, or an expression that normalizes to something of that
form (where the non-constructors are marked with the
[match_pattern]
attribute). The appearances of constructors prompt case splits, with
the arguments to the constructors represented by the given
variables. In
Section Dependent Pattern Matching
,
we will see that it is sometimes necessary to include explicit terms in patterns that
are needed to make an expression type check, though they do not play a
role in pattern matching. These are called "inaccessible patterns" for
that reason. But we will not need to use such inaccessible patterns
before
Section Dependent Pattern Matching
.
As we saw in the last section, the terms
t₁, ..., tₙ
can make use
of any of the parameters
a
, as well as any of the variables that
are introduced in the corresponding patterns. What makes recursion and
induction possible is that they can also involve recursive calls to
foo
. In this section, we will deal with
structural recursion
, in
which the arguments to
foo
occurring on the right-hand side of the
=>
are subterms of the patterns on the left-hand side. The idea is
that they are structurally smaller, and hence appear in the inductive
type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation
compiler:
open Nat
def add : Nat → Nat → Nat
  | m, zero   => m
  | m, succ n => succ (add m n)

theorem add_zero (m : Nat)   : add m zero = m := rfl
theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl

theorem zero_add : ∀ n, add zero n = n
  | zero   => rfl
  | succ n => congrArg succ (zero_add n)

def mul : Nat → Nat → Nat
  | n, zero   => zero
  | n, succ m => add (mul n m) n
The proof of
zero_add
makes it clear that proof by induction is
really a form of recursion in Lean.
The example above shows that the defining equations for
add
hold
definitionally, and the same is true of
mul
. The equation compiler
tries to ensure that this holds whenever possible, as is the case with
straightforward structural induction. In other situations, however,
reductions hold only
propositionally
, which is to say, they are
equational theorems that must be applied explicitly. The equation
compiler generates such theorems internally. They are not meant to be
used directly by the user; rather, the
simp
tactic
is configured to use them when necessary. Thus both of the following
proofs of
zero_add
work:
open Nat
def add : Nat → Nat → Nat
| m, zero   => m
| m, succ n => succ (add m n)
theorem zero_add : ∀ n, add zero n = n
  | zero   => by simp [add]
  | succ n => by simp [add, zero_add]
As with definition by pattern matching, parameters to a structural
recursion or induction may appear before the colon. Such parameters
are simply added to the local context before the definition is
processed. For example, the definition of addition may also be written
as follows:
open Nat
def add (m : Nat) : Nat → Nat
  | zero   => m
  | succ n => succ (add m n)
You can also write the example above using
match
.
open Nat
def add (m n : Nat) : Nat :=
  match n with
  | zero   => m
  | succ n => succ (add m n)
A more interesting example of structural recursion is given by the Fibonacci function
fib
.
def fib : Nat → Nat
  | 0   => 1
  | 1   => 1
  | n+2 => fib (n+1) + fib n

example : fib 0 = 1 := rfl
example : fib 1 = 1 := rfl
example : fib (n + 2) = fib (n + 1) + fib n := rfl

example : fib 7 = 21 := rfl
Here, the value of the
fib
function at
n + 2
(which is
definitionally equal to
succ (succ n)
) is defined in terms of the
values at
n + 1
(which is definitionally equivalent to
succ n
)
and the value at
n
. This is a notoriously inefficient way of
computing the Fibonacci function, however, with an execution time that
is exponential in
n
. Here is a better way:
def fibFast (n : Nat) : Nat :=
  (loop n).2
where
  loop : Nat → Nat × Nat
    | 0   => (0, 1)
    | n+1 => let p := loop n; (p.2, p.1 + p.2)

#eval fibFast 100
Here is the same definition using a
let rec
instead of a
where
.
def fibFast (n : Nat) : Nat :=
  let rec loop : Nat → Nat × Nat
    | 0   => (0, 1)
    | n+1 => let p := loop n; (p.2, p.1 + p.2)
  (loop n).2
In both cases, Lean generates the auxiliary function
fibFast.loop
.
To handle structural recursion, the equation compiler uses
course-of-values
recursion, using constants
below
and
brecOn
that are automatically generated with each inductively defined
type. You can get a sense of how it works by looking at the types of
Nat.below
and
Nat.brecOn
:
variable (C : Nat → Type u)

#check (@Nat.below C : Nat → Type u)

#reduce @Nat.below C (3 : Nat)

#check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
The type
@Nat.below C (3 : nat)
is a data structure that stores elements of
C 0
,
C 1
, and
C 2
.
The course-of-values recursion is implemented by
Nat.brecOn
. It enables us to define the value of a dependent
function of type
(n : Nat) → C n
at a particular input
n
in terms of all the previous values of the function,
presented as an element of
@Nat.below C n
.
The use of course-of-values recursion is one of the techniques the equation compiler uses to justify to
the Lean kernel that a function terminates. It does not affect the code generator which compiles recursive
functions as other functional programming language compilers. Recall that
#eval fib <n>
is exponential on
<n>
.
On the other hand,
#reduce fib <n>
is efficient because it uses the definition sent to the kernel that
is based on the
brecOn
construction.
def fib : Nat → Nat
  | 0   => 1
  | 1   => 1
  | n+2 => fib (n+1) + fib n

-- #eval fib 50 -- slow
#reduce fib 50  -- fast

#print fib
Another good example of a recursive definition is the list
append
function.
def append : List α → List α → List α
  | [],    bs => bs
  | a::as, bs => a :: append as bs

example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
Here is another: it adds elements of the first list to elements of the second list, until one of the two lists runs out.
def listAdd [Add α] : List α → List α → List α
  | [],      _       => []
  | _,       []      => []
  | a :: as, b :: bs => (a + b) :: listAdd as bs

#eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
-- [5, 7, 9]
You are encouraged to experiment with similar examples in the exercises below.
Local recursive declarations
You can define local recursive declarations using the
let rec
keyword.
def replicate (n : Nat) (a : α) : List α :=
  let rec loop : Nat → List α → List α
    | 0,   as => as
    | n+1, as => loop n (a::as)
  loop n []

#check @replicate.loop
-- {α : Type} → α → Nat → List α → List α
Lean creates an auxiliary declaration for each
let rec
. In the example above,
it created the declaration
replicate.loop
for the
let rec loop
occurring at
replicate
.
Note that, Lean "closes" the declaration by adding any local variable occurring in the
let rec
declaration as additional parameters. For example, the local variable
a
occurs
at
let rec loop
.
You can also use
let rec
in tactic mode and for creating proofs by induction.
def replicate (n : Nat) (a : α) : List α :=
let rec loop : Nat → List α → List α
| 0,   as => as
| n+1, as => loop n (a::as)
loop n []
theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
  let rec aux (n : Nat) (as : List α)
              : (replicate.loop a n as).length = n + as.length := by
    match n with
    | 0   => simp [replicate.loop]
    | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
  exact aux n []
You can also introduce auxiliary recursive declarations using
where
clause after your definition.
Lean converts them into a
let rec
.
def replicate (n : Nat) (a : α) : List α :=
  loop n []
where
  loop : Nat → List α → List α
    | 0,   as => as
    | n+1, as => loop n (a::as)

theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
  exact aux n []
where
  aux (n : Nat) (as : List α)
      : (replicate.loop a n as).length = n + as.length := by
    match n with
    | 0   => simp [replicate.loop]
    | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
Well-Founded Recursion and Induction
When structural recursion cannot be used, we can prove termination using well-founded recursion.
We need a well-founded relation and a proof that each recursive application is decreasing with respect to
this relation. Dependent type theory is powerful enough to encode and justify
well-founded recursion. Let us start with the logical background that
is needed to understand how it works.
Lean's standard library defines two predicates,
Acc r a
and
WellFounded r
, where
r
is a binary relation on a type
α
,
and
a
is an element of type
α
.
variable (α : Sort u)
variable (r : α → α → Prop)

#check (Acc r : α → Prop)
#check (WellFounded r : Prop)
The first,
Acc
, is an inductively defined predicate. According to
its definition,
Acc r x
is equivalent to
∀ y, r y x → Acc r y
. If you think of
r y x
as denoting a kind of order relation
y ≺ x
, then
Acc r x
says that
x
is accessible from below,
in the sense that all its predecessors are accessible. In particular,
if
x
has no predecessors, it is accessible. Given any type
α
,
we should be able to assign a value to each accessible element of
α
, recursively, by assigning values to all its predecessors first.
The statement that
r
is well-founded, denoted
WellFounded r
,
is exactly the statement that every element of the type is
accessible. By the above considerations, if
r
is a well-founded
relation on a type
α
, we should have a principle of well-founded
recursion on
α
, with respect to the relation
r
. And, indeed,
we do: the standard library defines
WellFounded.fix
, which serves
exactly that purpose.
noncomputable def f {α : Sort u}
      (r : α → α → Prop)
      (h : WellFounded r)
      (C : α → Sort v)
      (F : (x : α) → ((y : α) → r y x → C y) → C x)
      : (x : α) → C x := WellFounded.fix h F
There is a long cast of characters here, but the first block we have
already seen: the type,
α
, the relation,
r
, and the
assumption,
h
, that
r
is well-founded. The variable
C
represents the motive of the recursive definition: for each element
x : α
, we would like to construct an element of
C x
. The
function
F
provides the inductive recipe for doing that: it tells
us how to construct an element
C x
, given elements of
C y
for
each predecessor
y
of
x
.
Note that
WellFounded.fix
works equally well as an induction
principle. It says that if
≺
is well-founded and you want to prove
∀ x, C x
, it suffices to show that for an arbitrary
x
, if we
have
∀ y ≺ x, C y
, then we have
C x
.
In the example above we use the modifier
noncomputable
because the code
generator currently does not support
WellFounded.fix
. The function
WellFounded.fix
is another tool Lean uses to justify that a function
terminates.
Lean knows that the usual order
<
on the natural numbers is well
founded. It also knows a number of ways of constructing new well
founded orders from others, for example, using lexicographic order.
Here is essentially the definition of division on the natural numbers that is found in the standard library.
open Nat

theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
  fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left

def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
  if h : 0 < y ∧ y ≤ x then
    f (x - y) (div_lemma h) y + 1
  else
    zero

noncomputable def div := WellFounded.fix (measure id).wf div.F

#reduce div 8 2 -- 4
The definition is somewhat inscrutable. Here the recursion is on
x
, and
div.F x f : Nat → Nat
returns the "divide by
y
"
function for that fixed
x
. You have to remember that the second
argument to
div.F
, the recipe for the recursion, is a function
that is supposed to return the divide by
y
function for all values
x₁
smaller than
x
.
The elaborator is designed to make definitions like this more
convenient. It accepts the following:
def div (x y : Nat) : Nat :=
  if h : 0 < y ∧ y ≤ x then
    have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
    div (x - y) y + 1
  else
    0
When Lean encounters a recursive definition, it first
tries structural recursion, and only when that fails, does it fall
back on well-founded recursion. Lean uses the tactic
decreasing_tactic
to show that the recursive applications are smaller. The auxiliary
proposition
x - y < x
in the example above should be viewed as a hint
for this tactic.
The defining equation for
div
does
not
hold definitionally, but
we can unfold
div
using the
unfold
tactic. We use
conv
to select which
div
application we want to unfold.
def div (x y : Nat) : Nat :=
if h : 0 < y ∧ y ≤ x then
have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
div (x - y) y + 1
else
0
example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
  conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation

example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
  conv => lhs; unfold div
  simp [h]
The following example is similar: it converts any natural number to a
binary expression, represented as a list of 0's and 1's. We have to
provide evidence that the recursive call is
decreasing, which we do here with a
sorry
. The
sorry
does not
prevent the interpreter from evaluating the function successfully.
def natToBin : Nat → List Nat
  | 0     => [0]
  | 1     => [1]
  | n + 2 =>
    have : (n + 2) / 2 < n + 2 := sorry
    natToBin ((n + 2) / 2) ++ [n % 2]

#eval natToBin 1234567
As a final example, we observe that Ackermann's function can be
defined directly, because it is justified by the well-foundedness of
the lexicographic order on the natural numbers. The
termination_by
clause
instructs Lean to use a lexicographic order. This clause is actually mapping
the function arguments to elements of type
Nat × Nat
. Then, Lean uses typeclass
resolution to synthesize an element of type
WellFoundedRelation (Nat × Nat)
.
def ack : Nat → Nat → Nat
  | 0,   y   => y+1
  | x+1, 0   => ack x 1
  | x+1, y+1 => ack x (ack (x+1) y)
termination_by x y => (x, y)
Note that a lexicographic order is used in the example above because the instance
WellFoundedRelation (α × β)
uses a lexicographic order. Lean also defines the instance
instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
  sizeOfWFRel
In the following example, we prove termination by showing that
as.size - i
is decreasing
in the recursive application.
def takeWhile (p : α → Bool) (as : Array α) : Array α :=
  go 0 #[]
where
  go (i : Nat) (r : Array α) : Array α :=
    if h : i < as.size then
      let a := as.get ⟨i, h⟩
      if p a then
        go (i+1) (r.push a)
      else
        r
    else
      r
  termination_by as.size - i
Note that, auxiliary function
go
is recursive in this example, but
takeWhile
is not.
By default, Lean uses the tactic
decreasing_tactic
to prove recursive applications are decreasing. The modifier
decreasing_by
allows us to provide our own tactic. Here is an example.
theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
  fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos

def div (x y : Nat) : Nat :=
  if h : 0 < y ∧ y ≤ x then
    div (x - y) y + 1
  else
    0
decreasing_by apply div_lemma; assumption
Note that
decreasing_by
is not replacement for
termination_by
, they complement each other.
termination_by
is used to specify a well-founded relation, and
decreasing_by
for providing our own tactic for showing recursive applications are decreasing. In the following example, we use both of them.
def ack : Nat → Nat → Nat
  | 0,   y   => y+1
  | x+1, 0   => ack x 1
  | x+1, y+1 => ack x (ack (x+1) y)
termination_by x y => (x, y)
decreasing_by
  all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
  · apply Prod.Lex.left; simp_arith
  · apply Prod.Lex.right; simp_arith
  · apply Prod.Lex.left; simp_arith
We can use
decreasing_by sorry
to instruct Lean to "trust" us that the function terminates.
def natToBin : Nat → List Nat
  | 0     => [0]
  | 1     => [1]
  | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
decreasing_by sorry

#eval natToBin
 1234567
Recall that using
sorry
is equivalent to using a new axiom, and should be avoided. In the following example, we used the
sorry
to prove
False
.
The command
#print axioms unsound
shows that
unsound
depends on the unsound axiom
sorryAx
used to implement
sorry
.
def unsound (x : Nat) : False :=
  unsound (x + 1)
decreasing_by sorry

#check unsound 0
-- `unsound 0` is a proof of `False`

#print axioms unsound
-- 'unsound' depends on axioms: [sorryAx]
Summary:
If there is no
termination_by
, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.
If
termination_by
is specified, it maps the arguments of the function to a type
α
and type class resolution is again used. Recall that, the default instance for
β × γ
is a lexicographic order based on the well-founded relations for
β
and
γ
.
The default well-founded relation instance for
Nat
is
<
.
By default, the tactic
decreasing_tactic
is used to show that recursive applications are smaller with respect to the selected well-founded relation. If
decreasing_tactic
fails, the error message includes the remaining goal
... |- G
. Note that, the
decreasing_tactic
uses
assumption
. So, you can include a
have
-expression to prove goal
G
. You can also provide your own tactic using
decreasing_by
.
Mutual Recursion
Lean also supports mutual recursive definitions. The syntax is similar to that for mutual inductive types. Here is an example:
mutual
  def even : Nat → Bool
    | 0   => true
    | n+1 => odd n

  def odd : Nat → Bool
    | 0   => false
    | n+1 => even n
end

example : even (a + 1) = odd a := by
  simp [even]

example : odd (a + 1) = even a := by
  simp [odd]

theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
  intro a; induction a
  . simp [even, odd]
  . simp [even, odd, *]
What makes this a mutual definition is that
even
is defined recursively in terms of
odd
, while
odd
is defined recursively in terms of
even
. Under the hood, this is compiled as a single recursive definition. The internally defined function takes, as argument, an element of a sum type, either an input to
even
, or an input to
odd
. It then returns an output appropriate to the input. To define that function, Lean uses a suitable well-founded measure. The internals are meant to be hidden from users; the canonical way to make use of such definitions is to use
simp
(or
unfold
), as we did above.
Mutual recursive definitions also provide natural ways of working with mutual and nested inductive types. Recall the definition of
Even
and
Odd
as mutual inductive predicates as presented before.
mutual
  inductive Even : Nat → Prop where
    | even_zero : Even 0
    | even_succ : ∀ n, Odd n → Even (n + 1)

  inductive Odd : Nat → Prop where
    | odd_succ : ∀ n, Even n → Odd (n + 1)
end
The constructors,
even_zero
,
even_succ
, and
odd_succ
provide positive means for showing that a number is even or odd. We need to use the fact that the inductive type is generated by these constructors to know that zero is not odd, and that the latter two implications reverse. As usual, the constructors are kept in a namespace that is named after the type being defined, and the command
open Even Odd
allows us to access them more conveniently.
mutual
inductive Even : Nat → Prop where
| even_zero : Even 0
| even_succ : ∀ n, Odd n → Even (n + 1)
inductive Odd : Nat → Prop where
| odd_succ : ∀ n, Even n → Odd (n + 1)
end
open Even Odd

theorem not_odd_zero : ¬ Odd 0 :=
  fun h => nomatch h

theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
  | _, odd_succ n h => h

theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
  | _, even_succ n h => h
For another example, suppose we use a nested inductive type to define a set of terms inductively, so that a term is either a constant (with a name given by a string), or the result of applying a constant to a list of constants.
inductive Term where
  | const : String → Term
  | app   : String → List Term → Term
We can then use a mutual recursive definition to count the number of constants occurring in a term, as well as the number occurring in a list of terms.
inductive Term where
| const : String → Term
| app   : String → List Term → Term
namespace Term

mutual
  def numConsts : Term → Nat
    | const _ => 1
    | app _ cs => numConstsLst cs

  def numConstsLst : List Term → Nat
    | [] => 0
    | c :: cs => numConsts c + numConstsLst cs
end

def sample := app "f" [app "g" [const "x"], const "y"]

#eval numConsts sample

end Term
As a final example, we define a function
replaceConst a b e
that replaces a constant
a
with
b
in a term
e
, and then prove the number of constants is the same. Note that, our proof uses mutual recursion (aka induction).
inductive Term where
| const : String → Term
| app   : String → List Term → Term
namespace Term
mutual
def numConsts : Term → Nat
| const _ => 1
| app _ cs => numConstsLst cs
def numConstsLst : List Term → Nat
| [] => 0
| c :: cs => numConsts c + numConstsLst cs
end
mutual
  def replaceConst (a b : String) : Term → Term
    | const c => if a == c then const b else const c
    | app f cs => app f (replaceConstLst a b cs)

  def replaceConstLst (a b : String) : List Term → List Term
    | [] => []
    | c :: cs => replaceConst a b c :: replaceConstLst a b cs
end

mutual
  theorem numConsts_replaceConst (a b : String) (e : Term)
            : numConsts (replaceConst a b e) = numConsts e := by
    match e with
    | const c => simp [replaceConst]; split <;> simp [numConsts]
    | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]

  theorem numConsts_replaceConstLst (a b : String) (es : List Term)
            : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
    match es with
    | [] => simp [replaceConstLst, numConstsLst]
    | c :: cs =>
      simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
            numConsts_replaceConstLst a b cs]
end
Dependent Pattern Matching
All the examples of pattern matching we considered in
Section Pattern Matching
can easily be written using
casesOn
and
recOn
. However, this is often not the case with indexed
inductive families such as
Vector α n
, since case splits impose
constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very
simple functions such as
map
,
zip
, and
unzip
using
recursors. To understand the difficulty, consider what it would take
to define a function
tail
which takes a vector
v : Vector α (succ n)
and deletes the first element. A first thought might be to
use the
casesOn
function:
inductive Vector (α : Type u) : Nat → Type u
  | nil  : Vector α 0
  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)

namespace Vector

#check @Vector.casesOn
/-
  {α : Type u}
  → {motive : (a : Nat) → Vector α a → Sort v} →
  → {a : Nat} → (t : Vector α a)
  → motive 0 nil
  → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
  → motive a t
-/

end Vector
But what value should we return in the
nil
case? Something funny
is going on: if
v
has type
Vector α (succ n)
, it
can't
be
nil, but it is not clear how to tell that to
casesOn
.
One solution is to define an auxiliary function:
inductive Vector (α : Type u) : Nat → Type u
| nil  : Vector α 0
| cons : α → {n : Nat} → Vector α n → Vector α (n+1)
namespace Vector
def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
  Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
    (fun h : 0 = n + 1 => Nat.noConfusion h)
    (fun (a : α) (m : Nat) (as : Vector α m) =>
     fun (h : m + 1 = n + 1) =>
       Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))

def tail (v : Vector α (n+1)) : Vector α n :=
  tailAux v rfl
end Vector
In the
nil
case,
m
is instantiated to
0
, and
noConfusion
makes use of the fact that
0 = succ n
cannot
occur.  Otherwise,
v
is of the form
a :: w
, and we can simply
return
w
, after casting it from a vector of length
m
to a
vector of length
n
.
The difficulty in defining
tail
is to maintain the relationships between the indices.
The hypothesis
e : m = n + 1
in
tailAux
is used to communicate the relationship
between
n
and the index associated with the minor premise.
Moreover, the
zero = n + 1
case is unreachable, and the canonical way to discard such
a case is to use
noConfusion
.
The
tail
function is, however, easy to define using recursive
equations, and the equation compiler generates all the boilerplate
code automatically for us. Here are a number of similar examples:
inductive Vector (α : Type u) : Nat → Type u
| nil  : Vector α 0
| cons : α → {n : Nat} → Vector α n → Vector α (n+1)
namespace Vector
def head : {n : Nat} → Vector α (n+1) → α
  | n, cons a as => a

def tail : {n : Nat} → Vector α (n+1) → Vector α n
  | n, cons a as => as

theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
  | n, cons a as => rfl

def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
  | 0,   nil,       nil       => nil
  | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)

def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
  | 0,   nil,       nil       => nil
  | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
end Vector
Note that we can omit recursive equations for "unreachable" cases such
as
head nil
. The automatically generated definitions for indexed
families are far from straightforward. For example:
inductive Vector (α : Type u) : Nat → Type u
| nil  : Vector α 0
| cons : α → {n : Nat} → Vector α n → Vector α (n+1)
namespace Vector
def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
  | 0,   nil,       nil       => nil
  | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)

#print map
#print map.match_1
end Vector
The
map
function is even more tedious to define by hand than the
tail
function. We encourage you to try it, using
recOn
,
casesOn
and
noConfusion
.
Inaccessible Patterns
Sometimes an argument in a dependent matching pattern is not essential
to the definition, but nonetheless has to be included to specialize
the type of the expression appropriately. Lean allows users to mark
such subterms as
inaccessible
for pattern matching. These
annotations are essential, for example, when a term occurring in the
left-hand side is neither a variable nor a constructor application,
because these are not suitable targets for pattern matching. We can
view such inaccessible patterns as "don't care" components of the
patterns. You can declare a subterm inaccessible by writing
.(t)
. If the inaccessible pattern can be inferred, you can also write
_
.
The following example, we declare an inductive type that defines the
property of "being in the image of
f
". You can view an element of
the type
ImageOf f b
as evidence that
b
is in the image of
f
, whereby the constructor
imf
is used to build such
evidence. We can then define any function
f
with an "inverse"
which takes anything in the image of
f
to an element that is
mapped to it. The typing rules forces us to write
f a
for the
first argument, but this term is neither a variable nor a constructor
application, and plays no role in the pattern-matching definition. To
define the function
inverse
below, we
have to
mark
f a
inaccessible.
inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
  | imf : (a : α) → ImageOf f (f a)

open ImageOf

def inverse {f : α → β} : (b : β) → ImageOf f b → α
  | .(f a), imf a => a

def inverse' {f : α → β} : (b : β) → ImageOf f b → α
  | _, imf a => a
In the example above, the inaccessible annotation makes it clear that
f
is
not
a pattern matching variable.
Inaccessible patterns can be used to clarify and control definitions that
make use of dependent pattern matching. Consider the following
definition of the function
Vector.add
, which adds two vectors of
elements of a type, assuming that type has an associated addition
function:
inductive Vector (α : Type u) : Nat → Type u
  | nil  : Vector α 0
  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)

namespace Vector

def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
  | 0,   nil,       nil       => nil
  | n+1, cons a as, cons b bs => cons (a + b) (add as bs)

end Vector
The argument
{n : Nat}
appear after the colon, because it cannot
be held fixed throughout the definition.  When implementing this
definition, the equation compiler starts with a case distinction as to
whether the first argument is
0
or of the form
n+1
.  This is
followed by nested case splits on the next two arguments, and in each
case the equation compiler rules out the cases are not compatible with
the first pattern.
But, in fact, a case split is not required on the first argument; the
casesOn
eliminator for
Vector
automatically abstracts this
argument and replaces it by
0
and
n + 1
when we do a case
split on the second argument. Using inaccessible patterns, we can prompt
the equation compiler to avoid the case split on
n
inductive Vector (α : Type u) : Nat → Type u
| nil  : Vector α 0
| cons : α → {n : Nat} → Vector α n → Vector α (n+1)
namespace Vector
def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
  | .(_), nil,       nil       => nil
  | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
end Vector
Marking the position as an inaccessible pattern tells the
equation compiler first, that the form of the argument should be
inferred from the constraints posed by the other arguments, and,
second, that the first argument should
not
participate in pattern
matching.
The inaccessible pattern
.(_)
can be written as
_
for convenience.
inductive Vector (α : Type u) : Nat → Type u
| nil  : Vector α 0
| cons : α → {n : Nat} → Vector α n → Vector α (n+1)
namespace Vector
def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
  | _, nil,       nil       => nil
  | _, cons a as, cons b bs => cons (a + b) (add as bs)
end Vector
As we mentioned above, the argument
{n : Nat}
is part of the
pattern matching, because it cannot be held fixed throughout the
definition. In previous Lean versions, users often found it cumbersome
to have to include these extra discriminants. Thus, Lean 4
implements a new feature,
discriminant refinement
, which includes
these extra discriminants automatically for us.
inductive Vector (α : Type u) : Nat → Type u
| nil  : Vector α 0
| cons : α → {n : Nat} → Vector α n → Vector α (n+1)
namespace Vector
def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
  | nil,       nil       => nil
  | cons a as, cons b bs => cons (a + b) (add as bs)
end Vector
When combined with the
auto bound implicits
feature, you can simplify
the declare further and write:
inductive Vector (α : Type u) : Nat → Type u
| nil  : Vector α 0
| cons : α → {n : Nat} → Vector α n → Vector α (n+1)
namespace Vector
def add [Add α] : Vector α n → Vector α n → Vector α n
  | nil,       nil       => nil
  | cons a as, cons b bs => cons (a + b) (add as bs)
end Vector
Using these new features, you can write the other vector functions defined
in the previous sections more compactly as follows:
inductive Vector (α : Type u) : Nat → Type u
| nil  : Vector α 0
| cons : α → {n : Nat} → Vector α n → Vector α (n+1)
namespace Vector
def head : Vector α (n+1) → α
  | cons a as => a

def tail : Vector α (n+1) → Vector α n
  | cons a as => as

theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
  | cons a as => rfl

def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
  | nil,       nil       => nil
  | cons a as, cons b bs => cons (f a b) (map f as bs)

def zip : Vector α n → Vector β n → Vector (α × β) n
  | nil,       nil       => nil
  | cons a as, cons b bs => cons (a, b) (zip as bs)
end Vector
Match Expressions
Lean also provides a compiler for
match-with
expressions found in
many functional languages:
def isNotZero (m : Nat) : Bool :=
  match m with
  | 0   => false
  | n+1 => true
This does not look very different from an ordinary pattern matching
definition, but the point is that a
match
can be used anywhere in
an expression, and with arbitrary arguments.
def isNotZero (m : Nat) : Bool :=
  match m with
  | 0   => false
  | n+1 => true

def filter (p : α → Bool) : List α → List α
  | []      => []
  | a :: as =>
    match p a with
    | true => a :: filter p as
    | false => filter p as

example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
Here is another example:
def foo (n : Nat) (b c : Bool) :=
  5 + match n - 5, b && c with
      | 0,   true  => 0
      | m+1, true  => m + 7
      | 0,   false => 5
      | m+1, false => m + 3

#eval foo 7 true false

example : foo 7 true false = 9 := rfl
Lean uses the
match
construct internally to implement pattern-matching in all parts of the system.
Thus, all four of these definitions have the same net effect:
def bar₁ : Nat × Nat → Nat
  | (m, n) => m + n

def bar₂ (p : Nat × Nat) : Nat :=
  match p with
  | (m, n) => m + n

def bar₃ : Nat × Nat → Nat :=
  fun (m, n) => m + n

def bar₄ (p : Nat × Nat) : Nat :=
  let (m, n) := p; m + n
These variations are equally useful for destructing propositions:
variable (p q : Nat → Prop)

example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
  | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩

example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
        : ∃ x y, p x ∧ q y :=
  match h₀, h₁ with
  | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩

example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
  fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩

example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
        : ∃ x y, p x ∧ q y :=
  let ⟨x, px⟩ := h₀
  let ⟨y, qy⟩ := h₁
  ⟨x, y, px, qy⟩
Local Recursive Declarations
You can define local recursive declarations using the
let rec
keyword:
def replicate (n : Nat) (a : α) : List α :=
  let rec loop : Nat → List α → List α
    | 0,   as => as
    | n+1, as => loop n (a::as)
  loop n []

#check @replicate.loop
-- {α : Type} → α → Nat → List α → List α
Lean creates an auxiliary declaration for each
let rec
. In the example above,
it created the declaration
replicate.loop
for the
let rec loop
occurring at
replicate
.
Note that, Lean "closes" the declaration by adding any local variable occurring in the
let rec
declaration as additional parameters. For example, the local variable
a
occurs
at
let rec loop
.
You can also use
let rec
in tactic mode and for creating proofs by induction:
def replicate (n : Nat) (a : α) : List α :=
let rec loop : Nat → List α → List α
| 0,   as => as
| n+1, as => loop n (a::as)
loop n []
theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
  let rec aux (n : Nat) (as : List α)
              : (replicate.loop a n as).length = n + as.length := by
    match n with
    | 0   => simp [replicate.loop]
    | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
  exact aux n []
You can also introduce auxiliary recursive declarations using a
where
clause after your definition.
Lean converts them into a
let rec
:
def replicate (n : Nat) (a : α) : List α :=
  loop n []
where
  loop : Nat → List α → List α
    | 0,   as => as
    | n+1, as => loop n (a::as)

theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
  exact aux n []
where
  aux (n : Nat) (as : List α)
      : (replicate.loop a n as).length = n + as.length := by
    match n with
    | 0   => simp [replicate.loop]
    | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
Exercises
Open a namespace
Hidden
to avoid naming conflicts, and use the
equation compiler to define addition, multiplication, and
exponentiation on the natural numbers. Then use the equation
compiler to derive some of their basic properties.
Similarly, use the equation compiler to define some basic
operations on lists (like the
reverse
function) and prove
theorems about lists by induction (such as the fact that
reverse (reverse xs) = xs
for any list
xs
).
Define your own function to carry out course-of-value recursion on
the natural numbers. Similarly, see if you can figure out how to
define
WellFounded.fix
on your own.
Following the examples in
Section Dependent Pattern Matching
,
define a function that will append two vectors.
This is tricky; you will have to define an auxiliary function.
Consider the following type of arithmetic expressions. The idea is
that
var n
is a variable,
vₙ
, and
const n
is the
constant whose value is
n
.
inductive Expr where
  | const : Nat → Expr
  | var : Nat → Expr
  | plus : Expr → Expr → Expr
  | times : Expr → Expr → Expr
  deriving Repr

open Expr

def sampleExpr : Expr :=
  plus (times (var 0) (const 7)) (times (const 2) (var 1))
Here
sampleExpr
represents
(v₀ * 7) + (2 * v₁)
.
Write a function that evaluates such an expression, evaluating each
var n
to
v n
.
inductive Expr where
| const : Nat → Expr
| var : Nat → Expr
| plus : Expr → Expr → Expr
| times : Expr → Expr → Expr
deriving Repr
open Expr
def sampleExpr : Expr :=
plus (times (var 0) (const 7)) (times (const 2) (var 1))
def eval (v : Nat → Nat) : Expr → Nat
  | const n     => sorry
  | var n       => v n
  | plus e₁ e₂  => sorry
  | times e₁ e₂ => sorry

def sampleVal : Nat → Nat
  | 0 => 5
  | 1 => 6
  | _ => 0

-- Try it out. You should get 47 here.
-- #eval eval sampleVal sampleExpr
Implement "constant fusion," a procedure that simplifies subterms like
5 + 7
to
12
. Using the auxiliary function
simpConst
,
define a function "fuse": to simplify a plus or a times, first
simplify the arguments recursively, and then apply
simpConst
to
try to simplify the result.
inductive Expr where
| const : Nat → Expr
| var : Nat → Expr
| plus : Expr → Expr → Expr
| times : Expr → Expr → Expr
deriving Repr
open Expr
def eval (v : Nat → Nat) : Expr → Nat
| const n     => sorry
| var n       => v n
| plus e₁ e₂  => sorry
| times e₁ e₂ => sorry
def simpConst : Expr → Expr
  | plus (const n₁) (const n₂)  => const (n₁ + n₂)
  | times (const n₁) (const n₂) => const (n₁ * n₂)
  | e                           => e

def fuse : Expr → Expr := sorry

theorem simpConst_eq (v : Nat → Nat)
        : ∀ e : Expr, eval v (simpConst e) = eval v e :=
  sorry

theorem fuse_eq (v : Nat → Nat)
        : ∀ e : Expr, eval v (fuse e) = eval v e :=
  sorry
The last two theorems show that the definitions preserve the value.
Quantifiers and Equality - Theorem Proving in Lean 4
Theorem Proving in Lean 4
1.
Introduction
2.
Dependent Type Theory
3.
Propositions and Proofs
4.
Quantifiers and Equality
5.
Tactics
6.
Interacting with Lean
7.
Inductive Types
8.
Induction and Recursion
9.
Structures and Records
10.
Type Classes
11.
The Conversion Tactic Mode
12.
Axioms and Computation
Light (default)
Rust
Coal
Navy
Ayu
Theorem Proving in Lean 4
Quantifiers and Equality
The last chapter introduced you to methods that construct proofs of
statements involving the propositional connectives. In this chapter,
we extend the repertoire of logical constructions to include the
universal and existential quantifiers, and the equality relation.
The Universal Quantifier
Notice that if
α
is any type, we can represent a unary predicate
p
on
α
as an object of type
α → Prop
. In that case, given
x : α
,
p x
denotes the assertion that
p
holds of
x
. Similarly, an object
r : α → α → Prop
denotes a binary
relation on
α
: given
x y : α
,
r x y
denotes the assertion
that
x
is related to
y
.
The universal quantifier,
∀ x : α, p x
is supposed to denote the
assertion that "for every
x : α
,
p x
" holds. As with the
propositional connectives, in systems of natural deduction, "forall"
is governed by an introduction and elimination rule. Informally, the
introduction rule states:
Given a proof of
p x
, in a context where
x : α
is arbitrary, we obtain a proof
∀ x : α, p x
.
The elimination rule states:
Given a proof
∀ x : α, p x
and any term
t : α
, we obtain a proof of
p t
.
As was the case for implication, the propositions-as-types
interpretation now comes into play. Remember the introduction and
elimination rules for dependent arrow types:
Given a term
t
of type
β x
, in a context where
x : α
is arbitrary, we have
(fun x : α => t) : (x : α) → β x
.
The elimination rule states:
Given a term
s : (x : α) → β x
and any term
t : α
, we have
s t : β t
.
In the case where
p x
has type
Prop
, if we replace
(x : α) → β x
with
∀ x : α, p x
, we can read these as the correct rules
for building proofs involving the universal quantifier.
The Calculus of Constructions therefore identifies dependent arrow
types with forall-expressions in this way. If
p
is any expression,
∀ x : α, p
is nothing more than alternative notation for
(x : α) → p
, with the idea that the former is more natural than the latter
in cases where
p
is a proposition. Typically, the expression
p
will depend on
x : α
. Recall that, in the case of ordinary
function spaces, we could interpret
α → β
as the special case of
(x : α) → β
in which
β
does not depend on
x
. Similarly, we
can think of an implication
p → q
between propositions as the
special case of
∀ x : p, q
in which the expression
q
does not
depend on
x
.
Here is an example of how the propositions-as-types correspondence gets put into practice.
example (α : Type) (p q : α → Prop) : (∀ x : α, p x ∧ q x) → ∀ y : α, p y :=
  fun h : ∀ x : α, p x ∧ q x =>
  fun y : α =>
  show p y from (h y).left
As a notational convention, we give the universal quantifier the
widest scope possible, so parentheses are needed to limit the
quantifier over
x
to the hypothesis in the example above. The
canonical way to prove
∀ y : α, p y
is to take an arbitrary
y
,
and prove
p y
. This is the introduction rule. Now, given that
h
has type
∀ x : α, p x ∧ q x
, the expression
h y
has type
p y ∧ q y
. This is the elimination rule. Taking the left conjunct
gives the desired conclusion,
p y
.
Remember that expressions which differ up to renaming of bound
variables are considered to be equivalent. So, for example, we could
have used the same variable,
x
, in both the hypothesis and
conclusion, and instantiated it by a different variable,
z
, in the
proof:
example (α : Type) (p q : α → Prop) : (∀ x : α, p x ∧ q x) → ∀ x : α, p x :=
  fun h : ∀ x : α, p x ∧ q x =>
  fun z : α =>
  show p z from And.left (h z)
As another example, here is how we can express the fact that a relation,
r
, is transitive:
variable (α : Type) (r : α → α → Prop)
variable (trans_r : ∀ x y z, r x y → r y z → r x z)

variable (a b c : α)
variable (hab : r a b) (hbc : r b c)

#check trans_r    -- ∀ (x y z : α), r x y → r y z → r x z
#check trans_r a b c -- r a b → r b c → r a c
#check trans_r a b c hab -- r b c → r a c
#check trans_r a b c hab hbc -- r a c
Think about what is going on here. When we instantiate
trans_r
at
the values
a b c
, we end up with a proof of
r a b → r b c → r a c
.
Applying this to the "hypothesis"
hab : r a b
, we get a proof
of the implication
r b c → r a c
. Finally, applying it to the
hypothesis
hbc
yields a proof of the conclusion
r a c
.
In situations like this, it can be tedious to supply the arguments
a b c
, when they can be inferred from
hab hbc
. For that reason, it
is common to make these arguments implicit:
variable (α : Type) (r : α → α → Prop)
variable (trans_r : ∀ {x y z}, r x y → r y z → r x z)

variable (a b c : α)
variable (hab : r a b) (hbc : r b c)

#check trans_r
#check trans_r hab
#check trans_r hab hbc
The advantage is that we can simply write
trans_r hab hbc
as a
proof of
r a c
. A disadvantage is that Lean does not have enough
information to infer the types of the arguments in the expressions
trans_r
and
trans_r hab
. The output of the first
#check
command is
r ?m.1 ?m.2 → r ?m.2 ?m.3 → r ?m.1 ?m.3
, indicating
that the implicit arguments are unspecified in this case.
Here is an example of how we can carry out elementary reasoning with an equivalence relation:
variable (α : Type) (r : α → α → Prop)

variable (refl_r : ∀ x, r x x)
variable (symm_r : ∀ {x y}, r x y → r y x)
variable (trans_r : ∀ {x y z}, r x y → r y z → r x z)

example (a b c d : α) (hab : r a b) (hcb : r c b) (hcd : r c d) : r a d :=
  trans_r (trans_r hab (symm_r hcb)) hcd
To get used to using universal quantifiers, you should try some of the
exercises at the end of this section.
It is the typing rule for dependent arrow types, and the universal
quantifier in particular, that distinguishes
Prop
from other
types.  Suppose we have
α : Sort i
and
β : Sort j
, where the
expression
β
may depend on a variable
x : α
. Then
(x : α) → β
is an element of
Sort (imax i j)
, where
imax i j
is the
maximum of
i
and
j
if
j
is not 0, and 0 otherwise.
The idea is as follows. If
j
is not
0
, then
(x : α) → β
is
an element of
Sort (max i j)
. In other words, the type of
dependent functions from
α
to
β
"lives" in the universe whose
index is the maximum of
i
and
j
. Suppose, however, that
β
is of
Sort 0
, that is, an element of
Prop
. In that case,
(x : α) → β
is an element of
Sort 0
as well, no matter which
type universe
α
lives in. In other words, if
β
is a
proposition depending on
α
, then
∀ x : α, β
is again a
proposition. This reflects the interpretation of
Prop
as the type
of propositions rather than data, and it is what makes
Prop
impredicative
.
The term "predicative" stems from foundational developments around the
turn of the twentieth century, when logicians such as Poincaré and
Russell blamed set-theoretic paradoxes on the "vicious circles" that
arise when we define a property by quantifying over a collection that
includes the very property being defined. Notice that if
α
is any
type, we can form the type
α → Prop
of all predicates on
α
(the "power type of
α
"). The impredicativity of
Prop
means that we
can form propositions that quantify over
α → Prop
. In particular,
we can define predicates on
α
by quantifying over all predicates
on
α
, which is exactly the type of circularity that was once
considered problematic.
Equality
Let us now turn to one of the most fundamental relations defined in
Lean's library, namely, the equality relation. In
Chapter Inductive Types
,
we will explain
how
equality is defined from the primitives of Lean's logical framework.
In the meanwhile, here we explain how to use it.
Of course, a fundamental property of equality is that it is an equivalence relation:
#check Eq.refl    -- Eq.refl.{u_1} {α : Sort u_1} (a : α) : a = a
#check Eq.symm    -- Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a
#check Eq.trans   -- Eq.trans.{u} {α : Sort u} {a b c : α} (h₁ : a = b) (h₂ : b = c) : a = c
We can make the output easier to read by telling Lean not to insert
the implicit arguments (which are displayed here as metavariables).
universe u

#check @Eq.refl.{u}   -- @Eq.refl : ∀ {α : Sort u} (a : α), a = a
#check @Eq.symm.{u}   -- @Eq.symm : ∀ {α : Sort u} {a b : α}, a = b → b = a
#check @Eq.trans.{u}  -- @Eq.trans : ∀ {α : Sort u} {a b c : α}, a = b → b = c → a = c
The inscription
.{u}
tells Lean to instantiate the constants at the universe
u
.
Thus, for example, we can specialize the example from the previous section to the equality relation:
variable (α : Type) (a b c d : α)
variable (hab : a = b) (hcb : c = b) (hcd : c = d)

example : a = d :=
  Eq.trans (Eq.trans hab (Eq.symm hcb)) hcd
We can also use the projection notation:
variable (α : Type) (a b c d : α)
variable (hab : a = b) (hcb : c = b) (hcd : c = d)
example : a = d := (hab.trans hcb.symm).trans hcd
Reflexivity is more powerful than it looks. Recall that terms in the
Calculus of Constructions have a computational interpretation, and
that the logical framework treats terms with a common reduct as the
same. As a result, some nontrivial identities can be proved by
reflexivity:
variable (α β : Type)

example (f : α → β) (a : α) : (fun x => f x) a = f a := Eq.refl _
example (a : α) (b : β) : (a, b).1 = a := Eq.refl _
example : 2 + 3 = 5 := Eq.refl _
This feature of the framework is so important that the library defines a notation
rfl
for
Eq.refl _
:
variable (α β : Type)
example (f : α → β) (a : α) : (fun x => f x) a = f a := rfl
example (a : α) (b : β) : (a, b).1 = a := rfl
example : 2 + 3 = 5 := rfl
Equality is much more than an equivalence relation, however. It has
the important property that every assertion respects the equivalence,
in the sense that we can substitute equal expressions without changing
the truth value. That is, given
h1 : a = b
and
h2 : p a
, we
can construct a proof for
p b
using substitution:
Eq.subst h1 h2
.
example (α : Type) (a b : α) (p : α → Prop)
        (h1 : a = b) (h2 : p a) : p b :=
  Eq.subst h1 h2

example (α : Type) (a b : α) (p : α → Prop)
    (h1 : a = b) (h2 : p a) : p b :=
  h1 ▸ h2
The triangle in the second presentation is a macro built on top of
Eq.subst
and
Eq.symm
, and you can enter it by typing
\t
.
The rule
Eq.subst
is used to define the following auxiliary rules,
which carry out more explicit substitutions. They are designed to deal
with applicative terms, that is, terms of form
s t
. Specifically,
congrArg
can be used to replace the argument,
congrFun
can be
used to replace the term that is being applied, and
congr
can be
used to replace both at once.
variable (α : Type)
variable (a b : α)
variable (f g : α → Nat)
variable (h₁ : a = b)
variable (h₂ : f = g)

example : f a = f b := congrArg f h₁
example : f a = g a := congrFun h₂ a
example : f a = g b := congr h₂ h₁
Lean's library contains a large number of common identities, such as these:
variable (a b c : Nat)

example : a + 0 = a := Nat.add_zero a
example : 0 + a = a := Nat.zero_add a
example : a * 1 = a := Nat.mul_one a
example : 1 * a = a := Nat.one_mul a
example : a + b = b + a := Nat.add_comm a b
example : a + b + c = a + (b + c) := Nat.add_assoc a b c
example : a * b = b * a := Nat.mul_comm a b
example : a * b * c = a * (b * c) := Nat.mul_assoc a b c
example : a * (b + c) = a * b + a * c := Nat.mul_add a b c
example : a * (b + c) = a * b + a * c := Nat.left_distrib a b c
example : (a + b) * c = a * c + b * c := Nat.add_mul a b c
example : (a + b) * c = a * c + b * c := Nat.right_distrib a b c
Note that
Nat.mul_add
and
Nat.add_mul
are alternative names
for
Nat.left_distrib
and
Nat.right_distrib
, respectively.  The
properties above are stated for the natural numbers (type
Nat
).
Here is an example of a calculation in the natural numbers that uses
substitution combined with associativity and distributivity.
example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  have h1 : (x + y) * (x + y) = (x + y) * x + (x + y) * y :=
    Nat.mul_add (x + y) x y
  have h2 : (x + y) * (x + y) = x * x + y * x + (x * y + y * y) :=
    (Nat.add_mul x y x) ▸ (Nat.add_mul x y y) ▸ h1
  h2.trans (Nat.add_assoc (x * x + y * x) (x * y) (y * y)).symm
Notice that the second implicit parameter to
Eq.subst
, which
provides the context in which the substitution is to occur, has type
α → Prop
.  Inferring this predicate therefore requires an instance
of
higher-order unification
. In full generality, the problem of
determining whether a higher-order unifier exists is undecidable, and
Lean can at best provide imperfect and approximate solutions to the
problem. As a result,
Eq.subst
doesn't always do what you want it
to.  The macro
h ▸ e
uses more effective heuristics for computing
this implicit parameter, and often succeeds in situations where
applying
Eq.subst
fails.
Because equational reasoning is so common and important, Lean provides
a number of mechanisms to carry it out more effectively. The next
section offers syntax that allow you to write calculational proofs in
a more natural and perspicuous way. But, more importantly, equational
reasoning is supported by a term rewriter, a simplifier, and other
kinds of automation. The term rewriter and simplifier are described
briefly in the next section, and then in greater detail in the next
chapter.
Calculational Proofs
A calculational proof is just a chain of intermediate results that are
meant to be composed by basic principles such as the transitivity of
equality. In Lean, a calculational proof starts with the keyword
calc
, and has the following syntax:
calc
  <expr>_0  'op_1'  <expr>_1  ':='  <proof>_1
  '_'       'op_2'  <expr>_2  ':='  <proof>_2
  ...
  '_'       'op_n'  <expr>_n  ':='  <proof>_n
Note that the
calc
relations all have the same indentation. Each
<proof>_i
is a proof for
<expr>_{i-1} op_i <expr>_i
.
We can also use
_
in the first relation (right after
<expr>_0
)
which is useful to align the sequence of relation/proof pairs:
calc <expr>_0 
    '_' 'op_1' <expr>_1 ':=' <proof>_1
    '_' 'op_2' <expr>_2 ':=' <proof>_2
    ...
    '_' 'op_n' <expr>_n ':=' <proof>_n
Here is an example:
variable (a b c d e : Nat)
variable (h1 : a = b)
variable (h2 : b = c + 1)
variable (h3 : c = d)
variable (h4 : e = 1 + d)

theorem T : a = e :=
  calc
    a = b      := h1
    _ = c + 1  := h2
    _ = d + 1  := congrArg Nat.succ h3
    _ = 1 + d  := Nat.add_comm d 1
    _ = e      := Eq.symm h4
This style of writing proofs is most effective when it is used in
conjunction with the
simp
and
rewrite
tactics, which are
discussed in greater detail in the next chapter. For example, using
the abbreviation
rw
for rewrite, the proof above could be written
as follows:
variable (a b c d e : Nat)
variable (h1 : a = b)
variable (h2 : b = c + 1)
variable (h3 : c = d)
variable (h4 : e = 1 + d)
theorem T : a = e :=
  calc
    a = b      := by rw [h1]
    _ = c + 1  := by rw [h2]
    _ = d + 1  := by rw [h3]
    _ = 1 + d  := by rw [Nat.add_comm]
    _ = e      := by rw [h4]
Essentially, the
rw
tactic uses a given equality (which can be a
hypothesis, a theorem name, or a complex term) to "rewrite" the
goal. If doing so reduces the goal to an identity
t = t
, the
tactic applies reflexivity to prove it.
Rewrites can be applied sequentially, so that the proof above can be
shortened to this:
variable (a b c d e : Nat)
variable (h1 : a = b)
variable (h2 : b = c + 1)
variable (h3 : c = d)
variable (h4 : e = 1 + d)
theorem T : a = e :=
  calc
    a = d + 1  := by rw [h1, h2, h3]
    _ = 1 + d  := by rw [Nat.add_comm]
    _ = e      := by rw [h4]
Or even this:
variable (a b c d e : Nat)
variable (h1 : a = b)
variable (h2 : b = c + 1)
variable (h3 : c = d)
variable (h4 : e = 1 + d)
theorem T : a = e :=
  by rw [h1, h2, h3, Nat.add_comm, h4]
The
simp
tactic, instead, rewrites the goal by applying the given
identities repeatedly, in any order, anywhere they are applicable in a
term. It also uses other rules that have been previously declared to
the system, and applies commutativity wisely to avoid looping. As a
result, we can also prove the theorem as follows:
variable (a b c d e : Nat)
variable (h1 : a = b)
variable (h2 : b = c + 1)
variable (h3 : c = d)
variable (h4 : e = 1 + d)
theorem T : a = e :=
  by simp [h1, h2, h3, Nat.add_comm, h4]
We will discuss variations of
rw
and
simp
in the next chapter.
The
calc
command can be configured for any relation that supports
some form of transitivity. It can even combine different relations.
example (a b c d : Nat) (h1 : a = b) (h2 : b ≤ c) (h3 : c + 1 < d) : a < d :=
  calc
    a = b     := h1
    _ < b + 1 := Nat.lt_succ_self b
    _ ≤ c + 1 := Nat.succ_le_succ h2
    _ < d     := h3
You can "teach"
calc
new transitivity theorems by adding new instances
of the
Trans
type class. Type classes are introduced later, but the following
small example demonstrates how to extend the
calc
notation using new
Trans
instances.
def divides (x y : Nat) : Prop :=
  ∃ k, k*x = y

def divides_trans (h₁ : divides x y) (h₂ : divides y z) : divides x z :=
  let ⟨k₁, d₁⟩ := h₁
  let ⟨k₂, d₂⟩ := h₂
  ⟨k₁ * k₂, by rw [Nat.mul_comm k₁ k₂, Nat.mul_assoc, d₁, d₂]⟩

def divides_mul (x : Nat) (k : Nat) : divides x (k*x) :=
  ⟨k, rfl⟩

instance : Trans divides divides divides where
  trans := divides_trans

example (h₁ : divides x y) (h₂ : y = z) : divides x (2*z) :=
  calc
    divides x y     := h₁
    _ = z           := h₂
    divides _ (2*z) := divides_mul ..

infix:50 " ∣ " => divides

example (h₁ : divides x y) (h₂ : y = z) : divides x (2*z) :=
  calc
    x ∣ y   := h₁
    _ = z   := h₂
    _ ∣ 2*z := divides_mul ..
The example above also makes it clear that you can use
calc
even if you
do not have an infix notation for your relation. Finally we remark that
the vertical bar
∣
in the example above is the unicode one. We use
unicode to make sure we do not overload the ASCII
|
used in the
match .. with
expression.
With
calc
, we can write the proof in the last section in a more
natural and perspicuous way.
example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  calc
    (x + y) * (x + y) = (x + y) * x + (x + y) * y  := by rw [Nat.mul_add]
    _ = x * x + y * x + (x + y) * y                := by rw [Nat.add_mul]
    _ = x * x + y * x + (x * y + y * y)            := by rw [Nat.add_mul]
    _ = x * x + y * x + x * y + y * y              := by rw [←Nat.add_assoc]
The alternative
calc
notation is worth considering here. When the
first expression is taking this much space, using
_
in the first
relation naturally aligns all relations:
example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  calc (x + y) * (x + y)
    _ = (x + y) * x + (x + y) * y       := by rw [Nat.mul_add]
    _ = x * x + y * x + (x + y) * y     := by rw [Nat.add_mul]
    _ = x * x + y * x + (x * y + y * y) := by rw [Nat.add_mul]
    _ = x * x + y * x + x * y + y * y   := by rw [←Nat.add_assoc]
Here the left arrow before
Nat.add_assoc
tells rewrite to use the
identity in the opposite direction. (You can enter it with
\l
or
use the ascii equivalent,
<-
.) If brevity is what we are after,
both
rw
and
simp
can do the job on their own:
example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  by rw [Nat.mul_add, Nat.add_mul, Nat.add_mul, ←Nat.add_assoc]

example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  by simp [Nat.mul_add, Nat.add_mul, Nat.add_assoc]
The Existential Quantifier
Finally, consider the existential quantifier, which can be written as
either
exists x : α, p x
or
∃ x : α, p x
.  Both versions are
actually notationally convenient abbreviations for a more long-winded
expression,
Exists (fun x : α => p x)
, defined in Lean's library.
As you should by now expect, the library includes both an introduction
rule and an elimination rule. The introduction rule is
straightforward: to prove
∃ x : α, p x
, it suffices to provide a
suitable term
t
and a proof of
p t
. Here are some examples:
example : ∃ x : Nat, x > 0 :=
  have h : 1 > 0 := Nat.zero_lt_succ 0
  Exists.intro 1 h

example (x : Nat) (h : x > 0) : ∃ y, y < x :=
  Exists.intro 0 h

example (x y z : Nat) (hxy : x < y) (hyz : y < z) : ∃ w, x < w ∧ w < z :=
  Exists.intro y (And.intro hxy hyz)

#check @Exists.intro -- ∀ {α : Sort u_1} {p : α → Prop} (w : α), p w → Exists p
We can use the anonymous constructor notation
⟨t, h⟩
for
Exists.intro t h
, when the type is clear from the context.
example : ∃ x : Nat, x > 0 :=
  have h : 1 > 0 := Nat.zero_lt_succ 0
  ⟨1, h⟩

example (x : Nat) (h : x > 0) : ∃ y, y < x :=
  ⟨0, h⟩

example (x y z : Nat) (hxy : x < y) (hyz : y < z) : ∃ w, x < w ∧ w < z :=
  ⟨y, hxy, hyz⟩
Note that
Exists.intro
has implicit arguments: Lean has to infer
the predicate
p : α → Prop
in the conclusion
∃ x, p x
.  This
is not a trivial affair. For example, if we have
hg : g 0 0 = 0
and write
Exists.intro 0 hg
, there are many possible values
for the predicate
p
, corresponding to the theorems
∃ x, g x x = x
,
∃ x, g x x = 0
,
∃ x, g x 0 = x
, etc. Lean uses the
context to infer which one is appropriate. This is illustrated in the
following example, in which we set the option
pp.explicit
to true
to ask Lean's pretty-printer to show the implicit arguments.
variable (g : Nat → Nat → Nat)
variable (hg : g 0 0 = 0)

theorem gex1 : ∃ x, g x x = x := ⟨0, hg⟩
theorem gex2 : ∃ x, g x 0 = x := ⟨0, hg⟩
theorem gex3 : ∃ x, g 0 0 = x := ⟨0, hg⟩
theorem gex4 : ∃ x, g x x = 0 := ⟨0, hg⟩

set_option pp.explicit true  -- display implicit arguments
#print gex1
#print gex2
#print gex3
#print gex4
We can view
Exists.intro
as an information-hiding operation, since
it hides the witness to the body of the assertion. The existential
elimination rule,
Exists.elim
, performs the opposite operation. It
allows us to prove a proposition
q
from
∃ x : α, p x
, by
showing that
q
follows from
p w
for an arbitrary value
w
. Roughly speaking, since we know there is an
x
satisfying
p x
, we can give it a name, say,
w
. If
q
does not mention
w
, then showing that
q
follows from
p w
is tantamount to
showing that
q
follows from the existence of any such
x
. Here
is an example:
variable (α : Type) (p q : α → Prop)

example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  Exists.elim h
    (fun w =>
     fun hw : p w ∧ q w =>
     show ∃ x, q x ∧ p x from ⟨w, hw.right, hw.left⟩)
It may be helpful to compare the exists-elimination rule to the
or-elimination rule: the assertion
∃ x : α, p x
can be thought of
as a big disjunction of the propositions
p a
, as
a
ranges over
all the elements of
α
. Note that the anonymous constructor
notation
⟨w, hw.right, hw.left⟩
abbreviates a nested constructor
application; we could equally well have written
⟨w, ⟨hw.right, hw.left⟩⟩
.
Notice that an existential proposition is very similar to a sigma
type, as described in dependent types section.  The difference is that
given
a : α
and
h : p a
, the term
Exists.intro a h
has
type
(∃ x : α, p x) : Prop
and
Sigma.mk a h
has type
(Σ x : α, p x) : Type
. The similarity between
∃
and
Σ
is another
instance of the Curry-Howard isomorphism.
Lean provides a more convenient way to eliminate from an existential
quantifier with the
match
expression:
variable (α : Type) (p q : α → Prop)

example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  match h with
  | ⟨w, hw⟩ => ⟨w, hw.right, hw.left⟩
The
match
expression is part of Lean's function definition system,
which provides convenient and expressive ways of defining complex
functions.  Once again, it is the Curry-Howard isomorphism that allows
us to co-opt this mechanism for writing proofs as well.  The
match
statement "destructs" the existential assertion into the components
w
and
hw
, which can then be used in the body of the statement
to prove the proposition. We can annotate the types used in the match
for greater clarity:
variable (α : Type) (p q : α → Prop)
example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  match h with
  | ⟨(w : α), (hw : p w ∧ q w)⟩ => ⟨w, hw.right, hw.left⟩
We can even use the match statement to decompose the conjunction at the same time:
variable (α : Type) (p q : α → Prop)
example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  match h with
  | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
Lean also provides a pattern-matching
let
expression:
variable (α : Type) (p q : α → Prop)
example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  let ⟨w, hpw, hqw⟩ := h
  ⟨w, hqw, hpw⟩
This is essentially just alternative notation for the
match
construct above. Lean will even allow us to use an implicit
match
in the
fun
expression:
variable (α : Type) (p q : α → Prop)
example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
  fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
We will see in
Chapter Induction and Recursion
that all these variations are
instances of a more general pattern-matching construct.
In the following example, we define
is_even a
as
∃ b, a = 2 * b
,
and then we show that the sum of two even numbers is an even number.
def is_even (a : Nat) := ∃ b, a = 2 * b


2025-05-31 17:55:45,847 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.'}], 'model': 'o3-mini'}}
2025-05-31 17:55:45,847 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-05-31 17:55:45,848 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-05-31 17:55:45,858 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a6c374e86b0>
2025-05-31 17:55:45,858 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7a6d1fa5fbd0> server_hostname='api.openai.com' timeout=5.0
2025-05-31 17:55:45,867 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a6c374e8560>
2025-05-31 17:55:45,868 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-31 17:55:45,868 - DEBUG - send_request_headers.complete
2025-05-31 17:55:45,868 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-31 17:55:45,868 - DEBUG - send_request_body.complete
2025-05-31 17:55:45,868 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-31 17:55:51,524 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 31 May 2025 17:55:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5021'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5024'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199622'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'113ms'), (b'x-request-id', b'req_d50cab9012bebee11d48af4bbcbdf3f0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=aL66r35huAtoyaZWC0gXvcxSxLQNjO9U9z2Aj3qdZxU-1748714151-1.0.1.1-0CxSlxiUyFpMTmVg_6Ftyl.RPTeFczO3FqvrNnjpmjpF9p9X7o.LW3zZ6Xmc1V1q3KnLq2xUEAZL6dh4qr_rAdGp105Yt2A6fEvFOaT4q1s; path=/; expires=Sat, 31-May-25 18:25:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=3GmFD3KrZfYHA_1GMko_xtT1RS84hHqcrnQPtDByXOM-1748714151549-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94885813dd6a3cac-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-05-31 17:55:51,524 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-31 17:55:51,524 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-31 17:55:51,525 - DEBUG - receive_response_body.complete
2025-05-31 17:55:51,525 - DEBUG - response_closed.started
2025-05-31 17:55:51,525 - DEBUG - response_closed.complete
2025-05-31 17:55:51,525 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 31 May 2025 17:55:51 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '5021'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '5024'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '199622'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '113ms'), ('x-request-id', 'req_d50cab9012bebee11d48af4bbcbdf3f0'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=aL66r35huAtoyaZWC0gXvcxSxLQNjO9U9z2Aj3qdZxU-1748714151-1.0.1.1-0CxSlxiUyFpMTmVg_6Ftyl.RPTeFczO3FqvrNnjpmjpF9p9X7o.LW3zZ6Xmc1V1q3KnLq2xUEAZL6dh4qr_rAdGp105Yt2A6fEvFOaT4q1s; path=/; expires=Sat, 31-May-25 18:25:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=3GmFD3KrZfYHA_1GMko_xtT1RS84hHqcrnQPtDByXOM-1748714151549-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '94885813dd6a3cac-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-05-31 17:55:51,525 - DEBUG - request_id: req_d50cab9012bebee11d48af4bbcbdf3f0
2025-05-31 17:55:51,529 - INFO - Attempt 1/3
2025-05-31 17:55:51,529 - INFO - Current plan: {
  "plan_summary": "Define an identity function in Lean 4 that takes a natural number as input and returns the same natural number. The implementation is straightforward as it only involves returning the argument.",
  "steps": [
    "Define a function with the appropriate signature that takes a natural number (x) as input.",
    "Within the function body, simply return x.",
    "Ensure that the function checks out with Lean's type system by verifying that both the input and output are of type Nat."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "identity function",
    "Nat",
    "return"
  ],
  "proof_keywords": [
    "identity",
    "reflexivity",
    "type checking"
  ],
  "assumptions": [
    "The natural number type is available and denoted as Nat in Lean 4.",
    "No additional computation or transformation is required on the input."
  ],
  "retry_guidance": "If any errors arise, verify that the function signature matches Lean 4 syntax for defining functions and that the input type is correct. Revisit type annotations if Lean reports type mismatches."
}
2025-05-31 17:55:51,529 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define an identity function in Lean 4 that takes a natural number as input and returns the same natural number. The implementation is straightforward as it only involves returning the argument.",\n  "steps": [\n    "Define a function with the appropriate signature that takes a natural number (x) as input.",\n    "Within the function body, simply return x.",\n    "Ensure that the function checks out with Lean\'s type system by verifying that both the input and output are of type Nat."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "identity function",\n    "Nat",\n    "return"\n  ],\n  "proof_keywords": [\n    "identity",\n    "reflexivity",\n    "type checking"\n  ],\n  "assumptions": [\n    "The natural number type is available and denoted as Nat in Lean 4.",\n    "No additional computation or transformation is required on the input."\n  ],\n  "retry_guidance": "If any errors arise, verify that the function signature matches Lean 4 syntax for defining functions and that the input type is correct. Revisit type annotations if Lean reports type mismatches."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef ident (x : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\ndef ident_spec (x : Nat) (result: Nat) : Prop :=\n  -- << SPEC START >>\n  result = x\n  -- << SPEC END >>\n\ntheorem ident_spec_satisfied (x : Nat) :\n  ident_spec x (ident x) := by\n  -- << PROOF START >>\n  unfold ident ident_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\nInduction and Recursion - Theorem Proving in Lean 4\nTheorem Proving in Lean 4\n1.\nIntroduction\n2.\nDependent Type Theory\n3.\nPropositions and Proofs\n4.\nQuantifiers and Equality\n5.\nTactics\n6.\nInteracting with Lean\n7.\nInductive Types\n8.\nInduction and Recursion\n9.\nStructures and Records\n10.\nType Classes\n11.\nThe Conversion Tactic Mode\n12.\nAxioms and Computation\nLight (default)\nRust\nCoal\nNavy\nAyu\nTheorem Proving in Lean 4\nInduction and Recursion\nIn the previous chapter, we saw that inductive definitions provide a\npowerful means of introducing new types in Lean. Moreover, the\nconstructors and the recursors provide the only means of defining\nfunctions on these types. By the propositions-as-types correspondence,\nthis means that induction is the fundamental method of proof.\nLean provides natural ways of defining recursive functions, performing\npattern matching, and writing inductive proofs. It allows you to\ndefine a function by specifying equations that it should satisfy, and\nit allows you to prove a theorem by specifying how to handle various\ncases that can arise. Behind the scenes, these descriptions are\n"compiled" down to primitive recursors, using a procedure that we\nrefer to as the "equation compiler." The equation compiler is not part\nof the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\nPattern Matching\nThe interpretation of schematic patterns is the first step of the\ncompilation process. We have seen that the\ncasesOn\nrecursor can\nbe used to define functions and prove theorems by cases, according to\nthe constructors involved in an inductively defined type. But\ncomplicated definitions may use several nested\ncasesOn\napplications, and may be hard to read and understand. Pattern matching\nprovides an approach that is more convenient, and familiar to users of\nfunctional programming languages.\nConsider the inductively defined type of natural numbers. Every\nnatural number is either\nzero\nor\nsucc x\n, and so you can define\na function from the natural numbers to an arbitrary type by specifying\na value in each of those cases:\nopen Nat\n\ndef sub1 : Nat → Nat\n  | zero   => zero\n  | succ x => x\n\ndef isZero : Nat → Bool\n  | zero   => true\n  | succ x => false\nThe equations used to define these functions hold definitionally:\nopen Nat\ndef sub1 : Nat → Nat\n| zero   => zero\n| succ x => x\ndef isZero : Nat → Bool\n| zero   => true\n| succ x => false\nexample : sub1 0 = 0 := rfl\nexample (x : Nat) : sub1 (succ x) = x := rfl\n\nexample : isZero 0 = true := rfl\nexample (x : Nat) : isZero (succ x) = false := rfl\n\nexample : sub1 7 = 6 := rfl\nexample (x : Nat) : isZero (x + 3) = false := rfl\nInstead of\nzero\nand\nsucc\n, we can use more familiar notation:\ndef sub1 : Nat → Nat\n  | 0   => 0\n  | x+1 => x\n\ndef isZero : Nat → Bool\n  | 0   => true\n  | x+1 => false\nBecause addition and the zero notation have been assigned the\n[match_pattern]\nattribute, they can be used in pattern matching. Lean\nsimply normalizes these expressions until the constructors\nzero\nand\nsucc\nare exposed.\nPattern matching works with any inductive type, such as products and option types:\ndef swap : α × β → β × α\n  | (a, b) => (b, a)\n\ndef foo : Nat × Nat → Nat\n  | (m, n) => m + n\n\ndef bar : Option Nat → Nat\n  | some n => n + 1\n  | none   => 0\nHere we use it not only to define a function, but also to carry out a\nproof by cases:\nnamespace Hidden\ndef not : Bool → Bool\n  | true  => false\n  | false => true\n\ntheorem not_not : ∀ (b : Bool), not (not b) = b\n  | true  => rfl  -- proof that not (not true) = true\n  | false => rfl  -- proof that not (not false) = false\nend Hidden\nPattern matching can also be used to destruct inductively defined propositions:\nexample (p q : Prop) : p ∧ q → q ∧ p\n  | And.intro h₁ h₂ => And.intro h₂ h₁\n\nexample (p q : Prop) : p ∨ q → q ∨ p\n  | Or.inl hp => Or.inr hp\n  | Or.inr hq => Or.inl hq\nThis provides a compact way of unpacking hypotheses that make use of logical connectives.\nIn all these examples, pattern matching was used to carry out a single\ncase distinction. More interestingly, patterns can involve nested\nconstructors, as in the following examples.\ndef sub2 : Nat → Nat\n  | 0   => 0\n  | 1   => 0\n  | x+2 => x\nThe equation compiler first splits on cases as to whether the input is\nzero\nor of the form\nsucc x\n.  It then does a case split on\nwhether\nx\nis of the form\nzero\nor\nsucc x\n.  It determines\nthe necessary case splits from the patterns that are presented to it,\nand raises an error if the patterns fail to exhaust the cases. Once\nagain, we can use arithmetic notation, as in the version below. In\neither case, the defining equations hold definitionally.\ndef sub2 : Nat → Nat\n| 0   => 0\n| 1   => 0\n| x+2 => x\nexample : sub2 0 = 0 := rfl\nexample : sub2 1 = 0 := rfl\nexample : sub2 (x+2) = x := rfl\n\nexample : sub2 5 = 3 := rfl\nYou can write\n#print sub2\nto see how the function was compiled to\nrecursors. (Lean will tell you that\nsub2\nhas been defined in terms\nof an internal auxiliary function,\nsub2.match_1\n, but you can print\nthat out too.) Lean uses these auxiliary functions to compile\nmatch\nexpressions.\nActually, the definition above is expanded to\ndef sub2 : Nat → Nat :=\n  fun x =>\n    match x with\n    | 0   => 0\n    | 1   => 0\n    | x+2 => x\nHere are some more examples of nested pattern matching:\nexample (p q : α → Prop)\n        : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n  | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n  | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n\ndef foo : Nat × Nat → Nat\n  | (0, n)     => 0\n  | (m+1, 0)   => 1\n  | (m+1, n+1) => 2\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a\nfunction of two arguments:\ndef foo : Nat → Nat → Nat\n  | 0,   n   => 0\n  | m+1, 0   => 1\n  | m+1, n+1 => 2\nHere is another example:\ndef bar : List Nat → List Nat → Nat\n  | [],      []      => 0\n  | a :: as, []      => a\n  | [],      b :: bs => b\n  | a :: as, b :: bs => a + b\nNote that the patterns are separated by commas.\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of\npatterns.\nnamespace Hidden\ndef and : Bool → Bool → Bool\n  | true,  a => a\n  | false, _ => false\n\ndef or : Bool → Bool → Bool\n  | true,  _ => true\n  | false, a => a\n\ndef cond : Bool → α → α → α\n  | true,  x, y => x\n  | false, x, y => y\nend Hidden\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is\nknown as a\nwildcard pattern\n, or an\nanonymous variable\n. In contrast\nto usage outside the equation compiler, here the underscore does\nnot\nindicate an implicit argument. The use of underscores for wildcards is\ncommon in functional programming languages, and so Lean adopts that\nnotation.\nSection Wildcards and Overlapping Patterns\nexpands on the notion of a wildcard, and\nSection Inaccessible Patterns\nexplains how\nyou can use implicit arguments in patterns as well.\nAs described in\nChapter Inductive Types\n,\ninductive data types can depend on parameters. The following example defines\nthe\ntail\nfunction using pattern matching. The argument\nα : Type u\nis a parameter and occurs before the colon to indicate it does not participate in the pattern matching.\nLean also allows parameters to occur after\n:\n, but it cannot pattern match on them.\ndef tail1 {α : Type u} : List α → List α\n  | []      => []\n  | a :: as => as\n\ndef tail2 : {α : Type u} → List α → List α\n  | α, []      => []\n  | α, a :: as => as\nDespite the different placement of the parameter\nα\nin these two\nexamples, in both cases it is treated in the same way, in that it does\nnot participate in a case split.\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the\nvarious cases. Such examples of\ndependent pattern matching\nare\nconsidered in the\nSection Dependent Pattern Matching\n.\nWildcards and Overlapping Patterns\nConsider one of the examples from the last section:\ndef foo : Nat → Nat → Nat\n  | 0,   n   => 0\n  | m+1, 0   => 1\n  | m+1, n+1 => 2\nAn alternative presentation is:\ndef foo : Nat → Nat → Nat\n  | 0, n => 0\n  | m, 0 => 1\n  | m, n => 2\nIn the second presentation, the patterns overlap; for example, the\npair of arguments\n0 0\nmatches all three cases. But Lean handles\nthe ambiguity by using the first applicable equation, so in this example\nthe net result is the same. In particular, the following equations hold\ndefinitionally:\ndef foo : Nat → Nat → Nat\n| 0, n => 0\n| m, 0 => 1\n| m, n => 2\nexample : foo 0     0     = 0 := rfl\nexample : foo 0     (n+1) = 0 := rfl\nexample : foo (m+1) 0     = 1 := rfl\nexample : foo (m+1) (n+1) = 2 := rfl\nSince the values of\nm\nand\nn\nare not needed, we can just as well use wildcard patterns instead.\ndef foo : Nat → Nat → Nat\n  | 0, _ => 0\n  | _, 0 => 1\n  | _, _ => 2\nYou can check that this definition of\nfoo\nsatisfies the same\ndefinitional identities as before.\nSome functional programming languages support\nincomplete\npatterns\n. In these languages, the interpreter produces an exception\nor returns an arbitrary value for incomplete cases. We can simulate\nthe arbitrary value approach using the\nInhabited\ntype\nclass. Roughly, an element of\nInhabited α\nis a witness to the fact\nthat there is an element of\nα\n; in the\nChapter Type Classes\nwe will see that Lean can be instructed that suitable\nbase types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the\nstandard library provides a default element,\ndefault\n, of\nany inhabited type.\nWe can also use the type\nOption α\nto simulate incomplete patterns.\nThe idea is to return\nsome a\nfor the provided patterns, and use\nnone\nfor the incomplete cases. The following example demonstrates\nboth approaches.\ndef f1 : Nat → Nat → Nat\n  | 0, _  => 1\n  | _, 0  => 2\n  | _, _  => default  -- the "incomplete" case\n\nexample : f1 0     0     = 1       := rfl\nexample : f1 0     (a+1) = 1       := rfl\nexample : f1 (a+1) 0     = 2       := rfl\nexample : f1 (a+1) (b+1) = default := rfl\n\ndef f2 : Nat → Nat → Option Nat\n  | 0, _  => some 1\n  | _, 0  => some 2\n  | _, _  => none     -- the "incomplete" case\n\nexample : f2 0     0     = some 1 := rfl\nexample : f2 0     (a+1) = some 1 := rfl\nexample : f2 (a+1) 0     = some 2 := rfl\nexample : f2 (a+1) (b+1) = none   := rfl\nThe equation compiler is clever. If you leave out any of the cases in\nthe following definition, the error message will let you know what has\nnot been covered.\ndef bar : Nat → List Nat → Bool → Nat\n  | 0,   _,      false => 0\n  | 0,   b :: _, _     => b\n  | 0,   [],     true  => 7\n  | a+1, [],     false => a\n  | a+1, [],     true  => a + 1\n  | a+1, b :: _, _     => a + b\nIt will also use an "if ... then ... else" instead of a\ncasesOn\nin appropriate situations.\ndef foo : Char → Nat\n  | \'A\' => 1\n  | \'B\' => 2\n  | _   => 3\n\n#print foo.match_1\nStructural Recursion and Induction\nWhat makes the equation compiler powerful is that it also supports\nrecursive definitions. In the next three sections, we will describe,\nrespectively:\nstructurally recursive definitions\nwell-founded recursive definitions\nmutually recursive definitions\nGenerally speaking, the equation compiler processes input of the following form:\ndef foo (a : α) : (b : β) → γ\n  | [patterns₁] => t₁\n  ...\n  | [patternsₙ] => tₙ\nHere\n(a : α)\nis a sequence of parameters,\n(b : β)\nis the\nsequence of arguments on which pattern matching takes place, and\nγ\nis any type, which can depend on\na\nand\nb\n. Each line should\ncontain the same number of patterns, one for each element of\nβ\n. As we\nhave seen, a pattern is either a variable, a constructor applied to\nother patterns, or an expression that normalizes to something of that\nform (where the non-constructors are marked with the\n[match_pattern]\nattribute). The appearances of constructors prompt case splits, with\nthe arguments to the constructors represented by the given\nvariables. In\nSection Dependent Pattern Matching\n,\nwe will see that it is sometimes necessary to include explicit terms in patterns that\nare needed to make an expression type check, though they do not play a\nrole in pattern matching. These are called "inaccessible patterns" for\nthat reason. But we will not need to use such inaccessible patterns\nbefore\nSection Dependent Pattern Matching\n.\nAs we saw in the last section, the terms\nt₁, ..., tₙ\ncan make use\nof any of the parameters\na\n, as well as any of the variables that\nare introduced in the corresponding patterns. What makes recursion and\ninduction possible is that they can also involve recursive calls to\nfoo\n. In this section, we will deal with\nstructural recursion\n, in\nwhich the arguments to\nfoo\noccurring on the right-hand side of the\n=>\nare subterms of the patterns on the left-hand side. The idea is\nthat they are structurally smaller, and hence appear in the inductive\ntype at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation\ncompiler:\nopen Nat\ndef add : Nat → Nat → Nat\n  | m, zero   => m\n  | m, succ n => succ (add m n)\n\ntheorem add_zero (m : Nat)   : add m zero = m := rfl\ntheorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n\ntheorem zero_add : ∀ n, add zero n = n\n  | zero   => rfl\n  | succ n => congrArg succ (zero_add n)\n\ndef mul : Nat → Nat → Nat\n  | n, zero   => zero\n  | n, succ m => add (mul n m) n\nThe proof of\nzero_add\nmakes it clear that proof by induction is\nreally a form of recursion in Lean.\nThe example above shows that the defining equations for\nadd\nhold\ndefinitionally, and the same is true of\nmul\n. The equation compiler\ntries to ensure that this holds whenever possible, as is the case with\nstraightforward structural induction. In other situations, however,\nreductions hold only\npropositionally\n, which is to say, they are\nequational theorems that must be applied explicitly. The equation\ncompiler generates such theorems internally. They are not meant to be\nused directly by the user; rather, the\nsimp\ntactic\nis configured to use them when necessary. Thus both of the following\nproofs of\nzero_add\nwork:\nopen Nat\ndef add : Nat → Nat → Nat\n| m, zero   => m\n| m, succ n => succ (add m n)\ntheorem zero_add : ∀ n, add zero n = n\n  | zero   => by simp [add]\n  | succ n => by simp [add, zero_add]\nAs with definition by pattern matching, parameters to a structural\nrecursion or induction may appear before the colon. Such parameters\nare simply added to the local context before the definition is\nprocessed. For example, the definition of addition may also be written\nas follows:\nopen Nat\ndef add (m : Nat) : Nat → Nat\n  | zero   => m\n  | succ n => succ (add m n)\nYou can also write the example above using\nmatch\n.\nopen Nat\ndef add (m n : Nat) : Nat :=\n  match n with\n  | zero   => m\n  | succ n => succ (add m n)\nA more interesting example of structural recursion is given by the Fibonacci function\nfib\n.\ndef fib : Nat → Nat\n  | 0   => 1\n  | 1   => 1\n  | n+2 => fib (n+1) + fib n\n\nexample : fib 0 = 1 := rfl\nexample : fib 1 = 1 := rfl\nexample : fib (n + 2) = fib (n + 1) + fib n := rfl\n\nexample : fib 7 = 21 := rfl\nHere, the value of the\nfib\nfunction at\nn + 2\n(which is\ndefinitionally equal to\nsucc (succ n)\n) is defined in terms of the\nvalues at\nn + 1\n(which is definitionally equivalent to\nsucc n\n)\nand the value at\nn\n. This is a notoriously inefficient way of\ncomputing the Fibonacci function, however, with an execution time that\nis exponential in\nn\n. Here is a better way:\ndef fibFast (n : Nat) : Nat :=\n  (loop n).2\nwhere\n  loop : Nat → Nat × Nat\n    | 0   => (0, 1)\n    | n+1 => let p := loop n; (p.2, p.1 + p.2)\n\n#eval fibFast 100\nHere is the same definition using a\nlet rec\ninstead of a\nwhere\n.\ndef fibFast (n : Nat) : Nat :=\n  let rec loop : Nat → Nat × Nat\n    | 0   => (0, 1)\n    | n+1 => let p := loop n; (p.2, p.1 + p.2)\n  (loop n).2\nIn both cases, Lean generates the auxiliary function\nfibFast.loop\n.\nTo handle structural recursion, the equation compiler uses\ncourse-of-values\nrecursion, using constants\nbelow\nand\nbrecOn\nthat are automatically generated with each inductively defined\ntype. You can get a sense of how it works by looking at the types of\nNat.below\nand\nNat.brecOn\n:\nvariable (C : Nat → Type u)\n\n#check (@Nat.below C : Nat → Type u)\n\n#reduce @Nat.below C (3 : Nat)\n\n#check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\nThe type\n@Nat.below C (3 : nat)\nis a data structure that stores elements of\nC 0\n,\nC 1\n, and\nC 2\n.\nThe course-of-values recursion is implemented by\nNat.brecOn\n. It enables us to define the value of a dependent\nfunction of type\n(n : Nat) → C n\nat a particular input\nn\nin terms of all the previous values of the function,\npresented as an element of\n@Nat.below C n\n.\nThe use of course-of-values recursion is one of the techniques the equation compiler uses to justify to\nthe Lean kernel that a function terminates. It does not affect the code generator which compiles recursive\nfunctions as other functional programming language compilers. Recall that\n#eval fib <n>\nis exponential on\n<n>\n.\nOn the other hand,\n#reduce fib <n>\nis efficient because it uses the definition sent to the kernel that\nis based on the\nbrecOn\nconstruction.\ndef fib : Nat → Nat\n  | 0   => 1\n  | 1   => 1\n  | n+2 => fib (n+1) + fib n\n\n-- #eval fib 50 -- slow\n#reduce fib 50  -- fast\n\n#print fib\nAnother good example of a recursive definition is the list\nappend\nfunction.\ndef append : List α → List α → List α\n  | [],    bs => bs\n  | a::as, bs => a :: append as bs\n\nexample : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\nHere is another: it adds elements of the first list to elements of the second list, until one of the two lists runs out.\ndef listAdd [Add α] : List α → List α → List α\n  | [],      _       => []\n  | _,       []      => []\n  | a :: as, b :: bs => (a + b) :: listAdd as bs\n\n#eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n-- [5, 7, 9]\nYou are encouraged to experiment with similar examples in the exercises below.\nLocal recursive declarations\nYou can define local recursive declarations using the\nlet rec\nkeyword.\ndef replicate (n : Nat) (a : α) : List α :=\n  let rec loop : Nat → List α → List α\n    | 0,   as => as\n    | n+1, as => loop n (a::as)\n  loop n []\n\n#check @replicate.loop\n-- {α : Type} → α → Nat → List α → List α\nLean creates an auxiliary declaration for each\nlet rec\n. In the example above,\nit created the declaration\nreplicate.loop\nfor the\nlet rec loop\noccurring at\nreplicate\n.\nNote that, Lean "closes" the declaration by adding any local variable occurring in the\nlet rec\ndeclaration as additional parameters. For example, the local variable\na\noccurs\nat\nlet rec loop\n.\nYou can also use\nlet rec\nin tactic mode and for creating proofs by induction.\ndef replicate (n : Nat) (a : α) : List α :=\nlet rec loop : Nat → List α → List α\n| 0,   as => as\n| n+1, as => loop n (a::as)\nloop n []\ntheorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n  let rec aux (n : Nat) (as : List α)\n              : (replicate.loop a n as).length = n + as.length := by\n    match n with\n    | 0   => simp [replicate.loop]\n    | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n  exact aux n []\nYou can also introduce auxiliary recursive declarations using\nwhere\nclause after your definition.\nLean converts them into a\nlet rec\n.\ndef replicate (n : Nat) (a : α) : List α :=\n  loop n []\nwhere\n  loop : Nat → List α → List α\n    | 0,   as => as\n    | n+1, as => loop n (a::as)\n\ntheorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n  exact aux n []\nwhere\n  aux (n : Nat) (as : List α)\n      : (replicate.loop a n as).length = n + as.length := by\n    match n with\n    | 0   => simp [replicate.loop]\n    | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\nWell-Founded Recursion and Induction\nWhen structural recursion cannot be used, we can prove termination using well-founded recursion.\nWe need a well-founded relation and a proof that each recursive application is decreasing with respect to\nthis relation. Dependent type theory is powerful enough to encode and justify\nwell-founded recursion. Let us start with the logical background that\nis needed to understand how it works.\nLean\'s standard library defines two predicates,\nAcc r a\nand\nWellFounded r\n, where\nr\nis a binary relation on a type\nα\n,\nand\na\nis an element of type\nα\n.\nvariable (α : Sort u)\nvariable (r : α → α → Prop)\n\n#check (Acc r : α → Prop)\n#check (WellFounded r : Prop)\nThe first,\nAcc\n, is an inductively defined predicate. According to\nits definition,\nAcc r x\nis equivalent to\n∀ y, r y x → Acc r y\n. If you think of\nr y x\nas denoting a kind of order relation\ny ≺ x\n, then\nAcc r x\nsays that\nx\nis accessible from below,\nin the sense that all its predecessors are accessible. In particular,\nif\nx\nhas no predecessors, it is accessible. Given any type\nα\n,\nwe should be able to assign a value to each accessible element of\nα\n, recursively, by assigning values to all its predecessors first.\nThe statement that\nr\nis well-founded, denoted\nWellFounded r\n,\nis exactly the statement that every element of the type is\naccessible. By the above considerations, if\nr\nis a well-founded\nrelation on a type\nα\n, we should have a principle of well-founded\nrecursion on\nα\n, with respect to the relation\nr\n. And, indeed,\nwe do: the standard library defines\nWellFounded.fix\n, which serves\nexactly that purpose.\nnoncomputable def f {α : Sort u}\n      (r : α → α → Prop)\n      (h : WellFounded r)\n      (C : α → Sort v)\n      (F : (x : α) → ((y : α) → r y x → C y) → C x)\n      : (x : α) → C x := WellFounded.fix h F\nThere is a long cast of characters here, but the first block we have\nalready seen: the type,\nα\n, the relation,\nr\n, and the\nassumption,\nh\n, that\nr\nis well-founded. The variable\nC\nrepresents the motive of the recursive definition: for each element\nx : α\n, we would like to construct an element of\nC x\n. The\nfunction\nF\nprovides the inductive recipe for doing that: it tells\nus how to construct an element\nC x\n, given elements of\nC y\nfor\neach predecessor\ny\nof\nx\n.\nNote that\nWellFounded.fix\nworks equally well as an induction\nprinciple. It says that if\n≺\nis well-founded and you want to prove\n∀ x, C x\n, it suffices to show that for an arbitrary\nx\n, if we\nhave\n∀ y ≺ x, C y\n, then we have\nC x\n.\nIn the example above we use the modifier\nnoncomputable\nbecause the code\ngenerator currently does not support\nWellFounded.fix\n. The function\nWellFounded.fix\nis another tool Lean uses to justify that a function\nterminates.\nLean knows that the usual order\n<\non the natural numbers is well\nfounded. It also knows a number of ways of constructing new well\nfounded orders from others, for example, using lexicographic order.\nHere is essentially the definition of division on the natural numbers that is found in the standard library.\nopen Nat\n\ntheorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n  fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n\ndef div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n  if h : 0 < y ∧ y ≤ x then\n    f (x - y) (div_lemma h) y + 1\n  else\n    zero\n\nnoncomputable def div := WellFounded.fix (measure id).wf div.F\n\n#reduce div 8 2 -- 4\nThe definition is somewhat inscrutable. Here the recursion is on\nx\n, and\ndiv.F x f : Nat → Nat\nreturns the "divide by\ny\n"\nfunction for that fixed\nx\n. You have to remember that the second\nargument to\ndiv.F\n, the recipe for the recursion, is a function\nthat is supposed to return the divide by\ny\nfunction for all values\nx₁\nsmaller than\nx\n.\nThe elaborator is designed to make definitions like this more\nconvenient. It accepts the following:\ndef div (x y : Nat) : Nat :=\n  if h : 0 < y ∧ y ≤ x then\n    have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n    div (x - y) y + 1\n  else\n    0\nWhen Lean encounters a recursive definition, it first\ntries structural recursion, and only when that fails, does it fall\nback on well-founded recursion. Lean uses the tactic\ndecreasing_tactic\nto show that the recursive applications are smaller. The auxiliary\nproposition\nx - y < x\nin the example above should be viewed as a hint\nfor this tactic.\nThe defining equation for\ndiv\ndoes\nnot\nhold definitionally, but\nwe can unfold\ndiv\nusing the\nunfold\ntactic. We use\nconv\nto select which\ndiv\napplication we want to unfold.\ndef div (x y : Nat) : Nat :=\nif h : 0 < y ∧ y ≤ x then\nhave : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\ndiv (x - y) y + 1\nelse\n0\nexample (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n  conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n\nexample (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n  conv => lhs; unfold div\n  simp [h]\nThe following example is similar: it converts any natural number to a\nbinary expression, represented as a list of 0\'s and 1\'s. We have to\nprovide evidence that the recursive call is\ndecreasing, which we do here with a\nsorry\n. The\nsorry\ndoes not\nprevent the interpreter from evaluating the function successfully.\ndef natToBin : Nat → List Nat\n  | 0     => [0]\n  | 1     => [1]\n  | n + 2 =>\n    have : (n + 2) / 2 < n + 2 := sorry\n    natToBin ((n + 2) / 2) ++ [n % 2]\n\n#eval natToBin 1234567\nAs a final example, we observe that Ackermann\'s function can be\ndefined directly, because it is justified by the well-foundedness of\nthe lexicographic order on the natural numbers. The\ntermination_by\nclause\ninstructs Lean to use a lexicographic order. This clause is actually mapping\nthe function arguments to elements of type\nNat × Nat\n. Then, Lean uses typeclass\nresolution to synthesize an element of type\nWellFoundedRelation (Nat × Nat)\n.\ndef ack : Nat → Nat → Nat\n  | 0,   y   => y+1\n  | x+1, 0   => ack x 1\n  | x+1, y+1 => ack x (ack (x+1) y)\ntermination_by x y => (x, y)\nNote that a lexicographic order is used in the example above because the instance\nWellFoundedRelation (α × β)\nuses a lexicographic order. Lean also defines the instance\ninstance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n  sizeOfWFRel\nIn the following example, we prove termination by showing that\nas.size - i\nis decreasing\nin the recursive application.\ndef takeWhile (p : α → Bool) (as : Array α) : Array α :=\n  go 0 #[]\nwhere\n  go (i : Nat) (r : Array α) : Array α :=\n    if h : i < as.size then\n      let a := as.get ⟨i, h⟩\n      if p a then\n        go (i+1) (r.push a)\n      else\n        r\n    else\n      r\n  termination_by as.size - i\nNote that, auxiliary function\ngo\nis recursive in this example, but\ntakeWhile\nis not.\nBy default, Lean uses the tactic\ndecreasing_tactic\nto prove recursive applications are decreasing. The modifier\ndecreasing_by\nallows us to provide our own tactic. Here is an example.\ntheorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n  fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n\ndef div (x y : Nat) : Nat :=\n  if h : 0 < y ∧ y ≤ x then\n    div (x - y) y + 1\n  else\n    0\ndecreasing_by apply div_lemma; assumption\nNote that\ndecreasing_by\nis not replacement for\ntermination_by\n, they complement each other.\ntermination_by\nis used to specify a well-founded relation, and\ndecreasing_by\nfor providing our own tactic for showing recursive applications are decreasing. In the following example, we use both of them.\ndef ack : Nat → Nat → Nat\n  | 0,   y   => y+1\n  | x+1, 0   => ack x 1\n  | x+1, y+1 => ack x (ack (x+1) y)\ntermination_by x y => (x, y)\ndecreasing_by\n  all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n  · apply Prod.Lex.left; simp_arith\n  · apply Prod.Lex.right; simp_arith\n  · apply Prod.Lex.left; simp_arith\nWe can use\ndecreasing_by sorry\nto instruct Lean to "trust" us that the function terminates.\ndef natToBin : Nat → List Nat\n  | 0     => [0]\n  | 1     => [1]\n  | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\ndecreasing_by sorry\n\n#eval natToBin\n 1234567\nRecall that using\nsorry\nis equivalent to using a new axiom, and should be avoided. In the following example, we used the\nsorry\nto prove\nFalse\n.\nThe command\n#print axioms unsound\nshows that\nunsound\ndepends on the unsound axiom\nsorryAx\nused to implement\nsorry\n.\ndef unsound (x : Nat) : False :=\n  unsound (x + 1)\ndecreasing_by sorry\n\n#check unsound 0\n-- `unsound 0` is a proof of `False`\n\n#print axioms unsound\n-- \'unsound\' depends on axioms: [sorryAx]\nSummary:\nIf there is no\ntermination_by\n, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\nIf\ntermination_by\nis specified, it maps the arguments of the function to a type\nα\nand type class resolution is again used. Recall that, the default instance for\nβ × γ\nis a lexicographic order based on the well-founded relations for\nβ\nand\nγ\n.\nThe default well-founded relation instance for\nNat\nis\n<\n.\nBy default, the tactic\ndecreasing_tactic\nis used to show that recursive applications are smaller with respect to the selected well-founded relation. If\ndecreasing_tactic\nfails, the error message includes the remaining goal\n... |- G\n. Note that, the\ndecreasing_tactic\nuses\nassumption\n. So, you can include a\nhave\n-expression to prove goal\nG\n. You can also provide your own tactic using\ndecreasing_by\n.\nMutual Recursion\nLean also supports mutual recursive definitions. The syntax is similar to that for mutual inductive types. Here is an example:\nmutual\n  def even : Nat → Bool\n    | 0   => true\n    | n+1 => odd n\n\n  def odd : Nat → Bool\n    | 0   => false\n    | n+1 => even n\nend\n\nexample : even (a + 1) = odd a := by\n  simp [even]\n\nexample : odd (a + 1) = even a := by\n  simp [odd]\n\ntheorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n  intro a; induction a\n  . simp [even, odd]\n  . simp [even, odd, *]\nWhat makes this a mutual definition is that\neven\nis defined recursively in terms of\nodd\n, while\nodd\nis defined recursively in terms of\neven\n. Under the hood, this is compiled as a single recursive definition. The internally defined function takes, as argument, an element of a sum type, either an input to\neven\n, or an input to\nodd\n. It then returns an output appropriate to the input. To define that function, Lean uses a suitable well-founded measure. The internals are meant to be hidden from users; the canonical way to make use of such definitions is to use\nsimp\n(or\nunfold\n), as we did above.\nMutual recursive definitions also provide natural ways of working with mutual and nested inductive types. Recall the definition of\nEven\nand\nOdd\nas mutual inductive predicates as presented before.\nmutual\n  inductive Even : Nat → Prop where\n    | even_zero : Even 0\n    | even_succ : ∀ n, Odd n → Even (n + 1)\n\n  inductive Odd : Nat → Prop where\n    | odd_succ : ∀ n, Even n → Odd (n + 1)\nend\nThe constructors,\neven_zero\n,\neven_succ\n, and\nodd_succ\nprovide positive means for showing that a number is even or odd. We need to use the fact that the inductive type is generated by these constructors to know that zero is not odd, and that the latter two implications reverse. As usual, the constructors are kept in a namespace that is named after the type being defined, and the command\nopen Even Odd\nallows us to access them more conveniently.\nmutual\ninductive Even : Nat → Prop where\n| even_zero : Even 0\n| even_succ : ∀ n, Odd n → Even (n + 1)\ninductive Odd : Nat → Prop where\n| odd_succ : ∀ n, Even n → Odd (n + 1)\nend\nopen Even Odd\n\ntheorem not_odd_zero : ¬ Odd 0 :=\n  fun h => nomatch h\n\ntheorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n  | _, odd_succ n h => h\n\ntheorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n  | _, even_succ n h => h\nFor another example, suppose we use a nested inductive type to define a set of terms inductively, so that a term is either a constant (with a name given by a string), or the result of applying a constant to a list of constants.\ninductive Term where\n  | const : String → Term\n  | app   : String → List Term → Term\nWe can then use a mutual recursive definition to count the number of constants occurring in a term, as well as the number occurring in a list of terms.\ninductive Term where\n| const : String → Term\n| app   : String → List Term → Term\nnamespace Term\n\nmutual\n  def numConsts : Term → Nat\n    | const _ => 1\n    | app _ cs => numConstsLst cs\n\n  def numConstsLst : List Term → Nat\n    | [] => 0\n    | c :: cs => numConsts c + numConstsLst cs\nend\n\ndef sample := app "f" [app "g" [const "x"], const "y"]\n\n#eval numConsts sample\n\nend Term\nAs a final example, we define a function\nreplaceConst a b e\nthat replaces a constant\na\nwith\nb\nin a term\ne\n, and then prove the number of constants is the same. Note that, our proof uses mutual recursion (aka induction).\ninductive Term where\n| const : String → Term\n| app   : String → List Term → Term\nnamespace Term\nmutual\ndef numConsts : Term → Nat\n| const _ => 1\n| app _ cs => numConstsLst cs\ndef numConstsLst : List Term → Nat\n| [] => 0\n| c :: cs => numConsts c + numConstsLst cs\nend\nmutual\n  def replaceConst (a b : String) : Term → Term\n    | const c => if a == c then const b else const c\n    | app f cs => app f (replaceConstLst a b cs)\n\n  def replaceConstLst (a b : String) : List Term → List Term\n    | [] => []\n    | c :: cs => replaceConst a b c :: replaceConstLst a b cs\nend\n\nmutual\n  theorem numConsts_replaceConst (a b : String) (e : Term)\n            : numConsts (replaceConst a b e) = numConsts e := by\n    match e with\n    | const c => simp [replaceConst]; split <;> simp [numConsts]\n    | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n\n  theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n            : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n    match es with\n    | [] => simp [replaceConstLst, numConstsLst]\n    | c :: cs =>\n      simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n            numConsts_replaceConstLst a b cs]\nend\nDependent Pattern Matching\nAll the examples of pattern matching we considered in\nSection Pattern Matching\ncan easily be written using\ncasesOn\nand\nrecOn\n. However, this is often not the case with indexed\ninductive families such as\nVector α n\n, since case splits impose\nconstraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very\nsimple functions such as\nmap\n,\nzip\n, and\nunzip\nusing\nrecursors. To understand the difficulty, consider what it would take\nto define a function\ntail\nwhich takes a vector\nv : Vector α (succ n)\nand deletes the first element. A first thought might be to\nuse the\ncasesOn\nfunction:\ninductive Vector (α : Type u) : Nat → Type u\n  | nil  : Vector α 0\n  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n\nnamespace Vector\n\n#check @Vector.casesOn\n/-\n  {α : Type u}\n  → {motive : (a : Nat) → Vector α a → Sort v} →\n  → {a : Nat} → (t : Vector α a)\n  → motive 0 nil\n  → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n  → motive a t\n-/\n\nend Vector\nBut what value should we return in the\nnil\ncase? Something funny\nis going on: if\nv\nhas type\nVector α (succ n)\n, it\ncan\'t\nbe\nnil, but it is not clear how to tell that to\ncasesOn\n.\nOne solution is to define an auxiliary function:\ninductive Vector (α : Type u) : Nat → Type u\n| nil  : Vector α 0\n| cons : α → {n : Nat} → Vector α n → Vector α (n+1)\nnamespace Vector\ndef tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n  Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n    (fun h : 0 = n + 1 => Nat.noConfusion h)\n    (fun (a : α) (m : Nat) (as : Vector α m) =>\n     fun (h : m + 1 = n + 1) =>\n       Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n\ndef tail (v : Vector α (n+1)) : Vector α n :=\n  tailAux v rfl\nend Vector\nIn the\nnil\ncase,\nm\nis instantiated to\n0\n, and\nnoConfusion\nmakes use of the fact that\n0 = succ n\ncannot\noccur.  Otherwise,\nv\nis of the form\na :: w\n, and we can simply\nreturn\nw\n, after casting it from a vector of length\nm\nto a\nvector of length\nn\n.\nThe difficulty in defining\ntail\nis to maintain the relationships between the indices.\nThe hypothesis\ne : m = n + 1\nin\ntailAux\nis used to communicate the relationship\nbetween\nn\nand the index associated with the minor premise.\nMoreover, the\nzero = n + 1\ncase is unreachable, and the canonical way to discard such\na case is to use\nnoConfusion\n.\nThe\ntail\nfunction is, however, easy to define using recursive\nequations, and the equation compiler generates all the boilerplate\ncode automatically for us. Here are a number of similar examples:\ninductive Vector (α : Type u) : Nat → Type u\n| nil  : Vector α 0\n| cons : α → {n : Nat} → Vector α n → Vector α (n+1)\nnamespace Vector\ndef head : {n : Nat} → Vector α (n+1) → α\n  | n, cons a as => a\n\ndef tail : {n : Nat} → Vector α (n+1) → Vector α n\n  | n, cons a as => as\n\ntheorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n  | n, cons a as => rfl\n\ndef map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n  | 0,   nil,       nil       => nil\n  | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n\ndef zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n  | 0,   nil,       nil       => nil\n  | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\nend Vector\nNote that we can omit recursive equations for "unreachable" cases such\nas\nhead nil\n. The automatically generated definitions for indexed\nfamilies are far from straightforward. For example:\ninductive Vector (α : Type u) : Nat → Type u\n| nil  : Vector α 0\n| cons : α → {n : Nat} → Vector α n → Vector α (n+1)\nnamespace Vector\ndef map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n  | 0,   nil,       nil       => nil\n  | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n\n#print map\n#print map.match_1\nend Vector\nThe\nmap\nfunction is even more tedious to define by hand than the\ntail\nfunction. We encourage you to try it, using\nrecOn\n,\ncasesOn\nand\nnoConfusion\n.\nInaccessible Patterns\nSometimes an argument in a dependent matching pattern is not essential\nto the definition, but nonetheless has to be included to specialize\nthe type of the expression appropriately. Lean allows users to mark\nsuch subterms as\ninaccessible\nfor pattern matching. These\nannotations are essential, for example, when a term occurring in the\nleft-hand side is neither a variable nor a constructor application,\nbecause these are not suitable targets for pattern matching. We can\nview such inaccessible patterns as "don\'t care" components of the\npatterns. You can declare a subterm inaccessible by writing\n.(t)\n. If the inaccessible pattern can be inferred, you can also write\n_\n.\nThe following example, we declare an inductive type that defines the\nproperty of "being in the image of\nf\n". You can view an element of\nthe type\nImageOf f b\nas evidence that\nb\nis in the image of\nf\n, whereby the constructor\nimf\nis used to build such\nevidence. We can then define any function\nf\nwith an "inverse"\nwhich takes anything in the image of\nf\nto an element that is\nmapped to it. The typing rules forces us to write\nf a\nfor the\nfirst argument, but this term is neither a variable nor a constructor\napplication, and plays no role in the pattern-matching definition. To\ndefine the function\ninverse\nbelow, we\nhave to\nmark\nf a\ninaccessible.\ninductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n  | imf : (a : α) → ImageOf f (f a)\n\nopen ImageOf\n\ndef inverse {f : α → β} : (b : β) → ImageOf f b → α\n  | .(f a), imf a => a\n\ndef inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n  | _, imf a => a\nIn the example above, the inaccessible annotation makes it clear that\nf\nis\nnot\na pattern matching variable.\nInaccessible patterns can be used to clarify and control definitions that\nmake use of dependent pattern matching. Consider the following\ndefinition of the function\nVector.add\n, which adds two vectors of\nelements of a type, assuming that type has an associated addition\nfunction:\ninductive Vector (α : Type u) : Nat → Type u\n  | nil  : Vector α 0\n  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n\nnamespace Vector\n\ndef add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n  | 0,   nil,       nil       => nil\n  | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n\nend Vector\nThe argument\n{n : Nat}\nappear after the colon, because it cannot\nbe held fixed throughout the definition.  When implementing this\ndefinition, the equation compiler starts with a case distinction as to\nwhether the first argument is\n0\nor of the form\nn+1\n.  This is\nfollowed by nested case splits on the next two arguments, and in each\ncase the equation compiler rules out the cases are not compatible with\nthe first pattern.\nBut, in fact, a case split is not required on the first argument; the\ncasesOn\neliminator for\nVector\nautomatically abstracts this\nargument and replaces it by\n0\nand\nn + 1\nwhen we do a case\nsplit on the second argument. Using inaccessible patterns, we can prompt\nthe equation compiler to avoid the case split on\nn\ninductive Vector (α : Type u) : Nat → Type u\n| nil  : Vector α 0\n| cons : α → {n : Nat} → Vector α n → Vector α (n+1)\nnamespace Vector\ndef add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n  | .(_), nil,       nil       => nil\n  | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\nend Vector\nMarking the position as an inaccessible pattern tells the\nequation compiler first, that the form of the argument should be\ninferred from the constraints posed by the other arguments, and,\nsecond, that the first argument should\nnot\nparticipate in pattern\nmatching.\nThe inaccessible pattern\n.(_)\ncan be written as\n_\nfor convenience.\ninductive Vector (α : Type u) : Nat → Type u\n| nil  : Vector α 0\n| cons : α → {n : Nat} → Vector α n → Vector α (n+1)\nnamespace Vector\ndef add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n  | _, nil,       nil       => nil\n  | _, cons a as, cons b bs => cons (a + b) (add as bs)\nend Vector\nAs we mentioned above, the argument\n{n : Nat}\nis part of the\npattern matching, because it cannot be held fixed throughout the\ndefinition. In previous Lean versions, users often found it cumbersome\nto have to include these extra discriminants. Thus, Lean 4\nimplements a new feature,\ndiscriminant refinement\n, which includes\nthese extra discriminants automatically for us.\ninductive Vector (α : Type u) : Nat → Type u\n| nil  : Vector α 0\n| cons : α → {n : Nat} → Vector α n → Vector α (n+1)\nnamespace Vector\ndef add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n  | nil,       nil       => nil\n  | cons a as, cons b bs => cons (a + b) (add as bs)\nend Vector\nWhen combined with the\nauto bound implicits\nfeature, you can simplify\nthe declare further and write:\ninductive Vector (α : Type u) : Nat → Type u\n| nil  : Vector α 0\n| cons : α → {n : Nat} → Vector α n → Vector α (n+1)\nnamespace Vector\ndef add [Add α] : Vector α n → Vector α n → Vector α n\n  | nil,       nil       => nil\n  | cons a as, cons b bs => cons (a + b) (add as bs)\nend Vector\nUsing these new features, you can write the other vector functions defined\nin the previous sections more compactly as follows:\ninductive Vector (α : Type u) : Nat → Type u\n| nil  : Vector α 0\n| cons : α → {n : Nat} → Vector α n → Vector α (n+1)\nnamespace Vector\ndef head : Vector α (n+1) → α\n  | cons a as => a\n\ndef tail : Vector α (n+1) → Vector α n\n  | cons a as => as\n\ntheorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n  | cons a as => rfl\n\ndef map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n  | nil,       nil       => nil\n  | cons a as, cons b bs => cons (f a b) (map f as bs)\n\ndef zip : Vector α n → Vector β n → Vector (α × β) n\n  | nil,       nil       => nil\n  | cons a as, cons b bs => cons (a, b) (zip as bs)\nend Vector\nMatch Expressions\nLean also provides a compiler for\nmatch-with\nexpressions found in\nmany functional languages:\ndef isNotZero (m : Nat) : Bool :=\n  match m with\n  | 0   => false\n  | n+1 => true\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a\nmatch\ncan be used anywhere in\nan expression, and with arbitrary arguments.\ndef isNotZero (m : Nat) : Bool :=\n  match m with\n  | 0   => false\n  | n+1 => true\n\ndef filter (p : α → Bool) : List α → List α\n  | []      => []\n  | a :: as =>\n    match p a with\n    | true => a :: filter p as\n    | false => filter p as\n\nexample : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\nHere is another example:\ndef foo (n : Nat) (b c : Bool) :=\n  5 + match n - 5, b && c with\n      | 0,   true  => 0\n      | m+1, true  => m + 7\n      | 0,   false => 5\n      | m+1, false => m + 3\n\n#eval foo 7 true false\n\nexample : foo 7 true false = 9 := rfl\nLean uses the\nmatch\nconstruct internally to implement pattern-matching in all parts of the system.\nThus, all four of these definitions have the same net effect:\ndef bar₁ : Nat × Nat → Nat\n  | (m, n) => m + n\n\ndef bar₂ (p : Nat × Nat) : Nat :=\n  match p with\n  | (m, n) => m + n\n\ndef bar₃ : Nat × Nat → Nat :=\n  fun (m, n) => m + n\n\ndef bar₄ (p : Nat × Nat) : Nat :=\n  let (m, n) := p; m + n\nThese variations are equally useful for destructing propositions:\nvariable (p q : Nat → Prop)\n\nexample : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n  | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n\nexample (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n        : ∃ x y, p x ∧ q y :=\n  match h₀, h₁ with\n  | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n\nexample : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n  fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n\nexample (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n        : ∃ x y, p x ∧ q y :=\n  let ⟨x, px⟩ := h₀\n  let ⟨y, qy⟩ := h₁\n  ⟨x, y, px, qy⟩\nLocal Recursive Declarations\nYou can define local recursive declarations using the\nlet rec\nkeyword:\ndef replicate (n : Nat) (a : α) : List α :=\n  let rec loop : Nat → List α → List α\n    | 0,   as => as\n    | n+1, as => loop n (a::as)\n  loop n []\n\n#check @replicate.loop\n-- {α : Type} → α → Nat → List α → List α\nLean creates an auxiliary declaration for each\nlet rec\n. In the example above,\nit created the declaration\nreplicate.loop\nfor the\nlet rec loop\noccurring at\nreplicate\n.\nNote that, Lean "closes" the declaration by adding any local variable occurring in the\nlet rec\ndeclaration as additional parameters. For example, the local variable\na\noccurs\nat\nlet rec loop\n.\nYou can also use\nlet rec\nin tactic mode and for creating proofs by induction:\ndef replicate (n : Nat) (a : α) : List α :=\nlet rec loop : Nat → List α → List α\n| 0,   as => as\n| n+1, as => loop n (a::as)\nloop n []\ntheorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n  let rec aux (n : Nat) (as : List α)\n              : (replicate.loop a n as).length = n + as.length := by\n    match n with\n    | 0   => simp [replicate.loop]\n    | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n  exact aux n []\nYou can also introduce auxiliary recursive declarations using a\nwhere\nclause after your definition.\nLean converts them into a\nlet rec\n:\ndef replicate (n : Nat) (a : α) : List α :=\n  loop n []\nwhere\n  loop : Nat → List α → List α\n    | 0,   as => as\n    | n+1, as => loop n (a::as)\n\ntheorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n  exact aux n []\nwhere\n  aux (n : Nat) (as : List α)\n      : (replicate.loop a n as).length = n + as.length := by\n    match n with\n    | 0   => simp [replicate.loop]\n    | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\nExercises\nOpen a namespace\nHidden\nto avoid naming conflicts, and use the\nequation compiler to define addition, multiplication, and\nexponentiation on the natural numbers. Then use the equation\ncompiler to derive some of their basic properties.\nSimilarly, use the equation compiler to define some basic\noperations on lists (like the\nreverse\nfunction) and prove\ntheorems about lists by induction (such as the fact that\nreverse (reverse xs) = xs\nfor any list\nxs\n).\nDefine your own function to carry out course-of-value recursion on\nthe natural numbers. Similarly, see if you can figure out how to\ndefine\nWellFounded.fix\non your own.\nFollowing the examples in\nSection Dependent Pattern Matching\n,\ndefine a function that will append two vectors.\nThis is tricky; you will have to define an auxiliary function.\nConsider the following type of arithmetic expressions. The idea is\nthat\nvar n\nis a variable,\nvₙ\n, and\nconst n\nis the\nconstant whose value is\nn\n.\ninductive Expr where\n  | const : Nat → Expr\n  | var : Nat → Expr\n  | plus : Expr → Expr → Expr\n  | times : Expr → Expr → Expr\n  deriving Repr\n\nopen Expr\n\ndef sampleExpr : Expr :=\n  plus (times (var 0) (const 7)) (times (const 2) (var 1))\nHere\nsampleExpr\nrepresents\n(v₀ * 7) + (2 * v₁)\n.\nWrite a function that evaluates such an expression, evaluating each\nvar n\nto\nv n\n.\ninductive Expr where\n| const : Nat → Expr\n| var : Nat → Expr\n| plus : Expr → Expr → Expr\n| times : Expr → Expr → Expr\nderiving Repr\nopen Expr\ndef sampleExpr : Expr :=\nplus (times (var 0) (const 7)) (times (const 2) (var 1))\ndef eval (v : Nat → Nat) : Expr → Nat\n  | const n     => sorry\n  | var n       => v n\n  | plus e₁ e₂  => sorry\n  | times e₁ e₂ => sorry\n\ndef sampleVal : Nat → Nat\n  | 0 => 5\n  | 1 => 6\n  | _ => 0\n\n-- Try it out. You should get 47 here.\n-- #eval eval sampleVal sampleExpr\nImplement "constant fusion," a procedure that simplifies subterms like\n5 + 7\nto\n12\n. Using the auxiliary function\nsimpConst\n,\ndefine a function "fuse": to simplify a plus or a times, first\nsimplify the arguments recursively, and then apply\nsimpConst\nto\ntry to simplify the result.\ninductive Expr where\n| const : Nat → Expr\n| var : Nat → Expr\n| plus : Expr → Expr → Expr\n| times : Expr → Expr → Expr\nderiving Repr\nopen Expr\ndef eval (v : Nat → Nat) : Expr → Nat\n| const n     => sorry\n| var n       => v n\n| plus e₁ e₂  => sorry\n| times e₁ e₂ => sorry\ndef simpConst : Expr → Expr\n  | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n  | times (const n₁) (const n₂) => const (n₁ * n₂)\n  | e                           => e\n\ndef fuse : Expr → Expr := sorry\n\ntheorem simpConst_eq (v : Nat → Nat)\n        : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n  sorry\n\ntheorem fuse_eq (v : Nat → Nat)\n        : ∀ e : Expr, eval v (fuse e) = eval v e :=\n  sorry\nThe last two theorems show that the definitions preserve the value.\nQuantifiers and Equality - Theorem Proving in Lean 4\nTheorem Proving in Lean 4\n1.\nIntroduction\n2.\nDependent Type Theory\n3.\nPropositions and Proofs\n4.\nQuantifiers and Equality\n5.\nTactics\n6.\nInteracting with Lean\n7.\nInductive Types\n8.\nInduction and Recursion\n9.\nStructures and Records\n10.\nType Classes\n11.\nThe Conversion Tactic Mode\n12.\nAxioms and Computation\nLight (default)\nRust\nCoal\nNavy\nAyu\nTheorem Proving in Lean 4\nQuantifiers and Equality\nThe last chapter introduced you to methods that construct proofs of\nstatements involving the propositional connectives. In this chapter,\nwe extend the repertoire of logical constructions to include the\nuniversal and existential quantifiers, and the equality relation.\nThe Universal Quantifier\nNotice that if\nα\nis any type, we can represent a unary predicate\np\non\nα\nas an object of type\nα → Prop\n. In that case, given\nx : α\n,\np x\ndenotes the assertion that\np\nholds of\nx\n. Similarly, an object\nr : α → α → Prop\ndenotes a binary\nrelation on\nα\n: given\nx y : α\n,\nr x y\ndenotes the assertion\nthat\nx\nis related to\ny\n.\nThe universal quantifier,\n∀ x : α, p x\nis supposed to denote the\nassertion that "for every\nx : α\n,\np x\n" holds. As with the\npropositional connectives, in systems of natural deduction, "forall"\nis governed by an introduction and elimination rule. Informally, the\nintroduction rule states:\nGiven a proof of\np x\n, in a context where\nx : α\nis arbitrary, we obtain a proof\n∀ x : α, p x\n.\nThe elimination rule states:\nGiven a proof\n∀ x : α, p x\nand any term\nt : α\n, we obtain a proof of\np t\n.\nAs was the case for implication, the propositions-as-types\ninterpretation now comes into play. Remember the introduction and\nelimination rules for dependent arrow types:\nGiven a term\nt\nof type\nβ x\n, in a context where\nx : α\nis arbitrary, we have\n(fun x : α => t) : (x : α) → β x\n.\nThe elimination rule states:\nGiven a term\ns : (x : α) → β x\nand any term\nt : α\n, we have\ns t : β t\n.\nIn the case where\np x\nhas type\nProp\n, if we replace\n(x : α) → β x\nwith\n∀ x : α, p x\n, we can read these as the correct rules\nfor building proofs involving the universal quantifier.\nThe Calculus of Constructions therefore identifies dependent arrow\ntypes with forall-expressions in this way. If\np\nis any expression,\n∀ x : α, p\nis nothing more than alternative notation for\n(x : α) → p\n, with the idea that the former is more natural than the latter\nin cases where\np\nis a proposition. Typically, the expression\np\nwill depend on\nx : α\n. Recall that, in the case of ordinary\nfunction spaces, we could interpret\nα → β\nas the special case of\n(x : α) → β\nin which\nβ\ndoes not depend on\nx\n. Similarly, we\ncan think of an implication\np → q\nbetween propositions as the\nspecial case of\n∀ x : p, q\nin which the expression\nq\ndoes not\ndepend on\nx\n.\nHere is an example of how the propositions-as-types correspondence gets put into practice.\nexample (α : Type) (p q : α → Prop) : (∀ x : α, p x ∧ q x) → ∀ y : α, p y :=\n  fun h : ∀ x : α, p x ∧ q x =>\n  fun y : α =>\n  show p y from (h y).left\nAs a notational convention, we give the universal quantifier the\nwidest scope possible, so parentheses are needed to limit the\nquantifier over\nx\nto the hypothesis in the example above. The\ncanonical way to prove\n∀ y : α, p y\nis to take an arbitrary\ny\n,\nand prove\np y\n. This is the introduction rule. Now, given that\nh\nhas type\n∀ x : α, p x ∧ q x\n, the expression\nh y\nhas type\np y ∧ q y\n. This is the elimination rule. Taking the left conjunct\ngives the desired conclusion,\np y\n.\nRemember that expressions which differ up to renaming of bound\nvariables are considered to be equivalent. So, for example, we could\nhave used the same variable,\nx\n, in both the hypothesis and\nconclusion, and instantiated it by a different variable,\nz\n, in the\nproof:\nexample (α : Type) (p q : α → Prop) : (∀ x : α, p x ∧ q x) → ∀ x : α, p x :=\n  fun h : ∀ x : α, p x ∧ q x =>\n  fun z : α =>\n  show p z from And.left (h z)\nAs another example, here is how we can express the fact that a relation,\nr\n, is transitive:\nvariable (α : Type) (r : α → α → Prop)\nvariable (trans_r : ∀ x y z, r x y → r y z → r x z)\n\nvariable (a b c : α)\nvariable (hab : r a b) (hbc : r b c)\n\n#check trans_r    -- ∀ (x y z : α), r x y → r y z → r x z\n#check trans_r a b c -- r a b → r b c → r a c\n#check trans_r a b c hab -- r b c → r a c\n#check trans_r a b c hab hbc -- r a c\nThink about what is going on here. When we instantiate\ntrans_r\nat\nthe values\na b c\n, we end up with a proof of\nr a b → r b c → r a c\n.\nApplying this to the "hypothesis"\nhab : r a b\n, we get a proof\nof the implication\nr b c → r a c\n. Finally, applying it to the\nhypothesis\nhbc\nyields a proof of the conclusion\nr a c\n.\nIn situations like this, it can be tedious to supply the arguments\na b c\n, when they can be inferred from\nhab hbc\n. For that reason, it\nis common to make these arguments implicit:\nvariable (α : Type) (r : α → α → Prop)\nvariable (trans_r : ∀ {x y z}, r x y → r y z → r x z)\n\nvariable (a b c : α)\nvariable (hab : r a b) (hbc : r b c)\n\n#check trans_r\n#check trans_r hab\n#check trans_r hab hbc\nThe advantage is that we can simply write\ntrans_r hab hbc\nas a\nproof of\nr a c\n. A disadvantage is that Lean does not have enough\ninformation to infer the types of the arguments in the expressions\ntrans_r\nand\ntrans_r hab\n. The output of the first\n#check\ncommand is\nr ?m.1 ?m.2 → r ?m.2 ?m.3 → r ?m.1 ?m.3\n, indicating\nthat the implicit arguments are unspecified in this case.\nHere is an example of how we can carry out elementary reasoning with an equivalence relation:\nvariable (α : Type) (r : α → α → Prop)\n\nvariable (refl_r : ∀ x, r x x)\nvariable (symm_r : ∀ {x y}, r x y → r y x)\nvariable (trans_r : ∀ {x y z}, r x y → r y z → r x z)\n\nexample (a b c d : α) (hab : r a b) (hcb : r c b) (hcd : r c d) : r a d :=\n  trans_r (trans_r hab (symm_r hcb)) hcd\nTo get used to using universal quantifiers, you should try some of the\nexercises at the end of this section.\nIt is the typing rule for dependent arrow types, and the universal\nquantifier in particular, that distinguishes\nProp\nfrom other\ntypes.  Suppose we have\nα : Sort i\nand\nβ : Sort j\n, where the\nexpression\nβ\nmay depend on a variable\nx : α\n. Then\n(x : α) → β\nis an element of\nSort (imax i j)\n, where\nimax i j\nis the\nmaximum of\ni\nand\nj\nif\nj\nis not 0, and 0 otherwise.\nThe idea is as follows. If\nj\nis not\n0\n, then\n(x : α) → β\nis\nan element of\nSort (max i j)\n. In other words, the type of\ndependent functions from\nα\nto\nβ\n"lives" in the universe whose\nindex is the maximum of\ni\nand\nj\n. Suppose, however, that\nβ\nis of\nSort 0\n, that is, an element of\nProp\n. In that case,\n(x : α) → β\nis an element of\nSort 0\nas well, no matter which\ntype universe\nα\nlives in. In other words, if\nβ\nis a\nproposition depending on\nα\n, then\n∀ x : α, β\nis again a\nproposition. This reflects the interpretation of\nProp\nas the type\nof propositions rather than data, and it is what makes\nProp\nimpredicative\n.\nThe term "predicative" stems from foundational developments around the\nturn of the twentieth century, when logicians such as Poincaré and\nRussell blamed set-theoretic paradoxes on the "vicious circles" that\narise when we define a property by quantifying over a collection that\nincludes the very property being defined. Notice that if\nα\nis any\ntype, we can form the type\nα → Prop\nof all predicates on\nα\n(the "power type of\nα\n"). The impredicativity of\nProp\nmeans that we\ncan form propositions that quantify over\nα → Prop\n. In particular,\nwe can define predicates on\nα\nby quantifying over all predicates\non\nα\n, which is exactly the type of circularity that was once\nconsidered problematic.\nEquality\nLet us now turn to one of the most fundamental relations defined in\nLean\'s library, namely, the equality relation. In\nChapter Inductive Types\n,\nwe will explain\nhow\nequality is defined from the primitives of Lean\'s logical framework.\nIn the meanwhile, here we explain how to use it.\nOf course, a fundamental property of equality is that it is an equivalence relation:\n#check Eq.refl    -- Eq.refl.{u_1} {α : Sort u_1} (a : α) : a = a\n#check Eq.symm    -- Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a\n#check Eq.trans   -- Eq.trans.{u} {α : Sort u} {a b c : α} (h₁ : a = b) (h₂ : b = c) : a = c\nWe can make the output easier to read by telling Lean not to insert\nthe implicit arguments (which are displayed here as metavariables).\nuniverse u\n\n#check @Eq.refl.{u}   -- @Eq.refl : ∀ {α : Sort u} (a : α), a = a\n#check @Eq.symm.{u}   -- @Eq.symm : ∀ {α : Sort u} {a b : α}, a = b → b = a\n#check @Eq.trans.{u}  -- @Eq.trans : ∀ {α : Sort u} {a b c : α}, a = b → b = c → a = c\nThe inscription\n.{u}\ntells Lean to instantiate the constants at the universe\nu\n.\nThus, for example, we can specialize the example from the previous section to the equality relation:\nvariable (α : Type) (a b c d : α)\nvariable (hab : a = b) (hcb : c = b) (hcd : c = d)\n\nexample : a = d :=\n  Eq.trans (Eq.trans hab (Eq.symm hcb)) hcd\nWe can also use the projection notation:\nvariable (α : Type) (a b c d : α)\nvariable (hab : a = b) (hcb : c = b) (hcd : c = d)\nexample : a = d := (hab.trans hcb.symm).trans hcd\nReflexivity is more powerful than it looks. Recall that terms in the\nCalculus of Constructions have a computational interpretation, and\nthat the logical framework treats terms with a common reduct as the\nsame. As a result, some nontrivial identities can be proved by\nreflexivity:\nvariable (α β : Type)\n\nexample (f : α → β) (a : α) : (fun x => f x) a = f a := Eq.refl _\nexample (a : α) (b : β) : (a, b).1 = a := Eq.refl _\nexample : 2 + 3 = 5 := Eq.refl _\nThis feature of the framework is so important that the library defines a notation\nrfl\nfor\nEq.refl _\n:\nvariable (α β : Type)\nexample (f : α → β) (a : α) : (fun x => f x) a = f a := rfl\nexample (a : α) (b : β) : (a, b).1 = a := rfl\nexample : 2 + 3 = 5 := rfl\nEquality is much more than an equivalence relation, however. It has\nthe important property that every assertion respects the equivalence,\nin the sense that we can substitute equal expressions without changing\nthe truth value. That is, given\nh1 : a = b\nand\nh2 : p a\n, we\ncan construct a proof for\np b\nusing substitution:\nEq.subst h1 h2\n.\nexample (α : Type) (a b : α) (p : α → Prop)\n        (h1 : a = b) (h2 : p a) : p b :=\n  Eq.subst h1 h2\n\nexample (α : Type) (a b : α) (p : α → Prop)\n    (h1 : a = b) (h2 : p a) : p b :=\n  h1 ▸ h2\nThe triangle in the second presentation is a macro built on top of\nEq.subst\nand\nEq.symm\n, and you can enter it by typing\n\\t\n.\nThe rule\nEq.subst\nis used to define the following auxiliary rules,\nwhich carry out more explicit substitutions. They are designed to deal\nwith applicative terms, that is, terms of form\ns t\n. Specifically,\ncongrArg\ncan be used to replace the argument,\ncongrFun\ncan be\nused to replace the term that is being applied, and\ncongr\ncan be\nused to replace both at once.\nvariable (α : Type)\nvariable (a b : α)\nvariable (f g : α → Nat)\nvariable (h₁ : a = b)\nvariable (h₂ : f = g)\n\nexample : f a = f b := congrArg f h₁\nexample : f a = g a := congrFun h₂ a\nexample : f a = g b := congr h₂ h₁\nLean\'s library contains a large number of common identities, such as these:\nvariable (a b c : Nat)\n\nexample : a + 0 = a := Nat.add_zero a\nexample : 0 + a = a := Nat.zero_add a\nexample : a * 1 = a := Nat.mul_one a\nexample : 1 * a = a := Nat.one_mul a\nexample : a + b = b + a := Nat.add_comm a b\nexample : a + b + c = a + (b + c) := Nat.add_assoc a b c\nexample : a * b = b * a := Nat.mul_comm a b\nexample : a * b * c = a * (b * c) := Nat.mul_assoc a b c\nexample : a * (b + c) = a * b + a * c := Nat.mul_add a b c\nexample : a * (b + c) = a * b + a * c := Nat.left_distrib a b c\nexample : (a + b) * c = a * c + b * c := Nat.add_mul a b c\nexample : (a + b) * c = a * c + b * c := Nat.right_distrib a b c\nNote that\nNat.mul_add\nand\nNat.add_mul\nare alternative names\nfor\nNat.left_distrib\nand\nNat.right_distrib\n, respectively.  The\nproperties above are stated for the natural numbers (type\nNat\n).\nHere is an example of a calculation in the natural numbers that uses\nsubstitution combined with associativity and distributivity.\nexample (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n  have h1 : (x + y) * (x + y) = (x + y) * x + (x + y) * y :=\n    Nat.mul_add (x + y) x y\n  have h2 : (x + y) * (x + y) = x * x + y * x + (x * y + y * y) :=\n    (Nat.add_mul x y x) ▸ (Nat.add_mul x y y) ▸ h1\n  h2.trans (Nat.add_assoc (x * x + y * x) (x * y) (y * y)).symm\nNotice that the second implicit parameter to\nEq.subst\n, which\nprovides the context in which the substitution is to occur, has type\nα → Prop\n.  Inferring this predicate therefore requires an instance\nof\nhigher-order unification\n. In full generality, the problem of\ndetermining whether a higher-order unifier exists is undecidable, and\nLean can at best provide imperfect and approximate solutions to the\nproblem. As a result,\nEq.subst\ndoesn\'t always do what you want it\nto.  The macro\nh ▸ e\nuses more effective heuristics for computing\nthis implicit parameter, and often succeeds in situations where\napplying\nEq.subst\nfails.\nBecause equational reasoning is so common and important, Lean provides\na number of mechanisms to carry it out more effectively. The next\nsection offers syntax that allow you to write calculational proofs in\na more natural and perspicuous way. But, more importantly, equational\nreasoning is supported by a term rewriter, a simplifier, and other\nkinds of automation. The term rewriter and simplifier are described\nbriefly in the next section, and then in greater detail in the next\nchapter.\nCalculational Proofs\nA calculational proof is just a chain of intermediate results that are\nmeant to be composed by basic principles such as the transitivity of\nequality. In Lean, a calculational proof starts with the keyword\ncalc\n, and has the following syntax:\ncalc\n  <expr>_0  \'op_1\'  <expr>_1  \':=\'  <proof>_1\n  \'_\'       \'op_2\'  <expr>_2  \':=\'  <proof>_2\n  ...\n  \'_\'       \'op_n\'  <expr>_n  \':=\'  <proof>_n\nNote that the\ncalc\nrelations all have the same indentation. Each\n<proof>_i\nis a proof for\n<expr>_{i-1} op_i <expr>_i\n.\nWe can also use\n_\nin the first relation (right after\n<expr>_0\n)\nwhich is useful to align the sequence of relation/proof pairs:\ncalc <expr>_0 \n    \'_\' \'op_1\' <expr>_1 \':=\' <proof>_1\n    \'_\' \'op_2\' <expr>_2 \':=\' <proof>_2\n    ...\n    \'_\' \'op_n\' <expr>_n \':=\' <proof>_n\nHere is an example:\nvariable (a b c d e : Nat)\nvariable (h1 : a = b)\nvariable (h2 : b = c + 1)\nvariable (h3 : c = d)\nvariable (h4 : e = 1 + d)\n\ntheorem T : a = e :=\n  calc\n    a = b      := h1\n    _ = c + 1  := h2\n    _ = d + 1  := congrArg Nat.succ h3\n    _ = 1 + d  := Nat.add_comm d 1\n    _ = e      := Eq.symm h4\nThis style of writing proofs is most effective when it is used in\nconjunction with the\nsimp\nand\nrewrite\ntactics, which are\ndiscussed in greater detail in the next chapter. For example, using\nthe abbreviation\nrw\nfor rewrite, the proof above could be written\nas follows:\nvariable (a b c d e : Nat)\nvariable (h1 : a = b)\nvariable (h2 : b = c + 1)\nvariable (h3 : c = d)\nvariable (h4 : e = 1 + d)\ntheorem T : a = e :=\n  calc\n    a = b      := by rw [h1]\n    _ = c + 1  := by rw [h2]\n    _ = d + 1  := by rw [h3]\n    _ = 1 + d  := by rw [Nat.add_comm]\n    _ = e      := by rw [h4]\nEssentially, the\nrw\ntactic uses a given equality (which can be a\nhypothesis, a theorem name, or a complex term) to "rewrite" the\ngoal. If doing so reduces the goal to an identity\nt = t\n, the\ntactic applies reflexivity to prove it.\nRewrites can be applied sequentially, so that the proof above can be\nshortened to this:\nvariable (a b c d e : Nat)\nvariable (h1 : a = b)\nvariable (h2 : b = c + 1)\nvariable (h3 : c = d)\nvariable (h4 : e = 1 + d)\ntheorem T : a = e :=\n  calc\n    a = d + 1  := by rw [h1, h2, h3]\n    _ = 1 + d  := by rw [Nat.add_comm]\n    _ = e      := by rw [h4]\nOr even this:\nvariable (a b c d e : Nat)\nvariable (h1 : a = b)\nvariable (h2 : b = c + 1)\nvariable (h3 : c = d)\nvariable (h4 : e = 1 + d)\ntheorem T : a = e :=\n  by rw [h1, h2, h3, Nat.add_comm, h4]\nThe\nsimp\ntactic, instead, rewrites the goal by applying the given\nidentities repeatedly, in any order, anywhere they are applicable in a\nterm. It also uses other rules that have been previously declared to\nthe system, and applies commutativity wisely to avoid looping. As a\nresult, we can also prove the theorem as follows:\nvariable (a b c d e : Nat)\nvariable (h1 : a = b)\nvariable (h2 : b = c + 1)\nvariable (h3 : c = d)\nvariable (h4 : e = 1 + d)\ntheorem T : a = e :=\n  by simp [h1, h2, h3, Nat.add_comm, h4]\nWe will discuss variations of\nrw\nand\nsimp\nin the next chapter.\nThe\ncalc\ncommand can be configured for any relation that supports\nsome form of transitivity. It can even combine different relations.\nexample (a b c d : Nat) (h1 : a = b) (h2 : b ≤ c) (h3 : c + 1 < d) : a < d :=\n  calc\n    a = b     := h1\n    _ < b + 1 := Nat.lt_succ_self b\n    _ ≤ c + 1 := Nat.succ_le_succ h2\n    _ < d     := h3\nYou can "teach"\ncalc\nnew transitivity theorems by adding new instances\nof the\nTrans\ntype class. Type classes are introduced later, but the following\nsmall example demonstrates how to extend the\ncalc\nnotation using new\nTrans\ninstances.\ndef divides (x y : Nat) : Prop :=\n  ∃ k, k*x = y\n\ndef divides_trans (h₁ : divides x y) (h₂ : divides y z) : divides x z :=\n  let ⟨k₁, d₁⟩ := h₁\n  let ⟨k₂, d₂⟩ := h₂\n  ⟨k₁ * k₂, by rw [Nat.mul_comm k₁ k₂, Nat.mul_assoc, d₁, d₂]⟩\n\ndef divides_mul (x : Nat) (k : Nat) : divides x (k*x) :=\n  ⟨k, rfl⟩\n\ninstance : Trans divides divides divides where\n  trans := divides_trans\n\nexample (h₁ : divides x y) (h₂ : y = z) : divides x (2*z) :=\n  calc\n    divides x y     := h₁\n    _ = z           := h₂\n    divides _ (2*z) := divides_mul ..\n\ninfix:50 " ∣ " => divides\n\nexample (h₁ : divides x y) (h₂ : y = z) : divides x (2*z) :=\n  calc\n    x ∣ y   := h₁\n    _ = z   := h₂\n    _ ∣ 2*z := divides_mul ..\nThe example above also makes it clear that you can use\ncalc\neven if you\ndo not have an infix notation for your relation. Finally we remark that\nthe vertical bar\n∣\nin the example above is the unicode one. We use\nunicode to make sure we do not overload the ASCII\n|\nused in the\nmatch .. with\nexpression.\nWith\ncalc\n, we can write the proof in the last section in a more\nnatural and perspicuous way.\nexample (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n  calc\n    (x + y) * (x + y) = (x + y) * x + (x + y) * y  := by rw [Nat.mul_add]\n    _ = x * x + y * x + (x + y) * y                := by rw [Nat.add_mul]\n    _ = x * x + y * x + (x * y + y * y)            := by rw [Nat.add_mul]\n    _ = x * x + y * x + x * y + y * y              := by rw [←Nat.add_assoc]\nThe alternative\ncalc\nnotation is worth considering here. When the\nfirst expression is taking this much space, using\n_\nin the first\nrelation naturally aligns all relations:\nexample (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n  calc (x + y) * (x + y)\n    _ = (x + y) * x + (x + y) * y       := by rw [Nat.mul_add]\n    _ = x * x + y * x + (x + y) * y     := by rw [Nat.add_mul]\n    _ = x * x + y * x + (x * y + y * y) := by rw [Nat.add_mul]\n    _ = x * x + y * x + x * y + y * y   := by rw [←Nat.add_assoc]\nHere the left arrow before\nNat.add_assoc\ntells rewrite to use the\nidentity in the opposite direction. (You can enter it with\n\\l\nor\nuse the ascii equivalent,\n<-\n.) If brevity is what we are after,\nboth\nrw\nand\nsimp\ncan do the job on their own:\nexample (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n  by rw [Nat.mul_add, Nat.add_mul, Nat.add_mul, ←Nat.add_assoc]\n\nexample (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n  by simp [Nat.mul_add, Nat.add_mul, Nat.add_assoc]\nThe Existential Quantifier\nFinally, consider the existential quantifier, which can be written as\neither\nexists x : α, p x\nor\n∃ x : α, p x\n.  Both versions are\nactually notationally convenient abbreviations for a more long-winded\nexpression,\nExists (fun x : α => p x)\n, defined in Lean\'s library.\nAs you should by now expect, the library includes both an introduction\nrule and an elimination rule. The introduction rule is\nstraightforward: to prove\n∃ x : α, p x\n, it suffices to provide a\nsuitable term\nt\nand a proof of\np t\n. Here are some examples:\nexample : ∃ x : Nat, x > 0 :=\n  have h : 1 > 0 := Nat.zero_lt_succ 0\n  Exists.intro 1 h\n\nexample (x : Nat) (h : x > 0) : ∃ y, y < x :=\n  Exists.intro 0 h\n\nexample (x y z : Nat) (hxy : x < y) (hyz : y < z) : ∃ w, x < w ∧ w < z :=\n  Exists.intro y (And.intro hxy hyz)\n\n#check @Exists.intro -- ∀ {α : Sort u_1} {p : α → Prop} (w : α), p w → Exists p\nWe can use the anonymous constructor notation\n⟨t, h⟩\nfor\nExists.intro t h\n, when the type is clear from the context.\nexample : ∃ x : Nat, x > 0 :=\n  have h : 1 > 0 := Nat.zero_lt_succ 0\n  ⟨1, h⟩\n\nexample (x : Nat) (h : x > 0) : ∃ y, y < x :=\n  ⟨0, h⟩\n\nexample (x y z : Nat) (hxy : x < y) (hyz : y < z) : ∃ w, x < w ∧ w < z :=\n  ⟨y, hxy, hyz⟩\nNote that\nExists.intro\nhas implicit arguments: Lean has to infer\nthe predicate\np : α → Prop\nin the conclusion\n∃ x, p x\n.  This\nis not a trivial affair. For example, if we have\nhg : g 0 0 = 0\nand write\nExists.intro 0 hg\n, there are many possible values\nfor the predicate\np\n, corresponding to the theorems\n∃ x, g x x = x\n,\n∃ x, g x x = 0\n,\n∃ x, g x 0 = x\n, etc. Lean uses the\ncontext to infer which one is appropriate. This is illustrated in the\nfollowing example, in which we set the option\npp.explicit\nto true\nto ask Lean\'s pretty-printer to show the implicit arguments.\nvariable (g : Nat → Nat → Nat)\nvariable (hg : g 0 0 = 0)\n\ntheorem gex1 : ∃ x, g x x = x := ⟨0, hg⟩\ntheorem gex2 : ∃ x, g x 0 = x := ⟨0, hg⟩\ntheorem gex3 : ∃ x, g 0 0 = x := ⟨0, hg⟩\ntheorem gex4 : ∃ x, g x x = 0 := ⟨0, hg⟩\n\nset_option pp.explicit true  -- display implicit arguments\n#print gex1\n#print gex2\n#print gex3\n#print gex4\nWe can view\nExists.intro\nas an information-hiding operation, since\nit hides the witness to the body of the assertion. The existential\nelimination rule,\nExists.elim\n, performs the opposite operation. It\nallows us to prove a proposition\nq\nfrom\n∃ x : α, p x\n, by\nshowing that\nq\nfollows from\np w\nfor an arbitrary value\nw\n. Roughly speaking, since we know there is an\nx\nsatisfying\np x\n, we can give it a name, say,\nw\n. If\nq\ndoes not mention\nw\n, then showing that\nq\nfollows from\np w\nis tantamount to\nshowing that\nq\nfollows from the existence of any such\nx\n. Here\nis an example:\nvariable (α : Type) (p q : α → Prop)\n\nexample (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n  Exists.elim h\n    (fun w =>\n     fun hw : p w ∧ q w =>\n     show ∃ x, q x ∧ p x from ⟨w, hw.right, hw.left⟩)\nIt may be helpful to compare the exists-elimination rule to the\nor-elimination rule: the assertion\n∃ x : α, p x\ncan be thought of\nas a big disjunction of the propositions\np a\n, as\na\nranges over\nall the elements of\nα\n. Note that the anonymous constructor\nnotation\n⟨w, hw.right, hw.left⟩\nabbreviates a nested constructor\napplication; we could equally well have written\n⟨w, ⟨hw.right, hw.left⟩⟩\n.\nNotice that an existential proposition is very similar to a sigma\ntype, as described in dependent types section.  The difference is that\ngiven\na : α\nand\nh : p a\n, the term\nExists.intro a h\nhas\ntype\n(∃ x : α, p x) : Prop\nand\nSigma.mk a h\nhas type\n(Σ x : α, p x) : Type\n. The similarity between\n∃\nand\nΣ\nis another\ninstance of the Curry-Howard isomorphism.\nLean provides a more convenient way to eliminate from an existential\nquantifier with the\nmatch\nexpression:\nvariable (α : Type) (p q : α → Prop)\n\nexample (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n  match h with\n  | ⟨w, hw⟩ => ⟨w, hw.right, hw.left⟩\nThe\nmatch\nexpression is part of Lean\'s function definition system,\nwhich provides convenient and expressive ways of defining complex\nfunctions.  Once again, it is the Curry-Howard isomorphism that allows\nus to co-opt this mechanism for writing proofs as well.  The\nmatch\nstatement "destructs" the existential assertion into the components\nw\nand\nhw\n, which can then be used in the body of the statement\nto prove the proposition. We can annotate the types used in the match\nfor greater clarity:\nvariable (α : Type) (p q : α → Prop)\nexample (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n  match h with\n  | ⟨(w : α), (hw : p w ∧ q w)⟩ => ⟨w, hw.right, hw.left⟩\nWe can even use the match statement to decompose the conjunction at the same time:\nvariable (α : Type) (p q : α → Prop)\nexample (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n  match h with\n  | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\nLean also provides a pattern-matching\nlet\nexpression:\nvariable (α : Type) (p q : α → Prop)\nexample (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n  let ⟨w, hpw, hqw⟩ := h\n  ⟨w, hqw, hpw⟩\nThis is essentially just alternative notation for the\nmatch\nconstruct above. Lean will even allow us to use an implicit\nmatch\nin the\nfun\nexpression:\nvariable (α : Type) (p q : α → Prop)\nexample : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n  fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\nWe will see in\nChapter Induction and Recursion\nthat all these variations are\ninstances of a more general pattern-matching construct.\nIn the following example, we define\nis_even a\nas\n∃ b, a = 2 * b\n,\nand then we show that the sum of two even numbers is an even number.\ndef is_even (a : Nat) := ∃ b, a = 2 * b\n\n'}], 'model': 'gpt-4o'}}
2025-05-31 17:55:51,531 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-05-31 17:55:51,531 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-31 17:55:51,531 - DEBUG - send_request_headers.complete
2025-05-31 17:55:51,531 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-31 17:55:51,536 - DEBUG - send_request_body.complete
2025-05-31 17:55:51,536 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-31 17:55:54,629 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 31 May 2025 17:55:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2573'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2583'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'9665'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'40.67s'), (b'x-request-id', b'req_41138df848da98da116a2d6560c18121'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948858374e193cac-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-05-31 17:55:54,629 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-31 17:55:54,630 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-31 17:55:54,631 - DEBUG - receive_response_body.complete
2025-05-31 17:55:54,631 - DEBUG - response_closed.started
2025-05-31 17:55:54,631 - DEBUG - response_closed.complete
2025-05-31 17:55:54,631 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 31 May 2025 17:55:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2573', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2583', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '9665', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '40.67s', 'x-request-id': 'req_41138df848da98da116a2d6560c18121', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948858374e193cac-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-05-31 17:55:54,631 - DEBUG - request_id: req_41138df848da98da116a2d6560c18121
2025-05-31 17:55:54,632 - INFO - Raw solution received: ```json
{
  "code": "x",
  "proof": "rfl"
}
```
2025-05-31 17:55:54,632 - INFO - <class 'str'>
2025-05-31 17:55:54,632 - INFO - Generated solution: {'code': 'x', 'proof': 'rfl'}
2025-05-31 17:55:54,634 - INFO - Lean execution result: Error: Lean executable not found or temp_project directory doesn't exist.
2025-05-31 17:55:54,635 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef ident (x : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\ndef ident_spec (x : Nat) (result: Nat) : Prop :=\n  -- << SPEC START >>\n  result = x\n  -- << SPEC END >>\n\ntheorem ident_spec_satisfied (x : Nat) :\n  ident_spec x (ident x) := by\n  -- << PROOF START >>\n  unfold ident ident_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nx\n\nGenerated Proof:\nrfl\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nError: Lean executable not found or temp_project directory doesn't exist."}], 'model': 'o3-mini'}}
2025-05-31 17:55:54,635 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-05-31 17:55:54,635 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-31 17:55:54,635 - DEBUG - send_request_headers.complete
2025-05-31 17:55:54,635 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-31 17:55:54,636 - DEBUG - send_request_body.complete
2025-05-31 17:55:54,636 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-31 17:56:00,404 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 31 May 2025 17:56:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5269'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5276'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199415'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'175ms'), (b'x-request-id', b'req_2d55baae0b2065c3271de7a3d32d73ed'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9488584aacf83cac-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-05-31 17:56:00,404 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-31 17:56:00,405 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-31 17:56:00,405 - DEBUG - receive_response_body.complete
2025-05-31 17:56:00,405 - DEBUG - response_closed.started
2025-05-31 17:56:00,405 - DEBUG - response_closed.complete
2025-05-31 17:56:00,405 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 31 May 2025 17:56:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5269', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5276', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199415', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '175ms', 'x-request-id': 'req_2d55baae0b2065c3271de7a3d32d73ed', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9488584aacf83cac-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-05-31 17:56:00,405 - DEBUG - request_id: req_2d55baae0b2065c3271de7a3d32d73ed
2025-05-31 17:56:00,406 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': 'The error message indicates that the Lean executable or the temporary project directory is missing. This is an environment setup issue rather than a problem with the actual code or proof.', 'error_type': 'unknown', 'suggested_fix': 'Ensure that Lean 4 is properly installed and that the temporary project directory is correctly configured. Check your PATH for the lean executable and verify the project environment setup.', 'retry_strategy': 'Resolve the environment configuration issues and then re-run the Lean code to confirm that the code and proof execute without errors.'}
2025-05-31 17:56:00,406 - INFO - Solution generated in 15.75 seconds
2025-05-31 17:56:00,406 - INFO - Generated code length: 5 characters
2025-05-31 17:56:00,406 - INFO - Generated proof length: 5 characters
2025-05-31 17:56:00,406 - INFO - Loading Lean template and inserting generated solution...
2025-05-31 17:56:00,406 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-05-31 17:56:00,407 - INFO - Implementation test result: FAIL
2025-05-31 17:56:00,407 - INFO - Executing Lean code with implementation and proof...
2025-05-31 17:56:00,407 - INFO - Full solution test result: FAIL
2025-05-31 17:56:00,407 - ERROR - ❌ Implementation fails unit tests
2025-05-31 17:56:00,407 - ERROR - ❌ Proof has errors
2025-05-31 17:56:00,407 - INFO - 
==================================================
2025-05-31 17:56:00,407 - INFO - Processing task task_id_58...
2025-05-31 17:56:00,408 - INFO - Reading problem description and code template from tasks/task_id_58...
2025-05-31 17:56:00,410 - INFO - Problem description length: 700 characters
2025-05-31 17:56:00,410 - INFO - Reading unit tests from tasks/task_id_58...
2025-05-31 17:56:00,410 - INFO - Unit tests length: 462 characters
2025-05-31 17:56:00,410 - INFO - Running main workflow to generate solution...
2025-05-31 17:56:00,410 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.

-----Input-----
The input consists of two integers:
a: An integer.
b: An integer.

-----Output-----
The output is a Boolean value:
Returns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).
Returns false if both integers are either non-negative or non-positive, or if one (or both) is zero.
2025-05-31 17:56:00,411 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def hasOppositeSign (a : Int) (b : Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result is true if a and b have opposite signs
def hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=
  -- << SPEC START >>
  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result
  -- << SPEC END >>

theorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :
  hasOppositeSign_spec a b (hasOppositeSign a b) := by
  -- << PROOF START >>
  unfold hasOppositeSign hasOppositeSign_spec
  {{proof}}
  -- << PROOF END >>

2025-05-31 17:56:00,652 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7a6c34d56340>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-05-31 17:56:00,653 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-05-31 17:56:00,653 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-05-31 17:56:00,660 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a6c374eb350>
2025-05-31 17:56:00,660 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7a6c3719ed50> server_hostname='api.openai.com' timeout=5.0
2025-05-31 17:56:00,668 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7a6c374eb7d0>
2025-05-31 17:56:00,669 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-31 17:56:00,669 - DEBUG - send_request_headers.complete
2025-05-31 17:56:00,669 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-31 17:56:00,669 - DEBUG - send_request_body.complete
2025-05-31 17:56:00,669 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-31 17:56:01,495 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 31 May 2025 17:56:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'86'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7c4bf98c9f-9vxq9'), (b'x-envoy-upstream-service-time', b'93'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999825'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_c481de1c6f536aa22b26caa3aae79846'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1MxEga.avXQ.GnylHieVHNscxV5yiHr4A1idNN5O_xk-1748714161-1.0.1.1-5PBwwv63pZ9WwTZcGqSRpbYUokMS49gdnl.WzN3trqGSPX6AUC6d_BiqfOkE46PxPOArxVgNGcMO19vrP_iE__RQ.5mc3W61fC5nTdXIIq0; path=/; expires=Sat, 31-May-25 18:26:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=SVadP9I_h7K5DGQtSXSLKGtvZ8htHQfe5kwvsE0LOFg-1748714161520-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9488587069e63b10-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-05-31 17:56:01,495 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-05-31 17:56:01,495 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-31 17:56:01,496 - DEBUG - receive_response_body.complete
2025-05-31 17:56:01,496 - DEBUG - response_closed.started
2025-05-31 17:56:01,496 - DEBUG - response_closed.complete
2025-05-31 17:56:01,496 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sat, 31 May 2025 17:56:01 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '86'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-7c4bf98c9f-9vxq9'), ('x-envoy-upstream-service-time', '93'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999825'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '10ms'), ('x-request-id', 'req_c481de1c6f536aa22b26caa3aae79846'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=1MxEga.avXQ.GnylHieVHNscxV5yiHr4A1idNN5O_xk-1748714161-1.0.1.1-5PBwwv63pZ9WwTZcGqSRpbYUokMS49gdnl.WzN3trqGSPX6AUC6d_BiqfOkE46PxPOArxVgNGcMO19vrP_iE__RQ.5mc3W61fC5nTdXIIq0; path=/; expires=Sat, 31-May-25 18:26:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=SVadP9I_h7K5DGQtSXSLKGtvZ8htHQfe5kwvsE0LOFg-1748714161520-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9488587069e63b10-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-05-31 17:56:01,496 - DEBUG - request_id: req_c481de1c6f536aa22b26caa3aae79846
2025-05-31 17:56:01,534 - INFO - Retrieved context: theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
  Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
  Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
    Exists.intro (w1 + w2)
      (calc a + b
        _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
        _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
Using the various gadgets described in this chapter --- the match
statement, anonymous constructors, and the
rewrite
tactic, we can
write this proof concisely as follows:
def is_even (a : Nat) := ∃ b, a = 2 * b
theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
  match h1, h2 with
  | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
Just as the constructive "or" is stronger than the classical "or," so,
too, is the constructive "exists" stronger than the classical
"exists". For example, the following implication requires classical
reasoning because, from a constructive standpoint, knowing that it is
not the case that every
x
satisfies
¬ p
is not the same as
having a particular
x
that satisfies
p
.
open Classical
variable (p : α → Prop)

example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
  byContradiction
    (fun h1 : ¬ ∃ x, p x =>
      have h2 : ∀ x, ¬ p x :=
        fun x =>
        fun h3 : p x =>
        have h4 : ∃ x, p x := ⟨x, h3⟩
        show False from h1 h4
      show False from h h2)
What follows are some common identities involving the existential
quantifier. In the exercises below, we encourage you to prove as many
as you can. We also leave it to you to determine which are
nonconstructive, and hence require some form of classical reasoning.
open Classical

variable (α : Type) (p q : α → Prop)
variable (r : Prop)

example : (∃ x : α, r) → r := sorry
example (a : α) : r → (∃ x : α, r) := sorry
example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry

example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry

example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
Notice that the second example and the last two examples require the
assumption that there is at least one element
a
of type
α
.
Here are solutions to two of the more difficult ones:
open Classical

variable (α : Type) (p q : α → Prop)
variable (a : α)
variable (r : Prop)

example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
  Iff.intro
    (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
      Or.elim h1
        (fun hpa : p a => Or.inl ⟨a, hpa⟩)
        (fun hqa : q a => Or.inr ⟨a, hqa⟩))
    (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
      Or.elim h
        (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
        (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))

example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
  Iff.intro
    (fun ⟨b, (hb : p b → r)⟩ =>
     fun h2 : ∀ x, p x =>
     show r from hb (h2 b))
    (fun h1 : (∀ x, p x) → r =>
     show ∃ x, p x → r from
       byCases
         (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
         (fun hnap : ¬ ∀ x, p x =>
          byContradiction
            (fun hnex : ¬ ∃ x, p x → r =>
              have hap : ∀ x, p x :=
                fun x =>
                byContradiction
                  (fun hnp : ¬ p x =>
                    have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                    show False from hnex hex)
              show False from hnap hap)))
More on the Proof Language
We have seen that keywords like
fun
,
have
, and
show
make
it possible to write formal proof terms that mirror the structure of
informal mathematical proofs. In this section, we discuss some
additional features of the proof language that are often convenient.
To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last
expression introduced in this way using the keyword
this
:
variable (f : Nat → Nat)
variable (h : ∀ x : Nat, f x ≤ f (x + 1))

example : f 0 ≤ f 3 :=
  have : f 0 ≤ f 1 := h 0
  have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
  show f 0 ≤ f 3 from Nat.le_trans this (h 2)
Often proofs move from one fact to the next, so this can be effective
in eliminating the clutter of lots of labels.
When the goal can be inferred, we can also ask Lean instead to fill in
the proof by writing
by assumption
:
variable (f : Nat → Nat)
variable (h : ∀ x : Nat, f x ≤ f (x + 1))
example : f 0 ≤ f 3 :=
  have : f 0 ≤ f 1 := h 0
  have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
  show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
This tells Lean to use the
assumption
tactic, which, in turn,
proves the goal by finding a suitable hypothesis in the local
context. We will learn more about the
assumption
tactic in the
next chapter.
We can also ask Lean to fill in the proof by writing
‹p›
, where
p
is the proposition whose proof we want Lean to find in the
context.  You can type these corner quotes using
\f<
and
\f>
,
respectively. The letter "f" is for "French," since the unicode
symbols can also be used as French quotation marks. In fact, the
notation is defined in Lean as follows:
notation "‹" p "›" => show p by assumption
This approach is more robust than using
by assumption
, because the
type of the assumption that needs to be inferred is given
explicitly. It also makes proofs more readable. Here is a more
elaborate example:
variable (f : Nat → Nat)
variable (h : ∀ x : Nat, f x ≤ f (x + 1))

example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
  fun _ : f 0 ≥ f 1 =>
  fun _ : f 1 ≥ f 2 =>
  have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
  have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
  show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
Keep in mind that you can use the French quotation marks in this way
to refer to
anything
in the context, not just things that were
introduced anonymously. Its use is also not limited to propositions,
though using it for data is somewhat odd:
example (n : Nat) : Nat := ‹Nat›
Later, we show how you can extend the proof language using the Lean macro system.
Exercises
Prove these equivalences:
variable (α : Type) (p q : α → Prop)

example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
You should also try to understand why the reverse implication is not derivable in the last example.
It is often possible to bring a component of a formula outside a
universal quantifier, when it does not depend on the quantified
variable. Try proving these (one direction of the second of these
requires classical logic):
variable (α : Type) (p q : α → Prop)
variable (r : Prop)

example : α → ((∀ x : α, r) ↔ r) := sorry
example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
Consider the "barber paradox," that is, the claim that in a certain
town there is a (male) barber that shaves all and only the men who
do not shave themselves. Prove that this is a contradiction:
variable (men : Type) (barber : men)
variable (shaves : men → men → Prop)

example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
Remember that, without any parameters, an expression of type
Prop
is just an assertion. Fill in the definitions of
prime
and
Fermat_prime
below, and construct each of the given
assertions. For example, you can say that there are infinitely many
primes by asserting that for every natural number
n
, there is a
prime number greater than
n
. Goldbach's weak conjecture states
that every odd number greater than 5 is the sum of three
primes. Look up the definition of a Fermat prime or any of the
other statements, if necessary.
def even (n : Nat) : Prop := sorry

def prime (n : Nat) : Prop := sorry

def infinitely_many_primes : Prop := sorry

def Fermat_prime (n : Nat) : Prop := sorry

def infinitely_many_Fermat_primes : Prop := sorry

def goldbach_conjecture : Prop := sorry

def Goldbach's_weak_conjecture : Prop := sorry

def Fermat's_last_theorem : Prop := sorry
Prove as many of the identities listed in the Existential
Quantifier section as you can.
Quantifiers and Equality - Theorem Proving in Lean 4
Theorem Proving in Lean 4
1.
Introduction
2.
Dependent Type Theory
3.
Propositions and Proofs
4.
Quantifiers and Equality
5.
Tactics
6.
Interacting with Lean
7.
Inductive Types
8.
Induction and Recursion
9.
Structures and Records
10.
Type Classes
11.
The Conversion Tactic Mode
12.
Axioms and Computation
Light (default)
Rust
Coal
Navy
Ayu
Theorem Proving in Lean 4
Quantifiers and Equality
The last chapter introduced you to methods that construct proofs of
statements involving the propositional connectives. In this chapter,
we extend the repertoire of logical constructions to include the
universal and existential quantifiers, and the equality relation.
The Universal Quantifier
Notice that if
α
is any type, we can represent a unary predicate
p
on
α
as an object of type
α → Prop
. In that case, given
x : α
,
p x
denotes the assertion that
p
holds of
x
. Similarly, an object
r : α → α → Prop
denotes a binary
relation on
α
: given
x y : α
,
r x y
denotes the assertion
that
x
is related to
y
.
The universal quantifier,
∀ x : α, p x
is supposed to denote the
assertion that "for every
x : α
,
p x
" holds. As with the
propositional connectives, in systems of natural deduction, "forall"
is governed by an introduction and elimination rule. Informally, the
introduction rule states:
Given a proof of
p x
, in a context where
x : α
is arbitrary, we obtain a proof
∀ x : α, p x
.
The elimination rule states:
Given a proof
∀ x : α, p x
and any term
t : α
, we obtain a proof of
p t
.
As was the case for implication, the propositions-as-types
interpretation now comes into play. Remember the introduction and
elimination rules for dependent arrow types:
Given a term
t
of type
β x
, in a context where
x : α
is arbitrary, we have
(fun x : α => t) : (x : α) → β x
.
The elimination rule states:
Given a term
s : (x : α) → β x
and any term
t : α
, we have
s t : β t
.
In the case where
p x
has type
Prop
, if we replace
(x : α) → β x
with
∀ x : α, p x
, we can read these as the correct rules
for building proofs involving the universal quantifier.
The Calculus of Constructions therefore identifies dependent arrow
types with forall-expressions in this way. If
p
is any expression,
∀ x : α, p
is nothing more than alternative notation for
(x : α) → p
, with the idea that the former is more natural than the latter
in cases where
p
is a proposition. Typically, the expression
p
will depend on
x : α
. Recall that, in the case of ordinary
function spaces, we could interpret
α → β
as the special case of
(x : α) → β
in which
β
does not depend on
x
. Similarly, we
can think of an implication
p → q
between propositions as the
special case of
∀ x : p, q
in which the expression
q
does not
depend on
x
.
Here is an example of how the propositions-as-types correspondence gets put into practice.
example (α : Type) (p q : α → Prop) : (∀ x : α, p x ∧ q x) → ∀ y : α, p y :=
  fun h : ∀ x : α, p x ∧ q x =>
  fun y : α =>
  show p y from (h y).left
As a notational convention, we give the universal quantifier the
widest scope possible, so parentheses are needed to limit the
quantifier over
x
to the hypothesis in the example above. The
canonical way to prove
∀ y : α, p y
is to take an arbitrary
y
,
and prove
p y
. This is the introduction rule. Now, given that
h
has type
∀ x : α, p x ∧ q x
, the expression
h y
has type
p y ∧ q y
. This is the elimination rule. Taking the left conjunct
gives the desired conclusion,
p y
.
Remember that expressions which differ up to renaming of bound
variables are considered to be equivalent. So, for example, we could
have used the same variable,
x
, in both the hypothesis and
conclusion, and instantiated it by a different variable,
z
, in the
proof:
example (α : Type) (p q : α → Prop) : (∀ x : α, p x ∧ q x) → ∀ x : α, p x :=
  fun h : ∀ x : α, p x ∧ q x =>
  fun z : α =>
  show p z from And.left (h z)
As another example, here is how we can express the fact that a relation,
r
, is transitive:
variable (α : Type) (r : α → α → Prop)
variable (trans_r : ∀ x y z, r x y → r y z → r x z)

variable (a b c : α)
variable (hab : r a b) (hbc : r b c)

#check trans_r    -- ∀ (x y z : α), r x y → r y z → r x z
#check trans_r a b c -- r a b → r b c → r a c
#check trans_r a b c hab -- r b c → r a c
#check trans_r a b c hab hbc -- r a c
Think about what is going on here. When we instantiate
trans_r
at
the values
a b c
, we end up with a proof of
r a b → r b c → r a c
.
Applying this to the "hypothesis"
hab : r a b
, we get a proof
of the implication
r b c → r a c
. Finally, applying it to the
hypothesis
hbc
yields a proof of the conclusion
r a c
.
In situations like this, it can be tedious to supply the arguments
a b c
, when they can be inferred from
hab hbc
. For that reason, it
is common to make these arguments implicit:
variable (α : Type) (r : α → α → Prop)
variable (trans_r : ∀ {x y z}, r x y → r y z → r x z)

variable (a b c : α)
variable (hab : r a b) (hbc : r b c)

#check trans_r
#check trans_r hab
#check trans_r hab hbc
The advantage is that we can simply write
trans_r hab hbc
as a
proof of
r a c
. A disadvantage is that Lean does not have enough
information to infer the types of the arguments in the expressions
trans_r
and
trans_r hab
. The output of the first
#check
command is
r ?m.1 ?m.2 → r ?m.2 ?m.3 → r ?m.1 ?m.3
, indicating
that the implicit arguments are unspecified in this case.
Here is an example of how we can carry out elementary reasoning with an equivalence relation:
variable (α : Type) (r : α → α → Prop)

variable (refl_r : ∀ x, r x x)
variable (symm_r : ∀ {x y}, r x y → r y x)
variable (trans_r : ∀ {x y z}, r x y → r y z → r x z)

example (a b c d : α) (hab : r a b) (hcb : r c b) (hcd : r c d) : r a d :=
  trans_r (trans_r hab (symm_r hcb)) hcd
To get used to using universal quantifiers, you should try some of the
exercises at the end of this section.
It is the typing rule for dependent arrow types, and the universal
quantifier in particular, that distinguishes
Prop
from other
types.  Suppose we have
α : Sort i
and
β : Sort j
, where the
expression
β
may depend on a variable
x : α
. Then
(x : α) → β
is an element of
Sort (imax i j)
, where
imax i j
is the
maximum of
i
and
j
if
j
is not 0, and 0 otherwise.
The idea is as follows. If
j
is not
0
, then
(x : α) → β
is
an element of
Sort (max i j)
. In other words, the type of
dependent functions from
α
to
β
"lives" in the universe whose
index is the maximum of
i
and
j
. Suppose, however, that
β
is of
Sort 0
, that is, an element of
Prop
. In that case,
(x : α) → β
is an element of
Sort 0
as well, no matter which
type universe
α
lives in. In other words, if
β
is a
proposition depending on
α
, then
∀ x : α, β
is again a
proposition. This reflects the interpretation of
Prop
as the type
of propositions rather than data, and it is what makes
Prop
impredicative
.
The term "predicative" stems from foundational developments around the
turn of the twentieth century, when logicians such as Poincaré and
Russell blamed set-theoretic paradoxes on the "vicious circles" that
arise when we define a property by quantifying over a collection that
includes the very property being defined. Notice that if
α
is any
type, we can form the type
α → Prop
of all predicates on
α
(the "power type of
α
"). The impredicativity of
Prop
means that we
can form propositions that quantify over
α → Prop
. In particular,
we can define predicates on
α
by quantifying over all predicates
on
α
, which is exactly the type of circularity that was once
considered problematic.
Equality
Let us now turn to one of the most fundamental relations defined in
Lean's library, namely, the equality relation. In
Chapter Inductive Types
,
we will explain
how
equality is defined from the primitives of Lean's logical framework.
In the meanwhile, here we explain how to use it.
Of course, a fundamental property of equality is that it is an equivalence relation:
#check Eq.refl    -- Eq.refl.{u_1} {α : Sort u_1} (a : α) : a = a
#check Eq.symm    -- Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a
#check Eq.trans   -- Eq.trans.{u} {α : Sort u} {a b c : α} (h₁ : a = b) (h₂ : b = c) : a = c
We can make the output easier to read by telling Lean not to insert
the implicit arguments (which are displayed here as metavariables).
universe u

#check @Eq.refl.{u}   -- @Eq.refl : ∀ {α : Sort u} (a : α), a = a
#check @Eq.symm.{u}   -- @Eq.symm : ∀ {α : Sort u} {a b : α}, a = b → b = a
#check @Eq.trans.{u}  -- @Eq.trans : ∀ {α : Sort u} {a b c : α}, a = b → b = c → a = c
The inscription
.{u}
tells Lean to instantiate the constants at the universe
u
.
Thus, for example, we can specialize the example from the previous section to the equality relation:
variable (α : Type) (a b c d : α)
variable (hab : a = b) (hcb : c = b) (hcd : c = d)

example : a = d :=
  Eq.trans (Eq.trans hab (Eq.symm hcb)) hcd
We can also use the projection notation:
variable (α : Type) (a b c d : α)
variable (hab : a = b) (hcb : c = b) (hcd : c = d)
example : a = d := (hab.trans hcb.symm).trans hcd
Reflexivity is more powerful than it looks. Recall that terms in the
Calculus of Constructions have a computational interpretation, and
that the logical framework treats terms with a common reduct as the
same. As a result, some nontrivial identities can be proved by
reflexivity:
variable (α β : Type)

example (f : α → β) (a : α) : (fun x => f x) a = f a := Eq.refl _
example (a : α) (b : β) : (a, b).1 = a := Eq.refl _
example : 2 + 3 = 5 := Eq.refl _
This feature of the framework is so important that the library defines a notation
rfl
for
Eq.refl _
:
variable (α β : Type)
example (f : α → β) (a : α) : (fun x => f x) a = f a := rfl
example (a : α) (b : β) : (a, b).1 = a := rfl
example : 2 + 3 = 5 := rfl
Equality is much more than an equivalence relation, however. It has
the important property that every assertion respects the equivalence,
in the sense that we can substitute equal expressions without changing
the truth value. That is, given
h1 : a = b
and
h2 : p a
, we
can construct a proof for
p b
using substitution:
Eq.subst h1 h2
.
example (α : Type) (a b : α) (p : α → Prop)
        (h1 : a = b) (h2 : p a) : p b :=
  Eq.subst h1 h2

example (α : Type) (a b : α) (p : α → Prop)
    (h1 : a = b) (h2 : p a) : p b :=
  h1 ▸ h2
The triangle in the second presentation is a macro built on top of
Eq.subst
and
Eq.symm
, and you can enter it by typing
\t
.
The rule
Eq.subst
is used to define the following auxiliary rules,
which carry out more explicit substitutions. They are designed to deal
with applicative terms, that is, terms of form
s t
. Specifically,
congrArg
can be used to replace the argument,
congrFun
can be
used to replace the term that is being applied, and
congr
can be
used to replace both at once.
variable (α : Type)
variable (a b : α)
variable (f g : α → Nat)
variable (h₁ : a = b)
variable (h₂ : f = g)

example : f a = f b := congrArg f h₁
example : f a = g a := congrFun h₂ a
example : f a = g b := congr h₂ h₁
Lean's library contains a large number of common identities, such as these:
variable (a b c : Nat)

example : a + 0 = a := Nat.add_zero a
example : 0 + a = a := Nat.zero_add a
example : a * 1 = a := Nat.mul_one a
example : 1 * a = a := Nat.one_mul a
example : a + b = b + a := Nat.add_comm a b
example : a + b + c = a + (b + c) := Nat.add_assoc a b c
example : a * b = b * a := Nat.mul_comm a b
example : a * b * c = a * (b * c) := Nat.mul_assoc a b c
example : a * (b + c) = a * b + a * c := Nat.mul_add a b c
example : a * (b + c) = a * b + a * c := Nat.left_distrib a b c
example : (a + b) * c = a * c + b * c := Nat.add_mul a b c
example : (a + b) * c = a * c + b * c := Nat.right_distrib a b c
Note that
Nat.mul_add
and
Nat.add_mul
are alternative names
for
Nat.left_distrib
and
Nat.right_distrib
, respectively.  The
properties above are stated for the natural numbers (type
Nat
).
Here is an example of a calculation in the natural numbers that uses
substitution combined with associativity and distributivity.
example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  have h1 : (x + y) * (x + y) = (x + y) * x + (x + y) * y :=
    Nat.mul_add (x + y) x y
  have h2 : (x + y) * (x + y) = x * x + y * x + (x * y + y * y) :=
    (Nat.add_mul x y x) ▸ (Nat.add_mul x y y) ▸ h1
  h2.trans (Nat.add_assoc (x * x + y * x) (x * y) (y * y)).symm
Notice that the second implicit parameter to
Eq.subst
, which
provides the context in which the substitution is to occur, has type
α → Prop
.  Inferring this predicate therefore requires an instance
of
higher-order unification
. In full generality, the problem of
determining whether a higher-order unifier exists is undecidable, and
Lean can at best provide imperfect and approximate solutions to the
problem. As a result,
Eq.subst
doesn't always do what you want it
to.  The macro
h ▸ e
uses more effective heuristics for computing
this implicit parameter, and often succeeds in situations where
applying
Eq.subst
fails.
Because equational reasoning is so common and important, Lean provides
a number of mechanisms to carry it out more effectively. The next
section offers syntax that allow you to write calculational proofs in
a more natural and perspicuous way. But, more importantly, equational
reasoning is supported by a term rewriter, a simplifier, and other
kinds of automation. The term rewriter and simplifier are described
briefly in the next section, and then in greater detail in the next
chapter.
Calculational Proofs
A calculational proof is just a chain of intermediate results that are
meant to be composed by basic principles such as the transitivity of
equality. In Lean, a calculational proof starts with the keyword
calc
, and has the following syntax:
calc
  <expr>_0  'op_1'  <expr>_1  ':='  <proof>_1
  '_'       'op_2'  <expr>_2  ':='  <proof>_2
  ...
  '_'       'op_n'  <expr>_n  ':='  <proof>_n
Note that the
calc
relations all have the same indentation. Each
<proof>_i
is a proof for
<expr>_{i-1} op_i <expr>_i
.
We can also use
_
in the first relation (right after
<expr>_0
)
which is useful to align the sequence of relation/proof pairs:
calc <expr>_0 
    '_' 'op_1' <expr>_1 ':=' <proof>_1
    '_' 'op_2' <expr>_2 ':=' <proof>_2
    ...
    '_' 'op_n' <expr>_n ':=' <proof>_n
Here is an example:
variable (a b c d e : Nat)
variable (h1 : a = b)
variable (h2 : b = c + 1)
variable (h3 : c = d)
variable (h4 : e = 1 + d)

theorem T : a = e :=
  calc
    a = b      := h1
    _ = c + 1  := h2
    _ = d + 1  := congrArg Nat.succ h3
    _ = 1 + d  := Nat.add_comm d 1
    _ = e      := Eq.symm h4
This style of writing proofs is most effective when it is used in
conjunction with the
simp
and
rewrite
tactics, which are
discussed in greater detail in the next chapter. For example, using
the abbreviation
rw
for rewrite, the proof above could be written
as follows:
variable (a b c d e : Nat)
variable (h1 : a = b)
variable (h2 : b = c + 1)
variable (h3 : c = d)
variable (h4 : e = 1 + d)
theorem T : a = e :=
  calc
    a = b      := by rw [h1]
    _ = c + 1  := by rw [h2]
    _ = d + 1  := by rw [h3]
    _ = 1 + d  := by rw [Nat.add_comm]
    _ = e      := by rw [h4]
Essentially, the
rw
tactic uses a given equality (which can be a
hypothesis, a theorem name, or a complex term) to "rewrite" the
goal. If doing so reduces the goal to an identity
t = t
, the
tactic applies reflexivity to prove it.
Rewrites can be applied sequentially, so that the proof above can be
shortened to this:
variable (a b c d e : Nat)
variable (h1 : a = b)
variable (h2 : b = c + 1)
variable (h3 : c = d)
variable (h4 : e = 1 + d)
theorem T : a = e :=
  calc
    a = d + 1  := by rw [h1, h2, h3]
    _ = 1 + d  := by rw [Nat.add_comm]
    _ = e      := by rw [h4]
Or even this:
variable (a b c d e : Nat)
variable (h1 : a = b)
variable (h2 : b = c + 1)
variable (h3 : c = d)
variable (h4 : e = 1 + d)
theorem T : a = e :=
  by rw [h1, h2, h3, Nat.add_comm, h4]
The
simp
tactic, instead, rewrites the goal by applying the given
identities repeatedly, in any order, anywhere they are applicable in a
term. It also uses other rules that have been previously declared to
the system, and applies commutativity wisely to avoid looping. As a
result, we can also prove the theorem as follows:
variable (a b c d e : Nat)
variable (h1 : a = b)
variable (h2 : b = c + 1)
variable (h3 : c = d)
variable (h4 : e = 1 + d)
theorem T : a = e :=
  by simp [h1, h2, h3, Nat.add_comm, h4]
We will discuss variations of
rw
and
simp
in the next chapter.
The
calc
command can be configured for any relation that supports
some form of transitivity. It can even combine different relations.
example (a b c d : Nat) (h1 : a = b) (h2 : b ≤ c) (h3 : c + 1 < d) : a < d :=
  calc
    a = b     := h1
    _ < b + 1 := Nat.lt_succ_self b
    _ ≤ c + 1 := Nat.succ_le_succ h2
    _ < d     := h3
You can "teach"
calc
new transitivity theorems by adding new instances
of the
Trans
type class. Type classes are introduced later, but the following
small example demonstrates how to extend the
calc
notation using new
Trans
instances.
def divides (x y : Nat) : Prop :=
  ∃ k, k*x = y

def divides_trans (h₁ : divides x y) (h₂ : divides y z) : divides x z :=
  let ⟨k₁, d₁⟩ := h₁
  let ⟨k₂, d₂⟩ := h₂
  ⟨k₁ * k₂, by rw [Nat.mul_comm k₁ k₂, Nat.mul_assoc, d₁, d₂]⟩

def divides_mul (x : Nat) (k : Nat) : divides x (k*x) :=
  ⟨k, rfl⟩

instance : Trans divides divides divides where
  trans := divides_trans

example (h₁ : divides x y) (h₂ : y = z) : divides x (2*z) :=
  calc
    divides x y     := h₁
    _ = z           := h₂
    divides _ (2*z) := divides_mul ..

infix:50 " ∣ " => divides

example (h₁ : divides x y) (h₂ : y = z) : divides x (2*z) :=
  calc
    x ∣ y   := h₁
    _ = z   := h₂
    _ ∣ 2*z := divides_mul ..
The example above also makes it clear that you can use
calc
even if you
do not have an infix notation for your relation. Finally we remark that
the vertical bar
∣
in the example above is the unicode one. We use
unicode to make sure we do not overload the ASCII
|
used in the
match .. with
expression.
With
calc
, we can write the proof in the last section in a more
natural and perspicuous way.
example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  calc
    (x + y) * (x + y) = (x + y) * x + (x + y) * y  := by rw [Nat.mul_add]
    _ = x * x + y * x + (x + y) * y                := by rw [Nat.add_mul]
    _ = x * x + y * x + (x * y + y * y)            := by rw [Nat.add_mul]
    _ = x * x + y * x + x * y + y * y              := by rw [←Nat.add_assoc]
The alternative
calc
notation is worth considering here. When the
first expression is taking this much space, using
_
in the first
relation naturally aligns all relations:
example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  calc (x + y) * (x + y)
    _ = (x + y) * x + (x + y) * y       := by rw [Nat.mul_add]
    _ = x * x + y * x + (x + y) * y     := by rw [Nat.add_mul]
    _ = x * x + y * x + (x * y + y * y) := by rw [Nat.add_mul]
    _ = x * x + y * x + x * y + y * y   := by rw [←Nat.add_assoc]
Here the left arrow before
Nat.add_assoc
tells rewrite to use the
identity in the opposite direction. (You can enter it with
\l
or
use the ascii equivalent,
<-
.) If brevity is what we are after,
both
rw
and
simp
can do the job on their own:
example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  by rw [Nat.mul_add, Nat.add_mul, Nat.add_mul, ←Nat.add_assoc]

example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  by simp [Nat.mul_add, Nat.add_mul, Nat.add_assoc]
The Existential Quantifier
Finally, consider the existential quantifier, which can be written as
either
exists x : α, p x
or
∃ x : α, p x
.  Both versions are
actually notationally convenient abbreviations for a more long-winded
expression,
Exists (fun x : α => p x)
, defined in Lean's library.
As you should by now expect, the library includes both an introduction
rule and an elimination rule. The introduction rule is
straightforward: to prove
∃ x : α, p x
, it suffices to provide a
suitable term
t
and a proof of
p t
. Here are some examples:
example : ∃ x : Nat, x > 0 :=
  have h : 1 > 0 := Nat.zero_lt_succ 0
  Exists.intro 1 h

example (x : Nat) (h : x > 0) : ∃ y, y < x :=
  Exists.intro 0 h

example (x y z : Nat) (hxy : x < y) (hyz : y < z) : ∃ w, x < w ∧ w < z :=
  Exists.intro y (And.intro hxy hyz)

#check @Exists.intro -- ∀ {α : Sort u_1} {p : α → Prop} (w : α), p w → Exists p
We can use the anonymous constructor notation
⟨t, h⟩
for
Exists.intro t h
, when the type is clear from the context.
example : ∃ x : Nat, x > 0 :=
  have h : 1 > 0 := Nat.zero_lt_succ 0
  ⟨1, h⟩

example (x : Nat) (h : x > 0) : ∃ y, y < x :=
  ⟨0, h⟩

example (x y z : Nat) (hxy : x < y) (hyz : y < z) : ∃ w, x < w ∧ w < z :=
  ⟨y, hxy, hyz⟩
Note that
Exists.intro
has implicit arguments: Lean has to infer
the predicate
p : α → Prop
in the conclusion
∃ x, p x
.  This
is not a trivial affair. For example, if we have
hg : g 0 0 = 0
and write
Exists.intro 0 hg
, there are many possible values
for the predicate
p
, corresponding to the theorems
∃ x, g x x = x
,
∃ x, g x x = 0
,
∃ x, g x 0 = x
, etc. Lean uses the
context to infer which one is appropriate. This is illustrated in the
following example, in which we set the option
pp.explicit
to true
to ask Lean's pretty-printer to show the implicit arguments.
variable (g : Nat → Nat → Nat)
variable (hg : g 0 0 = 0)

theorem gex1 : ∃ x, g x x = x := ⟨0, hg⟩
theorem gex2 : ∃ x, g x 0 = x := ⟨0, hg⟩
theorem gex3 : ∃ x, g 0 0 = x := ⟨0, hg⟩
theorem gex4 : ∃ x, g x x = 0 := ⟨0, hg⟩

set_option pp.explicit true  -- display implicit arguments
#print gex1
#print gex2
#print gex3
#print gex4
We can view
Exists.intro
as an information-hiding operation, since
it hides the witness to the body of the assertion. The existential
elimination rule,
Exists.elim
, performs the opposite operation. It
allows us to prove a proposition
q
from
∃ x : α, p x
, by
showing that
q
follows from
p w
for an arbitrary value
w
. Roughly speaking, since we know there is an
x
satisfying
p x
, we can give it a name, say,
w
. If
q
does not mention
w
, then showing that
q
follows from
p w
is tantamount to
showing that
q
follows from the existence of any such
x
. Here
is an example:
variable (α : Type) (p q : α → Prop)

example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  Exists.elim h
    (fun w =>
     fun hw : p w ∧ q w =>
     show ∃ x, q x ∧ p x from ⟨w, hw.right, hw.left⟩)
It may be helpful to compare the exists-elimination rule to the
or-elimination rule: the assertion
∃ x : α, p x
can be thought of
as a big disjunction of the propositions
p a
, as
a
ranges over
all the elements of
α
. Note that the anonymous constructor
notation
⟨w, hw.right, hw.left⟩
abbreviates a nested constructor
application; we could equally well have written
⟨w, ⟨hw.right, hw.left⟩⟩
.
Notice that an existential proposition is very similar to a sigma
type, as described in dependent types section.  The difference is that
given
a : α
and
h : p a
, the term
Exists.intro a h
has
type
(∃ x : α, p x) : Prop
and
Sigma.mk a h
has type
(Σ x : α, p x) : Type
. The similarity between
∃
and
Σ
is another
instance of the Curry-Howard isomorphism.
Lean provides a more convenient way to eliminate from an existential
quantifier with the
match
expression:
variable (α : Type) (p q : α → Prop)

example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  match h with
  | ⟨w, hw⟩ => ⟨w, hw.right, hw.left⟩
The
match
expression is part of Lean's function definition system,
which provides convenient and expressive ways of defining complex
functions.  Once again, it is the Curry-Howard isomorphism that allows
us to co-opt this mechanism for writing proofs as well.  The
match
statement "destructs" the existential assertion into the components
w
and
hw
, which can then be used in the body of the statement
to prove the proposition. We can annotate the types used in the match
for greater clarity:
variable (α : Type) (p q : α → Prop)
example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  match h with
  | ⟨(w : α), (hw : p w ∧ q w)⟩ => ⟨w, hw.right, hw.left⟩
We can even use the match statement to decompose the conjunction at the same time:
variable (α : Type) (p q : α → Prop)
example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  match h with
  | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
Lean also provides a pattern-matching
let
expression:
variable (α : Type) (p q : α → Prop)
example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  let ⟨w, hpw, hqw⟩ := h
  ⟨w, hqw, hpw⟩
This is essentially just alternative notation for the
match
construct above. Lean will even allow us to use an implicit
match
in the
fun
expression:
variable (α : Type) (p q : α → Prop)
example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
  fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
We will see in
Chapter Induction and Recursion
that all these variations are
instances of a more general pattern-matching construct.
In the following example, we define
is_even a
as
∃ b, a = 2 * b
,
and then we show that the sum of two even numbers is an even number.
def is_even (a : Nat) := ∃ b, a = 2 * b



incrementally. Start writing the proof from the top down, using
sorry
to fill in subproofs. Make sure Lean accepts the term with
all the
sorry
's; if not, there are errors that you need to
correct. Then go back and replace each
sorry
with an actual proof,
until no more remain.
Here is another useful trick. Instead of using
sorry
, you can use
an underscore
_
as a placeholder. Recall this tells Lean that
the argument is implicit, and should be filled in automatically. If
Lean tries to do so and fails, it returns with an error message "don't
know how to synthesize placeholder," followed by the type of
the term it is expecting, and all the objects and hypotheses available
in the context. In other words, for each unresolved placeholder, Lean
reports the subgoal that needs to be filled at that point. You can
then construct a proof by incrementally filling in these placeholders.
For reference, here are two sample proofs of validities taken from the
list above.
open Classical

-- distributivity
example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
  Iff.intro
    (fun h : p ∧ (q ∨ r) =>
      have hp : p := h.left
      Or.elim (h.right)
        (fun hq : q =>
          show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)
        (fun hr : r =>
          show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))
    (fun h : (p ∧ q) ∨ (p ∧ r) =>
      Or.elim h
        (fun hpq : p ∧ q =>
          have hp : p := hpq.left
          have hq : q := hpq.right
          show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)
        (fun hpr : p ∧ r =>
          have hp : p := hpr.left
          have hr : r := hpr.right
          show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))

-- an example that requires classical reasoning
example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=
  fun h : ¬(p ∧ ¬q) =>
  fun hp : p =>
  show q from
    Or.elim (em q)
      (fun hq : q => hq)
      (fun hnq : ¬q => absurd (And.intro hp hnq) h)
Exercises
Prove the following identities, replacing the "sorry" placeholders with actual proofs.
variable (p q r : Prop)

-- commutativity of ∧ and ∨
example : p ∧ q ↔ q ∧ p := sorry
example : p ∨ q ↔ q ∨ p := sorry

-- associativity of ∧ and ∨
example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry
example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry

-- distributivity
example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry
example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry

-- other properties
example : (p → (q → r)) ↔ (p ∧ q → r) := sorry
example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry
example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry
example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry
example : ¬(p ∧ ¬p) := sorry
example : p ∧ ¬q → ¬(p → q) := sorry
example : ¬p → (p → q) := sorry
example : (¬p ∨ q) → (p → q) := sorry
example : p ∨ False ↔ p := sorry
example : p ∧ False ↔ False := sorry
example : (p → q) → (¬q → ¬p) := sorry
Prove the following identities, replacing the "sorry" placeholders
with actual proofs. These require classical reasoning.
open Classical

variable (p q r : Prop)

example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry
example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry
example : ¬(p → q) → p ∧ ¬q := sorry
example : (p → q) → (¬p ∨ q) := sorry
example : (¬q → ¬p) → (p → q) := sorry
example : p ∨ ¬p := sorry
example : (((p → q) → p) → p) := sorry
Prove
¬(p ↔ ¬p)
without using classical logic.
2025-05-31 17:56:01,546 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.'}], 'model': 'o3-mini'}}
2025-05-31 17:56:01,547 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-05-31 17:56:01,547 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-31 17:56:01,547 - DEBUG - send_request_headers.complete
2025-05-31 17:56:01,547 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-31 17:56:01,548 - DEBUG - send_request_body.complete
2025-05-31 17:56:01,548 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-31 17:56:06,958 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 31 May 2025 17:56:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5174'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5181'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199523'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'142ms'), (b'x-request-id', b'req_46b890ab88db1f9a78494537fd66040c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94885875d8b63cac-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-05-31 17:56:06,959 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-31 17:56:06,959 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-31 17:56:06,959 - DEBUG - receive_response_body.complete
2025-05-31 17:56:06,959 - DEBUG - response_closed.started
2025-05-31 17:56:06,959 - DEBUG - response_closed.complete
2025-05-31 17:56:06,959 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 31 May 2025 17:56:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5174', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5181', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199523', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '142ms', 'x-request-id': 'req_46b890ab88db1f9a78494537fd66040c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94885875d8b63cac-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-05-31 17:56:06,959 - DEBUG - request_id: req_46b890ab88db1f9a78494537fd66040c
2025-05-31 17:56:06,960 - INFO - Attempt 1/3
2025-05-31 17:56:06,960 - INFO - Current plan: {
  "plan_summary": "The task is to create a Lean 4 function that checks whether two integers have opposite signs, excluding the case when either integer is zero. The plan involves first checking if either integer is zero, and then confirming that one is positive and the other is negative using basic comparison operations.",
  "steps": [
    "Define the function with two integer parameters.",
    "Check if either parameter is equal to zero. If so, return false.",
    "Verify if one integer is greater than zero (positive) and the other is less than zero (negative). This condition should be done using a logical OR for the two possible combinations.",
    "Return true if the condition for opposite signs is met; otherwise, return false."
  ],
  "code_keywords": [
    "Lean 4",
    "if-then-else",
    "zero check",
    "positivity check",
    "integer comparison"
  ],
  "proof_keywords": [
    "case analysis",
    "exhaustive conditions",
    "contrapositive reasoning"
  ],
  "assumptions": [
    "Integers are checked using standard relational operators.",
    "Zero is treated as neither positive nor negative.",
    "Logical operators (and/or) behave as expected in Lean 4."
  ],
  "retry_guidance": "If issues arise, verify that the zero check is correctly implemented before proceeding to the sign checks. Also, ensure that the conditional branches cover all possible cases for input values."
}
2025-05-31 17:56:06,960 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "The task is to create a Lean 4 function that checks whether two integers have opposite signs, excluding the case when either integer is zero. The plan involves first checking if either integer is zero, and then confirming that one is positive and the other is negative using basic comparison operations.",\n  "steps": [\n    "Define the function with two integer parameters.",\n    "Check if either parameter is equal to zero. If so, return false.",\n    "Verify if one integer is greater than zero (positive) and the other is less than zero (negative). This condition should be done using a logical OR for the two possible combinations.",\n    "Return true if the condition for opposite signs is met; otherwise, return false."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "if-then-else",\n    "zero check",\n    "positivity check",\n    "integer comparison"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "exhaustive conditions",\n    "contrapositive reasoning"\n  ],\n  "assumptions": [\n    "Integers are checked using standard relational operators.",\n    "Zero is treated as neither positive nor negative.",\n    "Logical operators (and/or) behave as expected in Lean 4."\n  ],\n  "retry_guidance": "If issues arise, verify that the zero check is correctly implemented before proceeding to the sign checks. Also, ensure that the conditional branches cover all possible cases for input values."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\ntheorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n  Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n  Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n    Exists.intro (w1 + w2)\n      (calc a + b\n        _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n        _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\nUsing the various gadgets described in this chapter --- the match\nstatement, anonymous constructors, and the\nrewrite\ntactic, we can\nwrite this proof concisely as follows:\ndef is_even (a : Nat) := ∃ b, a = 2 * b\ntheorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n  match h1, h2 with\n  | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\nJust as the constructive "or" is stronger than the classical "or," so,\ntoo, is the constructive "exists" stronger than the classical\n"exists". For example, the following implication requires classical\nreasoning because, from a constructive standpoint, knowing that it is\nnot the case that every\nx\nsatisfies\n¬ p\nis not the same as\nhaving a particular\nx\nthat satisfies\np\n.\nopen Classical\nvariable (p : α → Prop)\n\nexample (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n  byContradiction\n    (fun h1 : ¬ ∃ x, p x =>\n      have h2 : ∀ x, ¬ p x :=\n        fun x =>\n        fun h3 : p x =>\n        have h4 : ∃ x, p x := ⟨x, h3⟩\n        show False from h1 h4\n      show False from h h2)\nWhat follows are some common identities involving the existential\nquantifier. In the exercises below, we encourage you to prove as many\nas you can. We also leave it to you to determine which are\nnonconstructive, and hence require some form of classical reasoning.\nopen Classical\n\nvariable (α : Type) (p q : α → Prop)\nvariable (r : Prop)\n\nexample : (∃ x : α, r) → r := sorry\nexample (a : α) : r → (∃ x : α, r) := sorry\nexample : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\nexample : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n\nexample : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\nexample : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\nexample : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\nexample : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n\nexample : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\nexample (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\nexample (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\nNotice that the second example and the last two examples require the\nassumption that there is at least one element\na\nof type\nα\n.\nHere are solutions to two of the more difficult ones:\nopen Classical\n\nvariable (α : Type) (p q : α → Prop)\nvariable (a : α)\nvariable (r : Prop)\n\nexample : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n  Iff.intro\n    (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n      Or.elim h1\n        (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n        (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n    (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n      Or.elim h\n        (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n        (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n\nexample : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n  Iff.intro\n    (fun ⟨b, (hb : p b → r)⟩ =>\n     fun h2 : ∀ x, p x =>\n     show r from hb (h2 b))\n    (fun h1 : (∀ x, p x) → r =>\n     show ∃ x, p x → r from\n       byCases\n         (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n         (fun hnap : ¬ ∀ x, p x =>\n          byContradiction\n            (fun hnex : ¬ ∃ x, p x → r =>\n              have hap : ∀ x, p x :=\n                fun x =>\n                byContradiction\n                  (fun hnp : ¬ p x =>\n                    have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                    show False from hnex hex)\n              show False from hnap hap)))\nMore on the Proof Language\nWe have seen that keywords like\nfun\n,\nhave\n, and\nshow\nmake\nit possible to write formal proof terms that mirror the structure of\ninformal mathematical proofs. In this section, we discuss some\nadditional features of the proof language that are often convenient.\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last\nexpression introduced in this way using the keyword\nthis\n:\nvariable (f : Nat → Nat)\nvariable (h : ∀ x : Nat, f x ≤ f (x + 1))\n\nexample : f 0 ≤ f 3 :=\n  have : f 0 ≤ f 1 := h 0\n  have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n  show f 0 ≤ f 3 from Nat.le_trans this (h 2)\nOften proofs move from one fact to the next, so this can be effective\nin eliminating the clutter of lots of labels.\nWhen the goal can be inferred, we can also ask Lean instead to fill in\nthe proof by writing\nby assumption\n:\nvariable (f : Nat → Nat)\nvariable (h : ∀ x : Nat, f x ≤ f (x + 1))\nexample : f 0 ≤ f 3 :=\n  have : f 0 ≤ f 1 := h 0\n  have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n  show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\nThis tells Lean to use the\nassumption\ntactic, which, in turn,\nproves the goal by finding a suitable hypothesis in the local\ncontext. We will learn more about the\nassumption\ntactic in the\nnext chapter.\nWe can also ask Lean to fill in the proof by writing\n‹p›\n, where\np\nis the proposition whose proof we want Lean to find in the\ncontext.  You can type these corner quotes using\n\\f<\nand\n\\f>\n,\nrespectively. The letter "f" is for "French," since the unicode\nsymbols can also be used as French quotation marks. In fact, the\nnotation is defined in Lean as follows:\nnotation "‹" p "›" => show p by assumption\nThis approach is more robust than using\nby assumption\n, because the\ntype of the assumption that needs to be inferred is given\nexplicitly. It also makes proofs more readable. Here is a more\nelaborate example:\nvariable (f : Nat → Nat)\nvariable (h : ∀ x : Nat, f x ≤ f (x + 1))\n\nexample : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n  fun _ : f 0 ≥ f 1 =>\n  fun _ : f 1 ≥ f 2 =>\n  have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n  have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n  show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\nKeep in mind that you can use the French quotation marks in this way\nto refer to\nanything\nin the context, not just things that were\nintroduced anonymously. Its use is also not limited to propositions,\nthough using it for data is somewhat odd:\nexample (n : Nat) : Nat := ‹Nat›\nLater, we show how you can extend the proof language using the Lean macro system.\nExercises\nProve these equivalences:\nvariable (α : Type) (p q : α → Prop)\n\nexample : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\nexample : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\nexample : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\nYou should also try to understand why the reverse implication is not derivable in the last example.\nIt is often possible to bring a component of a formula outside a\nuniversal quantifier, when it does not depend on the quantified\nvariable. Try proving these (one direction of the second of these\nrequires classical logic):\nvariable (α : Type) (p q : α → Prop)\nvariable (r : Prop)\n\nexample : α → ((∀ x : α, r) ↔ r) := sorry\nexample : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\nexample : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\nConsider the "barber paradox," that is, the claim that in a certain\ntown there is a (male) barber that shaves all and only the men who\ndo not shave themselves. Prove that this is a contradiction:\nvariable (men : Type) (barber : men)\nvariable (shaves : men → men → Prop)\n\nexample (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\nRemember that, without any parameters, an expression of type\nProp\nis just an assertion. Fill in the definitions of\nprime\nand\nFermat_prime\nbelow, and construct each of the given\nassertions. For example, you can say that there are infinitely many\nprimes by asserting that for every natural number\nn\n, there is a\nprime number greater than\nn\n. Goldbach\'s weak conjecture states\nthat every odd number greater than 5 is the sum of three\nprimes. Look up the definition of a Fermat prime or any of the\nother statements, if necessary.\ndef even (n : Nat) : Prop := sorry\n\ndef prime (n : Nat) : Prop := sorry\n\ndef infinitely_many_primes : Prop := sorry\n\ndef Fermat_prime (n : Nat) : Prop := sorry\n\ndef infinitely_many_Fermat_primes : Prop := sorry\n\ndef goldbach_conjecture : Prop := sorry\n\ndef Goldbach\'s_weak_conjecture : Prop := sorry\n\ndef Fermat\'s_last_theorem : Prop := sorry\nProve as many of the identities listed in the Existential\nQuantifier section as you can.\nQuantifiers and Equality - Theorem Proving in Lean 4\nTheorem Proving in Lean 4\n1.\nIntroduction\n2.\nDependent Type Theory\n3.\nPropositions and Proofs\n4.\nQuantifiers and Equality\n5.\nTactics\n6.\nInteracting with Lean\n7.\nInductive Types\n8.\nInduction and Recursion\n9.\nStructures and Records\n10.\nType Classes\n11.\nThe Conversion Tactic Mode\n12.\nAxioms and Computation\nLight (default)\nRust\nCoal\nNavy\nAyu\nTheorem Proving in Lean 4\nQuantifiers and Equality\nThe last chapter introduced you to methods that construct proofs of\nstatements involving the propositional connectives. In this chapter,\nwe extend the repertoire of logical constructions to include the\nuniversal and existential quantifiers, and the equality relation.\nThe Universal Quantifier\nNotice that if\nα\nis any type, we can represent a unary predicate\np\non\nα\nas an object of type\nα → Prop\n. In that case, given\nx : α\n,\np x\ndenotes the assertion that\np\nholds of\nx\n. Similarly, an object\nr : α → α → Prop\ndenotes a binary\nrelation on\nα\n: given\nx y : α\n,\nr x y\ndenotes the assertion\nthat\nx\nis related to\ny\n.\nThe universal quantifier,\n∀ x : α, p x\nis supposed to denote the\nassertion that "for every\nx : α\n,\np x\n" holds. As with the\npropositional connectives, in systems of natural deduction, "forall"\nis governed by an introduction and elimination rule. Informally, the\nintroduction rule states:\nGiven a proof of\np x\n, in a context where\nx : α\nis arbitrary, we obtain a proof\n∀ x : α, p x\n.\nThe elimination rule states:\nGiven a proof\n∀ x : α, p x\nand any term\nt : α\n, we obtain a proof of\np t\n.\nAs was the case for implication, the propositions-as-types\ninterpretation now comes into play. Remember the introduction and\nelimination rules for dependent arrow types:\nGiven a term\nt\nof type\nβ x\n, in a context where\nx : α\nis arbitrary, we have\n(fun x : α => t) : (x : α) → β x\n.\nThe elimination rule states:\nGiven a term\ns : (x : α) → β x\nand any term\nt : α\n, we have\ns t : β t\n.\nIn the case where\np x\nhas type\nProp\n, if we replace\n(x : α) → β x\nwith\n∀ x : α, p x\n, we can read these as the correct rules\nfor building proofs involving the universal quantifier.\nThe Calculus of Constructions therefore identifies dependent arrow\ntypes with forall-expressions in this way. If\np\nis any expression,\n∀ x : α, p\nis nothing more than alternative notation for\n(x : α) → p\n, with the idea that the former is more natural than the latter\nin cases where\np\nis a proposition. Typically, the expression\np\nwill depend on\nx : α\n. Recall that, in the case of ordinary\nfunction spaces, we could interpret\nα → β\nas the special case of\n(x : α) → β\nin which\nβ\ndoes not depend on\nx\n. Similarly, we\ncan think of an implication\np → q\nbetween propositions as the\nspecial case of\n∀ x : p, q\nin which the expression\nq\ndoes not\ndepend on\nx\n.\nHere is an example of how the propositions-as-types correspondence gets put into practice.\nexample (α : Type) (p q : α → Prop) : (∀ x : α, p x ∧ q x) → ∀ y : α, p y :=\n  fun h : ∀ x : α, p x ∧ q x =>\n  fun y : α =>\n  show p y from (h y).left\nAs a notational convention, we give the universal quantifier the\nwidest scope possible, so parentheses are needed to limit the\nquantifier over\nx\nto the hypothesis in the example above. The\ncanonical way to prove\n∀ y : α, p y\nis to take an arbitrary\ny\n,\nand prove\np y\n. This is the introduction rule. Now, given that\nh\nhas type\n∀ x : α, p x ∧ q x\n, the expression\nh y\nhas type\np y ∧ q y\n. This is the elimination rule. Taking the left conjunct\ngives the desired conclusion,\np y\n.\nRemember that expressions which differ up to renaming of bound\nvariables are considered to be equivalent. So, for example, we could\nhave used the same variable,\nx\n, in both the hypothesis and\nconclusion, and instantiated it by a different variable,\nz\n, in the\nproof:\nexample (α : Type) (p q : α → Prop) : (∀ x : α, p x ∧ q x) → ∀ x : α, p x :=\n  fun h : ∀ x : α, p x ∧ q x =>\n  fun z : α =>\n  show p z from And.left (h z)\nAs another example, here is how we can express the fact that a relation,\nr\n, is transitive:\nvariable (α : Type) (r : α → α → Prop)\nvariable (trans_r : ∀ x y z, r x y → r y z → r x z)\n\nvariable (a b c : α)\nvariable (hab : r a b) (hbc : r b c)\n\n#check trans_r    -- ∀ (x y z : α), r x y → r y z → r x z\n#check trans_r a b c -- r a b → r b c → r a c\n#check trans_r a b c hab -- r b c → r a c\n#check trans_r a b c hab hbc -- r a c\nThink about what is going on here. When we instantiate\ntrans_r\nat\nthe values\na b c\n, we end up with a proof of\nr a b → r b c → r a c\n.\nApplying this to the "hypothesis"\nhab : r a b\n, we get a proof\nof the implication\nr b c → r a c\n. Finally, applying it to the\nhypothesis\nhbc\nyields a proof of the conclusion\nr a c\n.\nIn situations like this, it can be tedious to supply the arguments\na b c\n, when they can be inferred from\nhab hbc\n. For that reason, it\nis common to make these arguments implicit:\nvariable (α : Type) (r : α → α → Prop)\nvariable (trans_r : ∀ {x y z}, r x y → r y z → r x z)\n\nvariable (a b c : α)\nvariable (hab : r a b) (hbc : r b c)\n\n#check trans_r\n#check trans_r hab\n#check trans_r hab hbc\nThe advantage is that we can simply write\ntrans_r hab hbc\nas a\nproof of\nr a c\n. A disadvantage is that Lean does not have enough\ninformation to infer the types of the arguments in the expressions\ntrans_r\nand\ntrans_r hab\n. The output of the first\n#check\ncommand is\nr ?m.1 ?m.2 → r ?m.2 ?m.3 → r ?m.1 ?m.3\n, indicating\nthat the implicit arguments are unspecified in this case.\nHere is an example of how we can carry out elementary reasoning with an equivalence relation:\nvariable (α : Type) (r : α → α → Prop)\n\nvariable (refl_r : ∀ x, r x x)\nvariable (symm_r : ∀ {x y}, r x y → r y x)\nvariable (trans_r : ∀ {x y z}, r x y → r y z → r x z)\n\nexample (a b c d : α) (hab : r a b) (hcb : r c b) (hcd : r c d) : r a d :=\n  trans_r (trans_r hab (symm_r hcb)) hcd\nTo get used to using universal quantifiers, you should try some of the\nexercises at the end of this section.\nIt is the typing rule for dependent arrow types, and the universal\nquantifier in particular, that distinguishes\nProp\nfrom other\ntypes.  Suppose we have\nα : Sort i\nand\nβ : Sort j\n, where the\nexpression\nβ\nmay depend on a variable\nx : α\n. Then\n(x : α) → β\nis an element of\nSort (imax i j)\n, where\nimax i j\nis the\nmaximum of\ni\nand\nj\nif\nj\nis not 0, and 0 otherwise.\nThe idea is as follows. If\nj\nis not\n0\n, then\n(x : α) → β\nis\nan element of\nSort (max i j)\n. In other words, the type of\ndependent functions from\nα\nto\nβ\n"lives" in the universe whose\nindex is the maximum of\ni\nand\nj\n. Suppose, however, that\nβ\nis of\nSort 0\n, that is, an element of\nProp\n. In that case,\n(x : α) → β\nis an element of\nSort 0\nas well, no matter which\ntype universe\nα\nlives in. In other words, if\nβ\nis a\nproposition depending on\nα\n, then\n∀ x : α, β\nis again a\nproposition. This reflects the interpretation of\nProp\nas the type\nof propositions rather than data, and it is what makes\nProp\nimpredicative\n.\nThe term "predicative" stems from foundational developments around the\nturn of the twentieth century, when logicians such as Poincaré and\nRussell blamed set-theoretic paradoxes on the "vicious circles" that\narise when we define a property by quantifying over a collection that\nincludes the very property being defined. Notice that if\nα\nis any\ntype, we can form the type\nα → Prop\nof all predicates on\nα\n(the "power type of\nα\n"). The impredicativity of\nProp\nmeans that we\ncan form propositions that quantify over\nα → Prop\n. In particular,\nwe can define predicates on\nα\nby quantifying over all predicates\non\nα\n, which is exactly the type of circularity that was once\nconsidered problematic.\nEquality\nLet us now turn to one of the most fundamental relations defined in\nLean\'s library, namely, the equality relation. In\nChapter Inductive Types\n,\nwe will explain\nhow\nequality is defined from the primitives of Lean\'s logical framework.\nIn the meanwhile, here we explain how to use it.\nOf course, a fundamental property of equality is that it is an equivalence relation:\n#check Eq.refl    -- Eq.refl.{u_1} {α : Sort u_1} (a : α) : a = a\n#check Eq.symm    -- Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a\n#check Eq.trans   -- Eq.trans.{u} {α : Sort u} {a b c : α} (h₁ : a = b) (h₂ : b = c) : a = c\nWe can make the output easier to read by telling Lean not to insert\nthe implicit arguments (which are displayed here as metavariables).\nuniverse u\n\n#check @Eq.refl.{u}   -- @Eq.refl : ∀ {α : Sort u} (a : α), a = a\n#check @Eq.symm.{u}   -- @Eq.symm : ∀ {α : Sort u} {a b : α}, a = b → b = a\n#check @Eq.trans.{u}  -- @Eq.trans : ∀ {α : Sort u} {a b c : α}, a = b → b = c → a = c\nThe inscription\n.{u}\ntells Lean to instantiate the constants at the universe\nu\n.\nThus, for example, we can specialize the example from the previous section to the equality relation:\nvariable (α : Type) (a b c d : α)\nvariable (hab : a = b) (hcb : c = b) (hcd : c = d)\n\nexample : a = d :=\n  Eq.trans (Eq.trans hab (Eq.symm hcb)) hcd\nWe can also use the projection notation:\nvariable (α : Type) (a b c d : α)\nvariable (hab : a = b) (hcb : c = b) (hcd : c = d)\nexample : a = d := (hab.trans hcb.symm).trans hcd\nReflexivity is more powerful than it looks. Recall that terms in the\nCalculus of Constructions have a computational interpretation, and\nthat the logical framework treats terms with a common reduct as the\nsame. As a result, some nontrivial identities can be proved by\nreflexivity:\nvariable (α β : Type)\n\nexample (f : α → β) (a : α) : (fun x => f x) a = f a := Eq.refl _\nexample (a : α) (b : β) : (a, b).1 = a := Eq.refl _\nexample : 2 + 3 = 5 := Eq.refl _\nThis feature of the framework is so important that the library defines a notation\nrfl\nfor\nEq.refl _\n:\nvariable (α β : Type)\nexample (f : α → β) (a : α) : (fun x => f x) a = f a := rfl\nexample (a : α) (b : β) : (a, b).1 = a := rfl\nexample : 2 + 3 = 5 := rfl\nEquality is much more than an equivalence relation, however. It has\nthe important property that every assertion respects the equivalence,\nin the sense that we can substitute equal expressions without changing\nthe truth value. That is, given\nh1 : a = b\nand\nh2 : p a\n, we\ncan construct a proof for\np b\nusing substitution:\nEq.subst h1 h2\n.\nexample (α : Type) (a b : α) (p : α → Prop)\n        (h1 : a = b) (h2 : p a) : p b :=\n  Eq.subst h1 h2\n\nexample (α : Type) (a b : α) (p : α → Prop)\n    (h1 : a = b) (h2 : p a) : p b :=\n  h1 ▸ h2\nThe triangle in the second presentation is a macro built on top of\nEq.subst\nand\nEq.symm\n, and you can enter it by typing\n\\t\n.\nThe rule\nEq.subst\nis used to define the following auxiliary rules,\nwhich carry out more explicit substitutions. They are designed to deal\nwith applicative terms, that is, terms of form\ns t\n. Specifically,\ncongrArg\ncan be used to replace the argument,\ncongrFun\ncan be\nused to replace the term that is being applied, and\ncongr\ncan be\nused to replace both at once.\nvariable (α : Type)\nvariable (a b : α)\nvariable (f g : α → Nat)\nvariable (h₁ : a = b)\nvariable (h₂ : f = g)\n\nexample : f a = f b := congrArg f h₁\nexample : f a = g a := congrFun h₂ a\nexample : f a = g b := congr h₂ h₁\nLean\'s library contains a large number of common identities, such as these:\nvariable (a b c : Nat)\n\nexample : a + 0 = a := Nat.add_zero a\nexample : 0 + a = a := Nat.zero_add a\nexample : a * 1 = a := Nat.mul_one a\nexample : 1 * a = a := Nat.one_mul a\nexample : a + b = b + a := Nat.add_comm a b\nexample : a + b + c = a + (b + c) := Nat.add_assoc a b c\nexample : a * b = b * a := Nat.mul_comm a b\nexample : a * b * c = a * (b * c) := Nat.mul_assoc a b c\nexample : a * (b + c) = a * b + a * c := Nat.mul_add a b c\nexample : a * (b + c) = a * b + a * c := Nat.left_distrib a b c\nexample : (a + b) * c = a * c + b * c := Nat.add_mul a b c\nexample : (a + b) * c = a * c + b * c := Nat.right_distrib a b c\nNote that\nNat.mul_add\nand\nNat.add_mul\nare alternative names\nfor\nNat.left_distrib\nand\nNat.right_distrib\n, respectively.  The\nproperties above are stated for the natural numbers (type\nNat\n).\nHere is an example of a calculation in the natural numbers that uses\nsubstitution combined with associativity and distributivity.\nexample (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n  have h1 : (x + y) * (x + y) = (x + y) * x + (x + y) * y :=\n    Nat.mul_add (x + y) x y\n  have h2 : (x + y) * (x + y) = x * x + y * x + (x * y + y * y) :=\n    (Nat.add_mul x y x) ▸ (Nat.add_mul x y y) ▸ h1\n  h2.trans (Nat.add_assoc (x * x + y * x) (x * y) (y * y)).symm\nNotice that the second implicit parameter to\nEq.subst\n, which\nprovides the context in which the substitution is to occur, has type\nα → Prop\n.  Inferring this predicate therefore requires an instance\nof\nhigher-order unification\n. In full generality, the problem of\ndetermining whether a higher-order unifier exists is undecidable, and\nLean can at best provide imperfect and approximate solutions to the\nproblem. As a result,\nEq.subst\ndoesn\'t always do what you want it\nto.  The macro\nh ▸ e\nuses more effective heuristics for computing\nthis implicit parameter, and often succeeds in situations where\napplying\nEq.subst\nfails.\nBecause equational reasoning is so common and important, Lean provides\na number of mechanisms to carry it out more effectively. The next\nsection offers syntax that allow you to write calculational proofs in\na more natural and perspicuous way. But, more importantly, equational\nreasoning is supported by a term rewriter, a simplifier, and other\nkinds of automation. The term rewriter and simplifier are described\nbriefly in the next section, and then in greater detail in the next\nchapter.\nCalculational Proofs\nA calculational proof is just a chain of intermediate results that are\nmeant to be composed by basic principles such as the transitivity of\nequality. In Lean, a calculational proof starts with the keyword\ncalc\n, and has the following syntax:\ncalc\n  <expr>_0  \'op_1\'  <expr>_1  \':=\'  <proof>_1\n  \'_\'       \'op_2\'  <expr>_2  \':=\'  <proof>_2\n  ...\n  \'_\'       \'op_n\'  <expr>_n  \':=\'  <proof>_n\nNote that the\ncalc\nrelations all have the same indentation. Each\n<proof>_i\nis a proof for\n<expr>_{i-1} op_i <expr>_i\n.\nWe can also use\n_\nin the first relation (right after\n<expr>_0\n)\nwhich is useful to align the sequence of relation/proof pairs:\ncalc <expr>_0 \n    \'_\' \'op_1\' <expr>_1 \':=\' <proof>_1\n    \'_\' \'op_2\' <expr>_2 \':=\' <proof>_2\n    ...\n    \'_\' \'op_n\' <expr>_n \':=\' <proof>_n\nHere is an example:\nvariable (a b c d e : Nat)\nvariable (h1 : a = b)\nvariable (h2 : b = c + 1)\nvariable (h3 : c = d)\nvariable (h4 : e = 1 + d)\n\ntheorem T : a = e :=\n  calc\n    a = b      := h1\n    _ = c + 1  := h2\n    _ = d + 1  := congrArg Nat.succ h3\n    _ = 1 + d  := Nat.add_comm d 1\n    _ = e      := Eq.symm h4\nThis style of writing proofs is most effective when it is used in\nconjunction with the\nsimp\nand\nrewrite\ntactics, which are\ndiscussed in greater detail in the next chapter. For example, using\nthe abbreviation\nrw\nfor rewrite, the proof above could be written\nas follows:\nvariable (a b c d e : Nat)\nvariable (h1 : a = b)\nvariable (h2 : b = c + 1)\nvariable (h3 : c = d)\nvariable (h4 : e = 1 + d)\ntheorem T : a = e :=\n  calc\n    a = b      := by rw [h1]\n    _ = c + 1  := by rw [h2]\n    _ = d + 1  := by rw [h3]\n    _ = 1 + d  := by rw [Nat.add_comm]\n    _ = e      := by rw [h4]\nEssentially, the\nrw\ntactic uses a given equality (which can be a\nhypothesis, a theorem name, or a complex term) to "rewrite" the\ngoal. If doing so reduces the goal to an identity\nt = t\n, the\ntactic applies reflexivity to prove it.\nRewrites can be applied sequentially, so that the proof above can be\nshortened to this:\nvariable (a b c d e : Nat)\nvariable (h1 : a = b)\nvariable (h2 : b = c + 1)\nvariable (h3 : c = d)\nvariable (h4 : e = 1 + d)\ntheorem T : a = e :=\n  calc\n    a = d + 1  := by rw [h1, h2, h3]\n    _ = 1 + d  := by rw [Nat.add_comm]\n    _ = e      := by rw [h4]\nOr even this:\nvariable (a b c d e : Nat)\nvariable (h1 : a = b)\nvariable (h2 : b = c + 1)\nvariable (h3 : c = d)\nvariable (h4 : e = 1 + d)\ntheorem T : a = e :=\n  by rw [h1, h2, h3, Nat.add_comm, h4]\nThe\nsimp\ntactic, instead, rewrites the goal by applying the given\nidentities repeatedly, in any order, anywhere they are applicable in a\nterm. It also uses other rules that have been previously declared to\nthe system, and applies commutativity wisely to avoid looping. As a\nresult, we can also prove the theorem as follows:\nvariable (a b c d e : Nat)\nvariable (h1 : a = b)\nvariable (h2 : b = c + 1)\nvariable (h3 : c = d)\nvariable (h4 : e = 1 + d)\ntheorem T : a = e :=\n  by simp [h1, h2, h3, Nat.add_comm, h4]\nWe will discuss variations of\nrw\nand\nsimp\nin the next chapter.\nThe\ncalc\ncommand can be configured for any relation that supports\nsome form of transitivity. It can even combine different relations.\nexample (a b c d : Nat) (h1 : a = b) (h2 : b ≤ c) (h3 : c + 1 < d) : a < d :=\n  calc\n    a = b     := h1\n    _ < b + 1 := Nat.lt_succ_self b\n    _ ≤ c + 1 := Nat.succ_le_succ h2\n    _ < d     := h3\nYou can "teach"\ncalc\nnew transitivity theorems by adding new instances\nof the\nTrans\ntype class. Type classes are introduced later, but the following\nsmall example demonstrates how to extend the\ncalc\nnotation using new\nTrans\ninstances.\ndef divides (x y : Nat) : Prop :=\n  ∃ k, k*x = y\n\ndef divides_trans (h₁ : divides x y) (h₂ : divides y z) : divides x z :=\n  let ⟨k₁, d₁⟩ := h₁\n  let ⟨k₂, d₂⟩ := h₂\n  ⟨k₁ * k₂, by rw [Nat.mul_comm k₁ k₂, Nat.mul_assoc, d₁, d₂]⟩\n\ndef divides_mul (x : Nat) (k : Nat) : divides x (k*x) :=\n  ⟨k, rfl⟩\n\ninstance : Trans divides divides divides where\n  trans := divides_trans\n\nexample (h₁ : divides x y) (h₂ : y = z) : divides x (2*z) :=\n  calc\n    divides x y     := h₁\n    _ = z           := h₂\n    divides _ (2*z) := divides_mul ..\n\ninfix:50 " ∣ " => divides\n\nexample (h₁ : divides x y) (h₂ : y = z) : divides x (2*z) :=\n  calc\n    x ∣ y   := h₁\n    _ = z   := h₂\n    _ ∣ 2*z := divides_mul ..\nThe example above also makes it clear that you can use\ncalc\neven if you\ndo not have an infix notation for your relation. Finally we remark that\nthe vertical bar\n∣\nin the example above is the unicode one. We use\nunicode to make sure we do not overload the ASCII\n|\nused in the\nmatch .. with\nexpression.\nWith\ncalc\n, we can write the proof in the last section in a more\nnatural and perspicuous way.\nexample (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n  calc\n    (x + y) * (x + y) = (x + y) * x + (x + y) * y  := by rw [Nat.mul_add]\n    _ = x * x + y * x + (x + y) * y                := by rw [Nat.add_mul]\n    _ = x * x + y * x + (x * y + y * y)            := by rw [Nat.add_mul]\n    _ = x * x + y * x + x * y + y * y              := by rw [←Nat.add_assoc]\nThe alternative\ncalc\nnotation is worth considering here. When the\nfirst expression is taking this much space, using\n_\nin the first\nrelation naturally aligns all relations:\nexample (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n  calc (x + y) * (x + y)\n    _ = (x + y) * x + (x + y) * y       := by rw [Nat.mul_add]\n    _ = x * x + y * x + (x + y) * y     := by rw [Nat.add_mul]\n    _ = x * x + y * x + (x * y + y * y) := by rw [Nat.add_mul]\n    _ = x * x + y * x + x * y + y * y   := by rw [←Nat.add_assoc]\nHere the left arrow before\nNat.add_assoc\ntells rewrite to use the\nidentity in the opposite direction. (You can enter it with\n\\l\nor\nuse the ascii equivalent,\n<-\n.) If brevity is what we are after,\nboth\nrw\nand\nsimp\ncan do the job on their own:\nexample (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n  by rw [Nat.mul_add, Nat.add_mul, Nat.add_mul, ←Nat.add_assoc]\n\nexample (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=\n  by simp [Nat.mul_add, Nat.add_mul, Nat.add_assoc]\nThe Existential Quantifier\nFinally, consider the existential quantifier, which can be written as\neither\nexists x : α, p x\nor\n∃ x : α, p x\n.  Both versions are\nactually notationally convenient abbreviations for a more long-winded\nexpression,\nExists (fun x : α => p x)\n, defined in Lean\'s library.\nAs you should by now expect, the library includes both an introduction\nrule and an elimination rule. The introduction rule is\nstraightforward: to prove\n∃ x : α, p x\n, it suffices to provide a\nsuitable term\nt\nand a proof of\np t\n. Here are some examples:\nexample : ∃ x : Nat, x > 0 :=\n  have h : 1 > 0 := Nat.zero_lt_succ 0\n  Exists.intro 1 h\n\nexample (x : Nat) (h : x > 0) : ∃ y, y < x :=\n  Exists.intro 0 h\n\nexample (x y z : Nat) (hxy : x < y) (hyz : y < z) : ∃ w, x < w ∧ w < z :=\n  Exists.intro y (And.intro hxy hyz)\n\n#check @Exists.intro -- ∀ {α : Sort u_1} {p : α → Prop} (w : α), p w → Exists p\nWe can use the anonymous constructor notation\n⟨t, h⟩\nfor\nExists.intro t h\n, when the type is clear from the context.\nexample : ∃ x : Nat, x > 0 :=\n  have h : 1 > 0 := Nat.zero_lt_succ 0\n  ⟨1, h⟩\n\nexample (x : Nat) (h : x > 0) : ∃ y, y < x :=\n  ⟨0, h⟩\n\nexample (x y z : Nat) (hxy : x < y) (hyz : y < z) : ∃ w, x < w ∧ w < z :=\n  ⟨y, hxy, hyz⟩\nNote that\nExists.intro\nhas implicit arguments: Lean has to infer\nthe predicate\np : α → Prop\nin the conclusion\n∃ x, p x\n.  This\nis not a trivial affair. For example, if we have\nhg : g 0 0 = 0\nand write\nExists.intro 0 hg\n, there are many possible values\nfor the predicate\np\n, corresponding to the theorems\n∃ x, g x x = x\n,\n∃ x, g x x = 0\n,\n∃ x, g x 0 = x\n, etc. Lean uses the\ncontext to infer which one is appropriate. This is illustrated in the\nfollowing example, in which we set the option\npp.explicit\nto true\nto ask Lean\'s pretty-printer to show the implicit arguments.\nvariable (g : Nat → Nat → Nat)\nvariable (hg : g 0 0 = 0)\n\ntheorem gex1 : ∃ x, g x x = x := ⟨0, hg⟩\ntheorem gex2 : ∃ x, g x 0 = x := ⟨0, hg⟩\ntheorem gex3 : ∃ x, g 0 0 = x := ⟨0, hg⟩\ntheorem gex4 : ∃ x, g x x = 0 := ⟨0, hg⟩\n\nset_option pp.explicit true  -- display implicit arguments\n#print gex1\n#print gex2\n#print gex3\n#print gex4\nWe can view\nExists.intro\nas an information-hiding operation, since\nit hides the witness to the body of the assertion. The existential\nelimination rule,\nExists.elim\n, performs the opposite operation. It\nallows us to prove a proposition\nq\nfrom\n∃ x : α, p x\n, by\nshowing that\nq\nfollows from\np w\nfor an arbitrary value\nw\n. Roughly speaking, since we know there is an\nx\nsatisfying\np x\n, we can give it a name, say,\nw\n. If\nq\ndoes not mention\nw\n, then showing that\nq\nfollows from\np w\nis tantamount to\nshowing that\nq\nfollows from the existence of any such\nx\n. Here\nis an example:\nvariable (α : Type) (p q : α → Prop)\n\nexample (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n  Exists.elim h\n    (fun w =>\n     fun hw : p w ∧ q w =>\n     show ∃ x, q x ∧ p x from ⟨w, hw.right, hw.left⟩)\nIt may be helpful to compare the exists-elimination rule to the\nor-elimination rule: the assertion\n∃ x : α, p x\ncan be thought of\nas a big disjunction of the propositions\np a\n, as\na\nranges over\nall the elements of\nα\n. Note that the anonymous constructor\nnotation\n⟨w, hw.right, hw.left⟩\nabbreviates a nested constructor\napplication; we could equally well have written\n⟨w, ⟨hw.right, hw.left⟩⟩\n.\nNotice that an existential proposition is very similar to a sigma\ntype, as described in dependent types section.  The difference is that\ngiven\na : α\nand\nh : p a\n, the term\nExists.intro a h\nhas\ntype\n(∃ x : α, p x) : Prop\nand\nSigma.mk a h\nhas type\n(Σ x : α, p x) : Type\n. The similarity between\n∃\nand\nΣ\nis another\ninstance of the Curry-Howard isomorphism.\nLean provides a more convenient way to eliminate from an existential\nquantifier with the\nmatch\nexpression:\nvariable (α : Type) (p q : α → Prop)\n\nexample (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n  match h with\n  | ⟨w, hw⟩ => ⟨w, hw.right, hw.left⟩\nThe\nmatch\nexpression is part of Lean\'s function definition system,\nwhich provides convenient and expressive ways of defining complex\nfunctions.  Once again, it is the Curry-Howard isomorphism that allows\nus to co-opt this mechanism for writing proofs as well.  The\nmatch\nstatement "destructs" the existential assertion into the components\nw\nand\nhw\n, which can then be used in the body of the statement\nto prove the proposition. We can annotate the types used in the match\nfor greater clarity:\nvariable (α : Type) (p q : α → Prop)\nexample (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n  match h with\n  | ⟨(w : α), (hw : p w ∧ q w)⟩ => ⟨w, hw.right, hw.left⟩\nWe can even use the match statement to decompose the conjunction at the same time:\nvariable (α : Type) (p q : α → Prop)\nexample (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n  match h with\n  | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\nLean also provides a pattern-matching\nlet\nexpression:\nvariable (α : Type) (p q : α → Prop)\nexample (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n  let ⟨w, hpw, hqw⟩ := h\n  ⟨w, hqw, hpw⟩\nThis is essentially just alternative notation for the\nmatch\nconstruct above. Lean will even allow us to use an implicit\nmatch\nin the\nfun\nexpression:\nvariable (α : Type) (p q : α → Prop)\nexample : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n  fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\nWe will see in\nChapter Induction and Recursion\nthat all these variations are\ninstances of a more general pattern-matching construct.\nIn the following example, we define\nis_even a\nas\n∃ b, a = 2 * b\n,\nand then we show that the sum of two even numbers is an even number.\ndef is_even (a : Nat) := ∃ b, a = 2 * b\n\n\n\nincrementally. Start writing the proof from the top down, using\nsorry\nto fill in subproofs. Make sure Lean accepts the term with\nall the\nsorry\n\'s; if not, there are errors that you need to\ncorrect. Then go back and replace each\nsorry\nwith an actual proof,\nuntil no more remain.\nHere is another useful trick. Instead of using\nsorry\n, you can use\nan underscore\n_\nas a placeholder. Recall this tells Lean that\nthe argument is implicit, and should be filled in automatically. If\nLean tries to do so and fails, it returns with an error message "don\'t\nknow how to synthesize placeholder," followed by the type of\nthe term it is expecting, and all the objects and hypotheses available\nin the context. In other words, for each unresolved placeholder, Lean\nreports the subgoal that needs to be filled at that point. You can\nthen construct a proof by incrementally filling in these placeholders.\nFor reference, here are two sample proofs of validities taken from the\nlist above.\nopen Classical\n\n-- distributivity\nexample (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=\n  Iff.intro\n    (fun h : p ∧ (q ∨ r) =>\n      have hp : p := h.left\n      Or.elim (h.right)\n        (fun hq : q =>\n          show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)\n        (fun hr : r =>\n          show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))\n    (fun h : (p ∧ q) ∨ (p ∧ r) =>\n      Or.elim h\n        (fun hpq : p ∧ q =>\n          have hp : p := hpq.left\n          have hq : q := hpq.right\n          show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)\n        (fun hpr : p ∧ r =>\n          have hp : p := hpr.left\n          have hr : r := hpr.right\n          show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))\n\n-- an example that requires classical reasoning\nexample (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=\n  fun h : ¬(p ∧ ¬q) =>\n  fun hp : p =>\n  show q from\n    Or.elim (em q)\n      (fun hq : q => hq)\n      (fun hnq : ¬q => absurd (And.intro hp hnq) h)\nExercises\nProve the following identities, replacing the "sorry" placeholders with actual proofs.\nvariable (p q r : Prop)\n\n-- commutativity of ∧ and ∨\nexample : p ∧ q ↔ q ∧ p := sorry\nexample : p ∨ q ↔ q ∨ p := sorry\n\n-- associativity of ∧ and ∨\nexample : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry\nexample : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry\n\n-- distributivity\nexample : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry\nexample : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry\n\n-- other properties\nexample : (p → (q → r)) ↔ (p ∧ q → r) := sorry\nexample : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry\nexample : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry\nexample : ¬p ∨ ¬q → ¬(p ∧ q) := sorry\nexample : ¬(p ∧ ¬p) := sorry\nexample : p ∧ ¬q → ¬(p → q) := sorry\nexample : ¬p → (p → q) := sorry\nexample : (¬p ∨ q) → (p → q) := sorry\nexample : p ∨ False ↔ p := sorry\nexample : p ∧ False ↔ False := sorry\nexample : (p → q) → (¬q → ¬p) := sorry\nProve the following identities, replacing the "sorry" placeholders\nwith actual proofs. These require classical reasoning.\nopen Classical\n\nvariable (p q r : Prop)\n\nexample : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry\nexample : ¬(p ∧ q) → ¬p ∨ ¬q := sorry\nexample : ¬(p → q) → p ∧ ¬q := sorry\nexample : (p → q) → (¬p ∨ q) := sorry\nexample : (¬q → ¬p) → (p → q) := sorry\nexample : p ∨ ¬p := sorry\nexample : (((p → q) → p) → p) := sorry\nProve\n¬(p ↔ ¬p)\nwithout using classical logic.'}], 'model': 'gpt-4o'}}
2025-05-31 17:56:06,961 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-05-31 17:56:06,962 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-31 17:56:06,962 - DEBUG - send_request_headers.complete
2025-05-31 17:56:06,962 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-31 17:56:06,962 - DEBUG - send_request_body.complete
2025-05-31 17:56:06,962 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-31 17:56:12,737 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 31 May 2025 17:56:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5536'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5542'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'2335'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'55.329s'), (b'x-request-id', b'req_ab0ef3809fab6a27a936d4fdddcbed33'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94885897bc6e3cac-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-05-31 17:56:12,737 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-31 17:56:12,737 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-31 17:56:12,738 - DEBUG - receive_response_body.complete
2025-05-31 17:56:12,738 - DEBUG - response_closed.started
2025-05-31 17:56:12,738 - DEBUG - response_closed.complete
2025-05-31 17:56:12,738 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 31 May 2025 17:56:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5536', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5542', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '2335', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '55.329s', 'x-request-id': 'req_ab0ef3809fab6a27a936d4fdddcbed33', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94885897bc6e3cac-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-05-31 17:56:12,738 - DEBUG - request_id: req_ab0ef3809fab6a27a936d4fdddcbed33
2025-05-31 17:56:12,738 - INFO - Raw solution received: ```json
{
  "code": "if a = 0 ∨ b = 0 then false else (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0)",
  "proof": "by_cases hz : a = 0 ∨ b = 0\n  case inl => simp [hz]\n  case inr =>\n    simp [hz]\n    by_cases hpos : a > 0\n    case inl =>\n      have hneg : b < 0 := by\n        rw [not_or_distrib] at hz\n        exact lt_of_not_ge (hz.right ∘ le_of_lt)\n      simp [hpos, hneg]\n    case inr =>\n      have hneg : a < 0 := lt_of_not_ge (le_of_lt hpos)\n      have hpos_b : b > 0 := by\n        rw [not_or_distrib] at hz\n        exact lt_of_not_ge (hz.left ∘ le_of_lt)\n      simp [hneg, hpos_b]\n      trivial"
}
```
2025-05-31 17:56:12,738 - INFO - <class 'str'>
2025-05-31 17:56:12,738 - INFO - Generated solution: {'code': 'if a = 0 ∨ b = 0 then false else (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0)', 'proof': 'by_cases hz : a = 0 ∨ b = 0\n  case inl => simp [hz]\n  case inr =>\n    simp [hz]\n    by_cases hpos : a > 0\n    case inl =>\n      have hneg : b < 0 := by\n        rw [not_or_distrib] at hz\n        exact lt_of_not_ge (hz.right ∘ le_of_lt)\n      simp [hpos, hneg]\n    case inr =>\n      have hneg : a < 0 := lt_of_not_ge (le_of_lt hpos)\n      have hpos_b : b > 0 := by\n        rw [not_or_distrib] at hz\n        exact lt_of_not_ge (hz.left ∘ le_of_lt)\n      simp [hneg, hpos_b]\n      trivial'}
2025-05-31 17:56:12,739 - INFO - Lean execution result: Error: Lean executable not found or temp_project directory doesn't exist.
2025-05-31 17:56:12,740 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a = 0 ∨ b = 0 then false else (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0)\n\nGenerated Proof:\nby_cases hz : a = 0 ∨ b = 0\n  case inl => simp [hz]\n  case inr =>\n    simp [hz]\n    by_cases hpos : a > 0\n    case inl =>\n      have hneg : b < 0 := by\n        rw [not_or_distrib] at hz\n        exact lt_of_not_ge (hz.right ∘ le_of_lt)\n      simp [hpos, hneg]\n    case inr =>\n      have hneg : a < 0 := lt_of_not_ge (le_of_lt hpos)\n      have hpos_b : b > 0 := by\n        rw [not_or_distrib] at hz\n        exact lt_of_not_ge (hz.left ∘ le_of_lt)\n      simp [hneg, hpos_b]\n      trivial\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nError: Lean executable not found or temp_project directory doesn't exist."}], 'model': 'o3-mini'}}
2025-05-31 17:56:12,740 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-05-31 17:56:12,741 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-31 17:56:12,741 - DEBUG - send_request_headers.complete
2025-05-31 17:56:12,741 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-31 17:56:12,741 - DEBUG - send_request_body.complete
2025-05-31 17:56:12,741 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-31 17:56:14,740 - DEBUG - receive_response_headers.failed exception=KeyboardInterrupt()
2025-05-31 17:56:14,740 - DEBUG - response_closed.started
2025-05-31 17:56:14,741 - DEBUG - response_closed.complete
2025-05-31 17:56:14,879 - DEBUG - close.started
2025-05-31 17:56:14,879 - DEBUG - close.complete
2025-05-31 17:56:14,880 - DEBUG - close.started
2025-05-31 17:56:14,880 - DEBUG - close.complete
