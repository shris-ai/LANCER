2025-06-01 02:51:28,893 - INFO - Starting test of 11 tasks: task_id_0, task_id_58, task_id_77, task_id_127, task_id_227, task_id_404, task_id_431, task_id_433, task_id_435, task_id_441, task_id_447
2025-06-01 02:51:28,893 - INFO - 
==================================================
2025-06-01 02:51:28,893 - INFO - Processing task task_id_0...
2025-06-01 02:51:28,893 - INFO - Reading problem description and code template from tasks/task_id_0...
2025-06-01 02:51:28,893 - INFO - Problem description length: 310 characters
2025-06-01 02:51:28,893 - INFO - Reading unit tests from tasks/task_id_0...
2025-06-01 02:51:28,893 - INFO - Unit tests length: 69 characters
2025-06-01 02:51:28,893 - INFO - Running main workflow to generate solution...
2025-06-01 02:51:28,893 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.

-----Input-----
The input consists of one natural number:
x: An natural number.

-----Output-----
The output is a natural number which the value equals to x.
2025-06-01 02:51:28,894 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def ident (x : Nat) : Nat :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


def ident_spec (x : Nat) (result: Nat) : Prop :=
  -- << SPEC START >>
  result = x
  -- << SPEC END >>

theorem ident_spec_satisfied (x : Nat) :
  ident_spec x (ident x) := by
  -- << PROOF START >>
  unfold ident ident_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:51:28,925 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7f4e6733e8e0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:51:28,927 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:51:28,927 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:51:28,934 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f7d9d0>
2025-06-01 02:51:28,934 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4e6784f250> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:51:28,944 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f7d760>
2025-06-01 02:51:28,944 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:51:28,945 - DEBUG - send_request_headers.complete
2025-06-01 02:51:28,945 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:51:28,945 - DEBUG - send_request_body.complete
2025-06-01 02:51:28,945 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:51:30,126 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:51:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'75'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-b5646b449-cmbmz'), (b'x-envoy-upstream-service-time', b'78'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999922'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'4ms'), (b'x-request-id', b'req_a55a996b0de86b2bfdcfeffd543b859c'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3W4Dt7PN5QhJNFjmN5AgOnZNOY5VcsEMc7JzqhJaTcI-1748746290-1.0.1.1-.g7wqyuBMFelRJCSVxEUc8RpZCuczjTfh.xWC7UhLEdD63D.o68ie5CVaojIvQH2N7FRJ5MxnpnF3o6o93o6uXCS4a7nv3GEliTgr0_JMQ8; path=/; expires=Sun, 01-Jun-25 03:21:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Z8T5.ZcUHmZOtSXDbCv_4Iizd.k.2JwtDRbRQlwGdcc-1748746290148-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b68d21dad8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:51:30,127 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:51:30,127 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:51:30,128 - DEBUG - receive_response_body.complete
2025-06-01 02:51:30,128 - DEBUG - response_closed.started
2025-06-01 02:51:30,128 - DEBUG - response_closed.complete
2025-06-01 02:51:30,128 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:51:30 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '75'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-b5646b449-cmbmz'), ('x-envoy-upstream-service-time', '78'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999922'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '4ms'), ('x-request-id', 'req_a55a996b0de86b2bfdcfeffd543b859c'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=3W4Dt7PN5QhJNFjmN5AgOnZNOY5VcsEMc7JzqhJaTcI-1748746290-1.0.1.1-.g7wqyuBMFelRJCSVxEUc8RpZCuczjTfh.xWC7UhLEdD63D.o68ie5CVaojIvQH2N7FRJ5MxnpnF3o6o93o6uXCS4a7nv3GEliTgr0_JMQ8; path=/; expires=Sun, 01-Jun-25 03:21:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Z8T5.ZcUHmZOtSXDbCv_4Iizd.k.2JwtDRbRQlwGdcc-1748746290148-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b68d21dad8fcd-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:51:30,128 - DEBUG - request_id: req_a55a996b0de86b2bfdcfeffd543b859c
2025-06-01 02:51:30,135 - INFO - Retrieved context:  modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
 Lean failed to infer it. Named arguments also improve
the readability of your code by identifying what each argument represents.

    
    
    def sum (xs : List Nat) :=
      xs.foldl (init := 0) (·+·)
    
    #eval sum [1, 2, 3, 4]
    -- 10
    
    example {a b : Nat} {p : Nat → Nat → Nat → Prop} (h₁ : p a b b) (h₂ : b = a)
        : p a a b :=
      Eq.subst (motive := fun x => p a x b) h₂ h₁
    

In the following examples, we illustrate the interaction between named and
default arguments.

    
    
    def f (x : Nat) (y : Nat := 1) (w : Nat := 2) (z : Nat) :=
      x + y + w - z
    
    example (x z : Nat) : f (z := z) x = x + 1 + 2 - z := rfl
    
    example (x z : Nat) : f x (z := z) = x + 1 + 2 - z := rfl
    
    example (x y : Nat) : f x y = fun z => x + y + 2 - z := rfl
    
    example : f = (fun x z => x + 1 + 2 - z) := rfl
    
    example (x : Nat) : f x = fun z => x + 1 + 2 - z := rfl
    
    example (y : Nat) : f (y := 5) = fun x z => x + 5 + 2 - z := rfl
    
    def g {α} [Add α] (a : α) (b? : Option α := none) (c : α) : α :=
      match b? with
      | none   => a + c
      | some b => a + b + c
    
    variable {α} [Add α]
    
    example : g = fun (a c : α) => a + c := rfl
    
    example (x : α) : g (c := x) = fun (a : α) => a + x := rfl
    
    example (x : α) : g (b? := some x) = fun (a c : α) => a + x + c := rfl
    
    example (x : α) : g x = fun (c : α) => x + c := rfl
    
    example (x y : α) : g x y = fun (c : α) => x + y + c := rfl
    

You can use `..` to provide missing explicit arguments as `_`. This feature
combined with named arguments is useful for writing patterns. Here is an
example:

    
    
    inductive Term where
      | var    (name : String)
      | num    (val : Nat)
      | app    (fn : Term) (arg : Term)
      | lambda (name : String) (type : Term) (body : Term)
    
    def getBinderName : Term → Option String
      | Term.lambda (name := n) .. => some n
      | _ => none
    
    def getBinderType : Term → Option Term
      | Term.lambda (type := t) .. => some t
      | _ => none
    

Ellipses are also useful when explicit arguments can be automatically inferred
by Lean, and we want to avoid a sequence of `_`s.

    
    
    example (f : Nat → Nat) (a b c : Nat) : f (a + b + c) = f (a + (b + c)) :=
      congrArg f (Nat.add_assoc ..)
    

[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next
chapter")

[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next
chapter")
2025-06-01 02:51:30,148 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.'}], 'model': 'o3-mini'}}
2025-06-01 02:51:30,149 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:51:30,149 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:51:30,161 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737c6e0>
2025-06-01 02:51:30,161 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:51:30,169 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737c3b0>
2025-06-01 02:51:30,169 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:51:30,169 - DEBUG - send_request_headers.complete
2025-06-01 02:51:30,169 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:51:30,169 - DEBUG - send_request_body.complete
2025-06-01 02:51:30,169 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:51:34,786 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:51:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4391'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4396'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199622'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'113ms'), (b'x-request-id', b'req_96a91e7deb77d0b7f910e160cb470ad6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QyCqN7FbxGPYVFxHBwLzhaW0hLoLpgiWjBaqsPMhsiE-1748746294-1.0.1.1-Pd8tIKnlZGWMTrggTa.9JzMX4hVQ765Bk9HS6iQNMK4erqA11ZFOP3V368IqNhPDeSGzn2IlH1OuOeavIxUTrIsp7cnjnrcHO2cJZU4zhiQ; path=/; expires=Sun, 01-Jun-25 03:21:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=CN8q4VIqmix6uZV6qX007w6dtqCEve00n2wrrZ44DGo-1748746294802-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b68d9beee3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:51:34,786 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:51:34,786 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:51:34,787 - DEBUG - receive_response_body.complete
2025-06-01 02:51:34,787 - DEBUG - response_closed.started
2025-06-01 02:51:34,787 - DEBUG - response_closed.complete
2025-06-01 02:51:34,787 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:51:34 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '4391'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '4396'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '199622'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '113ms'), ('x-request-id', 'req_96a91e7deb77d0b7f910e160cb470ad6'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=QyCqN7FbxGPYVFxHBwLzhaW0hLoLpgiWjBaqsPMhsiE-1748746294-1.0.1.1-Pd8tIKnlZGWMTrggTa.9JzMX4hVQ765Bk9HS6iQNMK4erqA11ZFOP3V368IqNhPDeSGzn2IlH1OuOeavIxUTrIsp7cnjnrcHO2cJZU4zhiQ; path=/; expires=Sun, 01-Jun-25 03:21:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=CN8q4VIqmix6uZV6qX007w6dtqCEve00n2wrrZ44DGo-1748746294802-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b68d9beee3bfe-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:51:34,787 - DEBUG - request_id: req_96a91e7deb77d0b7f910e160cb470ad6
2025-06-01 02:51:34,791 - INFO - Attempt 1/3
2025-06-01 02:51:34,791 - INFO - Current plan: {
  "plan_summary": "Define an identity function in Lean 4 that takes a natural number 'x' and returns it unmodified. The function will use pattern matching or a simple direct return since the type is nat.",
  "steps": [
    "Define the function with the correct Lean 4 type signature: Nat → Nat.",
    "Implement the function body by directly returning the input variable 'x'.",
    "Optionally, include tests or examples to ensure the function behaves as expected."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "identity function",
    "natural numbers"
  ],
  "proof_keywords": [
    "direct definition",
    "reflexivity",
    "identity mapping"
  ],
  "assumptions": [
    "The function should have a clear and simple definition without additional type constraints.",
    "No additional processing or check is required since the task only involves returning the input value."
  ],
  "retry_guidance": "Ensure that the function signature matches Lean 4 syntax for natural numbers and that the return type is correctly specified as Nat. Review Lean 4 documentation if type mismatch errors occur."
}
2025-06-01 02:51:34,791 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define an identity function in Lean 4 that takes a natural number \'x\' and returns it unmodified. The function will use pattern matching or a simple direct return since the type is nat.",\n  "steps": [\n    "Define the function with the correct Lean 4 type signature: Nat → Nat.",\n    "Implement the function body by directly returning the input variable \'x\'.",\n    "Optionally, include tests or examples to ensure the function behaves as expected."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "identity function",\n    "natural numbers"\n  ],\n  "proof_keywords": [\n    "direct definition",\n    "reflexivity",\n    "identity mapping"\n  ],\n  "assumptions": [\n    "The function should have a clear and simple definition without additional type constraints.",\n    "No additional processing or check is required since the task only involves returning the input value."\n  ],\n  "retry_guidance": "Ensure that the function signature matches Lean 4 syntax for natural numbers and that the return type is correctly specified as Nat. Review Lean 4 documentation if type mismatch errors occur."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef ident (x : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\ndef ident_spec (x : Nat) (result: Nat) : Prop :=\n  -- << SPEC START >>\n  result = x\n  -- << SPEC END >>\n\ntheorem ident_spec_satisfied (x : Nat) :\n  ident_spec x (ident x) := by\n  -- << PROOF START >>\n  unfold ident ident_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n Lean failed to infer it. Named arguments also improve\nthe readability of your code by identifying what each argument represents.\n\n    \n    \n    def sum (xs : List Nat) :=\n      xs.foldl (init := 0) (·+·)\n    \n    #eval sum [1, 2, 3, 4]\n    -- 10\n    \n    example {a b : Nat} {p : Nat → Nat → Nat → Prop} (h₁ : p a b b) (h₂ : b = a)\n        : p a a b :=\n      Eq.subst (motive := fun x => p a x b) h₂ h₁\n    \n\nIn the following examples, we illustrate the interaction between named and\ndefault arguments.\n\n    \n    \n    def f (x : Nat) (y : Nat := 1) (w : Nat := 2) (z : Nat) :=\n      x + y + w - z\n    \n    example (x z : Nat) : f (z := z) x = x + 1 + 2 - z := rfl\n    \n    example (x z : Nat) : f x (z := z) = x + 1 + 2 - z := rfl\n    \n    example (x y : Nat) : f x y = fun z => x + y + 2 - z := rfl\n    \n    example : f = (fun x z => x + 1 + 2 - z) := rfl\n    \n    example (x : Nat) : f x = fun z => x + 1 + 2 - z := rfl\n    \n    example (y : Nat) : f (y := 5) = fun x z => x + 5 + 2 - z := rfl\n    \n    def g {α} [Add α] (a : α) (b? : Option α := none) (c : α) : α :=\n      match b? with\n      | none   => a + c\n      | some b => a + b + c\n    \n    variable {α} [Add α]\n    \n    example : g = fun (a c : α) => a + c := rfl\n    \n    example (x : α) : g (c := x) = fun (a : α) => a + x := rfl\n    \n    example (x : α) : g (b? := some x) = fun (a c : α) => a + x + c := rfl\n    \n    example (x : α) : g x = fun (c : α) => x + c := rfl\n    \n    example (x y : α) : g x y = fun (c : α) => x + y + c := rfl\n    \n\nYou can use `..` to provide missing explicit arguments as `_`. This feature\ncombined with named arguments is useful for writing patterns. Here is an\nexample:\n\n    \n    \n    inductive Term where\n      | var    (name : String)\n      | num    (val : Nat)\n      | app    (fn : Term) (arg : Term)\n      | lambda (name : String) (type : Term) (body : Term)\n    \n    def getBinderName : Term → Option String\n      | Term.lambda (name := n) .. => some n\n      | _ => none\n    \n    def getBinderType : Term → Option Term\n      | Term.lambda (type := t) .. => some t\n      | _ => none\n    \n\nEllipses are also useful when explicit arguments can be automatically inferred\nby Lean, and we want to avoid a sequence of `_`s.\n\n    \n    \n    example (f : Nat → Nat) (a b c : Nat) : f (a + b + c) = f (a + (b + c)) :=\n      congrArg f (Nat.add_assoc ..)\n    \n\n[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next\nchapter")\n\n[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next\nchapter")'}], 'model': 'gpt-4o'}}
2025-06-01 02:51:34,793 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:51:34,793 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:51:34,793 - DEBUG - send_request_headers.complete
2025-06-01 02:51:34,793 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:51:34,798 - DEBUG - send_request_body.complete
2025-06-01 02:51:34,798 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:51:36,702 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:51:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'1683'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1685'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'13945'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'32.11s'), (b'x-request-id', b'req_43e15358eaa5964005133d634f30a59c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b68f69a103bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:51:36,703 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:51:36,703 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:51:36,704 - DEBUG - receive_response_body.complete
2025-06-01 02:51:36,704 - DEBUG - response_closed.started
2025-06-01 02:51:36,704 - DEBUG - response_closed.complete
2025-06-01 02:51:36,704 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:51:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '1683', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1685', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '13945', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '32.11s', 'x-request-id': 'req_43e15358eaa5964005133d634f30a59c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b68f69a103bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:51:36,704 - DEBUG - request_id: req_43e15358eaa5964005133d634f30a59c
2025-06-01 02:51:36,705 - INFO - Raw solution received: ```json
{
  "code": "x",
  "proof": "rfl"
}
```
2025-06-01 02:51:36,705 - INFO - <class 'str'>
2025-06-01 02:51:36,705 - INFO - Generated solution: {'code': 'x', 'proof': 'rfl'}
2025-06-01 02:51:42,026 - INFO - Lean execution result: Lean code executed successfully.
2025-06-01 02:51:42,027 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef ident (x : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\ndef ident_spec (x : Nat) (result: Nat) : Prop :=\n  -- << SPEC START >>\n  result = x\n  -- << SPEC END >>\n\ntheorem ident_spec_satisfied (x : Nat) :\n  ident_spec x (ident x) := by\n  -- << PROOF START >>\n  unfold ident ident_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nx\n\nGenerated Proof:\nrfl\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean code executed successfully.'}], 'model': 'o3-mini'}}
2025-06-01 02:51:42,027 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:51:42,027 - DEBUG - close.started
2025-06-01 02:51:42,027 - DEBUG - close.complete
2025-06-01 02:51:42,027 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:51:42,052 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737fce0>
2025-06-01 02:51:42,052 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:51:42,078 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737f9b0>
2025-06-01 02:51:42,078 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:51:42,079 - DEBUG - send_request_headers.complete
2025-06-01 02:51:42,079 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:51:42,079 - DEBUG - send_request_body.complete
2025-06-01 02:51:42,079 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:51:46,107 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:51:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'3781'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'3784'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199425'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'172ms'), (b'x-request-id', b'req_70398ffa975b5302dd2bcf12a2cb0593'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b69244a5f4436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:51:46,108 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:51:46,108 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:51:46,108 - DEBUG - receive_response_body.complete
2025-06-01 02:51:46,108 - DEBUG - response_closed.started
2025-06-01 02:51:46,108 - DEBUG - response_closed.complete
2025-06-01 02:51:46,108 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:51:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '3781', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '3784', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199425', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '172ms', 'x-request-id': 'req_70398ffa975b5302dd2bcf12a2cb0593', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b69244a5f4436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:51:46,108 - DEBUG - request_id: req_70398ffa975b5302dd2bcf12a2cb0593
2025-06-01 02:51:46,109 - INFO - Feedback received: {'verdict': 'pass', 'error_summary': 'The generated Lean code executed successfully with no errors.', 'error_type': 'unknown', 'suggested_fix': 'No fixes are necessary.', 'retry_strategy': 'No retry is needed since the implementation and proof are correct.'}
2025-06-01 02:51:46,109 - INFO - Solution generated in 17.22 seconds
2025-06-01 02:51:46,109 - INFO - Generated code length: 1 characters
2025-06-01 02:51:46,109 - INFO - Generated proof length: 3 characters
2025-06-01 02:51:46,109 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:51:46,109 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:51:51,191 - INFO - Implementation test result: PASS
2025-06-01 02:51:51,191 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:51:56,430 - INFO - Full solution test result: PASS
2025-06-01 02:51:56,430 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:51:56,430 - INFO - ✅ Proof is correct
2025-06-01 02:51:56,430 - INFO - 
==================================================
2025-06-01 02:51:56,430 - INFO - Processing task task_id_58...
2025-06-01 02:51:56,431 - INFO - Reading problem description and code template from tasks/task_id_58...
2025-06-01 02:51:56,431 - INFO - Problem description length: 700 characters
2025-06-01 02:51:56,431 - INFO - Reading unit tests from tasks/task_id_58...
2025-06-01 02:51:56,431 - INFO - Unit tests length: 462 characters
2025-06-01 02:51:56,431 - INFO - Running main workflow to generate solution...
2025-06-01 02:51:56,431 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.

-----Input-----
The input consists of two integers:
a: An integer.
b: An integer.

-----Output-----
The output is a Boolean value:
Returns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).
Returns false if both integers are either non-negative or non-positive, or if one (or both) is zero.
2025-06-01 02:51:56,431 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def hasOppositeSign (a : Int) (b : Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result is true if a and b have opposite signs
def hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=
  -- << SPEC START >>
  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result
  -- << SPEC END >>

theorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :
  hasOppositeSign_spec a b (hasOppositeSign a b) := by
  -- << PROOF START >>
  unfold hasOppositeSign hasOppositeSign_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:51:56,462 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7f4e6733f1a0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:51:56,462 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:51:56,462 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:51:56,486 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737f260>
2025-06-01 02:51:56,486 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4e6759fdd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:51:56,514 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f7f860>
2025-06-01 02:51:56,514 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:51:56,514 - DEBUG - send_request_headers.complete
2025-06-01 02:51:56,515 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:51:56,515 - DEBUG - send_request_body.complete
2025-06-01 02:51:56,515 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:51:57,268 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:51:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'95'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7c4c8df9b7-zdwbv'), (b'x-envoy-upstream-service-time', b'101'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999825'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_1fb68efb0be861513ce7ab6fc50ac18b'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=tMjf.NkYBcm0zTC_IxvAknBwYO2j6IYE2tG9xTyAsuo-1748746317-1.0.1.1-kR6B6t_zscNSKQeL4BWp9ysiSqWuao9ujHiwE_YJRzsZbmRLkH7EDvDcSJ0HKqoaXYOmsLjPTIvzHraB5kwNv_lYOFbh0.Ez6akNg.u9JmQ; path=/; expires=Sun, 01-Jun-25 03:21:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=piTPGkbRt4lwm37MIo_lH6NfL7IffZYnD.FD5GyPakY-1748746317289-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b697e7a8146f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:51:57,268 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:51:57,268 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:51:57,269 - DEBUG - receive_response_body.complete
2025-06-01 02:51:57,269 - DEBUG - response_closed.started
2025-06-01 02:51:57,269 - DEBUG - response_closed.complete
2025-06-01 02:51:57,269 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:51:57 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '95'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-7c4c8df9b7-zdwbv'), ('x-envoy-upstream-service-time', '101'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999825'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '10ms'), ('x-request-id', 'req_1fb68efb0be861513ce7ab6fc50ac18b'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=tMjf.NkYBcm0zTC_IxvAknBwYO2j6IYE2tG9xTyAsuo-1748746317-1.0.1.1-kR6B6t_zscNSKQeL4BWp9ysiSqWuao9ujHiwE_YJRzsZbmRLkH7EDvDcSJ0HKqoaXYOmsLjPTIvzHraB5kwNv_lYOFbh0.Ez6akNg.u9JmQ; path=/; expires=Sun, 01-Jun-25 03:21:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=piTPGkbRt4lwm37MIo_lH6NfL7IffZYnD.FD5GyPakY-1748746317289-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b697e7a8146f0-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:51:57,269 - DEBUG - request_id: req_1fb68efb0be861513ce7ab6fc50ac18b
2025-06-01 02:51:57,274 - INFO - Retrieved context:  the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
� r)`

Distributivity:

  5. `p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)`
  6. `p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)`

Other properties:

  7. `(p → (q → r)) ↔ (p ∧ q → r)`
  8. `((p ∨ q) → r) ↔ (p → r) ∧ (q → r)`
  9. `¬(p ∨ q) ↔ ¬p ∧ ¬q`
  10. `¬p ∨ ¬q → ¬(p ∧ q)`
  11. `¬(p ∧ ¬p)`
  12. `p ∧ ¬q → ¬(p → q)`
  13. `¬p → (p → q)`
  14. `(¬p ∨ q) → (p → q)`
  15. `p ∨ False ↔ p`
  16. `p ∧ False ↔ False`
  17. `¬(p ↔ ¬p)`
  18. `(p → q) → (¬q → ¬p)`

These require classical reasoning:

  19. `(p → r ∨ s) → ((p → r) ∨ (p → s))`
  20. `¬(p ∧ q) → ¬p ∨ ¬q`
  21. `¬(p → q) → p ∧ ¬q`
  22. `(p → q) → (¬p ∨ q)`
  23. `(¬q → ¬p) → (p → q)`
  24. `p ∨ ¬p`
  25. `(((p → q) → p) → p)`

The `sorry` identifier magically produces a proof of anything, or provides an
object of any data type at all. Of course, it is unsound as a proof method --
for example, you can use it to prove `False` \-- and Lean produces severe
warnings when files use or import theorems which depend on it. But it is very
useful for building long proofs incrementally. Start writing the proof from
the top down, using `sorry` to fill in subproofs. Make sure Lean accepts the
term with all the `sorry`'s; if not, there are errors that you need to
correct. Then go back and replace each `sorry` with an actual proof, until no
more remain.

Here is another useful trick. Instead of using `sorry`, you can use an
underscore `_` as a placeholder. Recall this tells Lean that the argument is
implicit, and should be filled in automatically. If Lean tries to do so and
fails, it returns with an error message "don't know how to synthesize
placeholder," followed by the type of the term it is expecting, and all the
objects and hypotheses available in the context. In other words, for each
unresolved placeholder, Lean reports the subgoal that needs to be filled at
that point. You can then construct a proof by incrementally filling in these
placeholders.

For reference, here are two sample proofs of validities taken from the list
above.

    
    
    open Classical
    
    -- distributivity
    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
      Iff.intro
        (fun h : p ∧ (q ∨ r) =>
          have hp : p := h.left
          Or.elim (h.right)
            (fun hq : q =>
              show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)
            (fun hr : r =>
              show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))
        (fun h : (p ∧ q) ∨ (p ∧ r) =>
          Or.elim h
            (fun hpq : p ∧ q =>
              have hp : p := hpq.left
              have hq : q := hpq.right
              show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)
            (fun hpr : p ∧ r =>
              have hp : p := hpr.left
              have hr : r := hpr.right
              show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))
    
    -- an example that requires classical reasoning
    example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=
      fun h : ¬(p ∧ ¬q) =>
      fun hp : p =>
      show q from
        Or.elim (em q)
          (fun hq : q => hq)
          (fun hnq : ¬q => absurd (And.intro hp hnq) h)
    

## Exercises

Prove the following identities, replacing the "sorry" placeholders with actual
proofs.

    
    
    variable (p q r : Prop)
    
    -- commutativity of ∧ and ∨
    example : p ∧ q ↔ q ∧ p := sorry
    example : p ∨ q ↔ q ∨ p := sorry
    
    -- associativity of ∧ and ∨
    example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry
    example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry
    
    -- distributivity
    example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry
    example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry
    
    -- other properties
    example : (p → (q → r)) ↔ (p ∧ q → r) := sorry
    example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry
    example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry
    example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry
    example : ¬(p ∧ ¬p) := sorry
    example : p ∧ ¬q → ¬(p → q) := sorry
    example : ¬p → (p → q) := sorry
    example : (¬p ∨ q) → (p → q) := sorry
    example : p ∨ False ↔ p := sorry
    example : p ∧ False ↔ False := sorry
    example : (p → q) → (¬q → ¬p) := sorry
    

Prove the following identities, replacing the "sorry" placeholders with actual
proofs. These require classical reasoning.

    
    
    open Classical
    
    variable (p q r : Prop)
    
    example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry
    example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry
    example : ¬(p → q) → p ∧ ¬q := sorry
    example : (p → q) → (¬p ∨ q) := sorry
    example : (¬q → ¬p) → (p → q) := sorry
    example : p ∨ ¬p := sorry
    example : (((p → q) → p) → p) := sorry
    

Prove `¬(p ↔ ¬p)` without using classical logic.

[ __](dependent_type_theory.html "Previous chapter") [
__](quantifiers_and_equality.html "Next chapter")

[ __](dependent_type_theory.html "Previous chapter") [
__](quantifiers_and_equality.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Propositions and Proofs

By now, you have seen some ways of defining objects and functions in Lean. In
this chapter, we will begin to explain how to write mathematical assertions
and proofs in the language of dependent type theory as well.

## Propositions as Types

One strategy for proving assertions about objects defined in the language of
dependent type theory is to layer an assertion language and a proof language
on top of the definition language. But there is no reason to multiply
languages in this way: dependent type theory is flexible and expressive, and
there is no reason we cannot represent assertions and proofs in the same
general framework.

For example, we could introduce a new type, `Prop`, to represent propositions,
and introduce constructors to build new propositions from others.

    
    
    def Implies (p q : Prop) : Prop := p → q
    #check And     -- Prop → Prop → Prop
    #check Or      -- Prop → Prop → Prop
    #check Not     -- Prop → Prop
    #check Implies -- Prop → Prop → Prop
    
    variable (p q r : Prop)
    #check And p q                      -- Prop
    #check Or (And p q) r               -- Prop
    #check Implies (And p q) (And q p)  -- Prop
    

We could then introduce, for each element `p : Prop`, another type `Proof p`,
for the type of proofs of `p`. An "axiom" would be a constant of such a type.

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    #check Proof   -- Proof : Prop → Type
    
    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))
    
    variable (p q : Prop)
    #check and_comm p q     -- Proof (Implies (And p q) (And q p))
    

In addition to axioms, however, we would also need rules to build new proofs
from old ones. For example, in many proof systems for propositional logic, we
have the rule of _modus ponens_ :

> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.

We could represent this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q
    

Systems of natural deduction for propositional logic also typically rely on
the following rule:

> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we
> can "cancel" the hypothesis and obtain a proof of `Implies p q`.

We could render this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)
    

This approach would provide us with a reasonable way of building assertions
and proofs. Determining that an expression `t` is a correct proof of assertion
`p` would then simply be a matter of checking that `t` has type `Proof p`.

Some simplifications are possible, however. To start with, we can avoid
writing the term `Proof` repeatedly by conflating `Proof p` with `p` itself.
In other words, whenever we have `p : Prop`, we can interpret `p` as a type,
namely, the type of its proofs. We can then read `t : p` as the assertion that
`t` is a proof of `p`.

Moreover, once we make this identification, the rules for implication show
that we can pass back and forth between `Implies p q` and `p → q`. In other
words, implication between propositions `p` and `q` corresponds to having a
function that takes any element of `p` to an element of `q`. As a result, the
introduction of the connective `Implies` is entirely redundant: we can use the
usual function space constructor `p → q` from dependent type theory as our
notion of implication.

This is the approach followed in the Calculus of Constructions, and hence in
Lean as well. The fact that the rules for implication in a proof system for
natural deduction correspond exactly to the rules governing abstraction and
application for functions is an instance of the _Curry-Howard isomorphism_ ,
sometimes known as the _propositions-as-types_ paradigm. In fact, the type
`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy
described in the last chapter. Moreover, `Type u` is also just syntactic sugar
for `Sort (u+1)`. `Prop` has some special features, but like the other type
universes, it is closed under the arrow constructor: if we have `p q : Prop`,
then `p → q : Prop`.

There are at least two ways of thinking about propositions as types. To some
who take a constructive view of logic and mathematics, this is a faithful
rendering of what it means to be a proposition: a proposition `p` represents a
sort of data type, namely, a specification of the type of data that
constitutes a proof. A proof of `p` is then simply an object `t : p` of the
right type.

Those not inclined to this ideology can view it, rather, as a simple coding
trick. To each proposition `p` we associate a type that is empty if `p` is
false and has a single element, say `*`, if `p` is true. In the latter case,
let us say that (the type associated with) `p` is _inhabited_. It just so
happens that the rules for function application and abstraction can
conveniently help us keep track of which elements of `Prop` are inhabited. So
constructing an element `t : p` tells us that `p` is indeed true. You can
think of the inhabitant of `p` as being the "fact that `p` is true." A proof
of `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is
true."

Indeed, if `p : Prop` is any proposition, Lean's kernel treats any two
elements `t1 t2 : p` as being definitionally equal, much the same way as it
treats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as
_proof irrelevance,_ and is consistent with the interpretation in the last
paragraph. It means that even though we can treat proofs `t : p` as ordinary
objects in the language of dependent type theory, they carry no information
beyond the fact that `p` is true.

The two ways we have suggested thinking about the propositions-as-types
paradigm differ in a fundamental way. From the constructive point of view,
proofs are abstract mathematical objects that are _denoted_ by suitable
expressions in dependent type theory. In contrast, if we think in terms of the
coding trick described above, then the expressions themselves do not denote
anything interesting. Rather, it is the fact that we can write them down and
check that they are well-typed that ensures that the proposition in question
is true. In other words, the expressions _themselves_ are the proofs.

In the exposition below, we will slip back and forth between these two ways of
talking, at times saying that an expression "constructs" or "produces" or
"returns" a proof of a proposition, and at other times simply saying that it
"is" such a proof. This is similar to the way that computer scientists
occasionally blur the distinction between syntax and semantics by saying, at
times, that a program "computes" a certain function, and at other times
speaking as though the program "is" the function in question.

In any case, all that really matters is the bottom line. To formally express a
mathematical assertion in the language of dependent type theory, we need to
exhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a
term `t : p`. Lean's task, as a proof assistant, is to help us to construct
such a term, `t`, and to verify that it is well-formed and has the correct
type.

## Working with Propositions as Types

In the propositions-as-types paradigm, theorems involving only `→` can be
proved using lambda abstraction and application. In Lean, the `theorem`
command introduces a new theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    

Compare this proof to the expression `fun x : α => fun y : β => x` of type `α
→ β → α`, where `α` and `β` are data types. This describes the function that
takes arguments `x` and `y` of type `α` and `β`, respectively, and returns
`x`. The proof of `t1` has the same form, the only difference being that `p`
and `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of
`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis
(trivially) to establish that the conclusion, `p`, is true.

Note that the `theorem` command is really a version of the `def` command:
under the propositions and types correspondence, proving the theorem `p → q →
p` is really the same as defining an element of the associated type. To the
kernel type checker, there is no difference between the two.

There are a few pragmatic differences between definitions and theorems,
however. In normal circumstances, it is never necessary to unfold the
"definition" of a theorem; by proof irrelevance, any two proofs of that
theorem are definitionally equal. Once the proof of a theorem is complete,
typically we only need to know that the proof exists; it doesn't matter what
the proof is. In light of that fact, Lean tags proofs as _irreducible_ , which
serves as a hint to the parser (more precisely, the _elaborator_) that there
is generally no need to unfold them when processing a file. In fact, Lean is
generally able to process and check proofs in parallel, since assessing the
correctness of one proof does not require knowing the details of another.

As with definitions, the `#print` command will show you the proof of a
theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    
    #print t1
    

Notice that the lambda abstractions `hp : p` and `hq : q` can be viewed as
temporary assumptions in the proof of `t1`. Lean also allows us to specify the
type of the final term `hp`, explicitly, with a `show` statement:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p :=
      fun hp : p =>
      fun hq : q =>
      show p from hp
    

Adding such extra information can improve the clarity of a proof and help
detect errors when writing a proof. The `show` command does nothing more than
annotate the type, and, internally, all the presentations of `t1` that we have
seen produce the same term.

As with ordinary definitions, we can move the lambda-abstracted variables to
the left of the colon:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    #print t1    -- p → q → p
    

We can use the theorem `t1` just as a function application:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    axiom hp : p
    
    theorem t2 : q → p := t1 hp
    

The `axiom` declaration postulates the existence of an element of the given
type and may compromise logical consistency. For example, we can use it to
postulate that the empty type `False` has an element:

    
    
    axiom unsound : False
    -- Everything follows from false
    theorem ex : 1 = 0 :=
      False.elim unsound
    

Declaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as
witnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`
that `p` is true yields the theorem `t1 hp : q → p`.

Recall that we can also write theorem `t1` as follows:

    
    
    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp
    
    #print t1
    

The type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the
assertion "for every pair of propositions `p q`, we have `p → q → p`." For
example, we can move all parameters to the right of the colon:

    
    
    theorem t1 : ∀ {p q : Prop}, p → q → p :=
      fun {p q : Prop} (hp : p) (hq : q) => hp
    

If `p` and `q` have been declared as variables, Lean will generalize them for
us automatically:

    
    
    variable {p q : Prop}
    
    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp
    

In fact, by the propositions-as-types correspondence, we can declare the
assumption `hp` that `p` holds, as another variable:

    
    
    variable {p q : Prop}
    variable (hp : p)
    
    theorem t1 : q → p := fun (hq : q) => hp
    

Lean detects that the proof uses `hp` and automatically adds `hp : p` as a
premise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →
q → p`. Remember that this type can just as well be written `∀ (p q : Prop)
(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type
in which the target does not depend on the bound variable.

When we generalize `t1` in such a way, we can then apply it to different pairs
of propositions, to obtain different instances of the general theorem.

    
    
    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp
    
    variable (p q r s : Prop)
    
    #check t1 p q                -- p → q → p
    #check t1 r s                -- r → s → r
    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s
    
    variable (h : r → s)
    #check t1 (r → s) (s → r) h  -- (s → r) → r → s
    

Once again, using the propositions-as-types correspondence, the variable `h`
of type `r → s` can be viewed as the hypothesis, or premise, that `r → s`
holds.

As another example, let us consider the composition function discussed in the
last chapter, now with propositions instead of types.

    
    
    variable (p q r s : Prop)
    
    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=
      fun h₃ : p =>
      show r from h₁ (h₂ h₃)
    

As a theorem of propositional logic, what does `t2` say?

Note that it is often useful to use numeric unicode subscripts, entered as
`\0`, `\1`, `\2`, ..., for hypotheses, as we did in this example.

## Propositional Logic

Lean defines all the standard logical connectives and notation. The
propositional connectives come with the following notation:

Ascii| Unicode| Editor shortcut| Definition  
---|---|---|---  
True| | | True  
False| | | False  
Not| ¬| `\not`, `\neg`| Not  
/\| ∧| `\and`| And  
\/| ∨| `\or`| Or  
->| →| `\to`, `\r`, `\imp`|   
<->| ↔| `\iff`, `\lr`| Iff  
  
They all take values in `Prop`.

    
    
    variable (p q : Prop)
    
    #check p → q → p ∧ q
    #check ¬p → p ↔ False
    #check p ∨ q → q ∨ p
    

The order of operations is as follows: unary negation `¬` binds most strongly,
then `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧
e` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right
(nothing changes now that the arguments are elements of `Prop`, instead of
some other `Type`), as do the other binary connectives. So if we have `p q r :
Prop`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This
is just the "curried" form of `p ∧ q → r`.

In the last chapter we observed that lambda abstraction can be viewed as an
"introduction rule" for `→`. In the current setting, it shows how to
"introduce" or establish an implication. Application can be viewed as an
"elimination rule," showing how to "eliminate" or use an implication in a
proof. The other propositional connectives are defined in Lean's library in
the file `Prelude.core` (see [importing
files](./interacting_with_lean.html#importing-files) for more information on
the library hierarchy), and each connective comes with its canonical
introduction and elimination rules.

### Conjunction

The expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :
p` and `h2 : q`. It is common to describe `And.intro` as the _and-
introduction_ rule. In the next example we use `And.intro` to create a proof
of `p → q → p ∧ q`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq
    
    #check fun (hp : p) (hq : q) => And.intro hp hq
    

The `example` command states a theorem without naming it or storing it in the
permanent context. Essentially, it just checks that the given term has the
indicated type. It is convenient for illustration, and we will use it often.

The expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.
Similarly, `And.right h` is a proof of `q`. They are commonly known as the
left and right _and-elimination_ rules.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : p := And.left h
    example (h : p ∧ q) : q := And.right h
    

We can now prove `p ∧ q → q ∧ p` with the following proof term.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      And.intro (And.right h) (And.left h)
    

Notice that and-introduction and and-elimination are similar to the pairing
and projection operations for the Cartesian product. The difference is that
given `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while
`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is
another instance of the Curry-Howard isomorphism, but in contrast to
implication and the function space constructor, `∧` and `×` are treated
separately in Lean. With the analogy, however, the proof we have just
constructed is similar to a function that swaps the elements of a pair.

We will see in [Chapter Structures and Records](./structures_and_records.html)
that certain types in Lean are _structures_ , which is to say, the type is
defined with a single canonical _constructor_ which builds an element of the
type from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is
an example: the canonical way to construct an element is to apply `And.intro`
to suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous
constructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the
relevant type is an inductive type and can be inferred from the context. In
particular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:

    
    
    variable (p q : Prop)
    variable (hp : p) (hq : q)
    
    #check (⟨hp, hq⟩ : p ∧ q)
    

These angle brackets are obtained by typing `\<` and `\>`, respectively.

Lean provides another useful syntactic gadget. Given an expression `e` of an
inductive type `Foo` (possibly applied to some arguments), the notation
`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of
accessing functions without opening a namespace. For example, the following
two expressions mean the same thing:

    
    
    variable (xs : List Nat)
    
    #check List.length xs
    #check xs.length
    

As a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and
`h.right` for `And.right h`. We can therefore rewrite the sample proof above
conveniently as follows:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      ⟨h.right, h.left⟩
    

There is a fine line between brevity and obfuscation, and omitting information
in this way can sometimes make a proof harder to read. But for straightforward
constructions like the one above, when the type of `h` and the goal of the
construction are salient, the notation is clean and effective.

It is common to iterate constructions like "And." Lean also allows you to
flatten nested constructors that associate to the right, so that these two
proofs are equivalent:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, ⟨h.left, h.right⟩⟩
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, h.left, h.right⟩
    

This is often useful as well.

### Disjunction

The expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof
`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a
proof `hq : q`. These are the left and right _or-introduction_ rules.

    
    
    variable (p q : Prop)
    example (hp : p) : p ∨ q := Or.intro_left q hp
    example (hq : q) : p ∨ q := Or.intro_right p hq
    

The _or-elimination_ rule is slightly more complicated. The idea is that we
can prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`
follows from `q`. In other words, it is a proof by cases. In the expression
`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :
p → r` and `hqr : q → r`, and produces a proof of `r`. In the following
example, we use `Or.elim` to prove `p ∨ q → q ∨ p`.

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h
        (fun hp : p =>
          show q ∨ p from Or.intro_right q hp)
        (fun hq : q =>
          show q ∨ p from Or.intro_left p hq)
    

In most cases, the first argument of `Or.intro_right` and `Or.intro_left` can
be inferred automatically by Lean. Lean therefore provides `Or.inr` and
`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and
`Or.intro_left _`. Thus the proof term above could be written more concisely:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Notice that there is enough information in the full expression for Lean to
infer the types of `hp` and `hq` as well. But using the type annotations in
the longer version makes the proof more readable, and can help catch and debug
errors.

Because `Or` has two constructors, we cannot use anonymous constructor
notation. But we can still write `h.elim` instead of `Or.elim h`:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Once again, you should exercise judgment as to whether such abbreviations
enhance or diminish readability.

### Negation and Falsity

Negation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by
deriving a contradiction from `p`. Similarly, the expression `hnp hp` produces
a proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both
these rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is
produced by typing `\not` or `\neg`.)

    
    
    variable (p q : Prop)
    
    example (hpq : p → q) (hnq : ¬q) : ¬p :=
      fun hp : p =>
      show False from hnq (hpq hp)
    

The connective `False` has a single elimination rule, `False.elim`, which
expresses the fact that anything follows from a contradiction. This rule is
sometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the
_principle of explosion_.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)
    

The arbitrary fact, `q`, that follows from falsity is an implicit argument in
`False.elim` and is inferred automatically. This pattern, deriving an
arbitrary fact from contradictory hypotheses, is quite common, and is
represented by `absurd`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := absurd hp hnp
    

Here, for example, is a proof of `¬p → q → (q → p) → r`:

    
    
    variable (p q r : Prop)
    
    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=
      absurd (hqp hq) hnp
    

Incidentally, just as `False` has only an elimination rule, `True` has only an
introduction rule, `True.intro : true`. In other words, `True` is simply true,
and has a canonical proof, `True.intro`.

### Logical Equivalence

The expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`
and `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from
`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔
q`. Here is a proof of `p ∧ q ↔ q ∧ p`:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      Iff.intro
        (fun h : p ∧ q =>
         show q ∧ p from And.intro (And.right h) (And.left h))
        (fun h : q ∧ p =>
         show p ∧ q from And.intro (And.right h) (And.left h))
    
    #check and_swap p q    -- p ∧ q ↔ q ∧ p
    
    variable (h : p ∧ q)
    example : q ∧ p := Iff.mp (and_swap p q) h
    

We can use the anonymous constructor notation to construct a proof of `p ↔ q`
from proofs of the forward and backward directions, and we can also use `.`
notation with `mp` and `mpr`. The previous examples can therefore be written
concisely as follows:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩
    
    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h
    

## Introducing Auxiliary Subgoals

This is a good place to introduce another device Lean offers to help structure
long proofs, namely, the `have` construct, which introduces an auxiliary
subgoal in a proof. Here is a small example, adapted from the last section:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      have hq : q := h.right
      show q ∧ p from And.intro hq hp
    

Internally, the expression `have h : p := s; t` produces the term `(fun (h :
p) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the
desired conclusion assuming `h : p`, and the two are combined by a lambda
abstraction and application. This simple device is extremely useful when it
comes to structuring long proofs, since we can use intermediate `have`'s as
stepping stones leading to the final goal.

Lean also supports a structured way of reasoning backwards from a goal, which
models the "suffices to show" construction in ordinary mathematics. The next
example simply permutes the last two lines in the previous proof.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      suffices hq : q from And.intro hq hp
      show q from And.right h
    

Writing `suffices hq : q` leaves us with two goals. First, we have to show
that it indeed suffices to show `q`, by proving the original goal of `q ∧ p`
with the additional hypothesis `hq : q`. Finally, we have to show `q`.

## Classical Logic

The introduction and elimination rules we have seen so far are all
constructive, which is to say, they reflect a computational understanding of
the logical connectives based on the propositions-as-types correspondence.
Ordinary classical logic adds to this the law of the excluded middle, `p ∨
¬p`. To use this principle, you have to open the classical namespace.

    
    
    open Classical
    
    variable (p : Prop)
    #check em p
    

Intuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts
to knowing which is the case. If `RH` represents the Riemann hypothesis, a
classical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot
yet assert either disjunct.

One consequence of the law of the excluded middle is the principle of double-
negation elimination:

    
    
    open Classical
    
    theorem dne {p : Prop} (h : ¬¬p) : p :=
      Or.elim (em p)
        (fun hp : p => hp)
        (fun hnp : ¬p => absurd hnp h)
    

Double-negation elimination allows one to prove any proposition, `p`, by
assuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In
other words, double-negation elimination allows one to carry out a proof by
contradiction, something which is not generally possible in constructive
logic. As an exercise, you might try proving the converse, that is, showing
that `em` can be proved from `dne`.

The classical axioms also give you access to additional patterns of proof that
can be justified by appeal to `em`. For example, one can carry out a proof by
cases:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byCases
        (fun h1 : p => h1)
        (fun h1 : ¬p => absurd h1 h)
    

Or you can carry out a proof by contradiction:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byContradiction
        (fun h1 : ¬p =>
         show False from h h1)
    

If you are not used to thinking constructively, it may take some time for you
to get a sense of where classical reasoning is used. It is needed in the
following example because, from a constructive standpoint, knowing that `p`
and `q` are not both true does not necessarily tell you which one is false:

    
    
    open Classical
    variable (p q : Prop)
    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=
      Or.elim (em p)
        (fun hp : p =>
          Or.inr
            (show ¬q from
              fun hq : q =>
              h ⟨hp, hq⟩))
        (fun hp : ¬p =>
          Or.inl hp)
    

We will see later that there _are_ situations in constructive logic where
principles like excluded middle and double-negation elimination are
permissible, and Lean supports the use of classical reasoning in such contexts
without relying on excluded middle.

The full list of axioms that are used in Lean to support classical reasoning
are discussed in [Axioms and Computation](./axioms_and_computation.html).

## Examples of Propositional Validities

Lean's standard library contains proofs of many valid statements of
propositional logic, all of which you are free to use in proofs of your own.
The following list includes a number of common identities.

Commutativity:

  1. `p ∧ q ↔ q ∧ p`
  2. `p ∨ q ↔ q ∨ p`

Associativity:

  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`
  4. `(p ∨ q) ∨ r ↔ p ∨ (q �
2025-06-01 02:51:57,286 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.'}], 'model': 'o3-mini'}}
2025-06-01 02:51:57,286 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:51:57,287 - DEBUG - close.started
2025-06-01 02:51:57,287 - DEBUG - close.complete
2025-06-01 02:51:57,287 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:51:57,292 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a5c10>
2025-06-01 02:51:57,292 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:51:57,301 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a5bb0>
2025-06-01 02:51:57,301 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:51:57,301 - DEBUG - send_request_headers.complete
2025-06-01 02:51:57,301 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:51:57,301 - DEBUG - send_request_body.complete
2025-06-01 02:51:57,301 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:52:03,296 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:52:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5763'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5768'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199523'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'142ms'), (b'x-request-id', b'req_0a56e21423c18a8123ec0c5c282825f2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b69834e973bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:52:03,296 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:52:03,296 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:52:03,297 - DEBUG - receive_response_body.complete
2025-06-01 02:52:03,297 - DEBUG - response_closed.started
2025-06-01 02:52:03,297 - DEBUG - response_closed.complete
2025-06-01 02:52:03,297 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:52:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5763', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5768', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199523', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '142ms', 'x-request-id': 'req_0a56e21423c18a8123ec0c5c282825f2', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b69834e973bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:52:03,297 - DEBUG - request_id: req_0a56e21423c18a8123ec0c5c282825f2
2025-06-01 02:52:03,297 - INFO - Attempt 1/3
2025-06-01 02:52:03,297 - INFO - Current plan: {
  "plan_summary": "We will create a Lean 4 function that accepts two integers and returns a Boolean value based on whether one integer is positive and the other negative, while treating zero as neither positive nor negative. The solution will first check if either integer is zero and return false immediately, then check the two possible cases where the first integer is positive and the second is negative, or vice versa.",
  "steps": [
    "Define the function with two integer parameters and a Boolean return type.",
    "Check if either integer is equal to zero. If yes, return false.",
    "Otherwise, use conditional checks to see if a > 0 and b < 0, or if a < 0 and b > 0.",
    "Return true if either condition holds; else, return false."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "if statement",
    "integer comparison",
    "Boolean"
  ],
  "proof_keywords": [
    "constructed case analysis",
    "conditional reasoning",
    "exhaustive checking"
  ],
  "assumptions": [
    "Zero is neither positive nor negative",
    "Integer ordering is implemented as expected in Lean 4",
    "The function only needs to check the sign relations and does not require additional error handling"
  ],
  "retry_guidance": "If previous errors indicate issues with condition evaluation or type mismatches, double-check the use of comparisons (>, <) and ensure that the function correctly handles the case when either input is zero."
}
2025-06-01 02:52:03,298 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "We will create a Lean 4 function that accepts two integers and returns a Boolean value based on whether one integer is positive and the other negative, while treating zero as neither positive nor negative. The solution will first check if either integer is zero and return false immediately, then check the two possible cases where the first integer is positive and the second is negative, or vice versa.",\n  "steps": [\n    "Define the function with two integer parameters and a Boolean return type.",\n    "Check if either integer is equal to zero. If yes, return false.",\n    "Otherwise, use conditional checks to see if a > 0 and b < 0, or if a < 0 and b > 0.",\n    "Return true if either condition holds; else, return false."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "if statement",\n    "integer comparison",\n    "Boolean"\n  ],\n  "proof_keywords": [\n    "constructed case analysis",\n    "conditional reasoning",\n    "exhaustive checking"\n  ],\n  "assumptions": [\n    "Zero is neither positive nor negative",\n    "Integer ordering is implemented as expected in Lean 4",\n    "The function only needs to check the sign relations and does not require additional error handling"\n  ],\n  "retry_guidance": "If previous errors indicate issues with condition evaluation or type mismatches, double-check the use of comparisons (>, <) and ensure that the function correctly handles the case when either input is zero."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n� r)`\n\nDistributivity:\n\n  5. `p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)`\n  6. `p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)`\n\nOther properties:\n\n  7. `(p → (q → r)) ↔ (p ∧ q → r)`\n  8. `((p ∨ q) → r) ↔ (p → r) ∧ (q → r)`\n  9. `¬(p ∨ q) ↔ ¬p ∧ ¬q`\n  10. `¬p ∨ ¬q → ¬(p ∧ q)`\n  11. `¬(p ∧ ¬p)`\n  12. `p ∧ ¬q → ¬(p → q)`\n  13. `¬p → (p → q)`\n  14. `(¬p ∨ q) → (p → q)`\n  15. `p ∨ False ↔ p`\n  16. `p ∧ False ↔ False`\n  17. `¬(p ↔ ¬p)`\n  18. `(p → q) → (¬q → ¬p)`\n\nThese require classical reasoning:\n\n  19. `(p → r ∨ s) → ((p → r) ∨ (p → s))`\n  20. `¬(p ∧ q) → ¬p ∨ ¬q`\n  21. `¬(p → q) → p ∧ ¬q`\n  22. `(p → q) → (¬p ∨ q)`\n  23. `(¬q → ¬p) → (p → q)`\n  24. `p ∨ ¬p`\n  25. `(((p → q) → p) → p)`\n\nThe `sorry` identifier magically produces a proof of anything, or provides an\nobject of any data type at all. Of course, it is unsound as a proof method --\nfor example, you can use it to prove `False` \\-- and Lean produces severe\nwarnings when files use or import theorems which depend on it. But it is very\nuseful for building long proofs incrementally. Start writing the proof from\nthe top down, using `sorry` to fill in subproofs. Make sure Lean accepts the\nterm with all the `sorry`\'s; if not, there are errors that you need to\ncorrect. Then go back and replace each `sorry` with an actual proof, until no\nmore remain.\n\nHere is another useful trick. Instead of using `sorry`, you can use an\nunderscore `_` as a placeholder. Recall this tells Lean that the argument is\nimplicit, and should be filled in automatically. If Lean tries to do so and\nfails, it returns with an error message "don\'t know how to synthesize\nplaceholder," followed by the type of the term it is expecting, and all the\nobjects and hypotheses available in the context. In other words, for each\nunresolved placeholder, Lean reports the subgoal that needs to be filled at\nthat point. You can then construct a proof by incrementally filling in these\nplaceholders.\n\nFor reference, here are two sample proofs of validities taken from the list\nabove.\n\n    \n    \n    open Classical\n    \n    -- distributivity\n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=\n      Iff.intro\n        (fun h : p ∧ (q ∨ r) =>\n          have hp : p := h.left\n          Or.elim (h.right)\n            (fun hq : q =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)\n            (fun hr : r =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))\n        (fun h : (p ∧ q) ∨ (p ∧ r) =>\n          Or.elim h\n            (fun hpq : p ∧ q =>\n              have hp : p := hpq.left\n              have hq : q := hpq.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)\n            (fun hpr : p ∧ r =>\n              have hp : p := hpr.left\n              have hr : r := hpr.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))\n    \n    -- an example that requires classical reasoning\n    example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=\n      fun h : ¬(p ∧ ¬q) =>\n      fun hp : p =>\n      show q from\n        Or.elim (em q)\n          (fun hq : q => hq)\n          (fun hnq : ¬q => absurd (And.intro hp hnq) h)\n    \n\n## Exercises\n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs.\n\n    \n    \n    variable (p q r : Prop)\n    \n    -- commutativity of ∧ and ∨\n    example : p ∧ q ↔ q ∧ p := sorry\n    example : p ∨ q ↔ q ∨ p := sorry\n    \n    -- associativity of ∧ and ∨\n    example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry\n    example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry\n    \n    -- distributivity\n    example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry\n    example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry\n    \n    -- other properties\n    example : (p → (q → r)) ↔ (p ∧ q → r) := sorry\n    example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry\n    example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry\n    example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry\n    example : ¬(p ∧ ¬p) := sorry\n    example : p ∧ ¬q → ¬(p → q) := sorry\n    example : ¬p → (p → q) := sorry\n    example : (¬p ∨ q) → (p → q) := sorry\n    example : p ∨ False ↔ p := sorry\n    example : p ∧ False ↔ False := sorry\n    example : (p → q) → (¬q → ¬p) := sorry\n    \n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs. These require classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (p q r : Prop)\n    \n    example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry\n    example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry\n    example : ¬(p → q) → p ∧ ¬q := sorry\n    example : (p → q) → (¬p ∨ q) := sorry\n    example : (¬q → ¬p) → (p → q) := sorry\n    example : p ∨ ¬p := sorry\n    example : (((p → q) → p) → p) := sorry\n    \n\nProve `¬(p ↔ ¬p)` without using classical logic.\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Propositions and Proofs\n\nBy now, you have seen some ways of defining objects and functions in Lean. In\nthis chapter, we will begin to explain how to write mathematical assertions\nand proofs in the language of dependent type theory as well.\n\n## Propositions as Types\n\nOne strategy for proving assertions about objects defined in the language of\ndependent type theory is to layer an assertion language and a proof language\non top of the definition language. But there is no reason to multiply\nlanguages in this way: dependent type theory is flexible and expressive, and\nthere is no reason we cannot represent assertions and proofs in the same\ngeneral framework.\n\nFor example, we could introduce a new type, `Prop`, to represent propositions,\nand introduce constructors to build new propositions from others.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    #check And     -- Prop → Prop → Prop\n    #check Or      -- Prop → Prop → Prop\n    #check Not     -- Prop → Prop\n    #check Implies -- Prop → Prop → Prop\n    \n    variable (p q r : Prop)\n    #check And p q                      -- Prop\n    #check Or (And p q) r               -- Prop\n    #check Implies (And p q) (And q p)  -- Prop\n    \n\nWe could then introduce, for each element `p : Prop`, another type `Proof p`,\nfor the type of proofs of `p`. An "axiom" would be a constant of such a type.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    #check Proof   -- Proof : Prop → Type\n    \n    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))\n    \n    variable (p q : Prop)\n    #check and_comm p q     -- Proof (Implies (And p q) (And q p))\n    \n\nIn addition to axioms, however, we would also need rules to build new proofs\nfrom old ones. For example, in many proof systems for propositional logic, we\nhave the rule of _modus ponens_ :\n\n> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.\n\nWe could represent this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q\n    \n\nSystems of natural deduction for propositional logic also typically rely on\nthe following rule:\n\n> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we\n> can "cancel" the hypothesis and obtain a proof of `Implies p q`.\n\nWe could render this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)\n    \n\nThis approach would provide us with a reasonable way of building assertions\nand proofs. Determining that an expression `t` is a correct proof of assertion\n`p` would then simply be a matter of checking that `t` has type `Proof p`.\n\nSome simplifications are possible, however. To start with, we can avoid\nwriting the term `Proof` repeatedly by conflating `Proof p` with `p` itself.\nIn other words, whenever we have `p : Prop`, we can interpret `p` as a type,\nnamely, the type of its proofs. We can then read `t : p` as the assertion that\n`t` is a proof of `p`.\n\nMoreover, once we make this identification, the rules for implication show\nthat we can pass back and forth between `Implies p q` and `p → q`. In other\nwords, implication between propositions `p` and `q` corresponds to having a\nfunction that takes any element of `p` to an element of `q`. As a result, the\nintroduction of the connective `Implies` is entirely redundant: we can use the\nusual function space constructor `p → q` from dependent type theory as our\nnotion of implication.\n\nThis is the approach followed in the Calculus of Constructions, and hence in\nLean as well. The fact that the rules for implication in a proof system for\nnatural deduction correspond exactly to the rules governing abstraction and\napplication for functions is an instance of the _Curry-Howard isomorphism_ ,\nsometimes known as the _propositions-as-types_ paradigm. In fact, the type\n`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy\ndescribed in the last chapter. Moreover, `Type u` is also just syntactic sugar\nfor `Sort (u+1)`. `Prop` has some special features, but like the other type\nuniverses, it is closed under the arrow constructor: if we have `p q : Prop`,\nthen `p → q : Prop`.\n\nThere are at least two ways of thinking about propositions as types. To some\nwho take a constructive view of logic and mathematics, this is a faithful\nrendering of what it means to be a proposition: a proposition `p` represents a\nsort of data type, namely, a specification of the type of data that\nconstitutes a proof. A proof of `p` is then simply an object `t : p` of the\nright type.\n\nThose not inclined to this ideology can view it, rather, as a simple coding\ntrick. To each proposition `p` we associate a type that is empty if `p` is\nfalse and has a single element, say `*`, if `p` is true. In the latter case,\nlet us say that (the type associated with) `p` is _inhabited_. It just so\nhappens that the rules for function application and abstraction can\nconveniently help us keep track of which elements of `Prop` are inhabited. So\nconstructing an element `t : p` tells us that `p` is indeed true. You can\nthink of the inhabitant of `p` as being the "fact that `p` is true." A proof\nof `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is\ntrue."\n\nIndeed, if `p : Prop` is any proposition, Lean\'s kernel treats any two\nelements `t1 t2 : p` as being definitionally equal, much the same way as it\ntreats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as\n_proof irrelevance,_ and is consistent with the interpretation in the last\nparagraph. It means that even though we can treat proofs `t : p` as ordinary\nobjects in the language of dependent type theory, they carry no information\nbeyond the fact that `p` is true.\n\nThe two ways we have suggested thinking about the propositions-as-types\nparadigm differ in a fundamental way. From the constructive point of view,\nproofs are abstract mathematical objects that are _denoted_ by suitable\nexpressions in dependent type theory. In contrast, if we think in terms of the\ncoding trick described above, then the expressions themselves do not denote\nanything interesting. Rather, it is the fact that we can write them down and\ncheck that they are well-typed that ensures that the proposition in question\nis true. In other words, the expressions _themselves_ are the proofs.\n\nIn the exposition below, we will slip back and forth between these two ways of\ntalking, at times saying that an expression "constructs" or "produces" or\n"returns" a proof of a proposition, and at other times simply saying that it\n"is" such a proof. This is similar to the way that computer scientists\noccasionally blur the distinction between syntax and semantics by saying, at\ntimes, that a program "computes" a certain function, and at other times\nspeaking as though the program "is" the function in question.\n\nIn any case, all that really matters is the bottom line. To formally express a\nmathematical assertion in the language of dependent type theory, we need to\nexhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a\nterm `t : p`. Lean\'s task, as a proof assistant, is to help us to construct\nsuch a term, `t`, and to verify that it is well-formed and has the correct\ntype.\n\n## Working with Propositions as Types\n\nIn the propositions-as-types paradigm, theorems involving only `→` can be\nproved using lambda abstraction and application. In Lean, the `theorem`\ncommand introduces a new theorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    \n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n\nCompare this proof to the expression `fun x : α => fun y : β => x` of type `α\n→ β → α`, where `α` and `β` are data types. This describes the function that\ntakes arguments `x` and `y` of type `α` and `β`, respectively, and returns\n`x`. The proof of `t1` has the same form, the only difference being that `p`\nand `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of\n`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis\n(trivially) to establish that the conclusion, `p`, is true.\n\nNote that the `theorem` command is really a version of the `def` command:\nunder the propositions and types correspondence, proving the theorem `p → q →\np` is really the same as defining an element of the associated type. To the\nkernel type checker, there is no difference between the two.\n\nThere are a few pragmatic differences between definitions and theorems,\nhowever. In normal circumstances, it is never necessary to unfold the\n"definition" of a theorem; by proof irrelevance, any two proofs of that\ntheorem are definitionally equal. Once the proof of a theorem is complete,\ntypically we only need to know that the proof exists; it doesn\'t matter what\nthe proof is. In light of that fact, Lean tags proofs as _irreducible_ , which\nserves as a hint to the parser (more precisely, the _elaborator_) that there\nis generally no need to unfold them when processing a file. In fact, Lean is\ngenerally able to process and check proofs in parallel, since assessing the\ncorrectness of one proof does not require knowing the details of another.\n\nAs with definitions, the `#print` command will show you the proof of a\ntheorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n    #print t1\n    \n\nNotice that the lambda abstractions `hp : p` and `hq : q` can be viewed as\ntemporary assumptions in the proof of `t1`. Lean also allows us to specify the\ntype of the final term `hp`, explicitly, with a `show` statement:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p :=\n      fun hp : p =>\n      fun hq : q =>\n      show p from hp\n    \n\nAdding such extra information can improve the clarity of a proof and help\ndetect errors when writing a proof. The `show` command does nothing more than\nannotate the type, and, internally, all the presentations of `t1` that we have\nseen produce the same term.\n\nAs with ordinary definitions, we can move the lambda-abstracted variables to\nthe left of the colon:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    #print t1    -- p → q → p\n    \n\nWe can use the theorem `t1` just as a function application:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    axiom hp : p\n    \n    theorem t2 : q → p := t1 hp\n    \n\nThe `axiom` declaration postulates the existence of an element of the given\ntype and may compromise logical consistency. For example, we can use it to\npostulate that the empty type `False` has an element:\n\n    \n    \n    axiom unsound : False\n    -- Everything follows from false\n    theorem ex : 1 = 0 :=\n      False.elim unsound\n    \n\nDeclaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as\nwitnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`\nthat `p` is true yields the theorem `t1 hp : q → p`.\n\nRecall that we can also write theorem `t1` as follows:\n\n    \n    \n    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp\n    \n    #print t1\n    \n\nThe type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the\nassertion "for every pair of propositions `p q`, we have `p → q → p`." For\nexample, we can move all parameters to the right of the colon:\n\n    \n    \n    theorem t1 : ∀ {p q : Prop}, p → q → p :=\n      fun {p q : Prop} (hp : p) (hq : q) => hp\n    \n\nIf `p` and `q` have been declared as variables, Lean will generalize them for\nus automatically:\n\n    \n    \n    variable {p q : Prop}\n    \n    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp\n    \n\nIn fact, by the propositions-as-types correspondence, we can declare the\nassumption `hp` that `p` holds, as another variable:\n\n    \n    \n    variable {p q : Prop}\n    variable (hp : p)\n    \n    theorem t1 : q → p := fun (hq : q) => hp\n    \n\nLean detects that the proof uses `hp` and automatically adds `hp : p` as a\npremise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →\nq → p`. Remember that this type can just as well be written `∀ (p q : Prop)\n(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type\nin which the target does not depend on the bound variable.\n\nWhen we generalize `t1` in such a way, we can then apply it to different pairs\nof propositions, to obtain different instances of the general theorem.\n\n    \n    \n    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp\n    \n    variable (p q r s : Prop)\n    \n    #check t1 p q                -- p → q → p\n    #check t1 r s                -- r → s → r\n    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s\n    \n    variable (h : r → s)\n    #check t1 (r → s) (s → r) h  -- (s → r) → r → s\n    \n\nOnce again, using the propositions-as-types correspondence, the variable `h`\nof type `r → s` can be viewed as the hypothesis, or premise, that `r → s`\nholds.\n\nAs another example, let us consider the composition function discussed in the\nlast chapter, now with propositions instead of types.\n\n    \n    \n    variable (p q r s : Prop)\n    \n    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=\n      fun h₃ : p =>\n      show r from h₁ (h₂ h₃)\n    \n\nAs a theorem of propositional logic, what does `t2` say?\n\nNote that it is often useful to use numeric unicode subscripts, entered as\n`\\0`, `\\1`, `\\2`, ..., for hypotheses, as we did in this example.\n\n## Propositional Logic\n\nLean defines all the standard logical connectives and notation. The\npropositional connectives come with the following notation:\n\nAscii| Unicode| Editor shortcut| Definition  \n---|---|---|---  \nTrue| | | True  \nFalse| | | False  \nNot| ¬| `\\not`, `\\neg`| Not  \n/\\| ∧| `\\and`| And  \n\\/| ∨| `\\or`| Or  \n->| →| `\\to`, `\\r`, `\\imp`|   \n<->| ↔| `\\iff`, `\\lr`| Iff  \n  \nThey all take values in `Prop`.\n\n    \n    \n    variable (p q : Prop)\n    \n    #check p → q → p ∧ q\n    #check ¬p → p ↔ False\n    #check p ∨ q → q ∨ p\n    \n\nThe order of operations is as follows: unary negation `¬` binds most strongly,\nthen `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧\ne` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right\n(nothing changes now that the arguments are elements of `Prop`, instead of\nsome other `Type`), as do the other binary connectives. So if we have `p q r :\nProp`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This\nis just the "curried" form of `p ∧ q → r`.\n\nIn the last chapter we observed that lambda abstraction can be viewed as an\n"introduction rule" for `→`. In the current setting, it shows how to\n"introduce" or establish an implication. Application can be viewed as an\n"elimination rule," showing how to "eliminate" or use an implication in a\nproof. The other propositional connectives are defined in Lean\'s library in\nthe file `Prelude.core` (see [importing\nfiles](./interacting_with_lean.html#importing-files) for more information on\nthe library hierarchy), and each connective comes with its canonical\nintroduction and elimination rules.\n\n### Conjunction\n\nThe expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :\np` and `h2 : q`. It is common to describe `And.intro` as the _and-\nintroduction_ rule. In the next example we use `And.intro` to create a proof\nof `p → q → p ∧ q`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq\n    \n    #check fun (hp : p) (hq : q) => And.intro hp hq\n    \n\nThe `example` command states a theorem without naming it or storing it in the\npermanent context. Essentially, it just checks that the given term has the\nindicated type. It is convenient for illustration, and we will use it often.\n\nThe expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.\nSimilarly, `And.right h` is a proof of `q`. They are commonly known as the\nleft and right _and-elimination_ rules.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : p := And.left h\n    example (h : p ∧ q) : q := And.right h\n    \n\nWe can now prove `p ∧ q → q ∧ p` with the following proof term.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      And.intro (And.right h) (And.left h)\n    \n\nNotice that and-introduction and and-elimination are similar to the pairing\nand projection operations for the Cartesian product. The difference is that\ngiven `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while\n`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is\nanother instance of the Curry-Howard isomorphism, but in contrast to\nimplication and the function space constructor, `∧` and `×` are treated\nseparately in Lean. With the analogy, however, the proof we have just\nconstructed is similar to a function that swaps the elements of a pair.\n\nWe will see in [Chapter Structures and Records](./structures_and_records.html)\nthat certain types in Lean are _structures_ , which is to say, the type is\ndefined with a single canonical _constructor_ which builds an element of the\ntype from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is\nan example: the canonical way to construct an element is to apply `And.intro`\nto suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous\nconstructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the\nrelevant type is an inductive type and can be inferred from the context. In\nparticular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:\n\n    \n    \n    variable (p q : Prop)\n    variable (hp : p) (hq : q)\n    \n    #check (⟨hp, hq⟩ : p ∧ q)\n    \n\nThese angle brackets are obtained by typing `\\<` and `\\>`, respectively.\n\nLean provides another useful syntactic gadget. Given an expression `e` of an\ninductive type `Foo` (possibly applied to some arguments), the notation\n`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of\naccessing functions without opening a namespace. For example, the following\ntwo expressions mean the same thing:\n\n    \n    \n    variable (xs : List Nat)\n    \n    #check List.length xs\n    #check xs.length\n    \n\nAs a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and\n`h.right` for `And.right h`. We can therefore rewrite the sample proof above\nconveniently as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      ⟨h.right, h.left⟩\n    \n\nThere is a fine line between brevity and obfuscation, and omitting information\nin this way can sometimes make a proof harder to read. But for straightforward\nconstructions like the one above, when the type of `h` and the goal of the\nconstruction are salient, the notation is clean and effective.\n\nIt is common to iterate constructions like "And." Lean also allows you to\nflatten nested constructors that associate to the right, so that these two\nproofs are equivalent:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, ⟨h.left, h.right⟩⟩\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, h.left, h.right⟩\n    \n\nThis is often useful as well.\n\n### Disjunction\n\nThe expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof\n`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a\nproof `hq : q`. These are the left and right _or-introduction_ rules.\n\n    \n    \n    variable (p q : Prop)\n    example (hp : p) : p ∨ q := Or.intro_left q hp\n    example (hq : q) : p ∨ q := Or.intro_right p hq\n    \n\nThe _or-elimination_ rule is slightly more complicated. The idea is that we\ncan prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`\nfollows from `q`. In other words, it is a proof by cases. In the expression\n`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :\np → r` and `hqr : q → r`, and produces a proof of `r`. In the following\nexample, we use `Or.elim` to prove `p ∨ q → q ∨ p`.\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h\n        (fun hp : p =>\n          show q ∨ p from Or.intro_right q hp)\n        (fun hq : q =>\n          show q ∨ p from Or.intro_left p hq)\n    \n\nIn most cases, the first argument of `Or.intro_right` and `Or.intro_left` can\nbe inferred automatically by Lean. Lean therefore provides `Or.inr` and\n`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and\n`Or.intro_left _`. Thus the proof term above could be written more concisely:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nNotice that there is enough information in the full expression for Lean to\ninfer the types of `hp` and `hq` as well. But using the type annotations in\nthe longer version makes the proof more readable, and can help catch and debug\nerrors.\n\nBecause `Or` has two constructors, we cannot use anonymous constructor\nnotation. But we can still write `h.elim` instead of `Or.elim h`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nOnce again, you should exercise judgment as to whether such abbreviations\nenhance or diminish readability.\n\n### Negation and Falsity\n\nNegation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by\nderiving a contradiction from `p`. Similarly, the expression `hnp hp` produces\na proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both\nthese rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is\nproduced by typing `\\not` or `\\neg`.)\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hpq : p → q) (hnq : ¬q) : ¬p :=\n      fun hp : p =>\n      show False from hnq (hpq hp)\n    \n\nThe connective `False` has a single elimination rule, `False.elim`, which\nexpresses the fact that anything follows from a contradiction. This rule is\nsometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the\n_principle of explosion_.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)\n    \n\nThe arbitrary fact, `q`, that follows from falsity is an implicit argument in\n`False.elim` and is inferred automatically. This pattern, deriving an\narbitrary fact from contradictory hypotheses, is quite common, and is\nrepresented by `absurd`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := absurd hp hnp\n    \n\nHere, for example, is a proof of `¬p → q → (q → p) → r`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=\n      absurd (hqp hq) hnp\n    \n\nIncidentally, just as `False` has only an elimination rule, `True` has only an\nintroduction rule, `True.intro : true`. In other words, `True` is simply true,\nand has a canonical proof, `True.intro`.\n\n### Logical Equivalence\n\nThe expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`\nand `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from\n`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔\nq`. Here is a proof of `p ∧ q ↔ q ∧ p`:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      Iff.intro\n        (fun h : p ∧ q =>\n         show q ∧ p from And.intro (And.right h) (And.left h))\n        (fun h : q ∧ p =>\n         show p ∧ q from And.intro (And.right h) (And.left h))\n    \n    #check and_swap p q    -- p ∧ q ↔ q ∧ p\n    \n    variable (h : p ∧ q)\n    example : q ∧ p := Iff.mp (and_swap p q) h\n    \n\nWe can use the anonymous constructor notation to construct a proof of `p ↔ q`\nfrom proofs of the forward and backward directions, and we can also use `.`\nnotation with `mp` and `mpr`. The previous examples can therefore be written\nconcisely as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩\n    \n    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h\n    \n\n## Introducing Auxiliary Subgoals\n\nThis is a good place to introduce another device Lean offers to help structure\nlong proofs, namely, the `have` construct, which introduces an auxiliary\nsubgoal in a proof. Here is a small example, adapted from the last section:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      have hq : q := h.right\n      show q ∧ p from And.intro hq hp\n    \n\nInternally, the expression `have h : p := s; t` produces the term `(fun (h :\np) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the\ndesired conclusion assuming `h : p`, and the two are combined by a lambda\nabstraction and application. This simple device is extremely useful when it\ncomes to structuring long proofs, since we can use intermediate `have`\'s as\nstepping stones leading to the final goal.\n\nLean also supports a structured way of reasoning backwards from a goal, which\nmodels the "suffices to show" construction in ordinary mathematics. The next\nexample simply permutes the last two lines in the previous proof.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      suffices hq : q from And.intro hq hp\n      show q from And.right h\n    \n\nWriting `suffices hq : q` leaves us with two goals. First, we have to show\nthat it indeed suffices to show `q`, by proving the original goal of `q ∧ p`\nwith the additional hypothesis `hq : q`. Finally, we have to show `q`.\n\n## Classical Logic\n\nThe introduction and elimination rules we have seen so far are all\nconstructive, which is to say, they reflect a computational understanding of\nthe logical connectives based on the propositions-as-types correspondence.\nOrdinary classical logic adds to this the law of the excluded middle, `p ∨\n¬p`. To use this principle, you have to open the classical namespace.\n\n    \n    \n    open Classical\n    \n    variable (p : Prop)\n    #check em p\n    \n\nIntuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts\nto knowing which is the case. If `RH` represents the Riemann hypothesis, a\nclassical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot\nyet assert either disjunct.\n\nOne consequence of the law of the excluded middle is the principle of double-\nnegation elimination:\n\n    \n    \n    open Classical\n    \n    theorem dne {p : Prop} (h : ¬¬p) : p :=\n      Or.elim (em p)\n        (fun hp : p => hp)\n        (fun hnp : ¬p => absurd hnp h)\n    \n\nDouble-negation elimination allows one to prove any proposition, `p`, by\nassuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In\nother words, double-negation elimination allows one to carry out a proof by\ncontradiction, something which is not generally possible in constructive\nlogic. As an exercise, you might try proving the converse, that is, showing\nthat `em` can be proved from `dne`.\n\nThe classical axioms also give you access to additional patterns of proof that\ncan be justified by appeal to `em`. For example, one can carry out a proof by\ncases:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byCases\n        (fun h1 : p => h1)\n        (fun h1 : ¬p => absurd h1 h)\n    \n\nOr you can carry out a proof by contradiction:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byContradiction\n        (fun h1 : ¬p =>\n         show False from h h1)\n    \n\nIf you are not used to thinking constructively, it may take some time for you\nto get a sense of where classical reasoning is used. It is needed in the\nfollowing example because, from a constructive standpoint, knowing that `p`\nand `q` are not both true does not necessarily tell you which one is false:\n\n    \n    \n    open Classical\n    variable (p q : Prop)\n    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=\n      Or.elim (em p)\n        (fun hp : p =>\n          Or.inr\n            (show ¬q from\n              fun hq : q =>\n              h ⟨hp, hq⟩))\n        (fun hp : ¬p =>\n          Or.inl hp)\n    \n\nWe will see later that there _are_ situations in constructive logic where\nprinciples like excluded middle and double-negation elimination are\npermissible, and Lean supports the use of classical reasoning in such contexts\nwithout relying on excluded middle.\n\nThe full list of axioms that are used in Lean to support classical reasoning\nare discussed in [Axioms and Computation](./axioms_and_computation.html).\n\n## Examples of Propositional Validities\n\nLean\'s standard library contains proofs of many valid statements of\npropositional logic, all of which you are free to use in proofs of your own.\nThe following list includes a number of common identities.\n\nCommutativity:\n\n  1. `p ∧ q ↔ q ∧ p`\n  2. `p ∨ q ↔ q ∨ p`\n\nAssociativity:\n\n  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`\n  4. `(p ∨ q) ∨ r ↔ p ∨ (q �'}], 'model': 'gpt-4o'}}
2025-06-01 02:52:03,299 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:52:03,300 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:52:03,300 - DEBUG - send_request_headers.complete
2025-06-01 02:52:03,300 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:52:03,307 - DEBUG - send_request_body.complete
2025-06-01 02:52:03,307 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:52:09,364 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:52:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4833'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4835'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'14163'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'31.673s'), (b'x-request-id', b'req_1578290f4f36f756967e1b4b77cba892'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b69a8cff23bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:52:09,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:52:09,364 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:52:09,365 - DEBUG - receive_response_body.complete
2025-06-01 02:52:09,365 - DEBUG - response_closed.started
2025-06-01 02:52:09,365 - DEBUG - response_closed.complete
2025-06-01 02:52:09,365 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:52:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4833', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4835', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '14163', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '31.673s', 'x-request-id': 'req_1578290f4f36f756967e1b4b77cba892', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b69a8cff23bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:52:09,365 - DEBUG - request_id: req_1578290f4f36f756967e1b4b77cba892
2025-06-01 02:52:09,365 - INFO - Raw solution received: ```json
{
  "code": "if a = 0 ∨ b = 0 then false else (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0)",
  "proof": "by_cases hz: a = 0 ∨ b = 0\n  case inl =>\n    unfold hasOppositeSign_spec\n    simp [hz]\n    trivial\n  case inr =>\n    unfold hasOppositeSign_spec\n    simp [hz]\n    by_cases hab: (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0)\n    case inl =>\n      simp [hab]\n      trivial\n    case inr =>\n      simp [hab]\n      trivial"
}
```
2025-06-01 02:52:09,365 - INFO - <class 'str'>
2025-06-01 02:52:09,365 - INFO - Generated solution: {'code': 'if a = 0 ∨ b = 0 then false else (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0)', 'proof': 'by_cases hz: a = 0 ∨ b = 0\n  case inl =>\n    unfold hasOppositeSign_spec\n    simp [hz]\n    trivial\n  case inr =>\n    unfold hasOppositeSign_spec\n    simp [hz]\n    by_cases hab: (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0)\n    case inl =>\n      simp [hab]\n      trivial\n    case inr =>\n      simp [hab]\n      trivial'}
2025-06-01 02:52:14,608 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:22:2: error: Case tag 'inl' not found.

Available tags: 'pos._@.lean_playground.TempTest._hyg.119', 'neg._@.lean_playground.TempTest._hyg.119'
2025-06-01 02:52:14,609 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a = 0 ∨ b = 0 then false else (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0)\n\nGenerated Proof:\nby_cases hz: a = 0 ∨ b = 0\n  case inl =>\n    unfold hasOppositeSign_spec\n    simp [hz]\n    trivial\n  case inr =>\n    unfold hasOppositeSign_spec\n    simp [hz]\n    by_cases hab: (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0)\n    case inl =>\n      simp [hab]\n      trivial\n    case inr =>\n      simp [hab]\n      trivial\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:22:2: error: Case tag 'inl' not found.\n\nAvailable tags: 'pos._@.lean_playground.TempTest._hyg.119', 'neg._@.lean_playground.TempTest._hyg.119'"}], 'model': 'o3-mini'}}
2025-06-01 02:52:14,610 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:52:14,610 - DEBUG - close.started
2025-06-01 02:52:14,610 - DEBUG - close.complete
2025-06-01 02:52:14,610 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:52:14,634 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f80590>
2025-06-01 02:52:14,634 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:52:14,661 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f80320>
2025-06-01 02:52:14,661 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:52:14,661 - DEBUG - send_request_headers.complete
2025-06-01 02:52:14,661 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:52:14,661 - DEBUG - send_request_body.complete
2025-06-01 02:52:14,661 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:52:21,512 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:52:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6603'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6607'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199142'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'257ms'), (b'x-request-id', b'req_4db8edc244fa7ad393394b0fe964fb26'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b69efede54436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:52:21,512 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:52:21,512 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:52:21,512 - DEBUG - receive_response_body.complete
2025-06-01 02:52:21,512 - DEBUG - response_closed.started
2025-06-01 02:52:21,512 - DEBUG - response_closed.complete
2025-06-01 02:52:21,512 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:52:21 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6603', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6607', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199142', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '257ms', 'x-request-id': 'req_4db8edc244fa7ad393394b0fe964fb26', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b69efede54436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:52:21,512 - DEBUG - request_id: req_4db8edc244fa7ad393394b0fe964fb26
2025-06-01 02:52:21,513 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "Lean failed with the error: 'Case tag 'inl' not found'. In Lean 4, the by_cases tactic produces cases with tags 'pos' (when the proposition holds) and 'neg' (when it does not); using 'inl' and 'inr' is incorrect.", 'error_type': 'proof', 'suggested_fix': "Replace the case tags 'inl' and 'inr' with 'pos' and 'neg' respectively. For example, rewrite the proof as:\n\nby_cases hz: a = 0 ∨ b = 0\n  case pos =>\n    unfold hasOppositeSign_spec\n    simp [hz]\n    trivial\n  case neg =>\n    unfold hasOppositeSign_spec\n    simp [hz]\n    by_cases hab: (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0)\n    case pos =>\n      simp [hab]\n      trivial\n    case neg =>\n      simp [hab]\n      trivial\n\nThis should align with Lean 4’s naming of the cases.", 'retry_strategy': 'Apply the suggested changes and re-run the proof to check that all cases use the correct case tags.'}
2025-06-01 02:52:21,514 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.\n\nPrevious plan:\n{\n  "plan_summary": "We will create a Lean 4 function that accepts two integers and returns a Boolean value based on whether one integer is positive and the other negative, while treating zero as neither positive nor negative. The solution will first check if either integer is zero and return false immediately, then check the two possible cases where the first integer is positive and the second is negative, or vice versa.",\n  "steps": [\n    "Define the function with two integer parameters and a Boolean return type.",\n    "Check if either integer is equal to zero. If yes, return false.",\n    "Otherwise, use conditional checks to see if a > 0 and b < 0, or if a < 0 and b > 0.",\n    "Return true if either condition holds; else, return false."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "if statement",\n    "integer comparison",\n    "Boolean"\n  ],\n  "proof_keywords": [\n    "constructed case analysis",\n    "conditional reasoning",\n    "exhaustive checking"\n  ],\n  "assumptions": [\n    "Zero is neither positive nor negative",\n    "Integer ordering is implemented as expected in Lean 4",\n    "The function only needs to check the sign relations and does not require additional error handling"\n  ],\n  "retry_guidance": "If previous errors indicate issues with condition evaluation or type mismatches, double-check the use of comparisons (>, <) and ensure that the function correctly handles the case when either input is zero."\n}\n\nLean error:\nLean failed with the error: \'Case tag \'inl\' not found\'. In Lean 4, the by_cases tactic produces cases with tags \'pos\' (when the proposition holds) and \'neg\' (when it does not); using \'inl\' and \'inr\' is incorrect.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 02:52:21,514 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:52:21,514 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:52:21,514 - DEBUG - send_request_headers.complete
2025-06-01 02:52:21,514 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:52:21,515 - DEBUG - send_request_body.complete
2025-06-01 02:52:21,515 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:52:27,194 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:52:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5432'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5435'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199052'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'284ms'), (b'x-request-id', b'req_c68b2613ea7b123e99b4d52c619b176c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6a1abf764436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:52:27,194 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:52:27,194 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:52:27,195 - DEBUG - receive_response_body.complete
2025-06-01 02:52:27,195 - DEBUG - response_closed.started
2025-06-01 02:52:27,195 - DEBUG - response_closed.complete
2025-06-01 02:52:27,195 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:52:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5432', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5435', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199052', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '284ms', 'x-request-id': 'req_c68b2613ea7b123e99b4d52c619b176c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6a1abf764436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:52:27,195 - DEBUG - request_id: req_c68b2613ea7b123e99b4d52c619b176c
2025-06-01 02:52:27,195 - INFO - Attempt 2/3
2025-06-01 02:52:27,195 - INFO - Current plan: {
  "plan_summary": "We will implement a Lean 4 function that determines if two integers have opposite signs by returning true when one is positive and the other is negative, and false otherwise (including cases when either integer is zero). The plan is mostly the same as before; however, we will amend our tactic usage by ensuring that when using by_cases, the cases are labeled with 'pos' and 'neg' instead of 'inl' and 'inr', which avoids the Lean error.",
  "steps": [
    "Define the function with two integer parameters that returns a Boolean value.",
    "Immediately check if either integer equals zero; if so, return false since zero is neither positive nor negative.",
    "Use conditional checks to determine if a > 0 and b < 0 or a < 0 and b > 0.",
    "When using by_cases for any auxiliary proofs or case analysis, ensure the case labels are 'pos' for the proposition holding and 'neg' for the proposition not holding.",
    "Return true if any of the cases for opposite signs is met; otherwise, return false."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "if statement",
    "integer comparison",
    "Boolean",
    "by_cases"
  ],
  "proof_keywords": [
    "case analysis",
    "conditional reasoning",
    "exhaustive checking",
    "by_cases tactic"
  ],
  "assumptions": [
    "Zero is treated as neither positive nor negative",
    "Standard integer comparisons (> and <) in Lean 4 behave as expected",
    "By_cases tactic in Lean 4 produces 'pos' and 'neg' cases rather than 'inl' and 'inr'"
  ],
  "retry_guidance": "Double-check any usage of by_cases to ensure that the tag names 'pos' and 'neg' are used instead of 'inl' and 'inr'. This change addresses the specific Lean error previously encountered."
}
2025-06-01 02:52:27,195 - INFO - Updated plan: {
  "plan_summary": "We will implement a Lean 4 function that determines if two integers have opposite signs by returning true when one is positive and the other is negative, and false otherwise (including cases when either integer is zero). The plan is mostly the same as before; however, we will amend our tactic usage by ensuring that when using by_cases, the cases are labeled with 'pos' and 'neg' instead of 'inl' and 'inr', which avoids the Lean error.",
  "steps": [
    "Define the function with two integer parameters that returns a Boolean value.",
    "Immediately check if either integer equals zero; if so, return false since zero is neither positive nor negative.",
    "Use conditional checks to determine if a > 0 and b < 0 or a < 0 and b > 0.",
    "When using by_cases for any auxiliary proofs or case analysis, ensure the case labels are 'pos' for the proposition holding and 'neg' for the proposition not holding.",
    "Return true if any of the cases for opposite signs is met; otherwise, return false."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "if statement",
    "integer comparison",
    "Boolean",
    "by_cases"
  ],
  "proof_keywords": [
    "case analysis",
    "conditional reasoning",
    "exhaustive checking",
    "by_cases tactic"
  ],
  "assumptions": [
    "Zero is treated as neither positive nor negative",
    "Standard integer comparisons (> and <) in Lean 4 behave as expected",
    "By_cases tactic in Lean 4 produces 'pos' and 'neg' cases rather than 'inl' and 'inr'"
  ],
  "retry_guidance": "Double-check any usage of by_cases to ensure that the tag names 'pos' and 'neg' are used instead of 'inl' and 'inr'. This change addresses the specific Lean error previously encountered."
}

Lean error summary:
Lean failed with the error: 'Case tag 'inl' not found'. In Lean 4, the by_cases tactic produces cases with tags 'pos' (when the proposition holds) and 'neg' (when it does not); using 'inl' and 'inr' is incorrect.
Retry guidance (MUST FOLLOW):
Apply the suggested changes and re-run the proof to check that all cases use the correct case tags.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 02:52:27,196 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "We will implement a Lean 4 function that determines if two integers have opposite signs by returning true when one is positive and the other is negative, and false otherwise (including cases when either integer is zero). The plan is mostly the same as before; however, we will amend our tactic usage by ensuring that when using by_cases, the cases are labeled with \'pos\' and \'neg\' instead of \'inl\' and \'inr\', which avoids the Lean error.",\n  "steps": [\n    "Define the function with two integer parameters that returns a Boolean value.",\n    "Immediately check if either integer equals zero; if so, return false since zero is neither positive nor negative.",\n    "Use conditional checks to determine if a > 0 and b < 0 or a < 0 and b > 0.",\n    "When using by_cases for any auxiliary proofs or case analysis, ensure the case labels are \'pos\' for the proposition holding and \'neg\' for the proposition not holding.",\n    "Return true if any of the cases for opposite signs is met; otherwise, return false."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "if statement",\n    "integer comparison",\n    "Boolean",\n    "by_cases"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "conditional reasoning",\n    "exhaustive checking",\n    "by_cases tactic"\n  ],\n  "assumptions": [\n    "Zero is treated as neither positive nor negative",\n    "Standard integer comparisons (> and <) in Lean 4 behave as expected",\n    "By_cases tactic in Lean 4 produces \'pos\' and \'neg\' cases rather than \'inl\' and \'inr\'"\n  ],\n  "retry_guidance": "Double-check any usage of by_cases to ensure that the tag names \'pos\' and \'neg\' are used instead of \'inl\' and \'inr\'. This change addresses the specific Lean error previously encountered."\n}\n\nLean error summary:\nLean failed with the error: \'Case tag \'inl\' not found\'. In Lean 4, the by_cases tactic produces cases with tags \'pos\' (when the proposition holds) and \'neg\' (when it does not); using \'inl\' and \'inr\' is incorrect.\nRetry guidance (MUST FOLLOW):\nApply the suggested changes and re-run the proof to check that all cases use the correct case tags.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n� r)`\n\nDistributivity:\n\n  5. `p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)`\n  6. `p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)`\n\nOther properties:\n\n  7. `(p → (q → r)) ↔ (p ∧ q → r)`\n  8. `((p ∨ q) → r) ↔ (p → r) ∧ (q → r)`\n  9. `¬(p ∨ q) ↔ ¬p ∧ ¬q`\n  10. `¬p ∨ ¬q → ¬(p ∧ q)`\n  11. `¬(p ∧ ¬p)`\n  12. `p ∧ ¬q → ¬(p → q)`\n  13. `¬p → (p → q)`\n  14. `(¬p ∨ q) → (p → q)`\n  15. `p ∨ False ↔ p`\n  16. `p ∧ False ↔ False`\n  17. `¬(p ↔ ¬p)`\n  18. `(p → q) → (¬q → ¬p)`\n\nThese require classical reasoning:\n\n  19. `(p → r ∨ s) → ((p → r) ∨ (p → s))`\n  20. `¬(p ∧ q) → ¬p ∨ ¬q`\n  21. `¬(p → q) → p ∧ ¬q`\n  22. `(p → q) → (¬p ∨ q)`\n  23. `(¬q → ¬p) → (p → q)`\n  24. `p ∨ ¬p`\n  25. `(((p → q) → p) → p)`\n\nThe `sorry` identifier magically produces a proof of anything, or provides an\nobject of any data type at all. Of course, it is unsound as a proof method --\nfor example, you can use it to prove `False` \\-- and Lean produces severe\nwarnings when files use or import theorems which depend on it. But it is very\nuseful for building long proofs incrementally. Start writing the proof from\nthe top down, using `sorry` to fill in subproofs. Make sure Lean accepts the\nterm with all the `sorry`\'s; if not, there are errors that you need to\ncorrect. Then go back and replace each `sorry` with an actual proof, until no\nmore remain.\n\nHere is another useful trick. Instead of using `sorry`, you can use an\nunderscore `_` as a placeholder. Recall this tells Lean that the argument is\nimplicit, and should be filled in automatically. If Lean tries to do so and\nfails, it returns with an error message "don\'t know how to synthesize\nplaceholder," followed by the type of the term it is expecting, and all the\nobjects and hypotheses available in the context. In other words, for each\nunresolved placeholder, Lean reports the subgoal that needs to be filled at\nthat point. You can then construct a proof by incrementally filling in these\nplaceholders.\n\nFor reference, here are two sample proofs of validities taken from the list\nabove.\n\n    \n    \n    open Classical\n    \n    -- distributivity\n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=\n      Iff.intro\n        (fun h : p ∧ (q ∨ r) =>\n          have hp : p := h.left\n          Or.elim (h.right)\n            (fun hq : q =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)\n            (fun hr : r =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))\n        (fun h : (p ∧ q) ∨ (p ∧ r) =>\n          Or.elim h\n            (fun hpq : p ∧ q =>\n              have hp : p := hpq.left\n              have hq : q := hpq.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)\n            (fun hpr : p ∧ r =>\n              have hp : p := hpr.left\n              have hr : r := hpr.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))\n    \n    -- an example that requires classical reasoning\n    example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=\n      fun h : ¬(p ∧ ¬q) =>\n      fun hp : p =>\n      show q from\n        Or.elim (em q)\n          (fun hq : q => hq)\n          (fun hnq : ¬q => absurd (And.intro hp hnq) h)\n    \n\n## Exercises\n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs.\n\n    \n    \n    variable (p q r : Prop)\n    \n    -- commutativity of ∧ and ∨\n    example : p ∧ q ↔ q ∧ p := sorry\n    example : p ∨ q ↔ q ∨ p := sorry\n    \n    -- associativity of ∧ and ∨\n    example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry\n    example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry\n    \n    -- distributivity\n    example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry\n    example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry\n    \n    -- other properties\n    example : (p → (q → r)) ↔ (p ∧ q → r) := sorry\n    example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry\n    example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry\n    example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry\n    example : ¬(p ∧ ¬p) := sorry\n    example : p ∧ ¬q → ¬(p → q) := sorry\n    example : ¬p → (p → q) := sorry\n    example : (¬p ∨ q) → (p → q) := sorry\n    example : p ∨ False ↔ p := sorry\n    example : p ∧ False ↔ False := sorry\n    example : (p → q) → (¬q → ¬p) := sorry\n    \n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs. These require classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (p q r : Prop)\n    \n    example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry\n    example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry\n    example : ¬(p → q) → p ∧ ¬q := sorry\n    example : (p → q) → (¬p ∨ q) := sorry\n    example : (¬q → ¬p) → (p → q) := sorry\n    example : p ∨ ¬p := sorry\n    example : (((p → q) → p) → p) := sorry\n    \n\nProve `¬(p ↔ ¬p)` without using classical logic.\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Propositions and Proofs\n\nBy now, you have seen some ways of defining objects and functions in Lean. In\nthis chapter, we will begin to explain how to write mathematical assertions\nand proofs in the language of dependent type theory as well.\n\n## Propositions as Types\n\nOne strategy for proving assertions about objects defined in the language of\ndependent type theory is to layer an assertion language and a proof language\non top of the definition language. But there is no reason to multiply\nlanguages in this way: dependent type theory is flexible and expressive, and\nthere is no reason we cannot represent assertions and proofs in the same\ngeneral framework.\n\nFor example, we could introduce a new type, `Prop`, to represent propositions,\nand introduce constructors to build new propositions from others.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    #check And     -- Prop → Prop → Prop\n    #check Or      -- Prop → Prop → Prop\n    #check Not     -- Prop → Prop\n    #check Implies -- Prop → Prop → Prop\n    \n    variable (p q r : Prop)\n    #check And p q                      -- Prop\n    #check Or (And p q) r               -- Prop\n    #check Implies (And p q) (And q p)  -- Prop\n    \n\nWe could then introduce, for each element `p : Prop`, another type `Proof p`,\nfor the type of proofs of `p`. An "axiom" would be a constant of such a type.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    #check Proof   -- Proof : Prop → Type\n    \n    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))\n    \n    variable (p q : Prop)\n    #check and_comm p q     -- Proof (Implies (And p q) (And q p))\n    \n\nIn addition to axioms, however, we would also need rules to build new proofs\nfrom old ones. For example, in many proof systems for propositional logic, we\nhave the rule of _modus ponens_ :\n\n> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.\n\nWe could represent this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q\n    \n\nSystems of natural deduction for propositional logic also typically rely on\nthe following rule:\n\n> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we\n> can "cancel" the hypothesis and obtain a proof of `Implies p q`.\n\nWe could render this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)\n    \n\nThis approach would provide us with a reasonable way of building assertions\nand proofs. Determining that an expression `t` is a correct proof of assertion\n`p` would then simply be a matter of checking that `t` has type `Proof p`.\n\nSome simplifications are possible, however. To start with, we can avoid\nwriting the term `Proof` repeatedly by conflating `Proof p` with `p` itself.\nIn other words, whenever we have `p : Prop`, we can interpret `p` as a type,\nnamely, the type of its proofs. We can then read `t : p` as the assertion that\n`t` is a proof of `p`.\n\nMoreover, once we make this identification, the rules for implication show\nthat we can pass back and forth between `Implies p q` and `p → q`. In other\nwords, implication between propositions `p` and `q` corresponds to having a\nfunction that takes any element of `p` to an element of `q`. As a result, the\nintroduction of the connective `Implies` is entirely redundant: we can use the\nusual function space constructor `p → q` from dependent type theory as our\nnotion of implication.\n\nThis is the approach followed in the Calculus of Constructions, and hence in\nLean as well. The fact that the rules for implication in a proof system for\nnatural deduction correspond exactly to the rules governing abstraction and\napplication for functions is an instance of the _Curry-Howard isomorphism_ ,\nsometimes known as the _propositions-as-types_ paradigm. In fact, the type\n`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy\ndescribed in the last chapter. Moreover, `Type u` is also just syntactic sugar\nfor `Sort (u+1)`. `Prop` has some special features, but like the other type\nuniverses, it is closed under the arrow constructor: if we have `p q : Prop`,\nthen `p → q : Prop`.\n\nThere are at least two ways of thinking about propositions as types. To some\nwho take a constructive view of logic and mathematics, this is a faithful\nrendering of what it means to be a proposition: a proposition `p` represents a\nsort of data type, namely, a specification of the type of data that\nconstitutes a proof. A proof of `p` is then simply an object `t : p` of the\nright type.\n\nThose not inclined to this ideology can view it, rather, as a simple coding\ntrick. To each proposition `p` we associate a type that is empty if `p` is\nfalse and has a single element, say `*`, if `p` is true. In the latter case,\nlet us say that (the type associated with) `p` is _inhabited_. It just so\nhappens that the rules for function application and abstraction can\nconveniently help us keep track of which elements of `Prop` are inhabited. So\nconstructing an element `t : p` tells us that `p` is indeed true. You can\nthink of the inhabitant of `p` as being the "fact that `p` is true." A proof\nof `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is\ntrue."\n\nIndeed, if `p : Prop` is any proposition, Lean\'s kernel treats any two\nelements `t1 t2 : p` as being definitionally equal, much the same way as it\ntreats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as\n_proof irrelevance,_ and is consistent with the interpretation in the last\nparagraph. It means that even though we can treat proofs `t : p` as ordinary\nobjects in the language of dependent type theory, they carry no information\nbeyond the fact that `p` is true.\n\nThe two ways we have suggested thinking about the propositions-as-types\nparadigm differ in a fundamental way. From the constructive point of view,\nproofs are abstract mathematical objects that are _denoted_ by suitable\nexpressions in dependent type theory. In contrast, if we think in terms of the\ncoding trick described above, then the expressions themselves do not denote\nanything interesting. Rather, it is the fact that we can write them down and\ncheck that they are well-typed that ensures that the proposition in question\nis true. In other words, the expressions _themselves_ are the proofs.\n\nIn the exposition below, we will slip back and forth between these two ways of\ntalking, at times saying that an expression "constructs" or "produces" or\n"returns" a proof of a proposition, and at other times simply saying that it\n"is" such a proof. This is similar to the way that computer scientists\noccasionally blur the distinction between syntax and semantics by saying, at\ntimes, that a program "computes" a certain function, and at other times\nspeaking as though the program "is" the function in question.\n\nIn any case, all that really matters is the bottom line. To formally express a\nmathematical assertion in the language of dependent type theory, we need to\nexhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a\nterm `t : p`. Lean\'s task, as a proof assistant, is to help us to construct\nsuch a term, `t`, and to verify that it is well-formed and has the correct\ntype.\n\n## Working with Propositions as Types\n\nIn the propositions-as-types paradigm, theorems involving only `→` can be\nproved using lambda abstraction and application. In Lean, the `theorem`\ncommand introduces a new theorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    \n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n\nCompare this proof to the expression `fun x : α => fun y : β => x` of type `α\n→ β → α`, where `α` and `β` are data types. This describes the function that\ntakes arguments `x` and `y` of type `α` and `β`, respectively, and returns\n`x`. The proof of `t1` has the same form, the only difference being that `p`\nand `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of\n`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis\n(trivially) to establish that the conclusion, `p`, is true.\n\nNote that the `theorem` command is really a version of the `def` command:\nunder the propositions and types correspondence, proving the theorem `p → q →\np` is really the same as defining an element of the associated type. To the\nkernel type checker, there is no difference between the two.\n\nThere are a few pragmatic differences between definitions and theorems,\nhowever. In normal circumstances, it is never necessary to unfold the\n"definition" of a theorem; by proof irrelevance, any two proofs of that\ntheorem are definitionally equal. Once the proof of a theorem is complete,\ntypically we only need to know that the proof exists; it doesn\'t matter what\nthe proof is. In light of that fact, Lean tags proofs as _irreducible_ , which\nserves as a hint to the parser (more precisely, the _elaborator_) that there\nis generally no need to unfold them when processing a file. In fact, Lean is\ngenerally able to process and check proofs in parallel, since assessing the\ncorrectness of one proof does not require knowing the details of another.\n\nAs with definitions, the `#print` command will show you the proof of a\ntheorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n    #print t1\n    \n\nNotice that the lambda abstractions `hp : p` and `hq : q` can be viewed as\ntemporary assumptions in the proof of `t1`. Lean also allows us to specify the\ntype of the final term `hp`, explicitly, with a `show` statement:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p :=\n      fun hp : p =>\n      fun hq : q =>\n      show p from hp\n    \n\nAdding such extra information can improve the clarity of a proof and help\ndetect errors when writing a proof. The `show` command does nothing more than\nannotate the type, and, internally, all the presentations of `t1` that we have\nseen produce the same term.\n\nAs with ordinary definitions, we can move the lambda-abstracted variables to\nthe left of the colon:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    #print t1    -- p → q → p\n    \n\nWe can use the theorem `t1` just as a function application:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    axiom hp : p\n    \n    theorem t2 : q → p := t1 hp\n    \n\nThe `axiom` declaration postulates the existence of an element of the given\ntype and may compromise logical consistency. For example, we can use it to\npostulate that the empty type `False` has an element:\n\n    \n    \n    axiom unsound : False\n    -- Everything follows from false\n    theorem ex : 1 = 0 :=\n      False.elim unsound\n    \n\nDeclaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as\nwitnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`\nthat `p` is true yields the theorem `t1 hp : q → p`.\n\nRecall that we can also write theorem `t1` as follows:\n\n    \n    \n    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp\n    \n    #print t1\n    \n\nThe type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the\nassertion "for every pair of propositions `p q`, we have `p → q → p`." For\nexample, we can move all parameters to the right of the colon:\n\n    \n    \n    theorem t1 : ∀ {p q : Prop}, p → q → p :=\n      fun {p q : Prop} (hp : p) (hq : q) => hp\n    \n\nIf `p` and `q` have been declared as variables, Lean will generalize them for\nus automatically:\n\n    \n    \n    variable {p q : Prop}\n    \n    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp\n    \n\nIn fact, by the propositions-as-types correspondence, we can declare the\nassumption `hp` that `p` holds, as another variable:\n\n    \n    \n    variable {p q : Prop}\n    variable (hp : p)\n    \n    theorem t1 : q → p := fun (hq : q) => hp\n    \n\nLean detects that the proof uses `hp` and automatically adds `hp : p` as a\npremise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →\nq → p`. Remember that this type can just as well be written `∀ (p q : Prop)\n(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type\nin which the target does not depend on the bound variable.\n\nWhen we generalize `t1` in such a way, we can then apply it to different pairs\nof propositions, to obtain different instances of the general theorem.\n\n    \n    \n    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp\n    \n    variable (p q r s : Prop)\n    \n    #check t1 p q                -- p → q → p\n    #check t1 r s                -- r → s → r\n    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s\n    \n    variable (h : r → s)\n    #check t1 (r → s) (s → r) h  -- (s → r) → r → s\n    \n\nOnce again, using the propositions-as-types correspondence, the variable `h`\nof type `r → s` can be viewed as the hypothesis, or premise, that `r → s`\nholds.\n\nAs another example, let us consider the composition function discussed in the\nlast chapter, now with propositions instead of types.\n\n    \n    \n    variable (p q r s : Prop)\n    \n    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=\n      fun h₃ : p =>\n      show r from h₁ (h₂ h₃)\n    \n\nAs a theorem of propositional logic, what does `t2` say?\n\nNote that it is often useful to use numeric unicode subscripts, entered as\n`\\0`, `\\1`, `\\2`, ..., for hypotheses, as we did in this example.\n\n## Propositional Logic\n\nLean defines all the standard logical connectives and notation. The\npropositional connectives come with the following notation:\n\nAscii| Unicode| Editor shortcut| Definition  \n---|---|---|---  \nTrue| | | True  \nFalse| | | False  \nNot| ¬| `\\not`, `\\neg`| Not  \n/\\| ∧| `\\and`| And  \n\\/| ∨| `\\or`| Or  \n->| →| `\\to`, `\\r`, `\\imp`|   \n<->| ↔| `\\iff`, `\\lr`| Iff  \n  \nThey all take values in `Prop`.\n\n    \n    \n    variable (p q : Prop)\n    \n    #check p → q → p ∧ q\n    #check ¬p → p ↔ False\n    #check p ∨ q → q ∨ p\n    \n\nThe order of operations is as follows: unary negation `¬` binds most strongly,\nthen `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧\ne` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right\n(nothing changes now that the arguments are elements of `Prop`, instead of\nsome other `Type`), as do the other binary connectives. So if we have `p q r :\nProp`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This\nis just the "curried" form of `p ∧ q → r`.\n\nIn the last chapter we observed that lambda abstraction can be viewed as an\n"introduction rule" for `→`. In the current setting, it shows how to\n"introduce" or establish an implication. Application can be viewed as an\n"elimination rule," showing how to "eliminate" or use an implication in a\nproof. The other propositional connectives are defined in Lean\'s library in\nthe file `Prelude.core` (see [importing\nfiles](./interacting_with_lean.html#importing-files) for more information on\nthe library hierarchy), and each connective comes with its canonical\nintroduction and elimination rules.\n\n### Conjunction\n\nThe expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :\np` and `h2 : q`. It is common to describe `And.intro` as the _and-\nintroduction_ rule. In the next example we use `And.intro` to create a proof\nof `p → q → p ∧ q`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq\n    \n    #check fun (hp : p) (hq : q) => And.intro hp hq\n    \n\nThe `example` command states a theorem without naming it or storing it in the\npermanent context. Essentially, it just checks that the given term has the\nindicated type. It is convenient for illustration, and we will use it often.\n\nThe expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.\nSimilarly, `And.right h` is a proof of `q`. They are commonly known as the\nleft and right _and-elimination_ rules.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : p := And.left h\n    example (h : p ∧ q) : q := And.right h\n    \n\nWe can now prove `p ∧ q → q ∧ p` with the following proof term.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      And.intro (And.right h) (And.left h)\n    \n\nNotice that and-introduction and and-elimination are similar to the pairing\nand projection operations for the Cartesian product. The difference is that\ngiven `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while\n`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is\nanother instance of the Curry-Howard isomorphism, but in contrast to\nimplication and the function space constructor, `∧` and `×` are treated\nseparately in Lean. With the analogy, however, the proof we have just\nconstructed is similar to a function that swaps the elements of a pair.\n\nWe will see in [Chapter Structures and Records](./structures_and_records.html)\nthat certain types in Lean are _structures_ , which is to say, the type is\ndefined with a single canonical _constructor_ which builds an element of the\ntype from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is\nan example: the canonical way to construct an element is to apply `And.intro`\nto suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous\nconstructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the\nrelevant type is an inductive type and can be inferred from the context. In\nparticular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:\n\n    \n    \n    variable (p q : Prop)\n    variable (hp : p) (hq : q)\n    \n    #check (⟨hp, hq⟩ : p ∧ q)\n    \n\nThese angle brackets are obtained by typing `\\<` and `\\>`, respectively.\n\nLean provides another useful syntactic gadget. Given an expression `e` of an\ninductive type `Foo` (possibly applied to some arguments), the notation\n`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of\naccessing functions without opening a namespace. For example, the following\ntwo expressions mean the same thing:\n\n    \n    \n    variable (xs : List Nat)\n    \n    #check List.length xs\n    #check xs.length\n    \n\nAs a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and\n`h.right` for `And.right h`. We can therefore rewrite the sample proof above\nconveniently as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      ⟨h.right, h.left⟩\n    \n\nThere is a fine line between brevity and obfuscation, and omitting information\nin this way can sometimes make a proof harder to read. But for straightforward\nconstructions like the one above, when the type of `h` and the goal of the\nconstruction are salient, the notation is clean and effective.\n\nIt is common to iterate constructions like "And." Lean also allows you to\nflatten nested constructors that associate to the right, so that these two\nproofs are equivalent:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, ⟨h.left, h.right⟩⟩\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, h.left, h.right⟩\n    \n\nThis is often useful as well.\n\n### Disjunction\n\nThe expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof\n`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a\nproof `hq : q`. These are the left and right _or-introduction_ rules.\n\n    \n    \n    variable (p q : Prop)\n    example (hp : p) : p ∨ q := Or.intro_left q hp\n    example (hq : q) : p ∨ q := Or.intro_right p hq\n    \n\nThe _or-elimination_ rule is slightly more complicated. The idea is that we\ncan prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`\nfollows from `q`. In other words, it is a proof by cases. In the expression\n`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :\np → r` and `hqr : q → r`, and produces a proof of `r`. In the following\nexample, we use `Or.elim` to prove `p ∨ q → q ∨ p`.\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h\n        (fun hp : p =>\n          show q ∨ p from Or.intro_right q hp)\n        (fun hq : q =>\n          show q ∨ p from Or.intro_left p hq)\n    \n\nIn most cases, the first argument of `Or.intro_right` and `Or.intro_left` can\nbe inferred automatically by Lean. Lean therefore provides `Or.inr` and\n`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and\n`Or.intro_left _`. Thus the proof term above could be written more concisely:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nNotice that there is enough information in the full expression for Lean to\ninfer the types of `hp` and `hq` as well. But using the type annotations in\nthe longer version makes the proof more readable, and can help catch and debug\nerrors.\n\nBecause `Or` has two constructors, we cannot use anonymous constructor\nnotation. But we can still write `h.elim` instead of `Or.elim h`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nOnce again, you should exercise judgment as to whether such abbreviations\nenhance or diminish readability.\n\n### Negation and Falsity\n\nNegation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by\nderiving a contradiction from `p`. Similarly, the expression `hnp hp` produces\na proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both\nthese rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is\nproduced by typing `\\not` or `\\neg`.)\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hpq : p → q) (hnq : ¬q) : ¬p :=\n      fun hp : p =>\n      show False from hnq (hpq hp)\n    \n\nThe connective `False` has a single elimination rule, `False.elim`, which\nexpresses the fact that anything follows from a contradiction. This rule is\nsometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the\n_principle of explosion_.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)\n    \n\nThe arbitrary fact, `q`, that follows from falsity is an implicit argument in\n`False.elim` and is inferred automatically. This pattern, deriving an\narbitrary fact from contradictory hypotheses, is quite common, and is\nrepresented by `absurd`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := absurd hp hnp\n    \n\nHere, for example, is a proof of `¬p → q → (q → p) → r`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=\n      absurd (hqp hq) hnp\n    \n\nIncidentally, just as `False` has only an elimination rule, `True` has only an\nintroduction rule, `True.intro : true`. In other words, `True` is simply true,\nand has a canonical proof, `True.intro`.\n\n### Logical Equivalence\n\nThe expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`\nand `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from\n`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔\nq`. Here is a proof of `p ∧ q ↔ q ∧ p`:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      Iff.intro\n        (fun h : p ∧ q =>\n         show q ∧ p from And.intro (And.right h) (And.left h))\n        (fun h : q ∧ p =>\n         show p ∧ q from And.intro (And.right h) (And.left h))\n    \n    #check and_swap p q    -- p ∧ q ↔ q ∧ p\n    \n    variable (h : p ∧ q)\n    example : q ∧ p := Iff.mp (and_swap p q) h\n    \n\nWe can use the anonymous constructor notation to construct a proof of `p ↔ q`\nfrom proofs of the forward and backward directions, and we can also use `.`\nnotation with `mp` and `mpr`. The previous examples can therefore be written\nconcisely as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩\n    \n    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h\n    \n\n## Introducing Auxiliary Subgoals\n\nThis is a good place to introduce another device Lean offers to help structure\nlong proofs, namely, the `have` construct, which introduces an auxiliary\nsubgoal in a proof. Here is a small example, adapted from the last section:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      have hq : q := h.right\n      show q ∧ p from And.intro hq hp\n    \n\nInternally, the expression `have h : p := s; t` produces the term `(fun (h :\np) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the\ndesired conclusion assuming `h : p`, and the two are combined by a lambda\nabstraction and application. This simple device is extremely useful when it\ncomes to structuring long proofs, since we can use intermediate `have`\'s as\nstepping stones leading to the final goal.\n\nLean also supports a structured way of reasoning backwards from a goal, which\nmodels the "suffices to show" construction in ordinary mathematics. The next\nexample simply permutes the last two lines in the previous proof.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      suffices hq : q from And.intro hq hp\n      show q from And.right h\n    \n\nWriting `suffices hq : q` leaves us with two goals. First, we have to show\nthat it indeed suffices to show `q`, by proving the original goal of `q ∧ p`\nwith the additional hypothesis `hq : q`. Finally, we have to show `q`.\n\n## Classical Logic\n\nThe introduction and elimination rules we have seen so far are all\nconstructive, which is to say, they reflect a computational understanding of\nthe logical connectives based on the propositions-as-types correspondence.\nOrdinary classical logic adds to this the law of the excluded middle, `p ∨\n¬p`. To use this principle, you have to open the classical namespace.\n\n    \n    \n    open Classical\n    \n    variable (p : Prop)\n    #check em p\n    \n\nIntuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts\nto knowing which is the case. If `RH` represents the Riemann hypothesis, a\nclassical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot\nyet assert either disjunct.\n\nOne consequence of the law of the excluded middle is the principle of double-\nnegation elimination:\n\n    \n    \n    open Classical\n    \n    theorem dne {p : Prop} (h : ¬¬p) : p :=\n      Or.elim (em p)\n        (fun hp : p => hp)\n        (fun hnp : ¬p => absurd hnp h)\n    \n\nDouble-negation elimination allows one to prove any proposition, `p`, by\nassuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In\nother words, double-negation elimination allows one to carry out a proof by\ncontradiction, something which is not generally possible in constructive\nlogic. As an exercise, you might try proving the converse, that is, showing\nthat `em` can be proved from `dne`.\n\nThe classical axioms also give you access to additional patterns of proof that\ncan be justified by appeal to `em`. For example, one can carry out a proof by\ncases:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byCases\n        (fun h1 : p => h1)\n        (fun h1 : ¬p => absurd h1 h)\n    \n\nOr you can carry out a proof by contradiction:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byContradiction\n        (fun h1 : ¬p =>\n         show False from h h1)\n    \n\nIf you are not used to thinking constructively, it may take some time for you\nto get a sense of where classical reasoning is used. It is needed in the\nfollowing example because, from a constructive standpoint, knowing that `p`\nand `q` are not both true does not necessarily tell you which one is false:\n\n    \n    \n    open Classical\n    variable (p q : Prop)\n    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=\n      Or.elim (em p)\n        (fun hp : p =>\n          Or.inr\n            (show ¬q from\n              fun hq : q =>\n              h ⟨hp, hq⟩))\n        (fun hp : ¬p =>\n          Or.inl hp)\n    \n\nWe will see later that there _are_ situations in constructive logic where\nprinciples like excluded middle and double-negation elimination are\npermissible, and Lean supports the use of classical reasoning in such contexts\nwithout relying on excluded middle.\n\nThe full list of axioms that are used in Lean to support classical reasoning\nare discussed in [Axioms and Computation](./axioms_and_computation.html).\n\n## Examples of Propositional Validities\n\nLean\'s standard library contains proofs of many valid statements of\npropositional logic, all of which you are free to use in proofs of your own.\nThe following list includes a number of common identities.\n\nCommutativity:\n\n  1. `p ∧ q ↔ q ∧ p`\n  2. `p ∨ q ↔ q ∨ p`\n\nAssociativity:\n\n  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`\n  4. `(p ∨ q) ∨ r ↔ p ∨ (q �'}], 'model': 'gpt-4o'}}
2025-06-01 02:52:27,197 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:52:27,197 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:52:27,198 - DEBUG - send_request_headers.complete
2025-06-01 02:52:27,198 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:52:27,198 - DEBUG - send_request_body.complete
2025-06-01 02:52:27,198 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:52:30,379 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:52:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2829'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2831'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'10644'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'38.71s'), (b'x-request-id', b'req_a320480dccc6d2f8d66bf12835864bb6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6a3e4bfb4436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:52:30,379 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:52:30,379 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:52:30,379 - DEBUG - receive_response_body.complete
2025-06-01 02:52:30,379 - DEBUG - response_closed.started
2025-06-01 02:52:30,380 - DEBUG - response_closed.complete
2025-06-01 02:52:30,380 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:52:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2829', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2831', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '10644', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '38.71s', 'x-request-id': 'req_a320480dccc6d2f8d66bf12835864bb6', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6a3e4bfb4436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:52:30,380 - DEBUG - request_id: req_a320480dccc6d2f8d66bf12835864bb6
2025-06-01 02:52:30,380 - INFO - Raw solution received: ```json
{
  "code": "if a = 0 ∨ b = 0 then\n    false\n  else if a > 0 ∧ b < 0 then\n    true\n  else if a < 0 ∧ b > 0 then\n    true\n  else\n    false",
  "proof": "by_cases hz : a = 0 ∨ b = 0\n  simp [hz]\n  trivial\nby_cases hab : a > 0 ∧ b < 0\n  simp [hz, hab]\n  trivial\nby_cases hba : a < 0 ∧ b > 0\n  simp [hz, hab, hba]\n  trivial\nsimp at hz hab hba\ndone"
}
```
2025-06-01 02:52:30,380 - INFO - <class 'str'>
2025-06-01 02:52:30,380 - INFO - Generated solution: {'code': 'if a = 0 ∨ b = 0 then\n    false\n  else if a > 0 ∧ b < 0 then\n    true\n  else if a < 0 ∧ b > 0 then\n    true\n  else\n    false', 'proof': 'by_cases hz : a = 0 ∨ b = 0\n  simp [hz]\n  trivial\nby_cases hab : a > 0 ∧ b < 0\n  simp [hz, hab]\n  trivial\nby_cases hba : a < 0 ∧ b > 0\n  simp [hz, hab, hba]\n  trivial\nsimp at hz hab hba\ndone'}
2025-06-01 02:52:35,833 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:30:2: error: tactic 'assumption' failed
case pos
a b : ℤ
hz : a = 0 ∨ b = 0
⊢ (a < 0 → b ≤ 0) ∧ (0 < a → 0 ≤ b)
lean_playground/TempTest.lean:31:0: error: unexpected identifier; expected command
2025-06-01 02:52:35,835 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a = 0 ∨ b = 0 then\n    false\n  else if a > 0 ∧ b < 0 then\n    true\n  else if a < 0 ∧ b > 0 then\n    true\n  else\n    false\n\nGenerated Proof:\nby_cases hz : a = 0 ∨ b = 0\n  simp [hz]\n  trivial\nby_cases hab : a > 0 ∧ b < 0\n  simp [hz, hab]\n  trivial\nby_cases hba : a < 0 ∧ b > 0\n  simp [hz, hab, hba]\n  trivial\nsimp at hz hab hba\ndone\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:30:2: error: tactic 'assumption' failed\ncase pos\na b : ℤ\nhz : a = 0 ∨ b = 0\n⊢ (a < 0 → b ≤ 0) ∧ (0 < a → 0 ≤ b)\nlean_playground/TempTest.lean:31:0: error: unexpected identifier; expected command"}], 'model': 'o3-mini'}}
2025-06-01 02:52:35,835 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:52:35,836 - DEBUG - close.started
2025-06-01 02:52:35,836 - DEBUG - close.complete
2025-06-01 02:52:35,836 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:52:35,843 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f81730>
2025-06-01 02:52:35,843 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:52:35,850 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f83950>
2025-06-01 02:52:35,850 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:52:35,851 - DEBUG - send_request_headers.complete
2025-06-01 02:52:35,851 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:52:35,851 - DEBUG - send_request_body.complete
2025-06-01 02:52:35,851 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:52:50,342 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:52:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'14257'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'14262'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199140'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'258ms'), (b'x-request-id', b'req_89c80ce069cf6ca38b46fe8d4f284c5f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6a743e9b47bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:52:50,342 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:52:50,342 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:52:50,343 - DEBUG - close.started
2025-06-01 02:52:50,343 - DEBUG - close.complete
2025-06-01 02:52:50,344 - DEBUG - close.started
2025-06-01 02:52:50,344 - DEBUG - close.complete
2025-06-01 02:52:50,346 - DEBUG - receive_response_body.complete
2025-06-01 02:52:50,346 - DEBUG - response_closed.started
2025-06-01 02:52:50,346 - DEBUG - response_closed.complete
2025-06-01 02:52:50,346 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:52:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '14257', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '14262', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199140', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '258ms', 'x-request-id': 'req_89c80ce069cf6ca38b46fe8d4f284c5f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6a743e9b47bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:52:50,346 - DEBUG - request_id: req_89c80ce069cf6ca38b46fe8d4f284c5f
2025-06-01 02:52:50,346 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The generated proof script fails in several ways. First, the use of by_cases followed by simp and trivial does not correctly discharge all cases, and the tactic 'assumption' (or its implicit use) fails because the necessary assumptions are not available. In addition, the final use of the identifier 'done' causes a syntax error. Overall, the proof script does not correctly structure the case analysis needed to prove the equivalence, and Lean rejects the proof due to both tactic failures and unexpected identifiers.", 'error_type': 'proof', 'suggested_fix': "Revise the proof to explicitly handle the cases: when a = 0 ∨ b = 0 and when a ≠ 0 ∧ b ≠ 0. For instance, start by doing 'by_cases h0 : a = 0 ∨ b = 0', then in the h0 branch simplify to show that both sides equal false, and in the other branch, use 'split' to prove the two implications. Avoid using tactics like 'trivial' where the goal is nontrivial, and remove the 'done' at the end. Here is an example of a corrected proof:\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  unfold hasOppositeSign_spec hasOppositeSign\n  by_cases h0 : a = 0 ∨ b = 0\n  { simp [h0] }\n  { -- when neither is zero\n    simp [h0]\n    split\n    { intro h; cases h with\n      | inl h₁ => simp [h₁]\n      | inr h₂ => simp [h₂] }\n    { intro h; by_cases hpos : a > 0 ∧ b < 0\n      { simp [hpos] }\n      { by_cases hneg : a < 0 ∧ b > 0\n        { simp [hneg] }\n        { exfalso, -- In the nonzero case, if neither hpos nor hneg holds,\n          -- we get a contradiction with the fact that one must be positive and one negative\n          -- (this step may require additional lemmas about integers)\n          admit } } }\n  }\n  -- Note: Replace 'admit' with a proper proof of the remaining case.", 'retry_strategy': "Revise the proof script by explicitly splitting the equivalence into two implications using 'split' and handle the case analysis with 'by_cases'. Remove ambiguous tactics such as 'trivial' and 'done', and ensure that every case is fully discharged. Once you have fixed the proof structure, recompile to check that the proof passes."}
2025-06-01 02:52:50,347 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.\n\nPrevious plan:\n{\n  "plan_summary": "We will implement a Lean 4 function that determines if two integers have opposite signs by returning true when one is positive and the other is negative, and false otherwise (including cases when either integer is zero). The plan is mostly the same as before; however, we will amend our tactic usage by ensuring that when using by_cases, the cases are labeled with \'pos\' and \'neg\' instead of \'inl\' and \'inr\', which avoids the Lean error.",\n  "steps": [\n    "Define the function with two integer parameters that returns a Boolean value.",\n    "Immediately check if either integer equals zero; if so, return false since zero is neither positive nor negative.",\n    "Use conditional checks to determine if a > 0 and b < 0 or a < 0 and b > 0.",\n    "When using by_cases for any auxiliary proofs or case analysis, ensure the case labels are \'pos\' for the proposition holding and \'neg\' for the proposition not holding.",\n    "Return true if any of the cases for opposite signs is met; otherwise, return false."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "if statement",\n    "integer comparison",\n    "Boolean",\n    "by_cases"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "conditional reasoning",\n    "exhaustive checking",\n    "by_cases tactic"\n  ],\n  "assumptions": [\n    "Zero is treated as neither positive nor negative",\n    "Standard integer comparisons (> and <) in Lean 4 behave as expected",\n    "By_cases tactic in Lean 4 produces \'pos\' and \'neg\' cases rather than \'inl\' and \'inr\'"\n  ],\n  "retry_guidance": "Double-check any usage of by_cases to ensure that the tag names \'pos\' and \'neg\' are used instead of \'inl\' and \'inr\'. This change addresses the specific Lean error previously encountered."\n}\n\nLean error summary:\nLean failed with the error: \'Case tag \'inl\' not found\'. In Lean 4, the by_cases tactic produces cases with tags \'pos\' (when the proposition holds) and \'neg\' (when it does not); using \'inl\' and \'inr\' is incorrect.\nRetry guidance (MUST FOLLOW):\nApply the suggested changes and re-run the proof to check that all cases use the correct case tags.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThe generated proof script fails in several ways. First, the use of by_cases followed by simp and trivial does not correctly discharge all cases, and the tactic \'assumption\' (or its implicit use) fails because the necessary assumptions are not available. In addition, the final use of the identifier \'done\' causes a syntax error. Overall, the proof script does not correctly structure the case analysis needed to prove the equivalence, and Lean rejects the proof due to both tactic failures and unexpected identifiers.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 02:52:50,347 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:52:50,348 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:52:50,348 - DEBUG - send_request_headers.complete
2025-06-01 02:52:50,348 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:52:50,348 - DEBUG - send_request_body.complete
2025-06-01 02:52:50,348 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:52:58,008 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:52:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7426'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7431'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'197681'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'695ms'), (b'x-request-id', b'req_a9001878c20055782c03c9614d04ea7f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6acedfff47bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:52:58,008 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:52:58,008 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:52:58,008 - DEBUG - receive_response_body.complete
2025-06-01 02:52:58,009 - DEBUG - response_closed.started
2025-06-01 02:52:58,009 - DEBUG - response_closed.complete
2025-06-01 02:52:58,009 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:52:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7426', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7431', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '197681', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '695ms', 'x-request-id': 'req_a9001878c20055782c03c9614d04ea7f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6acedfff47bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:52:58,009 - DEBUG - request_id: req_a9001878c20055782c03c9614d04ea7f
2025-06-01 02:52:58,009 - INFO - Attempt 3/3
2025-06-01 02:52:58,009 - INFO - Current plan: {
  "plan_summary": "Revise the function to correctly perform case analysis and complete proof without using incorrect case tags or tactics. We will structure the function with a primary check for zero values and then use explicit conditional tests to determine if one integer is positive and the other negative. In the proof, we will avoid using by_cases with the wrong tags (e.g., 'inl', 'inr') and instead use if-else or explicitly name the cases as 'pos' and 'neg' when necessary. The proof will be restructured to discharge all cases explicitly without relying on tactics that do not match the available assumptions.",
  "steps": [
    "Define the function with two integer parameters that returns a Boolean.",
    "Immediately check whether either of the two integers is zero. If so, return false because zero is neither positive nor negative.",
    "Use explicit if-else constructs to check both cases: one where a > 0 and b < 0, and the other where a < 0 and b > 0. Return true when either condition holds, and false otherwise.",
    "Remove reliance on by_cases if it leads to difficult tactics. If by_cases must be used, explicitly name the drawer cases with 'pos' (for the case when the proposition holds) and 'neg' (for when it does not) to avoid case-tag errors.",
    "For the proof of correctness, perform a detailed case analysis: analyze the case when one of the integers is zero, when both integers have the same nonzero sign, and when they have opposite signs. Use conditional reasoning and ensure that each branch is verified using straightforward, explicit reasoning steps.",
    "Avoid tactics that refer to 'inl' and 'inr' or use of an incorrect tactic like 'done'. Instead, complete each case with a correct application of Lean tactics such as 'simp' or 'exact' as appropriate.",
    "Verify that the proof script does not use 'assumption' in cases where the assumption is not available and that all cases are discharged explicitly."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "if statement",
    "integer comparison",
    "Boolean"
  ],
  "proof_keywords": [
    "case analysis",
    "conditional reasoning",
    "if-else proofs",
    "explicit discharge of cases",
    "by_cases (with proper tagging)"
  ],
  "assumptions": [
    "Zero is neither positive nor negative according to the specification",
    "Using explicit if-else clarifies all cases without malformed tags",
    "Standard integer comparisons (> and <) in Lean 4 behave as specified"
  ],
  "retry_guidance": "Ensure all case analysis uses explicit tagging ('pos' and 'neg') if by_cases is used. Prefer using if-else to perform clear and explicit conditional checks. Avoid tactics that attempt to use undefined identifiers such as 'done' or assumptions from non-existent cases. Discharge each branch thoroughly so that Lean can verify that all cases are handled, and re-run the proof to confirm the changes resolve the errors."
}
2025-06-01 02:52:58,009 - INFO - Updated plan: {
  "plan_summary": "Revise the function to correctly perform case analysis and complete proof without using incorrect case tags or tactics. We will structure the function with a primary check for zero values and then use explicit conditional tests to determine if one integer is positive and the other negative. In the proof, we will avoid using by_cases with the wrong tags (e.g., 'inl', 'inr') and instead use if-else or explicitly name the cases as 'pos' and 'neg' when necessary. The proof will be restructured to discharge all cases explicitly without relying on tactics that do not match the available assumptions.",
  "steps": [
    "Define the function with two integer parameters that returns a Boolean.",
    "Immediately check whether either of the two integers is zero. If so, return false because zero is neither positive nor negative.",
    "Use explicit if-else constructs to check both cases: one where a > 0 and b < 0, and the other where a < 0 and b > 0. Return true when either condition holds, and false otherwise.",
    "Remove reliance on by_cases if it leads to difficult tactics. If by_cases must be used, explicitly name the drawer cases with 'pos' (for the case when the proposition holds) and 'neg' (for when it does not) to avoid case-tag errors.",
    "For the proof of correctness, perform a detailed case analysis: analyze the case when one of the integers is zero, when both integers have the same nonzero sign, and when they have opposite signs. Use conditional reasoning and ensure that each branch is verified using straightforward, explicit reasoning steps.",
    "Avoid tactics that refer to 'inl' and 'inr' or use of an incorrect tactic like 'done'. Instead, complete each case with a correct application of Lean tactics such as 'simp' or 'exact' as appropriate.",
    "Verify that the proof script does not use 'assumption' in cases where the assumption is not available and that all cases are discharged explicitly."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "if statement",
    "integer comparison",
    "Boolean"
  ],
  "proof_keywords": [
    "case analysis",
    "conditional reasoning",
    "if-else proofs",
    "explicit discharge of cases",
    "by_cases (with proper tagging)"
  ],
  "assumptions": [
    "Zero is neither positive nor negative according to the specification",
    "Using explicit if-else clarifies all cases without malformed tags",
    "Standard integer comparisons (> and <) in Lean 4 behave as specified"
  ],
  "retry_guidance": "Ensure all case analysis uses explicit tagging ('pos' and 'neg') if by_cases is used. Prefer using if-else to perform clear and explicit conditional checks. Avoid tactics that attempt to use undefined identifiers such as 'done' or assumptions from non-existent cases. Discharge each branch thoroughly so that Lean can verify that all cases are handled, and re-run the proof to confirm the changes resolve the errors."
}

Lean error summary:
The generated proof script fails in several ways. First, the use of by_cases followed by simp and trivial does not correctly discharge all cases, and the tactic 'assumption' (or its implicit use) fails because the necessary assumptions are not available. In addition, the final use of the identifier 'done' causes a syntax error. Overall, the proof script does not correctly structure the case analysis needed to prove the equivalence, and Lean rejects the proof due to both tactic failures and unexpected identifiers.
Retry guidance (MUST FOLLOW):
Revise the proof script by explicitly splitting the equivalence into two implications using 'split' and handle the case analysis with 'by_cases'. Remove ambiguous tactics such as 'trivial' and 'done', and ensure that every case is fully discharged. Once you have fixed the proof structure, recompile to check that the proof passes.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 02:52:58,010 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the function to correctly perform case analysis and complete proof without using incorrect case tags or tactics. We will structure the function with a primary check for zero values and then use explicit conditional tests to determine if one integer is positive and the other negative. In the proof, we will avoid using by_cases with the wrong tags (e.g., \'inl\', \'inr\') and instead use if-else or explicitly name the cases as \'pos\' and \'neg\' when necessary. The proof will be restructured to discharge all cases explicitly without relying on tactics that do not match the available assumptions.",\n  "steps": [\n    "Define the function with two integer parameters that returns a Boolean.",\n    "Immediately check whether either of the two integers is zero. If so, return false because zero is neither positive nor negative.",\n    "Use explicit if-else constructs to check both cases: one where a > 0 and b < 0, and the other where a < 0 and b > 0. Return true when either condition holds, and false otherwise.",\n    "Remove reliance on by_cases if it leads to difficult tactics. If by_cases must be used, explicitly name the drawer cases with \'pos\' (for the case when the proposition holds) and \'neg\' (for when it does not) to avoid case-tag errors.",\n    "For the proof of correctness, perform a detailed case analysis: analyze the case when one of the integers is zero, when both integers have the same nonzero sign, and when they have opposite signs. Use conditional reasoning and ensure that each branch is verified using straightforward, explicit reasoning steps.",\n    "Avoid tactics that refer to \'inl\' and \'inr\' or use of an incorrect tactic like \'done\'. Instead, complete each case with a correct application of Lean tactics such as \'simp\' or \'exact\' as appropriate.",\n    "Verify that the proof script does not use \'assumption\' in cases where the assumption is not available and that all cases are discharged explicitly."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "if statement",\n    "integer comparison",\n    "Boolean"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "conditional reasoning",\n    "if-else proofs",\n    "explicit discharge of cases",\n    "by_cases (with proper tagging)"\n  ],\n  "assumptions": [\n    "Zero is neither positive nor negative according to the specification",\n    "Using explicit if-else clarifies all cases without malformed tags",\n    "Standard integer comparisons (> and <) in Lean 4 behave as specified"\n  ],\n  "retry_guidance": "Ensure all case analysis uses explicit tagging (\'pos\' and \'neg\') if by_cases is used. Prefer using if-else to perform clear and explicit conditional checks. Avoid tactics that attempt to use undefined identifiers such as \'done\' or assumptions from non-existent cases. Discharge each branch thoroughly so that Lean can verify that all cases are handled, and re-run the proof to confirm the changes resolve the errors."\n}\n\nLean error summary:\nThe generated proof script fails in several ways. First, the use of by_cases followed by simp and trivial does not correctly discharge all cases, and the tactic \'assumption\' (or its implicit use) fails because the necessary assumptions are not available. In addition, the final use of the identifier \'done\' causes a syntax error. Overall, the proof script does not correctly structure the case analysis needed to prove the equivalence, and Lean rejects the proof due to both tactic failures and unexpected identifiers.\nRetry guidance (MUST FOLLOW):\nRevise the proof script by explicitly splitting the equivalence into two implications using \'split\' and handle the case analysis with \'by_cases\'. Remove ambiguous tactics such as \'trivial\' and \'done\', and ensure that every case is fully discharged. Once you have fixed the proof structure, recompile to check that the proof passes.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n� r)`\n\nDistributivity:\n\n  5. `p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)`\n  6. `p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)`\n\nOther properties:\n\n  7. `(p → (q → r)) ↔ (p ∧ q → r)`\n  8. `((p ∨ q) → r) ↔ (p → r) ∧ (q → r)`\n  9. `¬(p ∨ q) ↔ ¬p ∧ ¬q`\n  10. `¬p ∨ ¬q → ¬(p ∧ q)`\n  11. `¬(p ∧ ¬p)`\n  12. `p ∧ ¬q → ¬(p → q)`\n  13. `¬p → (p → q)`\n  14. `(¬p ∨ q) → (p → q)`\n  15. `p ∨ False ↔ p`\n  16. `p ∧ False ↔ False`\n  17. `¬(p ↔ ¬p)`\n  18. `(p → q) → (¬q → ¬p)`\n\nThese require classical reasoning:\n\n  19. `(p → r ∨ s) → ((p → r) ∨ (p → s))`\n  20. `¬(p ∧ q) → ¬p ∨ ¬q`\n  21. `¬(p → q) → p ∧ ¬q`\n  22. `(p → q) → (¬p ∨ q)`\n  23. `(¬q → ¬p) → (p → q)`\n  24. `p ∨ ¬p`\n  25. `(((p → q) → p) → p)`\n\nThe `sorry` identifier magically produces a proof of anything, or provides an\nobject of any data type at all. Of course, it is unsound as a proof method --\nfor example, you can use it to prove `False` \\-- and Lean produces severe\nwarnings when files use or import theorems which depend on it. But it is very\nuseful for building long proofs incrementally. Start writing the proof from\nthe top down, using `sorry` to fill in subproofs. Make sure Lean accepts the\nterm with all the `sorry`\'s; if not, there are errors that you need to\ncorrect. Then go back and replace each `sorry` with an actual proof, until no\nmore remain.\n\nHere is another useful trick. Instead of using `sorry`, you can use an\nunderscore `_` as a placeholder. Recall this tells Lean that the argument is\nimplicit, and should be filled in automatically. If Lean tries to do so and\nfails, it returns with an error message "don\'t know how to synthesize\nplaceholder," followed by the type of the term it is expecting, and all the\nobjects and hypotheses available in the context. In other words, for each\nunresolved placeholder, Lean reports the subgoal that needs to be filled at\nthat point. You can then construct a proof by incrementally filling in these\nplaceholders.\n\nFor reference, here are two sample proofs of validities taken from the list\nabove.\n\n    \n    \n    open Classical\n    \n    -- distributivity\n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=\n      Iff.intro\n        (fun h : p ∧ (q ∨ r) =>\n          have hp : p := h.left\n          Or.elim (h.right)\n            (fun hq : q =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)\n            (fun hr : r =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))\n        (fun h : (p ∧ q) ∨ (p ∧ r) =>\n          Or.elim h\n            (fun hpq : p ∧ q =>\n              have hp : p := hpq.left\n              have hq : q := hpq.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)\n            (fun hpr : p ∧ r =>\n              have hp : p := hpr.left\n              have hr : r := hpr.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))\n    \n    -- an example that requires classical reasoning\n    example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=\n      fun h : ¬(p ∧ ¬q) =>\n      fun hp : p =>\n      show q from\n        Or.elim (em q)\n          (fun hq : q => hq)\n          (fun hnq : ¬q => absurd (And.intro hp hnq) h)\n    \n\n## Exercises\n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs.\n\n    \n    \n    variable (p q r : Prop)\n    \n    -- commutativity of ∧ and ∨\n    example : p ∧ q ↔ q ∧ p := sorry\n    example : p ∨ q ↔ q ∨ p := sorry\n    \n    -- associativity of ∧ and ∨\n    example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry\n    example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry\n    \n    -- distributivity\n    example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry\n    example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry\n    \n    -- other properties\n    example : (p → (q → r)) ↔ (p ∧ q → r) := sorry\n    example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry\n    example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry\n    example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry\n    example : ¬(p ∧ ¬p) := sorry\n    example : p ∧ ¬q → ¬(p → q) := sorry\n    example : ¬p → (p → q) := sorry\n    example : (¬p ∨ q) → (p → q) := sorry\n    example : p ∨ False ↔ p := sorry\n    example : p ∧ False ↔ False := sorry\n    example : (p → q) → (¬q → ¬p) := sorry\n    \n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs. These require classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (p q r : Prop)\n    \n    example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry\n    example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry\n    example : ¬(p → q) → p ∧ ¬q := sorry\n    example : (p → q) → (¬p ∨ q) := sorry\n    example : (¬q → ¬p) → (p → q) := sorry\n    example : p ∨ ¬p := sorry\n    example : (((p → q) → p) → p) := sorry\n    \n\nProve `¬(p ↔ ¬p)` without using classical logic.\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Propositions and Proofs\n\nBy now, you have seen some ways of defining objects and functions in Lean. In\nthis chapter, we will begin to explain how to write mathematical assertions\nand proofs in the language of dependent type theory as well.\n\n## Propositions as Types\n\nOne strategy for proving assertions about objects defined in the language of\ndependent type theory is to layer an assertion language and a proof language\non top of the definition language. But there is no reason to multiply\nlanguages in this way: dependent type theory is flexible and expressive, and\nthere is no reason we cannot represent assertions and proofs in the same\ngeneral framework.\n\nFor example, we could introduce a new type, `Prop`, to represent propositions,\nand introduce constructors to build new propositions from others.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    #check And     -- Prop → Prop → Prop\n    #check Or      -- Prop → Prop → Prop\n    #check Not     -- Prop → Prop\n    #check Implies -- Prop → Prop → Prop\n    \n    variable (p q r : Prop)\n    #check And p q                      -- Prop\n    #check Or (And p q) r               -- Prop\n    #check Implies (And p q) (And q p)  -- Prop\n    \n\nWe could then introduce, for each element `p : Prop`, another type `Proof p`,\nfor the type of proofs of `p`. An "axiom" would be a constant of such a type.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    #check Proof   -- Proof : Prop → Type\n    \n    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))\n    \n    variable (p q : Prop)\n    #check and_comm p q     -- Proof (Implies (And p q) (And q p))\n    \n\nIn addition to axioms, however, we would also need rules to build new proofs\nfrom old ones. For example, in many proof systems for propositional logic, we\nhave the rule of _modus ponens_ :\n\n> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.\n\nWe could represent this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q\n    \n\nSystems of natural deduction for propositional logic also typically rely on\nthe following rule:\n\n> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we\n> can "cancel" the hypothesis and obtain a proof of `Implies p q`.\n\nWe could render this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)\n    \n\nThis approach would provide us with a reasonable way of building assertions\nand proofs. Determining that an expression `t` is a correct proof of assertion\n`p` would then simply be a matter of checking that `t` has type `Proof p`.\n\nSome simplifications are possible, however. To start with, we can avoid\nwriting the term `Proof` repeatedly by conflating `Proof p` with `p` itself.\nIn other words, whenever we have `p : Prop`, we can interpret `p` as a type,\nnamely, the type of its proofs. We can then read `t : p` as the assertion that\n`t` is a proof of `p`.\n\nMoreover, once we make this identification, the rules for implication show\nthat we can pass back and forth between `Implies p q` and `p → q`. In other\nwords, implication between propositions `p` and `q` corresponds to having a\nfunction that takes any element of `p` to an element of `q`. As a result, the\nintroduction of the connective `Implies` is entirely redundant: we can use the\nusual function space constructor `p → q` from dependent type theory as our\nnotion of implication.\n\nThis is the approach followed in the Calculus of Constructions, and hence in\nLean as well. The fact that the rules for implication in a proof system for\nnatural deduction correspond exactly to the rules governing abstraction and\napplication for functions is an instance of the _Curry-Howard isomorphism_ ,\nsometimes known as the _propositions-as-types_ paradigm. In fact, the type\n`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy\ndescribed in the last chapter. Moreover, `Type u` is also just syntactic sugar\nfor `Sort (u+1)`. `Prop` has some special features, but like the other type\nuniverses, it is closed under the arrow constructor: if we have `p q : Prop`,\nthen `p → q : Prop`.\n\nThere are at least two ways of thinking about propositions as types. To some\nwho take a constructive view of logic and mathematics, this is a faithful\nrendering of what it means to be a proposition: a proposition `p` represents a\nsort of data type, namely, a specification of the type of data that\nconstitutes a proof. A proof of `p` is then simply an object `t : p` of the\nright type.\n\nThose not inclined to this ideology can view it, rather, as a simple coding\ntrick. To each proposition `p` we associate a type that is empty if `p` is\nfalse and has a single element, say `*`, if `p` is true. In the latter case,\nlet us say that (the type associated with) `p` is _inhabited_. It just so\nhappens that the rules for function application and abstraction can\nconveniently help us keep track of which elements of `Prop` are inhabited. So\nconstructing an element `t : p` tells us that `p` is indeed true. You can\nthink of the inhabitant of `p` as being the "fact that `p` is true." A proof\nof `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is\ntrue."\n\nIndeed, if `p : Prop` is any proposition, Lean\'s kernel treats any two\nelements `t1 t2 : p` as being definitionally equal, much the same way as it\ntreats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as\n_proof irrelevance,_ and is consistent with the interpretation in the last\nparagraph. It means that even though we can treat proofs `t : p` as ordinary\nobjects in the language of dependent type theory, they carry no information\nbeyond the fact that `p` is true.\n\nThe two ways we have suggested thinking about the propositions-as-types\nparadigm differ in a fundamental way. From the constructive point of view,\nproofs are abstract mathematical objects that are _denoted_ by suitable\nexpressions in dependent type theory. In contrast, if we think in terms of the\ncoding trick described above, then the expressions themselves do not denote\nanything interesting. Rather, it is the fact that we can write them down and\ncheck that they are well-typed that ensures that the proposition in question\nis true. In other words, the expressions _themselves_ are the proofs.\n\nIn the exposition below, we will slip back and forth between these two ways of\ntalking, at times saying that an expression "constructs" or "produces" or\n"returns" a proof of a proposition, and at other times simply saying that it\n"is" such a proof. This is similar to the way that computer scientists\noccasionally blur the distinction between syntax and semantics by saying, at\ntimes, that a program "computes" a certain function, and at other times\nspeaking as though the program "is" the function in question.\n\nIn any case, all that really matters is the bottom line. To formally express a\nmathematical assertion in the language of dependent type theory, we need to\nexhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a\nterm `t : p`. Lean\'s task, as a proof assistant, is to help us to construct\nsuch a term, `t`, and to verify that it is well-formed and has the correct\ntype.\n\n## Working with Propositions as Types\n\nIn the propositions-as-types paradigm, theorems involving only `→` can be\nproved using lambda abstraction and application. In Lean, the `theorem`\ncommand introduces a new theorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    \n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n\nCompare this proof to the expression `fun x : α => fun y : β => x` of type `α\n→ β → α`, where `α` and `β` are data types. This describes the function that\ntakes arguments `x` and `y` of type `α` and `β`, respectively, and returns\n`x`. The proof of `t1` has the same form, the only difference being that `p`\nand `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of\n`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis\n(trivially) to establish that the conclusion, `p`, is true.\n\nNote that the `theorem` command is really a version of the `def` command:\nunder the propositions and types correspondence, proving the theorem `p → q →\np` is really the same as defining an element of the associated type. To the\nkernel type checker, there is no difference between the two.\n\nThere are a few pragmatic differences between definitions and theorems,\nhowever. In normal circumstances, it is never necessary to unfold the\n"definition" of a theorem; by proof irrelevance, any two proofs of that\ntheorem are definitionally equal. Once the proof of a theorem is complete,\ntypically we only need to know that the proof exists; it doesn\'t matter what\nthe proof is. In light of that fact, Lean tags proofs as _irreducible_ , which\nserves as a hint to the parser (more precisely, the _elaborator_) that there\nis generally no need to unfold them when processing a file. In fact, Lean is\ngenerally able to process and check proofs in parallel, since assessing the\ncorrectness of one proof does not require knowing the details of another.\n\nAs with definitions, the `#print` command will show you the proof of a\ntheorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n    #print t1\n    \n\nNotice that the lambda abstractions `hp : p` and `hq : q` can be viewed as\ntemporary assumptions in the proof of `t1`. Lean also allows us to specify the\ntype of the final term `hp`, explicitly, with a `show` statement:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p :=\n      fun hp : p =>\n      fun hq : q =>\n      show p from hp\n    \n\nAdding such extra information can improve the clarity of a proof and help\ndetect errors when writing a proof. The `show` command does nothing more than\nannotate the type, and, internally, all the presentations of `t1` that we have\nseen produce the same term.\n\nAs with ordinary definitions, we can move the lambda-abstracted variables to\nthe left of the colon:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    #print t1    -- p → q → p\n    \n\nWe can use the theorem `t1` just as a function application:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    axiom hp : p\n    \n    theorem t2 : q → p := t1 hp\n    \n\nThe `axiom` declaration postulates the existence of an element of the given\ntype and may compromise logical consistency. For example, we can use it to\npostulate that the empty type `False` has an element:\n\n    \n    \n    axiom unsound : False\n    -- Everything follows from false\n    theorem ex : 1 = 0 :=\n      False.elim unsound\n    \n\nDeclaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as\nwitnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`\nthat `p` is true yields the theorem `t1 hp : q → p`.\n\nRecall that we can also write theorem `t1` as follows:\n\n    \n    \n    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp\n    \n    #print t1\n    \n\nThe type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the\nassertion "for every pair of propositions `p q`, we have `p → q → p`." For\nexample, we can move all parameters to the right of the colon:\n\n    \n    \n    theorem t1 : ∀ {p q : Prop}, p → q → p :=\n      fun {p q : Prop} (hp : p) (hq : q) => hp\n    \n\nIf `p` and `q` have been declared as variables, Lean will generalize them for\nus automatically:\n\n    \n    \n    variable {p q : Prop}\n    \n    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp\n    \n\nIn fact, by the propositions-as-types correspondence, we can declare the\nassumption `hp` that `p` holds, as another variable:\n\n    \n    \n    variable {p q : Prop}\n    variable (hp : p)\n    \n    theorem t1 : q → p := fun (hq : q) => hp\n    \n\nLean detects that the proof uses `hp` and automatically adds `hp : p` as a\npremise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →\nq → p`. Remember that this type can just as well be written `∀ (p q : Prop)\n(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type\nin which the target does not depend on the bound variable.\n\nWhen we generalize `t1` in such a way, we can then apply it to different pairs\nof propositions, to obtain different instances of the general theorem.\n\n    \n    \n    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp\n    \n    variable (p q r s : Prop)\n    \n    #check t1 p q                -- p → q → p\n    #check t1 r s                -- r → s → r\n    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s\n    \n    variable (h : r → s)\n    #check t1 (r → s) (s → r) h  -- (s → r) → r → s\n    \n\nOnce again, using the propositions-as-types correspondence, the variable `h`\nof type `r → s` can be viewed as the hypothesis, or premise, that `r → s`\nholds.\n\nAs another example, let us consider the composition function discussed in the\nlast chapter, now with propositions instead of types.\n\n    \n    \n    variable (p q r s : Prop)\n    \n    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=\n      fun h₃ : p =>\n      show r from h₁ (h₂ h₃)\n    \n\nAs a theorem of propositional logic, what does `t2` say?\n\nNote that it is often useful to use numeric unicode subscripts, entered as\n`\\0`, `\\1`, `\\2`, ..., for hypotheses, as we did in this example.\n\n## Propositional Logic\n\nLean defines all the standard logical connectives and notation. The\npropositional connectives come with the following notation:\n\nAscii| Unicode| Editor shortcut| Definition  \n---|---|---|---  \nTrue| | | True  \nFalse| | | False  \nNot| ¬| `\\not`, `\\neg`| Not  \n/\\| ∧| `\\and`| And  \n\\/| ∨| `\\or`| Or  \n->| →| `\\to`, `\\r`, `\\imp`|   \n<->| ↔| `\\iff`, `\\lr`| Iff  \n  \nThey all take values in `Prop`.\n\n    \n    \n    variable (p q : Prop)\n    \n    #check p → q → p ∧ q\n    #check ¬p → p ↔ False\n    #check p ∨ q → q ∨ p\n    \n\nThe order of operations is as follows: unary negation `¬` binds most strongly,\nthen `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧\ne` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right\n(nothing changes now that the arguments are elements of `Prop`, instead of\nsome other `Type`), as do the other binary connectives. So if we have `p q r :\nProp`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This\nis just the "curried" form of `p ∧ q → r`.\n\nIn the last chapter we observed that lambda abstraction can be viewed as an\n"introduction rule" for `→`. In the current setting, it shows how to\n"introduce" or establish an implication. Application can be viewed as an\n"elimination rule," showing how to "eliminate" or use an implication in a\nproof. The other propositional connectives are defined in Lean\'s library in\nthe file `Prelude.core` (see [importing\nfiles](./interacting_with_lean.html#importing-files) for more information on\nthe library hierarchy), and each connective comes with its canonical\nintroduction and elimination rules.\n\n### Conjunction\n\nThe expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :\np` and `h2 : q`. It is common to describe `And.intro` as the _and-\nintroduction_ rule. In the next example we use `And.intro` to create a proof\nof `p → q → p ∧ q`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq\n    \n    #check fun (hp : p) (hq : q) => And.intro hp hq\n    \n\nThe `example` command states a theorem without naming it or storing it in the\npermanent context. Essentially, it just checks that the given term has the\nindicated type. It is convenient for illustration, and we will use it often.\n\nThe expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.\nSimilarly, `And.right h` is a proof of `q`. They are commonly known as the\nleft and right _and-elimination_ rules.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : p := And.left h\n    example (h : p ∧ q) : q := And.right h\n    \n\nWe can now prove `p ∧ q → q ∧ p` with the following proof term.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      And.intro (And.right h) (And.left h)\n    \n\nNotice that and-introduction and and-elimination are similar to the pairing\nand projection operations for the Cartesian product. The difference is that\ngiven `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while\n`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is\nanother instance of the Curry-Howard isomorphism, but in contrast to\nimplication and the function space constructor, `∧` and `×` are treated\nseparately in Lean. With the analogy, however, the proof we have just\nconstructed is similar to a function that swaps the elements of a pair.\n\nWe will see in [Chapter Structures and Records](./structures_and_records.html)\nthat certain types in Lean are _structures_ , which is to say, the type is\ndefined with a single canonical _constructor_ which builds an element of the\ntype from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is\nan example: the canonical way to construct an element is to apply `And.intro`\nto suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous\nconstructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the\nrelevant type is an inductive type and can be inferred from the context. In\nparticular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:\n\n    \n    \n    variable (p q : Prop)\n    variable (hp : p) (hq : q)\n    \n    #check (⟨hp, hq⟩ : p ∧ q)\n    \n\nThese angle brackets are obtained by typing `\\<` and `\\>`, respectively.\n\nLean provides another useful syntactic gadget. Given an expression `e` of an\ninductive type `Foo` (possibly applied to some arguments), the notation\n`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of\naccessing functions without opening a namespace. For example, the following\ntwo expressions mean the same thing:\n\n    \n    \n    variable (xs : List Nat)\n    \n    #check List.length xs\n    #check xs.length\n    \n\nAs a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and\n`h.right` for `And.right h`. We can therefore rewrite the sample proof above\nconveniently as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      ⟨h.right, h.left⟩\n    \n\nThere is a fine line between brevity and obfuscation, and omitting information\nin this way can sometimes make a proof harder to read. But for straightforward\nconstructions like the one above, when the type of `h` and the goal of the\nconstruction are salient, the notation is clean and effective.\n\nIt is common to iterate constructions like "And." Lean also allows you to\nflatten nested constructors that associate to the right, so that these two\nproofs are equivalent:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, ⟨h.left, h.right⟩⟩\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, h.left, h.right⟩\n    \n\nThis is often useful as well.\n\n### Disjunction\n\nThe expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof\n`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a\nproof `hq : q`. These are the left and right _or-introduction_ rules.\n\n    \n    \n    variable (p q : Prop)\n    example (hp : p) : p ∨ q := Or.intro_left q hp\n    example (hq : q) : p ∨ q := Or.intro_right p hq\n    \n\nThe _or-elimination_ rule is slightly more complicated. The idea is that we\ncan prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`\nfollows from `q`. In other words, it is a proof by cases. In the expression\n`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :\np → r` and `hqr : q → r`, and produces a proof of `r`. In the following\nexample, we use `Or.elim` to prove `p ∨ q → q ∨ p`.\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h\n        (fun hp : p =>\n          show q ∨ p from Or.intro_right q hp)\n        (fun hq : q =>\n          show q ∨ p from Or.intro_left p hq)\n    \n\nIn most cases, the first argument of `Or.intro_right` and `Or.intro_left` can\nbe inferred automatically by Lean. Lean therefore provides `Or.inr` and\n`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and\n`Or.intro_left _`. Thus the proof term above could be written more concisely:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nNotice that there is enough information in the full expression for Lean to\ninfer the types of `hp` and `hq` as well. But using the type annotations in\nthe longer version makes the proof more readable, and can help catch and debug\nerrors.\n\nBecause `Or` has two constructors, we cannot use anonymous constructor\nnotation. But we can still write `h.elim` instead of `Or.elim h`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nOnce again, you should exercise judgment as to whether such abbreviations\nenhance or diminish readability.\n\n### Negation and Falsity\n\nNegation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by\nderiving a contradiction from `p`. Similarly, the expression `hnp hp` produces\na proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both\nthese rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is\nproduced by typing `\\not` or `\\neg`.)\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hpq : p → q) (hnq : ¬q) : ¬p :=\n      fun hp : p =>\n      show False from hnq (hpq hp)\n    \n\nThe connective `False` has a single elimination rule, `False.elim`, which\nexpresses the fact that anything follows from a contradiction. This rule is\nsometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the\n_principle of explosion_.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)\n    \n\nThe arbitrary fact, `q`, that follows from falsity is an implicit argument in\n`False.elim` and is inferred automatically. This pattern, deriving an\narbitrary fact from contradictory hypotheses, is quite common, and is\nrepresented by `absurd`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := absurd hp hnp\n    \n\nHere, for example, is a proof of `¬p → q → (q → p) → r`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=\n      absurd (hqp hq) hnp\n    \n\nIncidentally, just as `False` has only an elimination rule, `True` has only an\nintroduction rule, `True.intro : true`. In other words, `True` is simply true,\nand has a canonical proof, `True.intro`.\n\n### Logical Equivalence\n\nThe expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`\nand `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from\n`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔\nq`. Here is a proof of `p ∧ q ↔ q ∧ p`:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      Iff.intro\n        (fun h : p ∧ q =>\n         show q ∧ p from And.intro (And.right h) (And.left h))\n        (fun h : q ∧ p =>\n         show p ∧ q from And.intro (And.right h) (And.left h))\n    \n    #check and_swap p q    -- p ∧ q ↔ q ∧ p\n    \n    variable (h : p ∧ q)\n    example : q ∧ p := Iff.mp (and_swap p q) h\n    \n\nWe can use the anonymous constructor notation to construct a proof of `p ↔ q`\nfrom proofs of the forward and backward directions, and we can also use `.`\nnotation with `mp` and `mpr`. The previous examples can therefore be written\nconcisely as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩\n    \n    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h\n    \n\n## Introducing Auxiliary Subgoals\n\nThis is a good place to introduce another device Lean offers to help structure\nlong proofs, namely, the `have` construct, which introduces an auxiliary\nsubgoal in a proof. Here is a small example, adapted from the last section:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      have hq : q := h.right\n      show q ∧ p from And.intro hq hp\n    \n\nInternally, the expression `have h : p := s; t` produces the term `(fun (h :\np) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the\ndesired conclusion assuming `h : p`, and the two are combined by a lambda\nabstraction and application. This simple device is extremely useful when it\ncomes to structuring long proofs, since we can use intermediate `have`\'s as\nstepping stones leading to the final goal.\n\nLean also supports a structured way of reasoning backwards from a goal, which\nmodels the "suffices to show" construction in ordinary mathematics. The next\nexample simply permutes the last two lines in the previous proof.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      suffices hq : q from And.intro hq hp\n      show q from And.right h\n    \n\nWriting `suffices hq : q` leaves us with two goals. First, we have to show\nthat it indeed suffices to show `q`, by proving the original goal of `q ∧ p`\nwith the additional hypothesis `hq : q`. Finally, we have to show `q`.\n\n## Classical Logic\n\nThe introduction and elimination rules we have seen so far are all\nconstructive, which is to say, they reflect a computational understanding of\nthe logical connectives based on the propositions-as-types correspondence.\nOrdinary classical logic adds to this the law of the excluded middle, `p ∨\n¬p`. To use this principle, you have to open the classical namespace.\n\n    \n    \n    open Classical\n    \n    variable (p : Prop)\n    #check em p\n    \n\nIntuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts\nto knowing which is the case. If `RH` represents the Riemann hypothesis, a\nclassical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot\nyet assert either disjunct.\n\nOne consequence of the law of the excluded middle is the principle of double-\nnegation elimination:\n\n    \n    \n    open Classical\n    \n    theorem dne {p : Prop} (h : ¬¬p) : p :=\n      Or.elim (em p)\n        (fun hp : p => hp)\n        (fun hnp : ¬p => absurd hnp h)\n    \n\nDouble-negation elimination allows one to prove any proposition, `p`, by\nassuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In\nother words, double-negation elimination allows one to carry out a proof by\ncontradiction, something which is not generally possible in constructive\nlogic. As an exercise, you might try proving the converse, that is, showing\nthat `em` can be proved from `dne`.\n\nThe classical axioms also give you access to additional patterns of proof that\ncan be justified by appeal to `em`. For example, one can carry out a proof by\ncases:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byCases\n        (fun h1 : p => h1)\n        (fun h1 : ¬p => absurd h1 h)\n    \n\nOr you can carry out a proof by contradiction:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byContradiction\n        (fun h1 : ¬p =>\n         show False from h h1)\n    \n\nIf you are not used to thinking constructively, it may take some time for you\nto get a sense of where classical reasoning is used. It is needed in the\nfollowing example because, from a constructive standpoint, knowing that `p`\nand `q` are not both true does not necessarily tell you which one is false:\n\n    \n    \n    open Classical\n    variable (p q : Prop)\n    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=\n      Or.elim (em p)\n        (fun hp : p =>\n          Or.inr\n            (show ¬q from\n              fun hq : q =>\n              h ⟨hp, hq⟩))\n        (fun hp : ¬p =>\n          Or.inl hp)\n    \n\nWe will see later that there _are_ situations in constructive logic where\nprinciples like excluded middle and double-negation elimination are\npermissible, and Lean supports the use of classical reasoning in such contexts\nwithout relying on excluded middle.\n\nThe full list of axioms that are used in Lean to support classical reasoning\nare discussed in [Axioms and Computation](./axioms_and_computation.html).\n\n## Examples of Propositional Validities\n\nLean\'s standard library contains proofs of many valid statements of\npropositional logic, all of which you are free to use in proofs of your own.\nThe following list includes a number of common identities.\n\nCommutativity:\n\n  1. `p ∧ q ↔ q ∧ p`\n  2. `p ∨ q ↔ q ∨ p`\n\nAssociativity:\n\n  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`\n  4. `(p ∨ q) ∨ r ↔ p ∨ (q �'}], 'model': 'gpt-4o'}}
2025-06-01 02:52:58,011 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:52:58,011 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:52:58,012 - DEBUG - send_request_headers.complete
2025-06-01 02:52:58,012 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:52:58,012 - DEBUG - send_request_body.complete
2025-06-01 02:52:58,012 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:53:07,031 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:53:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8767'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8770'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'10540'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'38.918s'), (b'x-request-id', b'req_2709942bbf7c11d3a2d9eb0f6ab532a0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6afeb9f747bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:53:07,031 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:53:07,031 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:53:07,032 - DEBUG - receive_response_body.complete
2025-06-01 02:53:07,032 - DEBUG - response_closed.started
2025-06-01 02:53:07,032 - DEBUG - response_closed.complete
2025-06-01 02:53:07,032 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:53:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8767', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8770', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '10540', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '38.918s', 'x-request-id': 'req_2709942bbf7c11d3a2d9eb0f6ab532a0', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6afeb9f747bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:53:07,032 - DEBUG - request_id: req_2709942bbf7c11d3a2d9eb0f6ab532a0
2025-06-01 02:53:07,032 - INFO - Raw solution received: ```json
{
  "code": "if a = 0 ∨ b = 0 then\n    false\n  else\n    (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0)",
  "proof": "unfold hasOppositeSign hasOppositeSign_spec\n  split\n  \n  -- Forward direction\n  \n  -- Assume the left side: (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0)\n  intro h\n  cases h with\n  | inl hab =>\n    by_cases hab_zero : a = 0 ∨ b = 0\n    -- Case a is zero or b is zero\n    . exfalso\n      cases hab_zero with\n      | inl ha0 =>\n        specialize hab (Or.inl ha0)\n        contradiction\n      | inr hb0 =>\n        specialize hab (Or.inr hb0)\n        contradiction\n    -- Case neither a nor b is zero\n    . \n      left\n      assumption\n  | inr hab =>\n    by_cases hab_zero : a = 0 ∨ b = 0\n    -- Case a is zero or b is zero\n    . exfalso\n      cases hab_zero with\n      | inl ha0 =>\n        specialize hab (Or.inl ha0)\n        contradiction\n      | inr hb0 =>\n        specialize hab (Or.inr hb0)\n        contradiction\n    -- Case neither a nor b is zero\n    .\n      right\n      assumption\n  \n  -- Backward direction\n  \n  intro h\n  -- Assume the result: hasOppositeSign a b is true\n  by_cases h : a = 0 ∨ b = 0\n    -- Case a is zero or b is zero\n    . simp [h] at h\n      contradiction\n    -- Case neither a nor b is zero\n    .\n      simp [h] at h\n      exact h"
}
```
2025-06-01 02:53:07,032 - INFO - <class 'str'>
2025-06-01 02:53:07,033 - INFO - Generated solution: {'code': 'if a = 0 ∨ b = 0 then\n    false\n  else\n    (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0)', 'proof': 'unfold hasOppositeSign hasOppositeSign_spec\n  split\n  \n  -- Forward direction\n  \n  -- Assume the left side: (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0)\n  intro h\n  cases h with\n  | inl hab =>\n    by_cases hab_zero : a = 0 ∨ b = 0\n    -- Case a is zero or b is zero\n    . exfalso\n      cases hab_zero with\n      | inl ha0 =>\n        specialize hab (Or.inl ha0)\n        contradiction\n      | inr hb0 =>\n        specialize hab (Or.inr hb0)\n        contradiction\n    -- Case neither a nor b is zero\n    . \n      left\n      assumption\n  | inr hab =>\n    by_cases hab_zero : a = 0 ∨ b = 0\n    -- Case a is zero or b is zero\n    . exfalso\n      cases hab_zero with\n      | inl ha0 =>\n        specialize hab (Or.inl ha0)\n        contradiction\n      | inr hb0 =>\n        specialize hab (Or.inr hb0)\n        contradiction\n    -- Case neither a nor b is zero\n    .\n      right\n      assumption\n  \n  -- Backward direction\n  \n  intro h\n  -- Assume the result: hasOppositeSign a b is true\n  by_cases h : a = 0 ∨ b = 0\n    -- Case a is zero or b is zero\n    . simp [h] at h\n      contradiction\n    -- Case neither a nor b is zero\n    .\n      simp [h] at h\n      exact h'}
2025-06-01 02:53:12,272 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:24:9: error: tactic 'unfold' failed to unfold 'hasOppositeSign' at
  a < 0 ∧ b > 0 ∨ a > 0 ∧ b < 0 ↔ (if a = 0 ∨ b = 0 then false else decide (a > 0 ∧ b < 0 ∨ a < 0 ∧ b > 0)) = true
lean_playground/TempTest.lean:69:15: error: unexpected token 'at'; expected command
2025-06-01 02:53:12,273 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a = 0 ∨ b = 0 then\n    false\n  else\n    (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0)\n\nGenerated Proof:\nunfold hasOppositeSign hasOppositeSign_spec\n  split\n  \n  -- Forward direction\n  \n  -- Assume the left side: (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0)\n  intro h\n  cases h with\n  | inl hab =>\n    by_cases hab_zero : a = 0 ∨ b = 0\n    -- Case a is zero or b is zero\n    . exfalso\n      cases hab_zero with\n      | inl ha0 =>\n        specialize hab (Or.inl ha0)\n        contradiction\n      | inr hb0 =>\n        specialize hab (Or.inr hb0)\n        contradiction\n    -- Case neither a nor b is zero\n    . \n      left\n      assumption\n  | inr hab =>\n    by_cases hab_zero : a = 0 ∨ b = 0\n    -- Case a is zero or b is zero\n    . exfalso\n      cases hab_zero with\n      | inl ha0 =>\n        specialize hab (Or.inl ha0)\n        contradiction\n      | inr hb0 =>\n        specialize hab (Or.inr hb0)\n        contradiction\n    -- Case neither a nor b is zero\n    .\n      right\n      assumption\n  \n  -- Backward direction\n  \n  intro h\n  -- Assume the result: hasOppositeSign a b is true\n  by_cases h : a = 0 ∨ b = 0\n    -- Case a is zero or b is zero\n    . simp [h] at h\n      contradiction\n    -- Case neither a nor b is zero\n    .\n      simp [h] at h\n      exact h\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:24:9: error: tactic 'unfold' failed to unfold 'hasOppositeSign' at\n  a < 0 ∧ b > 0 ∨ a > 0 ∧ b < 0 ↔ (if a = 0 ∨ b = 0 then false else decide (a > 0 ∧ b < 0 ∨ a < 0 ∧ b > 0)) = true\nlean_playground/TempTest.lean:69:15: error: unexpected token 'at'; expected command"}], 'model': 'o3-mini'}}
2025-06-01 02:53:12,273 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:53:12,273 - DEBUG - close.started
2025-06-01 02:53:12,274 - DEBUG - close.complete
2025-06-01 02:53:12,274 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:53:12,280 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e67c2c830>
2025-06-01 02:53:12,280 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:53:12,290 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e67af6e70>
2025-06-01 02:53:12,290 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:53:12,290 - DEBUG - send_request_headers.complete
2025-06-01 02:53:12,291 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:53:12,291 - DEBUG - send_request_body.complete
2025-06-01 02:53:12,291 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:53:25,063 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:53:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'12525'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'12529'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198893'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'331ms'), (b'x-request-id', b'req_9cbb29f22d86ce8fa5d6fca8e8f10946'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6b57fdc88fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:53:25,063 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:53:25,063 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:53:25,064 - DEBUG - receive_response_body.complete
2025-06-01 02:53:25,064 - DEBUG - response_closed.started
2025-06-01 02:53:25,064 - DEBUG - response_closed.complete
2025-06-01 02:53:25,064 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:53:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '12525', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '12529', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198893', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '331ms', 'x-request-id': 'req_9cbb29f22d86ce8fa5d6fca8e8f10946', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6b57fdc88fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:53:25,064 - DEBUG - request_id: req_9cbb29f22d86ce8fa5d6fca8e8f10946
2025-06-01 02:53:25,064 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof failed because the 'unfold' tactic was unable to properly expand the definition of hasOppositeSign, which contains an if-expression. In addition, there is a misuse of the 'at' syntax in 'simp [h] at h', likely due to reusing the same identifier 'h'.", 'error_type': 'proof', 'suggested_fix': "Replace 'unfold' with 'dsimp' and use the 'split_ifs' tactic to handle the if-expression. For example, modify the theorem proof to:\n\n  theorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n    hasOppositeSign_spec a b (hasOppositeSign a b) := by\n    dsimp [hasOppositeSign, hasOppositeSign_spec]\n    split_ifs with h\n    · -- Case where (a = 0 ∨ b = 0): goal simplifies to false ↔ false\n      simp\n    · -- Case where ¬(a = 0 ∨ b = 0): goal simplifies to ( (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ) ↔ ( (a > 0 ∧ b < 0) ∨ (a < 0 ∧ b > 0) )\n      simp\n\nThis approach explicitly splits the if-condition and avoids reusing tactic names. Make sure to remove any duplicated use of 'h' in nested scopes.", 'retry_strategy': 'Revise the proof tactics as suggested and re-run the proof. Use dsimp and split_ifs to handle conditional definitions instead of unfolding them manually.'}
2025-06-01 02:53:25,065 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.\n\nPrevious plan:\n{\n  "plan_summary": "Revise the function to correctly perform case analysis and complete proof without using incorrect case tags or tactics. We will structure the function with a primary check for zero values and then use explicit conditional tests to determine if one integer is positive and the other negative. In the proof, we will avoid using by_cases with the wrong tags (e.g., \'inl\', \'inr\') and instead use if-else or explicitly name the cases as \'pos\' and \'neg\' when necessary. The proof will be restructured to discharge all cases explicitly without relying on tactics that do not match the available assumptions.",\n  "steps": [\n    "Define the function with two integer parameters that returns a Boolean.",\n    "Immediately check whether either of the two integers is zero. If so, return false because zero is neither positive nor negative.",\n    "Use explicit if-else constructs to check both cases: one where a > 0 and b < 0, and the other where a < 0 and b > 0. Return true when either condition holds, and false otherwise.",\n    "Remove reliance on by_cases if it leads to difficult tactics. If by_cases must be used, explicitly name the drawer cases with \'pos\' (for the case when the proposition holds) and \'neg\' (for when it does not) to avoid case-tag errors.",\n    "For the proof of correctness, perform a detailed case analysis: analyze the case when one of the integers is zero, when both integers have the same nonzero sign, and when they have opposite signs. Use conditional reasoning and ensure that each branch is verified using straightforward, explicit reasoning steps.",\n    "Avoid tactics that refer to \'inl\' and \'inr\' or use of an incorrect tactic like \'done\'. Instead, complete each case with a correct application of Lean tactics such as \'simp\' or \'exact\' as appropriate.",\n    "Verify that the proof script does not use \'assumption\' in cases where the assumption is not available and that all cases are discharged explicitly."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "if statement",\n    "integer comparison",\n    "Boolean"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "conditional reasoning",\n    "if-else proofs",\n    "explicit discharge of cases",\n    "by_cases (with proper tagging)"\n  ],\n  "assumptions": [\n    "Zero is neither positive nor negative according to the specification",\n    "Using explicit if-else clarifies all cases without malformed tags",\n    "Standard integer comparisons (> and <) in Lean 4 behave as specified"\n  ],\n  "retry_guidance": "Ensure all case analysis uses explicit tagging (\'pos\' and \'neg\') if by_cases is used. Prefer using if-else to perform clear and explicit conditional checks. Avoid tactics that attempt to use undefined identifiers such as \'done\' or assumptions from non-existent cases. Discharge each branch thoroughly so that Lean can verify that all cases are handled, and re-run the proof to confirm the changes resolve the errors."\n}\n\nLean error summary:\nThe generated proof script fails in several ways. First, the use of by_cases followed by simp and trivial does not correctly discharge all cases, and the tactic \'assumption\' (or its implicit use) fails because the necessary assumptions are not available. In addition, the final use of the identifier \'done\' causes a syntax error. Overall, the proof script does not correctly structure the case analysis needed to prove the equivalence, and Lean rejects the proof due to both tactic failures and unexpected identifiers.\nRetry guidance (MUST FOLLOW):\nRevise the proof script by explicitly splitting the equivalence into two implications using \'split\' and handle the case analysis with \'by_cases\'. Remove ambiguous tactics such as \'trivial\' and \'done\', and ensure that every case is fully discharged. Once you have fixed the proof structure, recompile to check that the proof passes.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThe proof failed because the \'unfold\' tactic was unable to properly expand the definition of hasOppositeSign, which contains an if-expression. In addition, there is a misuse of the \'at\' syntax in \'simp [h] at h\', likely due to reusing the same identifier \'h\'.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 02:53:25,066 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:53:25,066 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:53:25,066 - DEBUG - send_request_headers.complete
2025-06-01 02:53:25,066 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:53:25,066 - DEBUG - send_request_body.complete
2025-06-01 02:53:25,066 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:53:33,312 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:53:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7653'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7655'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198441'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'467ms'), (b'x-request-id', b'req_74df07f8814441f5b4996fb1bec8889d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6ba7dbdc8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:53:33,312 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:53:33,312 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:53:33,313 - DEBUG - receive_response_body.complete
2025-06-01 02:53:33,313 - DEBUG - response_closed.started
2025-06-01 02:53:33,313 - DEBUG - response_closed.complete
2025-06-01 02:53:33,313 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:53:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7653', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7655', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198441', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '467ms', 'x-request-id': 'req_74df07f8814441f5b4996fb1bec8889d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6ba7dbdc8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:53:33,313 - DEBUG - request_id: req_74df07f8814441f5b4996fb1bec8889d
2025-06-01 02:53:33,313 - INFO - Solution generated in 96.88 seconds
2025-06-01 02:53:33,313 - INFO - Generated code length: 76 characters
2025-06-01 02:53:33,313 - INFO - Generated proof length: 1144 characters
2025-06-01 02:53:33,313 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:53:33,314 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:53:38,632 - INFO - Implementation test result: PASS
2025-06-01 02:53:38,632 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:53:43,940 - INFO - Full solution test result: FAIL
2025-06-01 02:53:43,940 - ERROR - Proof error: lean_playground/TempTest.lean:24:9: error: tactic 'unfold' failed to unfold 'hasOppositeSign' at
  a < 0 ∧ b > 0 ∨ a > 0 ∧ b < 0 ↔ (if a = 0 ∨ b = 0 t...
2025-06-01 02:53:43,940 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:53:43,940 - ERROR - ❌ Proof has errors
2025-06-01 02:53:43,940 - INFO - 
==================================================
2025-06-01 02:53:43,940 - INFO - Processing task task_id_77...
2025-06-01 02:53:43,940 - INFO - Reading problem description and code template from tasks/task_id_77...
2025-06-01 02:53:43,940 - INFO - Problem description length: 456 characters
2025-06-01 02:53:43,940 - INFO - Reading unit tests from tasks/task_id_77...
2025-06-01 02:53:43,941 - INFO - Unit tests length: 449 characters
2025-06-01 02:53:43,941 - INFO - Running main workflow to generate solution...
2025-06-01 02:53:43,941 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.

-----Input-----
The input consists of:
n: An integer to check for divisibility by 11.

-----Output-----
The output is a Boolean value:
Returns true if the input number is divisible by 11.
Returns false if the input number is not divisible by 11.
2025-06-01 02:53:43,941 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def isDivisibleBy11 (n : Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result is true if n is divisible by 11
def isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=
  -- << SPEC START >>
  n % 11 = 0 ↔ result
  -- << SPEC END >>

theorem isDivisibleBy11_spec_satisfied (n : Int) :
  isDivisibleBy11_spec n (isDivisibleBy11 n) := by
  -- << PROOF START >>
  unfold isDivisibleBy11 isDivisibleBy11_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:53:43,968 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7f4e67396980>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:53:43,969 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:53:43,969 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:53:43,994 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f7d4c0>
2025-06-01 02:53:43,994 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4e67393f50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:53:44,021 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f7d310>
2025-06-01 02:53:44,021 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:53:44,021 - DEBUG - send_request_headers.complete
2025-06-01 02:53:44,021 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:53:44,021 - DEBUG - send_request_body.complete
2025-06-01 02:53:44,021 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:53:44,639 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:53:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'40'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5d97677bdb-llbpr'), (b'x-envoy-upstream-service-time', b'43'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999885'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_ab9fbf123039f48926a2837e9f074307'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Y8kUfSq6LK2HgBxzy.FJ7hDiqSE92WjuUSB9CdfK8PE-1748746424-1.0.1.1-puK1rcwlFcpDyvwPgSC1hJqOPd0S6N6o.fvCHmlraB3BAL0yZmGCKdVMu62GvRxzvT37bC.LJnQqfKJPWm6Klpqqa3GVB6YO5pmOIbpagr4; path=/; expires=Sun, 01-Jun-25 03:23:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=.ULs4R1Qg251Qd66PdBq_HlPYLOpJ39j4MWvB4LEXHw-1748746424661-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6c1e6d6046f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:53:44,640 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:53:44,640 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:53:44,640 - DEBUG - receive_response_body.complete
2025-06-01 02:53:44,640 - DEBUG - response_closed.started
2025-06-01 02:53:44,640 - DEBUG - response_closed.complete
2025-06-01 02:53:44,640 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:53:44 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '40'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-5d97677bdb-llbpr'), ('x-envoy-upstream-service-time', '43'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999885'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '6ms'), ('x-request-id', 'req_ab9fbf123039f48926a2837e9f074307'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Y8kUfSq6LK2HgBxzy.FJ7hDiqSE92WjuUSB9CdfK8PE-1748746424-1.0.1.1-puK1rcwlFcpDyvwPgSC1hJqOPd0S6N6o.fvCHmlraB3BAL0yZmGCKdVMu62GvRxzvT37bC.LJnQqfKJPWm6Klpqqa3GVB6YO5pmOIbpagr4; path=/; expires=Sun, 01-Jun-25 03:23:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=.ULs4R1Qg251Qd66PdBq_HlPYLOpJ39j4MWvB4LEXHw-1748746424661-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b6c1e6d6046f0-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:53:44,640 - DEBUG - request_id: req_ab9fbf123039f48926a2837e9f074307
2025-06-01 02:53:44,645 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
 the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
2025-06-01 02:53:44,648 - DEBUG - close.started
2025-06-01 02:53:44,648 - DEBUG - close.complete
2025-06-01 02:53:44,659 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.'}], 'model': 'o3-mini'}}
2025-06-01 02:53:44,659 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:53:44,660 - DEBUG - close.started
2025-06-01 02:53:44,660 - DEBUG - close.complete
2025-06-01 02:53:44,660 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:53:44,666 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f7da90>
2025-06-01 02:53:44,666 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:53:44,675 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f7d490>
2025-06-01 02:53:44,675 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:53:44,675 - DEBUG - send_request_headers.complete
2025-06-01 02:53:44,675 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:53:44,675 - DEBUG - send_request_body.complete
2025-06-01 02:53:44,675 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:53:50,187 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:53:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5287'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5291'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199585'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'124ms'), (b'x-request-id', b'req_c1364f666be242c83de6890df0996e9f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6c226da347bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:53:50,188 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:53:50,188 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:53:50,188 - DEBUG - receive_response_body.complete
2025-06-01 02:53:50,188 - DEBUG - response_closed.started
2025-06-01 02:53:50,188 - DEBUG - response_closed.complete
2025-06-01 02:53:50,188 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:53:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5287', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5291', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199585', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '124ms', 'x-request-id': 'req_c1364f666be242c83de6890df0996e9f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6c226da347bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:53:50,188 - DEBUG - request_id: req_c1364f666be242c83de6890df0996e9f
2025-06-01 02:53:50,189 - INFO - Attempt 1/3
2025-06-01 02:53:50,189 - INFO - Current plan: {
  "plan_summary": "Implement a Lean 4 function that takes an integer n and determines if it is divisible by 11 by using the modulo operator. The function returns true if n % 11 equals 0 and false otherwise.",
  "steps": [
    "Define the function signature that accepts an integer.",
    "Use the modulo operation (n % 11) to calculate the remainder when n is divided by 11.",
    "Compare the result of the modulo operation with 0.",
    "Return true if the remainder is 0, and false if it is not.",
    "Optionally, include test cases to validate the behavior of the function."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "modulo operator",
    "divisibility check",
    "conditional expression"
  ],
  "proof_keywords": [
    "modular arithmetic",
    "equality check"
  ],
  "assumptions": [
    "n is an integer.",
    "The % operator in Lean 4 works as expected for divisibility.",
    "Basic arithmetic properties hold in Lean 4 as defined in the standard library."
  ],
  "retry_guidance": "If there are errors, verify that the modulo operator is applied correctly to integers and that the function's return type is boolean. Also, review any type mismatches or implicit coercions required by Lean 4's arithmetic library."
}
2025-06-01 02:53:50,189 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Implement a Lean 4 function that takes an integer n and determines if it is divisible by 11 by using the modulo operator. The function returns true if n % 11 equals 0 and false otherwise.",\n  "steps": [\n    "Define the function signature that accepts an integer.",\n    "Use the modulo operation (n % 11) to calculate the remainder when n is divided by 11.",\n    "Compare the result of the modulo operation with 0.",\n    "Return true if the remainder is 0, and false if it is not.",\n    "Optionally, include test cases to validate the behavior of the function."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "modulo operator",\n    "divisibility check",\n    "conditional expression"\n  ],\n  "proof_keywords": [\n    "modular arithmetic",\n    "equality check"\n  ],\n  "assumptions": [\n    "n is an integer.",\n    "The % operator in Lean 4 works as expected for divisibility.",\n    "Basic arithmetic properties hold in Lean 4 as defined in the standard library."\n  ],\n  "retry_guidance": "If there are errors, verify that the modulo operator is applied correctly to integers and that the function\'s return type is boolean. Also, review any type mismatches or implicit coercions required by Lean 4\'s arithmetic library."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  n % 11 = 0 ↔ result\n  -- << SPEC END >>\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- << PROOF START >>\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The'}], 'model': 'gpt-4o'}}
2025-06-01 02:53:50,191 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:53:50,191 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:53:50,191 - DEBUG - send_request_headers.complete
2025-06-01 02:53:50,191 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:53:50,195 - DEBUG - send_request_body.complete
2025-06-01 02:53:50,195 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:53:52,810 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:53:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2318'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2322'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'16270'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'27.46s'), (b'x-request-id', b'req_9a5511336a5eb40e17d1fe1330b56ef4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6c44dd6c47bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:53:52,810 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:53:52,810 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:53:52,811 - DEBUG - receive_response_body.complete
2025-06-01 02:53:52,812 - DEBUG - response_closed.started
2025-06-01 02:53:52,812 - DEBUG - response_closed.complete
2025-06-01 02:53:52,812 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:53:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2318', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2322', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '16270', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '27.46s', 'x-request-id': 'req_9a5511336a5eb40e17d1fe1330b56ef4', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6c44dd6c47bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:53:52,812 - DEBUG - request_id: req_9a5511336a5eb40e17d1fe1330b56ef4
2025-06-01 02:53:52,812 - INFO - Raw solution received: ```json
{
  "code": "n % 11 == 0",
  "proof": "by\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  by_cases h : n % 11 = 0\n  simp [h]\n  exact Iff.intro (λ _ => h) (λ h' => h')\n  simp [h]\n  exact Iff.intro (λ h' => False.elim (h h')) (λ _ => h)"
}
```
2025-06-01 02:53:52,812 - INFO - <class 'str'>
2025-06-01 02:53:52,812 - INFO - Generated solution: {'code': 'n % 11 == 0', 'proof': "by\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  by_cases h : n % 11 = 0\n  simp [h]\n  exact Iff.intro (λ _ => h) (λ h' => h')\n  simp [h]\n  exact Iff.intro (λ h' => False.elim (h h')) (λ _ => h)"}
2025-06-01 02:53:57,939 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:18:48: error: unsolved goals
n : ℤ
⊢ n % 11 = 0 ↔ (n % 11 == 0) = true
lean_playground/TempTest.lean:21:2: error: unexpected token 'by'; expected command
2025-06-01 02:53:57,940 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  n % 11 = 0 ↔ result\n  -- << SPEC END >>\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- << PROOF START >>\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nn % 11 == 0\n\nGenerated Proof:\nby\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  by_cases h : n % 11 = 0\n  simp [h]\n  exact Iff.intro (λ _ => h) (λ h' => h')\n  simp [h]\n  exact Iff.intro (λ h' => False.elim (h h')) (λ _ => h)\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:18:48: error: unsolved goals\nn : ℤ\n⊢ n % 11 = 0 ↔ (n % 11 == 0) = true\nlean_playground/TempTest.lean:21:2: error: unexpected token 'by'; expected command"}], 'model': 'o3-mini'}}
2025-06-01 02:53:57,940 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:53:57,941 - DEBUG - close.started
2025-06-01 02:53:57,941 - DEBUG - close.complete
2025-06-01 02:53:57,941 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:53:57,948 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737f980>
2025-06-01 02:53:57,948 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:53:57,957 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e67962b40>
2025-06-01 02:53:57,957 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:53:57,957 - DEBUG - send_request_headers.complete
2025-06-01 02:53:57,957 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:53:57,957 - DEBUG - send_request_body.complete
2025-06-01 02:53:57,957 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:54:09,710 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:54:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'11525'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'11530'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199260'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'222ms'), (b'x-request-id', b'req_866ccac4da1ba72add38ac473d1147d3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6c756e258fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:54:09,710 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:54:09,711 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:54:09,711 - DEBUG - receive_response_body.complete
2025-06-01 02:54:09,711 - DEBUG - response_closed.started
2025-06-01 02:54:09,711 - DEBUG - response_closed.complete
2025-06-01 02:54:09,711 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:54:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '11525', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '11530', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199260', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '222ms', 'x-request-id': 'req_866ccac4da1ba72add38ac473d1147d3', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6c756e258fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:54:09,711 - DEBUG - request_id: req_866ccac4da1ba72add38ac473d1147d3
2025-06-01 02:54:09,712 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The generated code has two main issues. First, the implementation of isDivisibleBy11 is written as 'n % 11 == 0' which returns a Bool but the specification uses the equation 'n % 11 = 0' (a Prop) causing a mismatch during the proof. Second, the proof block includes an unexpected 'by' token in a nested manner. In summary, the code does not unify the boolean equality with the propositional equality and the proof script has an extra tactic marker.", 'error_type': 'type', 'suggested_fix': "To fix the issues, modify the implementation to use an if-then-else so that the returned Bool matches the intended semantics. For example, define isDivisibleBy11 as 'if n % 11 = 0 then true else false'. In the proof, unfold the definition and use a case analysis on the condition 'n % 11 = 0'. Remove the extra 'by' tactic marker and structure the proof using bullet points (or 'cases') to handle the two cases where n is divisible by 11 or not. An updated version may look like:\n\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  if n % 11 = 0 then true else false\n\n-- Specification\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  n % 11 = 0 ↔ result\n\n-- Proof\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  split\n  case mp =>\n    intro h\n    simp [if_pos h]\n  case mpr =>\n    intro h\n    by_cases (n % 11 = 0) with h1\n    case pos =>\n      simp [if_pos h1]\n      exact h1\n    case neg =>\n      simp [if_neg h1] at h\n      contradiction", 'retry_strategy': "Revise the implementation and proof as suggested. Replace the simple boolean equality with an if-then-else statement for clarity, and restructure the proof by eliminating the extra 'by' token and using case analysis explicitly."}
2025-06-01 02:54:09,712 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.\n\nPrevious plan:\n{\n  "plan_summary": "Implement a Lean 4 function that takes an integer n and determines if it is divisible by 11 by using the modulo operator. The function returns true if n % 11 equals 0 and false otherwise.",\n  "steps": [\n    "Define the function signature that accepts an integer.",\n    "Use the modulo operation (n % 11) to calculate the remainder when n is divided by 11.",\n    "Compare the result of the modulo operation with 0.",\n    "Return true if the remainder is 0, and false if it is not.",\n    "Optionally, include test cases to validate the behavior of the function."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "modulo operator",\n    "divisibility check",\n    "conditional expression"\n  ],\n  "proof_keywords": [\n    "modular arithmetic",\n    "equality check"\n  ],\n  "assumptions": [\n    "n is an integer.",\n    "The % operator in Lean 4 works as expected for divisibility.",\n    "Basic arithmetic properties hold in Lean 4 as defined in the standard library."\n  ],\n  "retry_guidance": "If there are errors, verify that the modulo operator is applied correctly to integers and that the function\'s return type is boolean. Also, review any type mismatches or implicit coercions required by Lean 4\'s arithmetic library."\n}\n\nLean error:\nThe generated code has two main issues. First, the implementation of isDivisibleBy11 is written as \'n % 11 == 0\' which returns a Bool but the specification uses the equation \'n % 11 = 0\' (a Prop) causing a mismatch during the proof. Second, the proof block includes an unexpected \'by\' token in a nested manner. In summary, the code does not unify the boolean equality with the propositional equality and the proof script has an extra tactic marker.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 02:54:09,713 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:54:09,713 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:54:09,713 - DEBUG - send_request_headers.complete
2025-06-01 02:54:09,713 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:54:09,713 - DEBUG - send_request_body.complete
2025-06-01 02:54:09,713 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:54:18,668 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:54:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8728'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8730'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199137'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'258ms'), (b'x-request-id', b'req_7a1c3e95a539b3b42f4051f55284e27e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6cbeeb448fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:54:18,668 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:54:18,668 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:54:18,669 - DEBUG - receive_response_body.complete
2025-06-01 02:54:18,669 - DEBUG - response_closed.started
2025-06-01 02:54:18,669 - DEBUG - response_closed.complete
2025-06-01 02:54:18,669 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:54:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8728', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8730', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199137', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '258ms', 'x-request-id': 'req_7a1c3e95a539b3b42f4051f55284e27e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6cbeeb448fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:54:18,669 - DEBUG - request_id: req_7a1c3e95a539b3b42f4051f55284e27e
2025-06-01 02:54:18,669 - INFO - Attempt 2/3
2025-06-01 02:54:18,669 - INFO - Current plan: {
  "plan_summary": "Revise the implementation to clearly separate the Boolean calculation from the propositional statement. The plan is to implement a function that returns a Bool using an if-then-else structure to avoid ambiguity between a Boolean equality and a propositional equality. Then, if necessary, prove a theorem that characterizes divisibility by 11 in the proposition world by relating the boolean result to the Prop statement. Also, remove the nested 'by' tokens in the proof script.",
  "steps": [
    "Define the function signature for isDivisibleBy11 that accepts an integer and returns a Bool.",
    "Implement the function using the modulo operator, but use an if-then-else expression: 'if n % 11 = 0 then true else false'. This structure ensures that we are using propositional equality within the conditional while returning a boolean.",
    "(Optional) Write a separate theorem that states: 'n % 11 = 0 ↔ isDivisibleBy11 n = true'. This theorem would require converting the decidable equality result from the function into a proposition.",
    "In the theorem or proof block, avoid any extra tactic markers like an unexpected nested 'by'. Write the proof either as a single 'by' with a clear script or as a have block without a second 'by'.",
    "Optionally include test cases or examples to validate the function, ensuring that the function signature and expected types (Bool, Prop) are handled correctly."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "if-then-else",
    "modulo operator",
    "boolean check"
  ],
  "proof_keywords": [
    "propositional equality",
    "decidable equality",
    "iff theorem",
    "proof refinement"
  ],
  "assumptions": [
    "n is an integer.",
    "The modulo operator is correctly defined for integers in Lean 4.",
    "We are allowed to separate Boolean computation from propositional assertions.",
    "If a theorem is provided, the conversion between decidable Boolean and Prop is possible."
  ],
  "retry_guidance": "If errors persist, verify that the if-then-else structure correctly distinguishes between a Boolean value and a Prop value. Also, ensure the conversion between 'n % 11 = 0' (a Prop) and the return of a Bool is clear and explicit. Check that no redundant 'by' tokens remain in the proof blocks."
}
2025-06-01 02:54:18,669 - INFO - Updated plan: {
  "plan_summary": "Revise the implementation to clearly separate the Boolean calculation from the propositional statement. The plan is to implement a function that returns a Bool using an if-then-else structure to avoid ambiguity between a Boolean equality and a propositional equality. Then, if necessary, prove a theorem that characterizes divisibility by 11 in the proposition world by relating the boolean result to the Prop statement. Also, remove the nested 'by' tokens in the proof script.",
  "steps": [
    "Define the function signature for isDivisibleBy11 that accepts an integer and returns a Bool.",
    "Implement the function using the modulo operator, but use an if-then-else expression: 'if n % 11 = 0 then true else false'. This structure ensures that we are using propositional equality within the conditional while returning a boolean.",
    "(Optional) Write a separate theorem that states: 'n % 11 = 0 ↔ isDivisibleBy11 n = true'. This theorem would require converting the decidable equality result from the function into a proposition.",
    "In the theorem or proof block, avoid any extra tactic markers like an unexpected nested 'by'. Write the proof either as a single 'by' with a clear script or as a have block without a second 'by'.",
    "Optionally include test cases or examples to validate the function, ensuring that the function signature and expected types (Bool, Prop) are handled correctly."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "if-then-else",
    "modulo operator",
    "boolean check"
  ],
  "proof_keywords": [
    "propositional equality",
    "decidable equality",
    "iff theorem",
    "proof refinement"
  ],
  "assumptions": [
    "n is an integer.",
    "The modulo operator is correctly defined for integers in Lean 4.",
    "We are allowed to separate Boolean computation from propositional assertions.",
    "If a theorem is provided, the conversion between decidable Boolean and Prop is possible."
  ],
  "retry_guidance": "If errors persist, verify that the if-then-else structure correctly distinguishes between a Boolean value and a Prop value. Also, ensure the conversion between 'n % 11 = 0' (a Prop) and the return of a Bool is clear and explicit. Check that no redundant 'by' tokens remain in the proof blocks."
}

Lean error summary:
The generated code has two main issues. First, the implementation of isDivisibleBy11 is written as 'n % 11 == 0' which returns a Bool but the specification uses the equation 'n % 11 = 0' (a Prop) causing a mismatch during the proof. Second, the proof block includes an unexpected 'by' token in a nested manner. In summary, the code does not unify the boolean equality with the propositional equality and the proof script has an extra tactic marker.
Retry guidance (MUST FOLLOW):
Revise the implementation and proof as suggested. Replace the simple boolean equality with an if-then-else statement for clarity, and restructure the proof by eliminating the extra 'by' token and using case analysis explicitly.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 02:54:18,670 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the implementation to clearly separate the Boolean calculation from the propositional statement. The plan is to implement a function that returns a Bool using an if-then-else structure to avoid ambiguity between a Boolean equality and a propositional equality. Then, if necessary, prove a theorem that characterizes divisibility by 11 in the proposition world by relating the boolean result to the Prop statement. Also, remove the nested \'by\' tokens in the proof script.",\n  "steps": [\n    "Define the function signature for isDivisibleBy11 that accepts an integer and returns a Bool.",\n    "Implement the function using the modulo operator, but use an if-then-else expression: \'if n % 11 = 0 then true else false\'. This structure ensures that we are using propositional equality within the conditional while returning a boolean.",\n    "(Optional) Write a separate theorem that states: \'n % 11 = 0 ↔ isDivisibleBy11 n = true\'. This theorem would require converting the decidable equality result from the function into a proposition.",\n    "In the theorem or proof block, avoid any extra tactic markers like an unexpected nested \'by\'. Write the proof either as a single \'by\' with a clear script or as a have block without a second \'by\'.",\n    "Optionally include test cases or examples to validate the function, ensuring that the function signature and expected types (Bool, Prop) are handled correctly."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "if-then-else",\n    "modulo operator",\n    "boolean check"\n  ],\n  "proof_keywords": [\n    "propositional equality",\n    "decidable equality",\n    "iff theorem",\n    "proof refinement"\n  ],\n  "assumptions": [\n    "n is an integer.",\n    "The modulo operator is correctly defined for integers in Lean 4.",\n    "We are allowed to separate Boolean computation from propositional assertions.",\n    "If a theorem is provided, the conversion between decidable Boolean and Prop is possible."\n  ],\n  "retry_guidance": "If errors persist, verify that the if-then-else structure correctly distinguishes between a Boolean value and a Prop value. Also, ensure the conversion between \'n % 11 = 0\' (a Prop) and the return of a Bool is clear and explicit. Check that no redundant \'by\' tokens remain in the proof blocks."\n}\n\nLean error summary:\nThe generated code has two main issues. First, the implementation of isDivisibleBy11 is written as \'n % 11 == 0\' which returns a Bool but the specification uses the equation \'n % 11 = 0\' (a Prop) causing a mismatch during the proof. Second, the proof block includes an unexpected \'by\' token in a nested manner. In summary, the code does not unify the boolean equality with the propositional equality and the proof script has an extra tactic marker.\nRetry guidance (MUST FOLLOW):\nRevise the implementation and proof as suggested. Replace the simple boolean equality with an if-then-else statement for clarity, and restructure the proof by eliminating the extra \'by\' token and using case analysis explicitly.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  n % 11 = 0 ↔ result\n  -- << SPEC END >>\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- << PROOF START >>\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The'}], 'model': 'gpt-4o'}}
2025-06-01 02:54:18,671 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:54:18,672 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:54:18,672 - DEBUG - send_request_headers.complete
2025-06-01 02:54:18,672 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:54:18,676 - DEBUG - send_request_body.complete
2025-06-01 02:54:18,676 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:54:24,826 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:54:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5724'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5728'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'15205'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'29.589s'), (b'x-request-id', b'req_e439099c4c1f5a815533848f7455ab0b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6cf6deba8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:54:24,826 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:54:24,826 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:54:24,826 - DEBUG - receive_response_body.complete
2025-06-01 02:54:24,827 - DEBUG - response_closed.started
2025-06-01 02:54:24,827 - DEBUG - response_closed.complete
2025-06-01 02:54:24,827 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:54:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5724', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5728', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '15205', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '29.589s', 'x-request-id': 'req_e439099c4c1f5a815533848f7455ab0b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6cf6deba8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:54:24,827 - DEBUG - request_id: req_e439099c4c1f5a815533848f7455ab0b
2025-06-01 02:54:24,827 - INFO - Raw solution received: ```json
{
  "code": "if (n % 11 == 0) then true else false",
  "proof": "by\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  by_cases h: n % 11 = 0\n  simp [h]\n  trivial\n  simp [h]\n  exfalso\n  apply h\n  exact h"
}
```
2025-06-01 02:54:24,827 - INFO - <class 'str'>
2025-06-01 02:54:24,827 - INFO - Generated solution: {'code': 'if (n % 11 == 0) then true else false', 'proof': 'by\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  by_cases h: n % 11 = 0\n  simp [h]\n  trivial\n  simp [h]\n  exfalso\n  apply h\n  exact h'}
2025-06-01 02:54:29,874 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:18:48: error: unsolved goals
n : ℤ
⊢ n % 11 = 0 ↔ (if (n % 11 == 0) = true then true else false) = true
lean_playground/TempTest.lean:21:2: error: unexpected token 'by'; expected command
2025-06-01 02:54:29,875 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  n % 11 = 0 ↔ result\n  -- << SPEC END >>\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- << PROOF START >>\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif (n % 11 == 0) then true else false\n\nGenerated Proof:\nby\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  by_cases h: n % 11 = 0\n  simp [h]\n  trivial\n  simp [h]\n  exfalso\n  apply h\n  exact h\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:18:48: error: unsolved goals\nn : ℤ\n⊢ n % 11 = 0 ↔ (if (n % 11 == 0) = true then true else false) = true\nlean_playground/TempTest.lean:21:2: error: unexpected token 'by'; expected command"}], 'model': 'o3-mini'}}
2025-06-01 02:54:29,875 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:54:29,876 - DEBUG - close.started
2025-06-01 02:54:29,876 - DEBUG - close.complete
2025-06-01 02:54:29,876 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:54:29,882 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f82e10>
2025-06-01 02:54:29,882 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:54:29,889 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f82de0>
2025-06-01 02:54:29,889 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:54:29,889 - DEBUG - send_request_headers.complete
2025-06-01 02:54:29,889 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:54:29,889 - DEBUG - send_request_body.complete
2025-06-01 02:54:29,890 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:54:45,785 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:54:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'15669'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'15672'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199261'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'221ms'), (b'x-request-id', b'req_2a324a1526f4b32585fee42a7bc63e16'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6d3cf9903bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:54:45,785 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:54:45,785 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:54:45,786 - DEBUG - receive_response_body.complete
2025-06-01 02:54:45,786 - DEBUG - response_closed.started
2025-06-01 02:54:45,786 - DEBUG - response_closed.complete
2025-06-01 02:54:45,786 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:54:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '15669', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '15672', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199261', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '221ms', 'x-request-id': 'req_2a324a1526f4b32585fee42a7bc63e16', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6d3cf9903bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:54:45,786 - DEBUG - request_id: req_2a324a1526f4b32585fee42a7bc63e16
2025-06-01 02:54:45,786 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof did not close the goal and Lean reported an 'unsolved goals' error as well as an 'unexpected token' error. In the proof, the tactic sequence using by_cases, simp, trivial, and exfalso did not successfully bridge the gap between the proposition (n % 11 = 0) and the Boolean expression produced by the if-then-else. This is compounded by a somewhat clumsy use of an if-expression that compares (n % 11 == 0) to true.", 'error_type': 'proof', 'suggested_fix': "A clearer strategy is to redefine the function by using the built-in Boolean equality (==) so that the definition is simply: \n\n  def isDivisibleBy11 (n : Int) : Bool := n % 11 == 0\n\nThen, the theorem becomes a statement about the equivalence between n % 11 = 0 and (isDivisibleBy11 n = true). One effective approach is to 'unfold' the definition and use the 'decide' tactic, which can automatically solve goals involving decidable propositions. For example:\n\n  theorem isDivisibleBy11_spec_satisfied (n : Int) : n % 11 = 0 ↔ (isDivisibleBy11 n = true) := by\n    unfold isDivisibleBy11\n    decide\n\nThis revision leverages the decidability of equality on integers and simplifies the proof considerably.", 'retry_strategy': "Refactor the implementation to use 'n % 11 == 0' directly, and rewrite the proof using 'unfold' and 'decide'. This should automatically resolve the equivalence between the proposition and the Boolean expression."}
2025-06-01 02:54:45,787 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.\n\nPrevious plan:\n{\n  "plan_summary": "Revise the implementation to clearly separate the Boolean calculation from the propositional statement. The plan is to implement a function that returns a Bool using an if-then-else structure to avoid ambiguity between a Boolean equality and a propositional equality. Then, if necessary, prove a theorem that characterizes divisibility by 11 in the proposition world by relating the boolean result to the Prop statement. Also, remove the nested \'by\' tokens in the proof script.",\n  "steps": [\n    "Define the function signature for isDivisibleBy11 that accepts an integer and returns a Bool.",\n    "Implement the function using the modulo operator, but use an if-then-else expression: \'if n % 11 = 0 then true else false\'. This structure ensures that we are using propositional equality within the conditional while returning a boolean.",\n    "(Optional) Write a separate theorem that states: \'n % 11 = 0 ↔ isDivisibleBy11 n = true\'. This theorem would require converting the decidable equality result from the function into a proposition.",\n    "In the theorem or proof block, avoid any extra tactic markers like an unexpected nested \'by\'. Write the proof either as a single \'by\' with a clear script or as a have block without a second \'by\'.",\n    "Optionally include test cases or examples to validate the function, ensuring that the function signature and expected types (Bool, Prop) are handled correctly."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "if-then-else",\n    "modulo operator",\n    "boolean check"\n  ],\n  "proof_keywords": [\n    "propositional equality",\n    "decidable equality",\n    "iff theorem",\n    "proof refinement"\n  ],\n  "assumptions": [\n    "n is an integer.",\n    "The modulo operator is correctly defined for integers in Lean 4.",\n    "We are allowed to separate Boolean computation from propositional assertions.",\n    "If a theorem is provided, the conversion between decidable Boolean and Prop is possible."\n  ],\n  "retry_guidance": "If errors persist, verify that the if-then-else structure correctly distinguishes between a Boolean value and a Prop value. Also, ensure the conversion between \'n % 11 = 0\' (a Prop) and the return of a Bool is clear and explicit. Check that no redundant \'by\' tokens remain in the proof blocks."\n}\n\nLean error summary:\nThe generated code has two main issues. First, the implementation of isDivisibleBy11 is written as \'n % 11 == 0\' which returns a Bool but the specification uses the equation \'n % 11 = 0\' (a Prop) causing a mismatch during the proof. Second, the proof block includes an unexpected \'by\' token in a nested manner. In summary, the code does not unify the boolean equality with the propositional equality and the proof script has an extra tactic marker.\nRetry guidance (MUST FOLLOW):\nRevise the implementation and proof as suggested. Replace the simple boolean equality with an if-then-else statement for clarity, and restructure the proof by eliminating the extra \'by\' token and using case analysis explicitly.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThe proof did not close the goal and Lean reported an \'unsolved goals\' error as well as an \'unexpected token\' error. In the proof, the tactic sequence using by_cases, simp, trivial, and exfalso did not successfully bridge the gap between the proposition (n % 11 = 0) and the Boolean expression produced by the if-then-else. This is compounded by a somewhat clumsy use of an if-expression that compares (n % 11 == 0) to true.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 02:54:45,788 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:54:45,788 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:54:45,788 - DEBUG - send_request_headers.complete
2025-06-01 02:54:45,788 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:54:45,788 - DEBUG - send_request_body.complete
2025-06-01 02:54:45,788 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:55:00,632 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:55:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'14619'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'14622'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'196822'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'953ms'), (b'x-request-id', b'req_a8dfa2c1c3a7c24e8dcdf2a2c180922b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6da05a753bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:55:00,632 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:55:00,632 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:55:00,633 - DEBUG - receive_response_body.complete
2025-06-01 02:55:00,633 - DEBUG - response_closed.started
2025-06-01 02:55:00,633 - DEBUG - response_closed.complete
2025-06-01 02:55:00,633 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:55:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '14619', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '14622', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '196822', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '953ms', 'x-request-id': 'req_a8dfa2c1c3a7c24e8dcdf2a2c180922b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6da05a753bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:55:00,633 - DEBUG - request_id: req_a8dfa2c1c3a7c24e8dcdf2a2c180922b
2025-06-01 02:55:00,634 - INFO - Attempt 3/3
2025-06-01 02:55:00,634 - INFO - Current plan: {
  "plan_summary": "Revise the function and the associated theorem to clearly separate the boolean computation from the underlying propositional statement. The revised plan is to implement a function that returns a Bool using an if-then-else expression that employs the boolean equality (==) for testing whether the remainder is zero. In addition, a theorem will be provided that relates (n % 11 = 0) (a Prop) to (isDivisibleBy11 n = true) (a Bool), using explicit case analysis in the proof to bridge the differences between Bool and Prop without any nested 'by' tokens.",
  "steps": [
    "Define the function signature for isDivisibleBy11, which takes an integer n and returns a Bool.",
    "Implement isDivisibleBy11 using an if-then-else expression. Use the boolean equality operator (==) to check if (n % 11) is equal to 0 (i.e., 'if n % 11 == 0 then true else false'). This ensures that the condition is a Bool.",
    "Write a theorem stating that n % 11 = 0 if and only if isDivisibleBy11 n = true. This theorem makes explicit the connection between the computation in the function and the corresponding mathematical proposition.",
    "In the proof of the theorem, use clear case analysis on the result of the if-then-else expression. Handle each case (true and false) explicitly to match the propositional condition (n % 11 = 0), thereby avoiding any nested tactic markers like additional 'by' tokens.",
    "Optionally include test cases or examples to verify that isDivisibleBy11 behaves as expected with respect to the divisibility by 11."
  ],
  "code_keywords": [
    "Lean 4",
    "if-then-else",
    "boolean equality",
    "modulo operator",
    "function definition"
  ],
  "proof_keywords": [
    "prop vs bool",
    "iff theorem",
    "case analysis",
    "decidable equality",
    "proof by cases"
  ],
  "assumptions": [
    "The modulo operator (%) is correctly defined for integers in Lean 4.",
    "Boolean equality (==) is used to perform decidable comparisons that return Bool.",
    "We are allowed and expected to connect the computational content (Bool) with propositional statements (Prop) through an auxiliary theorem.",
    "The proof system permits explicit case analysis without nested or redundant 'by' tokens."
  ],
  "retry_guidance": "Ensure that the if-then-else condition uses the boolean equality operator (==) to produce a Bool. In the theorem, provide an explicit case split on the outcome of isDivisibleBy11 and relate each branch to the equality (n % 11 = 0). Avoid using nested 'by' tokens; instead, structure the proof with one 'by' for the tactic script or use direct tactic blocks, thus ensuring there are no unsolved goals."
}
2025-06-01 02:55:00,634 - INFO - Updated plan: {
  "plan_summary": "Revise the function and the associated theorem to clearly separate the boolean computation from the underlying propositional statement. The revised plan is to implement a function that returns a Bool using an if-then-else expression that employs the boolean equality (==) for testing whether the remainder is zero. In addition, a theorem will be provided that relates (n % 11 = 0) (a Prop) to (isDivisibleBy11 n = true) (a Bool), using explicit case analysis in the proof to bridge the differences between Bool and Prop without any nested 'by' tokens.",
  "steps": [
    "Define the function signature for isDivisibleBy11, which takes an integer n and returns a Bool.",
    "Implement isDivisibleBy11 using an if-then-else expression. Use the boolean equality operator (==) to check if (n % 11) is equal to 0 (i.e., 'if n % 11 == 0 then true else false'). This ensures that the condition is a Bool.",
    "Write a theorem stating that n % 11 = 0 if and only if isDivisibleBy11 n = true. This theorem makes explicit the connection between the computation in the function and the corresponding mathematical proposition.",
    "In the proof of the theorem, use clear case analysis on the result of the if-then-else expression. Handle each case (true and false) explicitly to match the propositional condition (n % 11 = 0), thereby avoiding any nested tactic markers like additional 'by' tokens.",
    "Optionally include test cases or examples to verify that isDivisibleBy11 behaves as expected with respect to the divisibility by 11."
  ],
  "code_keywords": [
    "Lean 4",
    "if-then-else",
    "boolean equality",
    "modulo operator",
    "function definition"
  ],
  "proof_keywords": [
    "prop vs bool",
    "iff theorem",
    "case analysis",
    "decidable equality",
    "proof by cases"
  ],
  "assumptions": [
    "The modulo operator (%) is correctly defined for integers in Lean 4.",
    "Boolean equality (==) is used to perform decidable comparisons that return Bool.",
    "We are allowed and expected to connect the computational content (Bool) with propositional statements (Prop) through an auxiliary theorem.",
    "The proof system permits explicit case analysis without nested or redundant 'by' tokens."
  ],
  "retry_guidance": "Ensure that the if-then-else condition uses the boolean equality operator (==) to produce a Bool. In the theorem, provide an explicit case split on the outcome of isDivisibleBy11 and relate each branch to the equality (n % 11 = 0). Avoid using nested 'by' tokens; instead, structure the proof with one 'by' for the tactic script or use direct tactic blocks, thus ensuring there are no unsolved goals."
}

Lean error summary:
The proof did not close the goal and Lean reported an 'unsolved goals' error as well as an 'unexpected token' error. In the proof, the tactic sequence using by_cases, simp, trivial, and exfalso did not successfully bridge the gap between the proposition (n % 11 = 0) and the Boolean expression produced by the if-then-else. This is compounded by a somewhat clumsy use of an if-expression that compares (n % 11 == 0) to true.
Retry guidance (MUST FOLLOW):
Refactor the implementation to use 'n % 11 == 0' directly, and rewrite the proof using 'unfold' and 'decide'. This should automatically resolve the equivalence between the proposition and the Boolean expression.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 02:55:00,635 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the function and the associated theorem to clearly separate the boolean computation from the underlying propositional statement. The revised plan is to implement a function that returns a Bool using an if-then-else expression that employs the boolean equality (==) for testing whether the remainder is zero. In addition, a theorem will be provided that relates (n % 11 = 0) (a Prop) to (isDivisibleBy11 n = true) (a Bool), using explicit case analysis in the proof to bridge the differences between Bool and Prop without any nested \'by\' tokens.",\n  "steps": [\n    "Define the function signature for isDivisibleBy11, which takes an integer n and returns a Bool.",\n    "Implement isDivisibleBy11 using an if-then-else expression. Use the boolean equality operator (==) to check if (n % 11) is equal to 0 (i.e., \'if n % 11 == 0 then true else false\'). This ensures that the condition is a Bool.",\n    "Write a theorem stating that n % 11 = 0 if and only if isDivisibleBy11 n = true. This theorem makes explicit the connection between the computation in the function and the corresponding mathematical proposition.",\n    "In the proof of the theorem, use clear case analysis on the result of the if-then-else expression. Handle each case (true and false) explicitly to match the propositional condition (n % 11 = 0), thereby avoiding any nested tactic markers like additional \'by\' tokens.",\n    "Optionally include test cases or examples to verify that isDivisibleBy11 behaves as expected with respect to the divisibility by 11."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "if-then-else",\n    "boolean equality",\n    "modulo operator",\n    "function definition"\n  ],\n  "proof_keywords": [\n    "prop vs bool",\n    "iff theorem",\n    "case analysis",\n    "decidable equality",\n    "proof by cases"\n  ],\n  "assumptions": [\n    "The modulo operator (%) is correctly defined for integers in Lean 4.",\n    "Boolean equality (==) is used to perform decidable comparisons that return Bool.",\n    "We are allowed and expected to connect the computational content (Bool) with propositional statements (Prop) through an auxiliary theorem.",\n    "The proof system permits explicit case analysis without nested or redundant \'by\' tokens."\n  ],\n  "retry_guidance": "Ensure that the if-then-else condition uses the boolean equality operator (==) to produce a Bool. In the theorem, provide an explicit case split on the outcome of isDivisibleBy11 and relate each branch to the equality (n % 11 = 0). Avoid using nested \'by\' tokens; instead, structure the proof with one \'by\' for the tactic script or use direct tactic blocks, thus ensuring there are no unsolved goals."\n}\n\nLean error summary:\nThe proof did not close the goal and Lean reported an \'unsolved goals\' error as well as an \'unexpected token\' error. In the proof, the tactic sequence using by_cases, simp, trivial, and exfalso did not successfully bridge the gap between the proposition (n % 11 = 0) and the Boolean expression produced by the if-then-else. This is compounded by a somewhat clumsy use of an if-expression that compares (n % 11 == 0) to true.\nRetry guidance (MUST FOLLOW):\nRefactor the implementation to use \'n % 11 == 0\' directly, and rewrite the proof using \'unfold\' and \'decide\'. This should automatically resolve the equivalence between the proposition and the Boolean expression.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  n % 11 = 0 ↔ result\n  -- << SPEC END >>\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- << PROOF START >>\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The'}], 'model': 'gpt-4o'}}
2025-06-01 02:55:00,636 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:55:00,636 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:55:00,636 - DEBUG - send_request_headers.complete
2025-06-01 02:55:00,636 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:55:00,636 - DEBUG - send_request_body.complete
2025-06-01 02:55:00,636 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:55:03,871 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:55:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2995'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2999'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'15709'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'28.582s'), (b'x-request-id', b'req_8958774dde4aa8f01532f0b5b26c394d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6dfd1c7e3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:55:03,872 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:55:03,872 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:55:03,872 - DEBUG - receive_response_body.complete
2025-06-01 02:55:03,872 - DEBUG - response_closed.started
2025-06-01 02:55:03,872 - DEBUG - response_closed.complete
2025-06-01 02:55:03,872 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:55:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2995', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2999', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '15709', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '28.582s', 'x-request-id': 'req_8958774dde4aa8f01532f0b5b26c394d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6dfd1c7e3bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:55:03,872 - DEBUG - request_id: req_8958774dde4aa8f01532f0b5b26c394d
2025-06-01 02:55:03,873 - INFO - Raw solution received: ```json
{
  "code": "n % 11 == 0",
  "proof": "\n  by_cases h : n % 11 = 0\n  case pos {\n    simp [h] }\n  case neg {\n    simp [h, Int.mod_ne_zero] at *\n    exfalso\n    exact h (Int.mod_eq_zero_of_dvd $ dvd_of_eq (by simp [h]))\n  }"
}
```
2025-06-01 02:55:03,873 - INFO - <class 'str'>
2025-06-01 02:55:03,873 - INFO - Generated solution: {'code': 'n % 11 == 0', 'proof': '\n  by_cases h : n % 11 = 0\n  case pos {\n    simp [h] }\n  case neg {\n    simp [h, Int.mod_ne_zero] at *\n    exfalso\n    exact h (Int.mod_eq_zero_of_dvd $ dvd_of_eq (by simp [h]))\n  }'}
2025-06-01 02:55:09,155 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:18:48: error: unsolved goals
case pos
n : ℤ
h : n % 11 = 0
⊢ n % 11 = 0 ↔ (n % 11 == 0) = true

case neg
n : ℤ
h : ¬n % 11 = 0
⊢ n % 11 = 0 ↔ (n % 11 == 0) = true
lean_playground/TempTest.lean:23:11: error: unexpected token '{'; expected command
2025-06-01 02:55:09,156 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  n % 11 = 0 ↔ result\n  -- << SPEC END >>\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- << PROOF START >>\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nn % 11 == 0\n\nGenerated Proof:\n\n  by_cases h : n % 11 = 0\n  case pos {\n    simp [h] }\n  case neg {\n    simp [h, Int.mod_ne_zero] at *\n    exfalso\n    exact h (Int.mod_eq_zero_of_dvd $ dvd_of_eq (by simp [h]))\n  }\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:18:48: error: unsolved goals\ncase pos\nn : ℤ\nh : n % 11 = 0\n⊢ n % 11 = 0 ↔ (n % 11 == 0) = true\n\ncase neg\nn : ℤ\nh : ¬n % 11 = 0\n⊢ n % 11 = 0 ↔ (n % 11 == 0) = true\nlean_playground/TempTest.lean:23:11: error: unexpected token '{'; expected command"}], 'model': 'o3-mini'}}
2025-06-01 02:55:09,156 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:55:09,157 - DEBUG - close.started
2025-06-01 02:55:09,157 - DEBUG - close.complete
2025-06-01 02:55:09,157 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:55:09,164 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a6f90>
2025-06-01 02:55:09,164 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:55:09,174 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6784ad80>
2025-06-01 02:55:09,174 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:55:09,174 - DEBUG - send_request_headers.complete
2025-06-01 02:55:09,175 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:55:09,175 - DEBUG - send_request_body.complete
2025-06-01 02:55:09,175 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:55:29,363 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:55:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'19559'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'19589'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199240'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'228ms'), (b'x-request-id', b'req_ebf4abd2b4e1ef631329fb02477f07dd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6e328d768fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:55:29,363 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:55:29,364 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:55:29,364 - DEBUG - receive_response_body.complete
2025-06-01 02:55:29,364 - DEBUG - response_closed.started
2025-06-01 02:55:29,364 - DEBUG - response_closed.complete
2025-06-01 02:55:29,364 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:55:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '19559', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '19589', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199240', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '228ms', 'x-request-id': 'req_ebf4abd2b4e1ef631329fb02477f07dd', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6e328d768fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:55:29,364 - DEBUG - request_id: req_ebf4abd2b4e1ef631329fb02477f07dd
2025-06-01 02:55:29,365 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof failed because the current approach attempts to reason directly about the equivalence between the proposition (n % 11 = 0) and the Boolean (n % 11 == 0) = true. Lean complains that the goal is unsolved and that the 'case neg' block has an unexpected token. In particular, the error indicates that the proof is trying to prove an equivalence between a ℤ-equality and a Boolean equality, and that the proof does not correctly bridge the gap between these two types.", 'error_type': 'proof', 'suggested_fix': "One way to fix the issue is to prove a lemma that relates a Bool b to the equation b = true. For example, prove a helper lemma 'bool_eq_true_iff' stating that for any Bool b, b = true ↔ b. Then, in the specification theorem, unfold definitions and use this lemma to turn the goal into showing (n % 11 = 0) ↔ (n % 11 == 0). Since the definition of (==) on integers is given by checking whether n % 11 = 0, this should reduce to reflexivity. Here is a revised version of the code:\n\n------------------------------------------------------------\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  n % 11 == 0\n\n-- Specification: the result is true if and only if n % 11 = 0\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  n % 11 = 0 ↔ result\n\n-- Helper lemma relating a Bool and its equality to true\nlemma bool_eq_true_iff (b : Bool) : b = true ↔ b :=\n  ⟨fun h => by rw [h] ; trivial,\n   fun h => by cases b;\n     { simp at h, exact rfl };\n     { simp at h, exact rfl }⟩\n\n-- Theorem: isDivisibleBy11_spec is satisfied\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- Unfold definitions\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  -- Replace (n % 11 == 0) = true with (n % 11 == 0) using our helper lemma\n  rw [bool_eq_true_iff]\n  -- Now the goal is: n % 11 = 0 ↔ n % 11 == 0, which is definitionally true\n  rfl\n------------------------------------------------------------\n\nThis revised proof avoids the problematic case analysis and uses a helper lemma to connect Boolean equality with propositions.", 'retry_strategy': "Apply the modifications by including the helper lemma 'bool_eq_true_iff' and rewriting the proof to use it. Then re-run Lean to check that the theorem type-checks and the equivalence holds definitionally."}
2025-06-01 02:55:29,365 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.\n\nPrevious plan:\n{\n  "plan_summary": "Revise the function and the associated theorem to clearly separate the boolean computation from the underlying propositional statement. The revised plan is to implement a function that returns a Bool using an if-then-else expression that employs the boolean equality (==) for testing whether the remainder is zero. In addition, a theorem will be provided that relates (n % 11 = 0) (a Prop) to (isDivisibleBy11 n = true) (a Bool), using explicit case analysis in the proof to bridge the differences between Bool and Prop without any nested \'by\' tokens.",\n  "steps": [\n    "Define the function signature for isDivisibleBy11, which takes an integer n and returns a Bool.",\n    "Implement isDivisibleBy11 using an if-then-else expression. Use the boolean equality operator (==) to check if (n % 11) is equal to 0 (i.e., \'if n % 11 == 0 then true else false\'). This ensures that the condition is a Bool.",\n    "Write a theorem stating that n % 11 = 0 if and only if isDivisibleBy11 n = true. This theorem makes explicit the connection between the computation in the function and the corresponding mathematical proposition.",\n    "In the proof of the theorem, use clear case analysis on the result of the if-then-else expression. Handle each case (true and false) explicitly to match the propositional condition (n % 11 = 0), thereby avoiding any nested tactic markers like additional \'by\' tokens.",\n    "Optionally include test cases or examples to verify that isDivisibleBy11 behaves as expected with respect to the divisibility by 11."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "if-then-else",\n    "boolean equality",\n    "modulo operator",\n    "function definition"\n  ],\n  "proof_keywords": [\n    "prop vs bool",\n    "iff theorem",\n    "case analysis",\n    "decidable equality",\n    "proof by cases"\n  ],\n  "assumptions": [\n    "The modulo operator (%) is correctly defined for integers in Lean 4.",\n    "Boolean equality (==) is used to perform decidable comparisons that return Bool.",\n    "We are allowed and expected to connect the computational content (Bool) with propositional statements (Prop) through an auxiliary theorem.",\n    "The proof system permits explicit case analysis without nested or redundant \'by\' tokens."\n  ],\n  "retry_guidance": "Ensure that the if-then-else condition uses the boolean equality operator (==) to produce a Bool. In the theorem, provide an explicit case split on the outcome of isDivisibleBy11 and relate each branch to the equality (n % 11 = 0). Avoid using nested \'by\' tokens; instead, structure the proof with one \'by\' for the tactic script or use direct tactic blocks, thus ensuring there are no unsolved goals."\n}\n\nLean error summary:\nThe proof did not close the goal and Lean reported an \'unsolved goals\' error as well as an \'unexpected token\' error. In the proof, the tactic sequence using by_cases, simp, trivial, and exfalso did not successfully bridge the gap between the proposition (n % 11 = 0) and the Boolean expression produced by the if-then-else. This is compounded by a somewhat clumsy use of an if-expression that compares (n % 11 == 0) to true.\nRetry guidance (MUST FOLLOW):\nRefactor the implementation to use \'n % 11 == 0\' directly, and rewrite the proof using \'unfold\' and \'decide\'. This should automatically resolve the equivalence between the proposition and the Boolean expression.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThe proof failed because the current approach attempts to reason directly about the equivalence between the proposition (n % 11 = 0) and the Boolean (n % 11 == 0) = true. Lean complains that the goal is unsolved and that the \'case neg\' block has an unexpected token. In particular, the error indicates that the proof is trying to prove an equivalence between a ℤ-equality and a Boolean equality, and that the proof does not correctly bridge the gap between these two types.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 02:55:29,366 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:55:29,366 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:55:29,366 - DEBUG - send_request_headers.complete
2025-06-01 02:55:29,366 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:55:29,366 - DEBUG - send_request_body.complete
2025-06-01 02:55:29,366 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:55:39,275 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:55:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'9272'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'9280'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'197307'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'807ms'), (b'x-request-id', b'req_f7a95a08a23c1b44ef0eebd4bbd815f2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6eb0b9748fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:55:39,275 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:55:39,275 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:55:39,275 - DEBUG - receive_response_body.complete
2025-06-01 02:55:39,275 - DEBUG - response_closed.started
2025-06-01 02:55:39,275 - DEBUG - response_closed.complete
2025-06-01 02:55:39,276 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:55:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '9272', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '9280', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '197307', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '807ms', 'x-request-id': 'req_f7a95a08a23c1b44ef0eebd4bbd815f2', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6eb0b9748fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:55:39,276 - DEBUG - request_id: req_f7a95a08a23c1b44ef0eebd4bbd815f2
2025-06-01 02:55:39,276 - INFO - Solution generated in 115.34 seconds
2025-06-01 02:55:39,276 - INFO - Generated code length: 11 characters
2025-06-01 02:55:39,276 - INFO - Generated proof length: 181 characters
2025-06-01 02:55:39,276 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:55:39,276 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:55:44,555 - INFO - Implementation test result: PASS
2025-06-01 02:55:44,555 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:55:49,705 - INFO - Full solution test result: FAIL
2025-06-01 02:55:49,706 - ERROR - Proof error: lean_playground/TempTest.lean:18:48: error: unsolved goals
case pos
n : ℤ
h : n % 11 = 0
⊢ n % 11 = 0 ↔ (n % 11 == 0) = true

case neg
n : ℤ
h : ¬n % ...
2025-06-01 02:55:49,706 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:55:49,706 - ERROR - ❌ Proof has errors
2025-06-01 02:55:49,706 - INFO - 
==================================================
2025-06-01 02:55:49,706 - INFO - Processing task task_id_127...
2025-06-01 02:55:49,706 - INFO - Reading problem description and code template from tasks/task_id_127...
2025-06-01 02:55:49,706 - INFO - Problem description length: 342 characters
2025-06-01 02:55:49,706 - INFO - Reading unit tests from tasks/task_id_127...
2025-06-01 02:55:49,706 - INFO - Unit tests length: 219 characters
2025-06-01 02:55:49,706 - INFO - Running main workflow to generate solution...
2025-06-01 02:55:49,706 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.

-----Input-----
The input consists of:
a: The first integer.
b: The second integer.

-----Output-----
The output is an integer:
Returns the product of the two input integers (a * b).
2025-06-01 02:55:49,707 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def multiply (a : Int) (b : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result should be the product of the two input integers
def multiply_spec (a : Int) (b : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  result = a * b
  -- << SPEC END >>

theorem multiply_spec_satisfied (a : Int) (b : Int) :
  multiply_spec a b (multiply a b) := by
  -- << PROOF START >>
  unfold multiply multiply_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:55:49,734 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7f4e6733e660>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.\n\n-----Input-----\nThe input consists of:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the product of the two input integers (a * b).', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:55:49,735 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:55:49,735 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:55:49,740 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f82cf0>
2025-06-01 02:55:49,741 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4e67393150> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:55:49,749 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f833b0>
2025-06-01 02:55:49,749 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:55:49,749 - DEBUG - send_request_headers.complete
2025-06-01 02:55:49,749 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:55:49,749 - DEBUG - send_request_body.complete
2025-06-01 02:55:49,749 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:55:50,130 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:55:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'81'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-78998c59cd-fzzv7'), (b'x-envoy-upstream-service-time', b'84'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999915'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'x-request-id', b'req_1702a67637709d3c9bae1112248ea662'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zFMRLJ4.wji9Bcd77lth2MaRisRkWZ7HcINBdyoIJ9Q-1748746550-1.0.1.1-bOMFFIFYcD0rkD2f.m3tHyux3Xw8NggsUswXwyW0uqWN74JjUrt_B89cKuBZwoc2aNwptFiKMaigI7sCKN9pdMNSB5623rbbB2ZDHxebIa4; path=/; expires=Sun, 01-Jun-25 03:25:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=GIBphOqpXUF5M82vM4V7d3F9zXws_MSlwvyZ4SUO96E-1748746550147-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6f301a3f3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:55:50,130 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:55:50,130 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:55:50,131 - DEBUG - receive_response_body.complete
2025-06-01 02:55:50,131 - DEBUG - response_closed.started
2025-06-01 02:55:50,131 - DEBUG - response_closed.complete
2025-06-01 02:55:50,131 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:55:50 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '81'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-78998c59cd-fzzv7'), ('x-envoy-upstream-service-time', '84'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999915'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '5ms'), ('x-request-id', 'req_1702a67637709d3c9bae1112248ea662'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=zFMRLJ4.wji9Bcd77lth2MaRisRkWZ7HcINBdyoIJ9Q-1748746550-1.0.1.1-bOMFFIFYcD0rkD2f.m3tHyux3Xw8NggsUswXwyW0uqWN74JjUrt_B89cKuBZwoc2aNwptFiKMaigI7sCKN9pdMNSB5623rbbB2ZDHxebIa4; path=/; expires=Sun, 01-Jun-25 03:25:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=GIBphOqpXUF5M82vM4V7d3F9zXws_MSlwvyZ4SUO96E-1748746550147-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b6f301a3f3bfe-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:55:50,131 - DEBUG - request_id: req_1702a67637709d3c9bae1112248ea662
2025-06-01 02:55:50,138 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Interacting with Lean

You are now familiar with the fundamentals of dependent type theory, both as a
language for defining mathematical objects and a language for constructing
proofs. The one thing you are missing is a mechanism for defining new data
types. We will fill this gap in the next chapter, which introduces the notion
of an _inductive data type_. But first, in this chapter, we take a break from
the mechanics of type theory to explore some pragmatic aspects of interacting
with Lean.

Not all of the information found here will be useful to you right away. We
recommend skimming this section to get a sense of Lean's features, and then
returning to it as necessary.

## Importing Files

The goal of Lean's front end is to interpret user input, construct formal
expressions, and check that they are well-formed and type-correct. Lean also
supports the use of various editors, which provide continuous checking and
feedback. More information can be found on the Lean [documentation
pages](https://lean-lang.org/documentation/).

The definitions and theorems in Lean's standard library are spread across
multiple files. Users may also wish to make use of additional libraries, or
develop their own projects across multiple files. When Lean starts, it
automatically imports the contents of the library `Init` folder, which
includes a number of fundamental definitions and constructions. As a result,
most of the examples we present here work "out of the box."

If you want to use additional files, however, they need to be imported
manually, via an `import` statement at the beginning of a file. The command

    
    
    import Bar.Baz.Blah
    

imports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted
relative to the Lean _search path_. Information as to how the search path is
determined can be found on the [documentation pages](https://lean-
lang.org/documentation/). By default, it includes the standard library
directory, and (in some contexts) the root of the user's local project.

Importing is transitive. In other words, if you import `Foo` and `Foo` imports
`Bar`, then you also have access to the contents of `Bar`, and do not need to
import it explicitly.

## More on Sections

Lean provides various sectioning mechanisms to help structure a theory. You
saw in [Variables and Sections](./dependent_type_theory.html#variables-and-
sections) that the `section` command makes it possible not only to group
together elements of a theory that go together, but also to declare variables
that are inserted as arguments to theorems and definitions, as necessary.
Remember that the point of the `variable` command is to declare variables for
use in theorems, as in the following example:

    
    
    section
    variable (x y : Nat)
    
    def double := x + x
    
    #check double y
    #check double (2 * x)
    
    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm
    
    theorem t1 : double (x + y) = double x + double y := by
      simp [double]
    
    #check t1 y
    #check t1 (2 * x)
    
    theorem t2 : double (x * y) = double x * y := by
      simp [double, Nat.add_mul]
    
    end
    

The definition of `double` does not have to declare `x` as an argument; Lean
detects the dependence and inserts it automatically. Similarly, Lean detects
the occurrence of `x` in `t1` and `t2`, and inserts it automatically there,
too. Note that `double` does _not_ have `y` as argument. Variables are only
included in declarations where they are actually used.

## More on Namespaces

In Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We
saw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean
provides mechanisms for working with hierarchical names. The command
`namespace foo` causes `foo` to be prepended to the name of each definition
and theorem until `end foo` is encountered. The command `open foo` then
creates temporary _aliases_ to definitions and theorems that begin with prefix
`foo`.

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    
    open Foo
    
    #check bar
    #check Foo.bar
    

The following definition

    
    
    def Foo.bar : Nat := 1
    

is treated as a macro, and expands to

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    

Although the names of theorems and definitions have to be unique, the aliases
that identify them do not. When we open a namespace, an identifier may be
ambiguous. Lean tries to use type information to disambiguate the meaning in
context, but you can always disambiguate by giving the full name. To that end,
the string `_root_` is an explicit description of the empty prefix.

    
    
    def String.add (a b : String) : String :=
      a ++ b
    
    def Bool.add (a b : Bool) : Bool :=
      a != b
    
    def add (α β : Type) : Type := Sum α β
    
    open Bool
    open String
    -- #check add -- ambiguous
    #check String.add           -- String → String → String
    #check Bool.add             -- Bool → Bool → Bool
    #check _root_.add           -- Type → Type → Type
    
    #check add "hello" "world"  -- String
    #check add true false       -- Bool
    #check add Nat Nat          -- Type
    

We can prevent the shorter alias from being created by using the `protected`
keyword:

    
    
    protected def Foo.bar : Nat := 1
    
    open Foo
    
    -- #check bar -- error
    #check Foo.bar
    

This is often used for names like `Nat.rec` and `Nat.recOn`, to prevent
overloading of common names.

The `open` command admits variations. The command

    
    
    open Nat (succ zero gcd)
    #check zero     -- Nat
    #eval gcd 15 6  -- 3
    

creates aliases for only the identifiers listed. The command

    
    
    open Nat hiding succ gcd
    #check zero     -- Nat
    -- #eval gcd 15 6  -- error
    #eval Nat.gcd 15 6  -- 3
    

creates aliases for everything in the `Nat` namespace _except_ the identifiers
listed.

    
    
    open Nat renaming mul → times, add → plus
    #eval plus (times 2 2) 3  -- 7
    

creates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.

It is sometimes useful to `export` aliases from one namespace to another, or
to the top level. The command

    
    
    export Nat (succ add sub)
    

creates aliases for `succ`, `add`, and `sub` in the current namespace, so that
whenever the namespace is open, these aliases are available. If this command
is used outside a namespace, the aliases are exported to the top level.

## Attributes

The main function of Lean is to translate user input to formal expressions
that are checked by the kernel for correctness and then stored in the
environment for later use. But some commands have other effects on the
environment, either assigning attributes to objects in the environment,
defining notation, or declaring instances of type classes, as described in
[Chapter Type Classes](./type_classes.html). Most of these commands have
global effects, which is to say, they remain in effect not only in the current
file, but also in any file that imports it. However, such commands often
support the `local` modifier, which indicates that they only have effect until
the current `section` or `namespace` is closed, or until the end of the
current file.

In [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw
that theorems can be annotated with the `[simp]` attribute, which makes them
available for use by the simplifier. The following example defines the prefix
relation on lists, proves that this relation is reflexive, and assigns the
`[simp]` attribute to that theorem.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    

The simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to
`True`.

One can also assign the attribute any time after the definition takes place:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [simp] List.isPrefix_self
    

In all these cases, the attribute remains in effect in any file that imports
the one in which the declaration occurs. Adding the `local` modifier restricts
the scope:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    section
    
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [local simp] List.isPrefix_self
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    
    end
    
    -- Error:
    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by
    --  simp
    

For another example, we can use the `instance` command to assign the notation
`≤` to the `isPrefix` relation. That command, which will be explained in
[Chapter Type Classes](./type_classes.html), works by assigning an
`[instance]` attribute to the associated definition.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    instance : LE (List α) where
      le := isPrefix
    
    theorem List.isPrefix_self (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    

That assignment can also be made local:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    def instLe : LE (List α) :=
      { le := isPrefix }
    
    section
    attribute [local instance] instLe
    
    example (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    
    end
    
    -- Error:
    -- example (as : List α) : as ≤ as :=
    --  ⟨[], by simp⟩
    

In Section Notation below, we will discuss Lean's mechanisms for defining
notation, and see that they also support the `local` modifier. However, in
Section Setting Options, we will discuss Lean's mechanisms for setting
options, which does _not_ follow this pattern: options can _only_ be set
locally, which is to say, their scope is always restricted to the current
section or current file.

## More on Implicit Arguments

In [Section Implicit Arguments](./dependent_type_theory.html#implicit-
arguments), we saw that if Lean displays the type of a term `t` as `{x : α} →
β x`, then the curly brackets indicate that `x` has been marked as an
_implicit argument_ to `t`. This means that whenever you write `t`, a
placeholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you
don't want that to happen, you have to write `@t` instead.

Notice that implicit arguments are inserted eagerly. Suppose we define a
function `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,
when we write the expression `f 7` without further arguments, it is parsed as
`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that
a placeholder should only be added _before_ a subsequent explicit argument.
This annotation can also be written using as `⦃y : Nat⦄`, where the unicode
brackets are entered as `\{{` and `\}}`, respectively. With this annotation,
the expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as
`f 7 _ 3`, just as it would be with the strong annotation.

To illustrate the difference, consider the following example, which shows that
a reflexive euclidean relation is both symmetric and transitive.

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b : α}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
     th2 (th1 reflr @euclr) @euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3
    

The results are broken down into small steps: `th1` shows that a relation that
is reflexive and euclidean is symmetric, and `th2` shows that a relation that
is symmetric and euclidean is transitive. Then `th3` combines the two results.
But notice that we have to manually disable the implicit arguments in `euclr`,
because otherwise too many implicit arguments are inserted. The problem goes
away if we use weak implicit arguments:

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b : α}}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
      th2 (th1 reflr euclr) euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- euclidean r
    

There is a third kind of implicit argument that is denoted with square
brackets, `[` and `]`. These are used for type classes, as explained in
[Chapter Type Classes](./type_classes.html).

## Notation

Identifiers in Lean can include any alphanumeric characters, including Greek
characters (other than ∀ , Σ , and λ , which, as we have seen, have a special
meaning in the dependent type theory). They can also include subscripts, which
can be entered by typing `\_` followed by the desired subscripted character.

Lean's parser is extensible, which is to say, we can define new notation.

Lean's syntax can be extended and customized by users at every level, ranging
from basic "mixfix" notations to custom elaborators. In fact, all builtin
syntax is parsed and processed using the same mechanisms and APIs open to
users. In this section, we will describe and explain the various extension
points.

While introducing new notations is a relatively rare feature in programming
languages and sometimes even frowned upon because of its potential to obscure
code, it is an invaluable tool in formalization for expressing established
conventions and notations of the respective field succinctly in code. Going
beyond basic notations, Lean's ability to factor out common boilerplate code
into (well-behaved) macros and to embed entire custom domain specific
languages (DSLs) to textually encode subproblems efficiently and readably can
be of great benefit to both programmers and proof engineers alike.

### Notations and Precedence

The most basic syntax extension commands allow introducing new (or overloading
existing) prefix, infix, and postfix operators.

    
    
    infixl:65   " + " => HAdd.hAdd  -- left-associative
    infix:50    " = " => Eq         -- non-associative
    infixr:80   " ^ " => HPow.hPow  -- right-associative
    prefix:100  "-"   => Neg.neg
    set_option quotPrecheck false
    postfix:max "⁻¹"  => Inv.inv
    

After the initial command name describing the operator kind (its "fixity"), we
give the _parsing precedence_ of the operator preceded by a colon `:`, then a
new or existing token surrounded by double quotes (the whitespace is used for
pretty printing), then the function this operator should be translated to
after the arrow `=>`.

The precedence is a natural number describing how "tightly" an operator binds
to its arguments, encoding the order of operations. We can make this more
precise by looking at the commands the above unfold to:

    
    
    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs
    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs
    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs
    notation:100 "-" arg:100 => Neg.neg arg
    set_option quotPrecheck false
    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024
    

It turns out that all commands from the first code block are in fact command
_macros_ translating to the more general `notation` command. We will learn
about writing such macros below. Instead of a single token, the `notation`
command accepts a mixed sequence of tokens and named term placeholders with
precedences, which can be referenced on the right-hand side of `=>` and will
be replaced by the respective term parsed at that position. A placeholder with
precedence `p` accepts only notations with precedence at least `p` in that
place. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +
(b + c)` because the right-hand side operand of an `infixl` notation has
precedence one greater than the notation itself. In contrast, `infixr` reuses
the notation's precedence for the right-hand side operand, so `a ^ b ^ c`
_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to
introduce an infix notation like

    
    
    set_option quotPrecheck false
    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs
    

where the precedences do not sufficiently determine associativity, Lean's
parser will default to right associativity. More precisely, Lean's parser
follows a local _longest parse_ rule in the presence of ambiguous grammars:
when parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue
parsing as long as possible (as the current precedence allows), not stopping
after `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~
c)`.

As mentioned above, the `notation` command allows us to define arbitrary
_mixfix_ syntax freely mixing tokens and placeholders.

    
    
    set_option quotPrecheck false
    notation:max "(" e ")" => e
    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ
    

Placeholders without precedence default to `0`, i.e. they accept notations of
any precedence in their place. If two notations overlap, we again apply the
longest parse rule:

    
    
    notation:65 a " + " b:66 " + " c:66 => a + b - c
    #eval 1 + 2 + 3  -- 0
    

The new notation is preferred to the binary notation since the latter, before
chaining, would stop parsing after `1 + 2`. If there are multiple notations
accepting the same longest parse, the choice will be delayed until
elaboration, which will fail unless exactly one overload is type-correct.

## Coercions

In Lean, the type of natural numbers, `Nat`, is different from the type of
integers, `Int`. But there is a function `Int.ofNat` that embeds the natural
numbers in the integers, meaning that we can view any natural number as an
integer, when needed. Lean has mechanisms to detect and insert _coercions_ of
this sort.

    
    
    variable (m n : Nat)
    variable (i j : Int)
    
    #check i + m      -- i + Int.ofNat m : Int
    #check i + m + j  -- i + Int.ofNat m + j : Int
    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int
    

## Displaying Information

There are a number of ways in which you can query Lean for information about
its current state and the objects and theorems that are available in the
current context. You have already seen two of the most common ones, `#check`
and `#eval`. Remember that `#check` is often used in conjunction with the `@`
operator, which makes all of the arguments to a theorem or definition
explicit. In addition, you can use the `#print` command to get information
about any identifier. If the identifier denotes a definition or theorem, Lean
prints the type of the symbol, and its definition. If it is a constant or an
axiom, Lean indicates that fact, and shows the type.

    
    
    -- examples with equality
    #check Eq
    #check @Eq
    #check Eq.symm
    #check @Eq.symm
    
    #print Eq.symm
    
    -- examples with And
    #check And
    #check And.intro
    #check @And.intro
    
    -- a user-defined function
    def foo {α : Type u} (x : α) : α := x
    
    #check foo
    #check @foo
    #print foo
    

## Setting Options

Lean maintains a number of internal variables that can be set by users to
control its behavior. The syntax for doing so is as follows:

    
    
    set_option <name> <value>
    

One very useful family of options controls the way Lean's _pretty- printer_
displays terms. The following options take an input of true or false:

    
    
    pp.explicit  : display implicit arguments
    pp.universes : display hidden universe parameters
    pp.notation  : display output using defined notations
    

As an example, the following settings yield much longer output:

    
    
    set_option pp.explicit true
    set_option pp.universes true
    set_option pp.notation false
    
    #check 2 + 2 = 4
    #reduce (fun x => x + 2) = (fun x => x + 3)
    #check (fun x => x + 1) 1
    

The command `set_option pp.all true` carries out these settings all at once,
whereas `set_option pp.all false` reverts to the previous values. Pretty
printing additional information is often very useful when you are debugging a
proof, or trying to understand a cryptic error message. Too much information
can be overwhelming, though, and Lean's defaults are generally sufficient for
ordinary interactions.

## Using the Library

To use Lean effectively you will inevitably need to make use of definitions
and theorems in the library. Recall that the `import` command at the beginning
of a file imports previously compiled results from other files, and that
importing is transitive; if you import `Foo` and `Foo` imports `Bar`, then the
definitions and theorems from `Bar` are available to you as well. But the act
of opening a namespace, which provides shorter names, does not carry over. In
each file, you need to open the namespaces you wish to use.

In general, it is important for you to be familiar with the library and its
contents, so you know what theorems, definitions, notations, and resources are
available to you. Below we will see that Lean's editor modes can also help you
find things you need, but studying the contents of the library directly is
often unavoidable. Lean's standard library can be found online, on GitHub:

  * <https://github.com/leanprover/lean4/tree/master/src/Init>

  * <https://github.com/leanprover/std4/tree/main/Std>

You can see the contents of these directories and files using GitHub's browser
interface. If you have installed Lean on your own computer, you can find the
library in the `lean` folder, and explore it with your file manager. Comment
headers at the top of each file provide additional information.

Lean's library developers follow general naming guidelines to make it easier
to guess the name of a theorem you need, or to find it using tab completion in
editors with a Lean mode that supports this, which is discussed in the next
section. Identifiers are generally `camelCase`, and types are `CamelCase`. For
theorem names, we rely on descriptive names where the different components are
separated by `_`s. Often the name of theorem simply describes the conclusion:

    
    
    #check Nat.succ_ne_zero
    #check Nat.zero_add
    #check Nat.mul_one
    #check Nat.le_of_succ_le_succ
    

Remember that identifiers in Lean can be organized into hierarchical
namespaces. For example, the theorem named `le_of_succ_le_succ` in the
namespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name
is made available by the command `open Nat` (for names not marked as
`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)
and [Chapter Structures and Records](./structures_and_records.html) that
defining structures and inductive data types in Lean generates associated
operations, and these are stored in a namespace with the same name as the type
under definition. For example, the product type comes with the following
operations:

    
    
    #check @Prod.mk
    #check @Prod.fst
    #check @Prod.snd
    #check @Prod.rec
    

The first is used to construct a pair, whereas the next two, `Prod.fst` and
`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another
mechanism for defining functions on a product in terms of a function on the
two components. Names like `Prod.rec` are _protected_ , which means that one
has to use the full name even when the `Prod` namespace is open.

With the propositions as types correspondence, logical connectives are also
instances of inductive types, and so we tend to use dot notation for them as
well:

    
    
    #check @And.intro
    #check @And.casesOn
    #check @And.left
    #check @And.right
    #check @Or.inl
    #check @Or.inr
    #check @Or.elim
    #check @Exists.intro
    #check @Exists.elim
    #check @Eq.refl
    #check @Eq.subst
    

## Auto Bound Implicit Arguments

In the previous section, we have shown how implicit arguments make functions
more convenient to use. However, functions such as `compose` are still quite
verbose to define. Note that the universe polymorphic `compose` is even more
verbose than the one previously defined.

    
    
    universe u v w
    def compose {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

You can avoid the `universe` command by providing the universe parameters when
defining `compose`.

    
    
    def compose.{u, v, w}
                {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

Lean 4 supports a new feature called _auto bound implicit arguments_. It makes
functions such as `compose` much more convenient to write. When Lean processes
the header of a declaration, any unbound identifier is automatically added as
an implicit argument _if_ it is a single lower case or greek letter. With this
feature we can write `compose` as

    
    
    def compose (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    
    #check @compose
    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ
    

Note that Lean inferred a more general type using `Sort` instead of `Type`.

Although we love this feature and use it extensively when implementing Lean,
we realize some users may feel uncomfortable with it. Thus, you can disable it
using the command `set_option autoImplicit false`.

    
    
    set_option autoImplicit false
    /- The following definition produces `unknown identifier` errors -/
    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=
    --   g (f x)
    

## Implicit Lambdas

In Lean 3 stdlib, we find many
[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)
of the dreadful `@`+`_` idiom. It is often used when the expected type is a
function type with implicit arguments, and we have a constant (`reader_t.pure`
in the example) which also takes implicit arguments. In Lean 4, the elaborator
automatically introduces lambdas for consuming implicit arguments. We are
still exploring this feature and analyzing its impact, but the experience so
far has been very positive. Here is the example from the link above using Lean
4 implicit lambdas.

    
    
    variable (ρ : Type) (m : Type → Type) [Monad m]
    instance : Monad (ReaderT ρ m) where
      pure := ReaderT.pure
      bind := ReaderT.bind
    

Users can disable the implicit lambda feature by using `@` or writing a lambda
expression with `{}` or `[]` binder annotations. Here are few examples

    
    
    namespace ex2
    def id1 : {α : Type} → α → α :=
      fun x => x
    
    def listId : List ({α : Type} → α → α) :=
      (fun x => x) :: []
    
    -- In this example, implicit lambda introduction has been disabled because
    -- we use `@` before `fun`
    def id2 : {α : Type} → α → α :=
      @fun α (x : α) => id1 x
    
    def id3 : {α : Type} → α → α :=
      @fun α x => id1 x
    
    def id4 : {α : Type} → α → α :=
      fun x => id1 x
    
    -- In this example, implicit lambda introduction has been disabled
    -- because we used the binder annotation `{...}`
    def id5 : {α : Type} → α → α :=
      fun {α} x => id1 x
    end ex2
    

## Sugar for Simple Functions

In Lean 3, we can create simple functions from infix operators by using
parentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we
generalize this notation using `·` as a placeholder. Here are a few examples:

    
    
    namespace ex3
    #check (· + 1)
    -- fun a => a + 1
    #check (2 - ·)
    -- fun a => 2 - a
    #eval [1, 2, 3, 4, 5].foldl (·*·) 1
    -- 120
    
    def f (x y z : Nat) :=
      x + y + z
    
    #check (f · 1 ·)
    -- fun a b => f a 1 b
    
    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)
    -- [1, 3, 5]
    end ex3
    

As in Lean 3, the notation is activated using parentheses, and the lambda
abstraction is created by collecting the nested `·`s. The collection is
interrupted by nested parentheses. In the following example, two different
lambda expressions are created.

    
    
    #check (Prod.mk · (· + 1))
    -- fun a => (a, fun b => b + 1)
    

## Named Arguments

Named arguments enable you to specify an argument for a parameter by matching
the argument with its name rather than with its position in the parameter
list. If you don't remember the order of the parameters but know their names,
you can send the arguments in any order. You may also provide the value for an
implicit parameter when
 modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
2025-06-01 02:55:50,155 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.\n\n-----Input-----\nThe input consists of:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the product of the two input integers (a * b).'}], 'model': 'o3-mini'}}
2025-06-01 02:55:50,156 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:55:50,156 - DEBUG - close.started
2025-06-01 02:55:50,157 - DEBUG - close.complete
2025-06-01 02:55:50,157 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:55:50,181 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f80530>
2025-06-01 02:55:50,181 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:55:50,207 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f83200>
2025-06-01 02:55:50,208 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:55:50,208 - DEBUG - send_request_headers.complete
2025-06-01 02:55:50,208 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:55:50,208 - DEBUG - send_request_body.complete
2025-06-01 02:55:50,208 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:55:54,844 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:55:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4371'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4376'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199613'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'115ms'), (b'x-request-id', b'req_a50079ca019da6ae0317a6a855d8c3b2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6f331e764436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:55:54,844 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:55:54,844 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:55:54,845 - DEBUG - receive_response_body.complete
2025-06-01 02:55:54,845 - DEBUG - response_closed.started
2025-06-01 02:55:54,845 - DEBUG - response_closed.complete
2025-06-01 02:55:54,845 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:55:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4371', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4376', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199613', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '115ms', 'x-request-id': 'req_a50079ca019da6ae0317a6a855d8c3b2', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6f331e764436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:55:54,845 - DEBUG - request_id: req_a50079ca019da6ae0317a6a855d8c3b2
2025-06-01 02:55:54,845 - INFO - Attempt 1/3
2025-06-01 02:55:54,845 - INFO - Current plan: {
  "plan_summary": "We will create a Lean 4 function that takes two integers as input and returns their product using the built-in multiplication operator. The approach is straightforward, relying on Lean's built-in arithmetic. No complex proofs are required as the function is directly using the arithmetic operator.",
  "steps": [
    "Define the function with two parameters of type Int.",
    "Use the built-in multiplication operator (*) to compute the product.",
    "Return the result.",
    "Optionally, add any documentation or comments to describe the function's purpose."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "integers",
    "multiplication",
    "Int"
  ],
  "proof_keywords": [
    "direct computation",
    "arithmetic properties",
    "commutative",
    "associative"
  ],
  "assumptions": [
    "Lean 4 is set up and its standard library is available.",
    "The built-in multiplication operator (*) behaves as expected for integer values."
  ],
  "retry_guidance": "If errors occur, check that the function signature and type annotations are correct, especially ensuring that the parameters and return type are properly declared as Int. Also verify that the multiplication operator is used with the right precedence and that any necessary imports for basic arithmetic are present."
}
2025-06-01 02:55:54,846 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "We will create a Lean 4 function that takes two integers as input and returns their product using the built-in multiplication operator. The approach is straightforward, relying on Lean\'s built-in arithmetic. No complex proofs are required as the function is directly using the arithmetic operator.",\n  "steps": [\n    "Define the function with two parameters of type Int.",\n    "Use the built-in multiplication operator (*) to compute the product.",\n    "Return the result.",\n    "Optionally, add any documentation or comments to describe the function\'s purpose."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "integers",\n    "multiplication",\n    "Int"\n  ],\n  "proof_keywords": [\n    "direct computation",\n    "arithmetic properties",\n    "commutative",\n    "associative"\n  ],\n  "assumptions": [\n    "Lean 4 is set up and its standard library is available.",\n    "The built-in multiplication operator (*) behaves as expected for integer values."\n  ],\n  "retry_guidance": "If errors occur, check that the function signature and type annotations are correct, especially ensuring that the parameters and return type are properly declared as Int. Also verify that the multiplication operator is used with the right precedence and that any necessary imports for basic arithmetic are present."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef multiply (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result should be the product of the two input integers\ndef multiply_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = a * b\n  -- << SPEC END >>\n\ntheorem multiply_spec_satisfied (a : Int) (b : Int) :\n  multiply_spec a b (multiply a b) := by\n  -- << PROOF START >>\n  unfold multiply multiply_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 02:55:54,848 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:55:54,848 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:55:54,848 - DEBUG - send_request_headers.complete
2025-06-01 02:55:54,848 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:55:54,870 - DEBUG - send_request_body.complete
2025-06-01 02:55:54,870 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:55:57,085 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:55:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'1832'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1838'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'11787'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'36.426s'), (b'x-request-id', b'req_c880ee72f43ec9f61c466e1d536634a3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6f501f044436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:55:57,086 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:55:57,086 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:55:57,087 - DEBUG - receive_response_body.complete
2025-06-01 02:55:57,087 - DEBUG - response_closed.started
2025-06-01 02:55:57,087 - DEBUG - response_closed.complete
2025-06-01 02:55:57,087 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:55:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '1832', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1838', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '11787', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '36.426s', 'x-request-id': 'req_c880ee72f43ec9f61c466e1d536634a3', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6f501f044436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:55:57,087 - DEBUG - request_id: req_c880ee72f43ec9f61c466e1d536634a3
2025-06-01 02:55:57,087 - INFO - Raw solution received: ```json
{
  "code": "a * b",
  "proof": "trivial"
}
```
2025-06-01 02:55:57,087 - INFO - <class 'str'>
2025-06-01 02:55:57,087 - INFO - Generated solution: {'code': 'a * b', 'proof': 'trivial'}
2025-06-01 02:56:02,464 - INFO - Lean execution result: Lean code executed successfully.
2025-06-01 02:56:02,465 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.\n\n-----Input-----\nThe input consists of:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the product of the two input integers (a * b).\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef multiply (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result should be the product of the two input integers\ndef multiply_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = a * b\n  -- << SPEC END >>\n\ntheorem multiply_spec_satisfied (a : Int) (b : Int) :\n  multiply_spec a b (multiply a b) := by\n  -- << PROOF START >>\n  unfold multiply multiply_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na * b\n\nGenerated Proof:\ntrivial\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean code executed successfully.'}], 'model': 'o3-mini'}}
2025-06-01 02:56:02,466 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:56:02,466 - DEBUG - close.started
2025-06-01 02:56:02,466 - DEBUG - close.complete
2025-06-01 02:56:02,466 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:56:02,491 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737d580>
2025-06-01 02:56:02,491 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:56:02,518 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737c4d0>
2025-06-01 02:56:02,518 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:56:02,518 - DEBUG - send_request_headers.complete
2025-06-01 02:56:02,519 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:56:02,519 - DEBUG - send_request_body.complete
2025-06-01 02:56:02,519 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:56:05,096 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:56:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2312'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2317'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199382'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'185ms'), (b'x-request-id', b'req_2d86039fb5ebb49a07c2f97e85cc6cc1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6f800b524278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:56:05,096 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:56:05,097 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:56:05,097 - DEBUG - receive_response_body.complete
2025-06-01 02:56:05,097 - DEBUG - response_closed.started
2025-06-01 02:56:05,097 - DEBUG - response_closed.complete
2025-06-01 02:56:05,097 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:56:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2312', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2317', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199382', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '185ms', 'x-request-id': 'req_2d86039fb5ebb49a07c2f97e85cc6cc1', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6f800b524278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:56:05,097 - DEBUG - request_id: req_2d86039fb5ebb49a07c2f97e85cc6cc1
2025-06-01 02:56:05,098 - INFO - Feedback received: {'verdict': 'pass', 'error_summary': 'The generated code and proof executed successfully without any errors; the implementation multiplies two integers correctly, and the trivial proof completes the theorem.', 'error_type': 'unknown', 'suggested_fix': 'No fixes needed. The implementation and proof are correct.', 'retry_strategy': 'Ensure that additional tests or more complex proofs are added only if the problem requirements change.'}
2025-06-01 02:56:05,098 - INFO - Solution generated in 15.39 seconds
2025-06-01 02:56:05,098 - INFO - Generated code length: 5 characters
2025-06-01 02:56:05,098 - INFO - Generated proof length: 7 characters
2025-06-01 02:56:05,098 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:56:05,098 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:56:10,413 - INFO - Implementation test result: PASS
2025-06-01 02:56:10,413 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:56:15,580 - INFO - Full solution test result: PASS
2025-06-01 02:56:15,580 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:56:15,580 - INFO - ✅ Proof is correct
2025-06-01 02:56:15,580 - INFO - 
==================================================
2025-06-01 02:56:15,580 - INFO - Processing task task_id_227...
2025-06-01 02:56:15,580 - INFO - Reading problem description and code template from tasks/task_id_227...
2025-06-01 02:56:15,580 - INFO - Problem description length: 608 characters
2025-06-01 02:56:15,580 - INFO - Reading unit tests from tasks/task_id_227...
2025-06-01 02:56:15,580 - INFO - Unit tests length: 339 characters
2025-06-01 02:56:15,580 - INFO - Running main workflow to generate solution...
2025-06-01 02:56:15,581 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.

-----Input-----
The input consists of three integers:
a: The first integer.
b: The second integer.
c: The third integer.

-----Output-----
The output is an integer:
Returns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.
2025-06-01 02:56:15,581 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def minOfThree (a : Int) (b : Int) (c : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The returned value is the minimum of the three input numbers
def minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  (result <= a ∧ result <= b ∧ result <= c) ∧
  (result = a ∨ result = b ∨ result = c)
  -- << SPEC END >>

theorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :
  minOfThree_spec a b c (minOfThree a b c) := by
  -- << PROOF START >>
  unfold minOfThree minOfThree_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:56:15,609 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7f4e67394220>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:56:15,609 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:56:15,609 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:56:15,634 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737dfa0>
2025-06-01 02:56:15,634 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4e6784f750> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:56:15,660 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737c230>
2025-06-01 02:56:15,660 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:56:15,660 - DEBUG - send_request_headers.complete
2025-06-01 02:56:15,660 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:56:15,660 - DEBUG - send_request_body.complete
2025-06-01 02:56:15,660 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:56:16,019 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:56:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'53'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-78998c59cd-fzzv7'), (b'x-envoy-upstream-service-time', b'56'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999847'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_8ba51f3e804ed5bf770141f4b66750b6'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=lCUcJe91MhfmbuXEBwJJU5NGxJk8UGlzoWS2slAdLJI-1748746576-1.0.1.1-XViykNmwoEeK4SM_GVCKD3iwOolXEYa7ixt9ElVZNooYZG.KWG0shWFxKuO9VKWfEWTtYhryJlmV7NbyCUVbpUkUkR80sTN.pucHEvqCqvE; path=/; expires=Sun, 01-Jun-25 03:26:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=.93ZK1otn6SffBT0dr_99wvFU_2dw0JuSCnmvD0EAkE-1748746576041-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6fd22e314436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:56:16,020 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:56:16,020 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:56:16,020 - DEBUG - receive_response_body.complete
2025-06-01 02:56:16,020 - DEBUG - response_closed.started
2025-06-01 02:56:16,020 - DEBUG - response_closed.complete
2025-06-01 02:56:16,020 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:56:16 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '53'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-78998c59cd-fzzv7'), ('x-envoy-upstream-service-time', '56'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999847'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '9ms'), ('x-request-id', 'req_8ba51f3e804ed5bf770141f4b66750b6'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=lCUcJe91MhfmbuXEBwJJU5NGxJk8UGlzoWS2slAdLJI-1748746576-1.0.1.1-XViykNmwoEeK4SM_GVCKD3iwOolXEYa7ixt9ElVZNooYZG.KWG0shWFxKuO9VKWfEWTtYhryJlmV7NbyCUVbpUkUkR80sTN.pucHEvqCqvE; path=/; expires=Sun, 01-Jun-25 03:26:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=.93ZK1otn6SffBT0dr_99wvFU_2dw0JuSCnmvD0EAkE-1748746576041-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b6fd22e314436-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:56:16,020 - DEBUG - request_id: req_8ba51f3e804ed5bf770141f4b66750b6
2025-06-01 02:56:16,025 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Interacting with Lean

You are now familiar with the fundamentals of dependent type theory, both as a
language for defining mathematical objects and a language for constructing
proofs. The one thing you are missing is a mechanism for defining new data
types. We will fill this gap in the next chapter, which introduces the notion
of an _inductive data type_. But first, in this chapter, we take a break from
the mechanics of type theory to explore some pragmatic aspects of interacting
with Lean.

Not all of the information found here will be useful to you right away. We
recommend skimming this section to get a sense of Lean's features, and then
returning to it as necessary.

## Importing Files

The goal of Lean's front end is to interpret user input, construct formal
expressions, and check that they are well-formed and type-correct. Lean also
supports the use of various editors, which provide continuous checking and
feedback. More information can be found on the Lean [documentation
pages](https://lean-lang.org/documentation/).

The definitions and theorems in Lean's standard library are spread across
multiple files. Users may also wish to make use of additional libraries, or
develop their own projects across multiple files. When Lean starts, it
automatically imports the contents of the library `Init` folder, which
includes a number of fundamental definitions and constructions. As a result,
most of the examples we present here work "out of the box."

If you want to use additional files, however, they need to be imported
manually, via an `import` statement at the beginning of a file. The command

    
    
    import Bar.Baz.Blah
    

imports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted
relative to the Lean _search path_. Information as to how the search path is
determined can be found on the [documentation pages](https://lean-
lang.org/documentation/). By default, it includes the standard library
directory, and (in some contexts) the root of the user's local project.

Importing is transitive. In other words, if you import `Foo` and `Foo` imports
`Bar`, then you also have access to the contents of `Bar`, and do not need to
import it explicitly.

## More on Sections

Lean provides various sectioning mechanisms to help structure a theory. You
saw in [Variables and Sections](./dependent_type_theory.html#variables-and-
sections) that the `section` command makes it possible not only to group
together elements of a theory that go together, but also to declare variables
that are inserted as arguments to theorems and definitions, as necessary.
Remember that the point of the `variable` command is to declare variables for
use in theorems, as in the following example:

    
    
    section
    variable (x y : Nat)
    
    def double := x + x
    
    #check double y
    #check double (2 * x)
    
    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm
    
    theorem t1 : double (x + y) = double x + double y := by
      simp [double]
    
    #check t1 y
    #check t1 (2 * x)
    
    theorem t2 : double (x * y) = double x * y := by
      simp [double, Nat.add_mul]
    
    end
    

The definition of `double` does not have to declare `x` as an argument; Lean
detects the dependence and inserts it automatically. Similarly, Lean detects
the occurrence of `x` in `t1` and `t2`, and inserts it automatically there,
too. Note that `double` does _not_ have `y` as argument. Variables are only
included in declarations where they are actually used.

## More on Namespaces

In Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We
saw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean
provides mechanisms for working with hierarchical names. The command
`namespace foo` causes `foo` to be prepended to the name of each definition
and theorem until `end foo` is encountered. The command `open foo` then
creates temporary _aliases_ to definitions and theorems that begin with prefix
`foo`.

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    
    open Foo
    
    #check bar
    #check Foo.bar
    

The following definition

    
    
    def Foo.bar : Nat := 1
    

is treated as a macro, and expands to

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    

Although the names of theorems and definitions have to be unique, the aliases
that identify them do not. When we open a namespace, an identifier may be
ambiguous. Lean tries to use type information to disambiguate the meaning in
context, but you can always disambiguate by giving the full name. To that end,
the string `_root_` is an explicit description of the empty prefix.

    
    
    def String.add (a b : String) : String :=
      a ++ b
    
    def Bool.add (a b : Bool) : Bool :=
      a != b
    
    def add (α β : Type) : Type := Sum α β
    
    open Bool
    open String
    -- #check add -- ambiguous
    #check String.add           -- String → String → String
    #check Bool.add             -- Bool → Bool → Bool
    #check _root_.add           -- Type → Type → Type
    
    #check add "hello" "world"  -- String
    #check add true false       -- Bool
    #check add Nat Nat          -- Type
    

We can prevent the shorter alias from being created by using the `protected`
keyword:

    
    
    protected def Foo.bar : Nat := 1
    
    open Foo
    
    -- #check bar -- error
    #check Foo.bar
    

This is often used for names like `Nat.rec` and `Nat.recOn`, to prevent
overloading of common names.

The `open` command admits variations. The command

    
    
    open Nat (succ zero gcd)
    #check zero     -- Nat
    #eval gcd 15 6  -- 3
    

creates aliases for only the identifiers listed. The command

    
    
    open Nat hiding succ gcd
    #check zero     -- Nat
    -- #eval gcd 15 6  -- error
    #eval Nat.gcd 15 6  -- 3
    

creates aliases for everything in the `Nat` namespace _except_ the identifiers
listed.

    
    
    open Nat renaming mul → times, add → plus
    #eval plus (times 2 2) 3  -- 7
    

creates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.

It is sometimes useful to `export` aliases from one namespace to another, or
to the top level. The command

    
    
    export Nat (succ add sub)
    

creates aliases for `succ`, `add`, and `sub` in the current namespace, so that
whenever the namespace is open, these aliases are available. If this command
is used outside a namespace, the aliases are exported to the top level.

## Attributes

The main function of Lean is to translate user input to formal expressions
that are checked by the kernel for correctness and then stored in the
environment for later use. But some commands have other effects on the
environment, either assigning attributes to objects in the environment,
defining notation, or declaring instances of type classes, as described in
[Chapter Type Classes](./type_classes.html). Most of these commands have
global effects, which is to say, they remain in effect not only in the current
file, but also in any file that imports it. However, such commands often
support the `local` modifier, which indicates that they only have effect until
the current `section` or `namespace` is closed, or until the end of the
current file.

In [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw
that theorems can be annotated with the `[simp]` attribute, which makes them
available for use by the simplifier. The following example defines the prefix
relation on lists, proves that this relation is reflexive, and assigns the
`[simp]` attribute to that theorem.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    

The simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to
`True`.

One can also assign the attribute any time after the definition takes place:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [simp] List.isPrefix_self
    

In all these cases, the attribute remains in effect in any file that imports
the one in which the declaration occurs. Adding the `local` modifier restricts
the scope:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    section
    
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [local simp] List.isPrefix_self
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    
    end
    
    -- Error:
    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by
    --  simp
    

For another example, we can use the `instance` command to assign the notation
`≤` to the `isPrefix` relation. That command, which will be explained in
[Chapter Type Classes](./type_classes.html), works by assigning an
`[instance]` attribute to the associated definition.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    instance : LE (List α) where
      le := isPrefix
    
    theorem List.isPrefix_self (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    

That assignment can also be made local:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    def instLe : LE (List α) :=
      { le := isPrefix }
    
    section
    attribute [local instance] instLe
    
    example (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    
    end
    
    -- Error:
    -- example (as : List α) : as ≤ as :=
    --  ⟨[], by simp⟩
    

In Section Notation below, we will discuss Lean's mechanisms for defining
notation, and see that they also support the `local` modifier. However, in
Section Setting Options, we will discuss Lean's mechanisms for setting
options, which does _not_ follow this pattern: options can _only_ be set
locally, which is to say, their scope is always restricted to the current
section or current file.

## More on Implicit Arguments

In [Section Implicit Arguments](./dependent_type_theory.html#implicit-
arguments), we saw that if Lean displays the type of a term `t` as `{x : α} →
β x`, then the curly brackets indicate that `x` has been marked as an
_implicit argument_ to `t`. This means that whenever you write `t`, a
placeholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you
don't want that to happen, you have to write `@t` instead.

Notice that implicit arguments are inserted eagerly. Suppose we define a
function `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,
when we write the expression `f 7` without further arguments, it is parsed as
`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that
a placeholder should only be added _before_ a subsequent explicit argument.
This annotation can also be written using as `⦃y : Nat⦄`, where the unicode
brackets are entered as `\{{` and `\}}`, respectively. With this annotation,
the expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as
`f 7 _ 3`, just as it would be with the strong annotation.

To illustrate the difference, consider the following example, which shows that
a reflexive euclidean relation is both symmetric and transitive.

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b : α}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
     th2 (th1 reflr @euclr) @euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3
    

The results are broken down into small steps: `th1` shows that a relation that
is reflexive and euclidean is symmetric, and `th2` shows that a relation that
is symmetric and euclidean is transitive. Then `th3` combines the two results.
But notice that we have to manually disable the implicit arguments in `euclr`,
because otherwise too many implicit arguments are inserted. The problem goes
away if we use weak implicit arguments:

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b : α}}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
      th2 (th1 reflr euclr) euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- euclidean r
    

There is a third kind of implicit argument that is denoted with square
brackets, `[` and `]`. These are used for type classes, as explained in
[Chapter Type Classes](./type_classes.html).

## Notation

Identifiers in Lean can include any alphanumeric characters, including Greek
characters (other than ∀ , Σ , and λ , which, as we have seen, have a special
meaning in the dependent type theory). They can also include subscripts, which
can be entered by typing `\_` followed by the desired subscripted character.

Lean's parser is extensible, which is to say, we can define new notation.

Lean's syntax can be extended and customized by users at every level, ranging
from basic "mixfix" notations to custom elaborators. In fact, all builtin
syntax is parsed and processed using the same mechanisms and APIs open to
users. In this section, we will describe and explain the various extension
points.

While introducing new notations is a relatively rare feature in programming
languages and sometimes even frowned upon because of its potential to obscure
code, it is an invaluable tool in formalization for expressing established
conventions and notations of the respective field succinctly in code. Going
beyond basic notations, Lean's ability to factor out common boilerplate code
into (well-behaved) macros and to embed entire custom domain specific
languages (DSLs) to textually encode subproblems efficiently and readably can
be of great benefit to both programmers and proof engineers alike.

### Notations and Precedence

The most basic syntax extension commands allow introducing new (or overloading
existing) prefix, infix, and postfix operators.

    
    
    infixl:65   " + " => HAdd.hAdd  -- left-associative
    infix:50    " = " => Eq         -- non-associative
    infixr:80   " ^ " => HPow.hPow  -- right-associative
    prefix:100  "-"   => Neg.neg
    set_option quotPrecheck false
    postfix:max "⁻¹"  => Inv.inv
    

After the initial command name describing the operator kind (its "fixity"), we
give the _parsing precedence_ of the operator preceded by a colon `:`, then a
new or existing token surrounded by double quotes (the whitespace is used for
pretty printing), then the function this operator should be translated to
after the arrow `=>`.

The precedence is a natural number describing how "tightly" an operator binds
to its arguments, encoding the order of operations. We can make this more
precise by looking at the commands the above unfold to:

    
    
    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs
    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs
    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs
    notation:100 "-" arg:100 => Neg.neg arg
    set_option quotPrecheck false
    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024
    

It turns out that all commands from the first code block are in fact command
_macros_ translating to the more general `notation` command. We will learn
about writing such macros below. Instead of a single token, the `notation`
command accepts a mixed sequence of tokens and named term placeholders with
precedences, which can be referenced on the right-hand side of `=>` and will
be replaced by the respective term parsed at that position. A placeholder with
precedence `p` accepts only notations with precedence at least `p` in that
place. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +
(b + c)` because the right-hand side operand of an `infixl` notation has
precedence one greater than the notation itself. In contrast, `infixr` reuses
the notation's precedence for the right-hand side operand, so `a ^ b ^ c`
_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to
introduce an infix notation like

    
    
    set_option quotPrecheck false
    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs
    

where the precedences do not sufficiently determine associativity, Lean's
parser will default to right associativity. More precisely, Lean's parser
follows a local _longest parse_ rule in the presence of ambiguous grammars:
when parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue
parsing as long as possible (as the current precedence allows), not stopping
after `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~
c)`.

As mentioned above, the `notation` command allows us to define arbitrary
_mixfix_ syntax freely mixing tokens and placeholders.

    
    
    set_option quotPrecheck false
    notation:max "(" e ")" => e
    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ
    

Placeholders without precedence default to `0`, i.e. they accept notations of
any precedence in their place. If two notations overlap, we again apply the
longest parse rule:

    
    
    notation:65 a " + " b:66 " + " c:66 => a + b - c
    #eval 1 + 2 + 3  -- 0
    

The new notation is preferred to the binary notation since the latter, before
chaining, would stop parsing after `1 + 2`. If there are multiple notations
accepting the same longest parse, the choice will be delayed until
elaboration, which will fail unless exactly one overload is type-correct.

## Coercions

In Lean, the type of natural numbers, `Nat`, is different from the type of
integers, `Int`. But there is a function `Int.ofNat` that embeds the natural
numbers in the integers, meaning that we can view any natural number as an
integer, when needed. Lean has mechanisms to detect and insert _coercions_ of
this sort.

    
    
    variable (m n : Nat)
    variable (i j : Int)
    
    #check i + m      -- i + Int.ofNat m : Int
    #check i + m + j  -- i + Int.ofNat m + j : Int
    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int
    

## Displaying Information

There are a number of ways in which you can query Lean for information about
its current state and the objects and theorems that are available in the
current context. You have already seen two of the most common ones, `#check`
and `#eval`. Remember that `#check` is often used in conjunction with the `@`
operator, which makes all of the arguments to a theorem or definition
explicit. In addition, you can use the `#print` command to get information
about any identifier. If the identifier denotes a definition or theorem, Lean
prints the type of the symbol, and its definition. If it is a constant or an
axiom, Lean indicates that fact, and shows the type.

    
    
    -- examples with equality
    #check Eq
    #check @Eq
    #check Eq.symm
    #check @Eq.symm
    
    #print Eq.symm
    
    -- examples with And
    #check And
    #check And.intro
    #check @And.intro
    
    -- a user-defined function
    def foo {α : Type u} (x : α) : α := x
    
    #check foo
    #check @foo
    #print foo
    

## Setting Options

Lean maintains a number of internal variables that can be set by users to
control its behavior. The syntax for doing so is as follows:

    
    
    set_option <name> <value>
    

One very useful family of options controls the way Lean's _pretty- printer_
displays terms. The following options take an input of true or false:

    
    
    pp.explicit  : display implicit arguments
    pp.universes : display hidden universe parameters
    pp.notation  : display output using defined notations
    

As an example, the following settings yield much longer output:

    
    
    set_option pp.explicit true
    set_option pp.universes true
    set_option pp.notation false
    
    #check 2 + 2 = 4
    #reduce (fun x => x + 2) = (fun x => x + 3)
    #check (fun x => x + 1) 1
    

The command `set_option pp.all true` carries out these settings all at once,
whereas `set_option pp.all false` reverts to the previous values. Pretty
printing additional information is often very useful when you are debugging a
proof, or trying to understand a cryptic error message. Too much information
can be overwhelming, though, and Lean's defaults are generally sufficient for
ordinary interactions.

## Using the Library

To use Lean effectively you will inevitably need to make use of definitions
and theorems in the library. Recall that the `import` command at the beginning
of a file imports previously compiled results from other files, and that
importing is transitive; if you import `Foo` and `Foo` imports `Bar`, then the
definitions and theorems from `Bar` are available to you as well. But the act
of opening a namespace, which provides shorter names, does not carry over. In
each file, you need to open the namespaces you wish to use.

In general, it is important for you to be familiar with the library and its
contents, so you know what theorems, definitions, notations, and resources are
available to you. Below we will see that Lean's editor modes can also help you
find things you need, but studying the contents of the library directly is
often unavoidable. Lean's standard library can be found online, on GitHub:

  * <https://github.com/leanprover/lean4/tree/master/src/Init>

  * <https://github.com/leanprover/std4/tree/main/Std>

You can see the contents of these directories and files using GitHub's browser
interface. If you have installed Lean on your own computer, you can find the
library in the `lean` folder, and explore it with your file manager. Comment
headers at the top of each file provide additional information.

Lean's library developers follow general naming guidelines to make it easier
to guess the name of a theorem you need, or to find it using tab completion in
editors with a Lean mode that supports this, which is discussed in the next
section. Identifiers are generally `camelCase`, and types are `CamelCase`. For
theorem names, we rely on descriptive names where the different components are
separated by `_`s. Often the name of theorem simply describes the conclusion:

    
    
    #check Nat.succ_ne_zero
    #check Nat.zero_add
    #check Nat.mul_one
    #check Nat.le_of_succ_le_succ
    

Remember that identifiers in Lean can be organized into hierarchical
namespaces. For example, the theorem named `le_of_succ_le_succ` in the
namespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name
is made available by the command `open Nat` (for names not marked as
`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)
and [Chapter Structures and Records](./structures_and_records.html) that
defining structures and inductive data types in Lean generates associated
operations, and these are stored in a namespace with the same name as the type
under definition. For example, the product type comes with the following
operations:

    
    
    #check @Prod.mk
    #check @Prod.fst
    #check @Prod.snd
    #check @Prod.rec
    

The first is used to construct a pair, whereas the next two, `Prod.fst` and
`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another
mechanism for defining functions on a product in terms of a function on the
two components. Names like `Prod.rec` are _protected_ , which means that one
has to use the full name even when the `Prod` namespace is open.

With the propositions as types correspondence, logical connectives are also
instances of inductive types, and so we tend to use dot notation for them as
well:

    
    
    #check @And.intro
    #check @And.casesOn
    #check @And.left
    #check @And.right
    #check @Or.inl
    #check @Or.inr
    #check @Or.elim
    #check @Exists.intro
    #check @Exists.elim
    #check @Eq.refl
    #check @Eq.subst
    

## Auto Bound Implicit Arguments

In the previous section, we have shown how implicit arguments make functions
more convenient to use. However, functions such as `compose` are still quite
verbose to define. Note that the universe polymorphic `compose` is even more
verbose than the one previously defined.

    
    
    universe u v w
    def compose {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

You can avoid the `universe` command by providing the universe parameters when
defining `compose`.

    
    
    def compose.{u, v, w}
                {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

Lean 4 supports a new feature called _auto bound implicit arguments_. It makes
functions such as `compose` much more convenient to write. When Lean processes
the header of a declaration, any unbound identifier is automatically added as
an implicit argument _if_ it is a single lower case or greek letter. With this
feature we can write `compose` as

    
    
    def compose (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    
    #check @compose
    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ
    

Note that Lean inferred a more general type using `Sort` instead of `Type`.

Although we love this feature and use it extensively when implementing Lean,
we realize some users may feel uncomfortable with it. Thus, you can disable it
using the command `set_option autoImplicit false`.

    
    
    set_option autoImplicit false
    /- The following definition produces `unknown identifier` errors -/
    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=
    --   g (f x)
    

## Implicit Lambdas

In Lean 3 stdlib, we find many
[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)
of the dreadful `@`+`_` idiom. It is often used when the expected type is a
function type with implicit arguments, and we have a constant (`reader_t.pure`
in the example) which also takes implicit arguments. In Lean 4, the elaborator
automatically introduces lambdas for consuming implicit arguments. We are
still exploring this feature and analyzing its impact, but the experience so
far has been very positive. Here is the example from the link above using Lean
4 implicit lambdas.

    
    
    variable (ρ : Type) (m : Type → Type) [Monad m]
    instance : Monad (ReaderT ρ m) where
      pure := ReaderT.pure
      bind := ReaderT.bind
    

Users can disable the implicit lambda feature by using `@` or writing a lambda
expression with `{}` or `[]` binder annotations. Here are few examples

    
    
    namespace ex2
    def id1 : {α : Type} → α → α :=
      fun x => x
    
    def listId : List ({α : Type} → α → α) :=
      (fun x => x) :: []
    
    -- In this example, implicit lambda introduction has been disabled because
    -- we use `@` before `fun`
    def id2 : {α : Type} → α → α :=
      @fun α (x : α) => id1 x
    
    def id3 : {α : Type} → α → α :=
      @fun α x => id1 x
    
    def id4 : {α : Type} → α → α :=
      fun x => id1 x
    
    -- In this example, implicit lambda introduction has been disabled
    -- because we used the binder annotation `{...}`
    def id5 : {α : Type} → α → α :=
      fun {α} x => id1 x
    end ex2
    

## Sugar for Simple Functions

In Lean 3, we can create simple functions from infix operators by using
parentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we
generalize this notation using `·` as a placeholder. Here are a few examples:

    
    
    namespace ex3
    #check (· + 1)
    -- fun a => a + 1
    #check (2 - ·)
    -- fun a => 2 - a
    #eval [1, 2, 3, 4, 5].foldl (·*·) 1
    -- 120
    
    def f (x y z : Nat) :=
      x + y + z
    
    #check (f · 1 ·)
    -- fun a b => f a 1 b
    
    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)
    -- [1, 3, 5]
    end ex3
    

As in Lean 3, the notation is activated using parentheses, and the lambda
abstraction is created by collecting the nested `·`s. The collection is
interrupted by nested parentheses. In the following example, two different
lambda expressions are created.

    
    
    #check (Prod.mk · (· + 1))
    -- fun a => (a, fun b => b + 1)
    

## Named Arguments

Named arguments enable you to specify an argument for a parameter by matching
the argument with its name rather than with its position in the parameter
list. If you don't remember the order of the parameters but know their names,
you can send the arguments in any order. You may also provide the value for an
implicit parameter when
2025-06-01 02:56:16,039 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.'}], 'model': 'o3-mini'}}
2025-06-01 02:56:16,040 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:56:16,040 - DEBUG - close.started
2025-06-01 02:56:16,040 - DEBUG - close.complete
2025-06-01 02:56:16,041 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:56:16,047 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6784ba10>
2025-06-01 02:56:16,047 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:56:16,055 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f7d580>
2025-06-01 02:56:16,055 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:56:16,056 - DEBUG - send_request_headers.complete
2025-06-01 02:56:16,056 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:56:16,056 - DEBUG - send_request_body.complete
2025-06-01 02:56:16,056 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:56:22,530 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:56:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6241'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6246'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199547'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'135ms'), (b'x-request-id', b'req_06e7882175204f3d649f723fbccc3403'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6fd48cd03fe6-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:56:22,531 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:56:22,531 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:56:22,531 - DEBUG - receive_response_body.complete
2025-06-01 02:56:22,531 - DEBUG - response_closed.started
2025-06-01 02:56:22,531 - DEBUG - response_closed.complete
2025-06-01 02:56:22,531 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:56:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6241', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6246', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199547', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '135ms', 'x-request-id': 'req_06e7882175204f3d649f723fbccc3403', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6fd48cd03fe6-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:56:22,531 - DEBUG - request_id: req_06e7882175204f3d649f723fbccc3403
2025-06-01 02:56:22,532 - INFO - Attempt 1/3
2025-06-01 02:56:22,532 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that takes three integers (a, b, and c) and computes the minimum value among them using conditional constructs. The plan includes verifying the properties that the returned value is less than or equal to a, b, and c and that it matches one of the given inputs. A proof strategy may involve a case analysis using if-then-else expressions.",
  "steps": [
    "1. Define the function with signature taking three integers and returning an integer.",
    "2. Use if-then-else expressions or other conditional constructs to compare a and b, obtaining the minimum of these two.",
    "3. Compare the result from step 2 with c to obtain the overall minimum value.",
    "4. Ensure that the resulting value is proven or shown to be less than or equal to each of a, b, and c.",
    "5. Optionally, write a lemma or proof that confirms the returned value is one of the original inputs and meets the specification.",
    "6. Verify the function's correctness by testing with sample inputs or through formal proof strategies."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "conditional statements",
    "if-then-else",
    "min",
    "comparison"
  ],
  "proof_keywords": [
    "case analysis",
    "constructive proof",
    "verification",
    "lemma"
  ],
  "assumptions": [
    "Lean's built-in comparison operations on integers are used.",
    "The minimum function can be implemented solely with the if-then-else construct.",
    "The users will provide three valid integers as input."
  ],
  "retry_guidance": "If the solution fails to meet the specification, check the ordering of comparisons and ensure that the proof or justification covers every branch of the conditional expressions. Confirm that the returned value is not only the minimum but also one of the original inputs."
}
2025-06-01 02:56:22,533 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that takes three integers (a, b, and c) and computes the minimum value among them using conditional constructs. The plan includes verifying the properties that the returned value is less than or equal to a, b, and c and that it matches one of the given inputs. A proof strategy may involve a case analysis using if-then-else expressions.",\n  "steps": [\n    "1. Define the function with signature taking three integers and returning an integer.",\n    "2. Use if-then-else expressions or other conditional constructs to compare a and b, obtaining the minimum of these two.",\n    "3. Compare the result from step 2 with c to obtain the overall minimum value.",\n    "4. Ensure that the resulting value is proven or shown to be less than or equal to each of a, b, and c.",\n    "5. Optionally, write a lemma or proof that confirms the returned value is one of the original inputs and meets the specification.",\n    "6. Verify the function\'s correctness by testing with sample inputs or through formal proof strategies."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "conditional statements",\n    "if-then-else",\n    "min",\n    "comparison"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "constructive proof",\n    "verification",\n    "lemma"\n  ],\n  "assumptions": [\n    "Lean\'s built-in comparison operations on integers are used.",\n    "The minimum function can be implemented solely with the if-then-else construct.",\n    "The users will provide three valid integers as input."\n  ],\n  "retry_guidance": "If the solution fails to meet the specification, check the ordering of comparisons and ensure that the proof or justification covers every branch of the conditional expressions. Confirm that the returned value is not only the minimum but also one of the original inputs."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned value is the minimum of the three input numbers\ndef minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result <= a ∧ result <= b ∧ result <= c) ∧\n  (result = a ∨ result = b ∨ result = c)\n  -- << SPEC END >>\n\ntheorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :\n  minOfThree_spec a b c (minOfThree a b c) := by\n  -- << PROOF START >>\n  unfold minOfThree minOfThree_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:56:22,534 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:56:22,534 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:56:22,534 - DEBUG - send_request_headers.complete
2025-06-01 02:56:22,534 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:56:22,539 - DEBUG - send_request_body.complete
2025-06-01 02:56:22,539 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:56:28,689 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:56:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5893'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5897'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'5623'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'48.752s'), (b'x-request-id', b'req_03acd5d8493a95cade215a4418deef14'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b6ffd09033fe6-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:56:28,689 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:56:28,689 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:56:28,690 - DEBUG - receive_response_body.complete
2025-06-01 02:56:28,690 - DEBUG - response_closed.started
2025-06-01 02:56:28,690 - DEBUG - response_closed.complete
2025-06-01 02:56:28,690 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:56:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5893', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5897', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '5623', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '48.752s', 'x-request-id': 'req_03acd5d8493a95cade215a4418deef14', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b6ffd09033fe6-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:56:28,690 - DEBUG - request_id: req_03acd5d8493a95cade215a4418deef14
2025-06-01 02:56:28,690 - INFO - Raw solution received: ```json
{
  "code": "if a <= b then (if a <= c then a else c) else (if b <= c then b else c)",
  "proof": "unfold minOfThree minOfThree_spec\n  by_cases h₁ : a <= b\n  case pos =>\n    by_cases h₂ : a <= c\n    case pos =>\n      simp [h₁, h₂]\n      exact And.intro (le_refl a) (And.intro (le_trans h₁ (by assumption)) (or.inl (eq.refl a)))\n    case neg =>\n      simp [h₁, not_le.mp h₂]\n      exact And.intro (by assumption) (And.intro (le_trans h₁ (le_refl b)) (or.inr (or.inr (eq.refl c))))\n  case neg =>\n    by_cases h₂ : b <= c\n    case pos =>\n      simp [not_le.mp h₁, h₂]\n      exact And.intro (le_refl b) (And.intro (by assumption) (or.inr (eq.refl b)))\n    case neg =>\n      simp [not_le.mp h₁, h₂]\n      exact And.intro (by assumption) (And.intro (le_refl c) (or.inr (or.inr (eq.refl c))))"
}
```
2025-06-01 02:56:28,690 - INFO - <class 'str'>
2025-06-01 02:56:28,690 - INFO - Generated solution: {'code': 'if a <= b then (if a <= c then a else c) else (if b <= c then b else c)', 'proof': 'unfold minOfThree minOfThree_spec\n  by_cases h₁ : a <= b\n  case pos =>\n    by_cases h₂ : a <= c\n    case pos =>\n      simp [h₁, h₂]\n      exact And.intro (le_refl a) (And.intro (le_trans h₁ (by assumption)) (or.inl (eq.refl a)))\n    case neg =>\n      simp [h₁, not_le.mp h₂]\n      exact And.intro (by assumption) (And.intro (le_trans h₁ (le_refl b)) (or.inr (or.inr (eq.refl c))))\n  case neg =>\n    by_cases h₂ : b <= c\n    case pos =>\n      simp [not_le.mp h₁, h₂]\n      exact And.intro (le_refl b) (And.intro (by assumption) (or.inr (eq.refl b)))\n    case neg =>\n      simp [not_le.mp h₁, h₂]\n      exact And.intro (by assumption) (And.intro (le_refl c) (or.inr (or.inr (eq.refl c))))'}
2025-06-01 02:56:34,007 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:22:9: error: tactic 'unfold' failed to unfold 'minOfThree' at
  ((if a ≤ b then if a ≤ c then a else c else if b ≤ c then b else c) ≤ a ∧
      (if a ≤ b then if a ≤ c then a else c else if b ≤ c then b else c) ≤ b ∧
        (if a ≤ b then if a ≤ c then a else c else if b ≤ c then b else c) ≤ c) ∧
    ((if a ≤ b then if a ≤ c then a else c else if b ≤ c then b else c) = a ∨
      (if a ≤ b then if a ≤ c then a else c else if b ≤ c then b else c) = b ∨
        (if a ≤ b then if a ≤ c then a else c else if b ≤ c then b else c) = c)
2025-06-01 02:56:34,008 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned value is the minimum of the three input numbers\ndef minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result <= a ∧ result <= b ∧ result <= c) ∧\n  (result = a ∨ result = b ∨ result = c)\n  -- << SPEC END >>\n\ntheorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :\n  minOfThree_spec a b c (minOfThree a b c) := by\n  -- << PROOF START >>\n  unfold minOfThree minOfThree_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a <= b then (if a <= c then a else c) else (if b <= c then b else c)\n\nGenerated Proof:\nunfold minOfThree minOfThree_spec\n  by_cases h₁ : a <= b\n  case pos =>\n    by_cases h₂ : a <= c\n    case pos =>\n      simp [h₁, h₂]\n      exact And.intro (le_refl a) (And.intro (le_trans h₁ (by assumption)) (or.inl (eq.refl a)))\n    case neg =>\n      simp [h₁, not_le.mp h₂]\n      exact And.intro (by assumption) (And.intro (le_trans h₁ (le_refl b)) (or.inr (or.inr (eq.refl c))))\n  case neg =>\n    by_cases h₂ : b <= c\n    case pos =>\n      simp [not_le.mp h₁, h₂]\n      exact And.intro (le_refl b) (And.intro (by assumption) (or.inr (eq.refl b)))\n    case neg =>\n      simp [not_le.mp h₁, h₂]\n      exact And.intro (by assumption) (And.intro (le_refl c) (or.inr (or.inr (eq.refl c))))\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:22:9: error: tactic 'unfold' failed to unfold 'minOfThree' at\n  ((if a ≤ b then if a ≤ c then a else c else if b ≤ c then b else c) ≤ a ∧\n      (if a ≤ b then if a ≤ c then a else c else if b ≤ c then b else c) ≤ b ∧\n        (if a ≤ b then if a ≤ c then a else c else if b ≤ c then b else c) ≤ c) ∧\n    ((if a ≤ b then if a ≤ c then a else c else if b ≤ c then b else c) = a ∨\n      (if a ≤ b then if a ≤ c then a else c else if b ≤ c then b else c) = b ∨\n        (if a ≤ b then if a ≤ c then a else c else if b ≤ c then b else c) = c)"}], 'model': 'o3-mini'}}
2025-06-01 02:56:34,008 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:56:34,008 - DEBUG - close.started
2025-06-01 02:56:34,009 - DEBUG - close.complete
2025-06-01 02:56:34,009 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:56:34,033 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a44a0>
2025-06-01 02:56:34,033 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:56:34,059 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a47d0>
2025-06-01 02:56:34,059 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:56:34,060 - DEBUG - send_request_headers.complete
2025-06-01 02:56:34,060 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:56:34,060 - DEBUG - send_request_body.complete
2025-06-01 02:56:34,060 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:56:40,138 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:56:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5835'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5838'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198941'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'317ms'), (b'x-request-id', b'req_b5525501619f42b3fdcc26e277a50baf'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b70452f5f4278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:56:40,138 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:56:40,138 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:56:40,139 - DEBUG - receive_response_body.complete
2025-06-01 02:56:40,139 - DEBUG - response_closed.started
2025-06-01 02:56:40,139 - DEBUG - response_closed.complete
2025-06-01 02:56:40,139 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:56:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5835', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5838', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198941', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '317ms', 'x-request-id': 'req_b5525501619f42b3fdcc26e277a50baf', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b70452f5f4278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:56:40,139 - DEBUG - request_id: req_b5525501619f42b3fdcc26e277a50baf
2025-06-01 02:56:40,139 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The error indicates that the 'unfold' tactic failed to expand the definition 'minOfThree'. This prevents the spec from being evaluated properly, likely because the if-then-else expression was not reduced as expected.", 'error_type': 'proof', 'suggested_fix': "Replace 'unfold minOfThree minOfThree_spec' with a tactic that effectively reduces the definition. For example, use 'dsimp [minOfThree, minOfThree_spec]' or 'simp' to simplify the goal. You might also consider marking the definition as reducible (if it isn’t by default) or restructuring the proof to work directly with the if-then-else construct.", 'retry_strategy': "Revise the proof by using 'dsimp' or 'simp' instead of 'unfold' to fully simplify the definitions. Recompile and check each branch of the case analysis to ensure that the goal correctly reduces to the desired properties."}
2025-06-01 02:56:40,140 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.\n\nPrevious plan:\n{\n  "plan_summary": "Define a Lean 4 function that takes three integers (a, b, and c) and computes the minimum value among them using conditional constructs. The plan includes verifying the properties that the returned value is less than or equal to a, b, and c and that it matches one of the given inputs. A proof strategy may involve a case analysis using if-then-else expressions.",\n  "steps": [\n    "1. Define the function with signature taking three integers and returning an integer.",\n    "2. Use if-then-else expressions or other conditional constructs to compare a and b, obtaining the minimum of these two.",\n    "3. Compare the result from step 2 with c to obtain the overall minimum value.",\n    "4. Ensure that the resulting value is proven or shown to be less than or equal to each of a, b, and c.",\n    "5. Optionally, write a lemma or proof that confirms the returned value is one of the original inputs and meets the specification.",\n    "6. Verify the function\'s correctness by testing with sample inputs or through formal proof strategies."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "conditional statements",\n    "if-then-else",\n    "min",\n    "comparison"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "constructive proof",\n    "verification",\n    "lemma"\n  ],\n  "assumptions": [\n    "Lean\'s built-in comparison operations on integers are used.",\n    "The minimum function can be implemented solely with the if-then-else construct.",\n    "The users will provide three valid integers as input."\n  ],\n  "retry_guidance": "If the solution fails to meet the specification, check the ordering of comparisons and ensure that the proof or justification covers every branch of the conditional expressions. Confirm that the returned value is not only the minimum but also one of the original inputs."\n}\n\nLean error:\nThe error indicates that the \'unfold\' tactic failed to expand the definition \'minOfThree\'. This prevents the spec from being evaluated properly, likely because the if-then-else expression was not reduced as expected.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 02:56:40,140 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:56:40,141 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:56:40,141 - DEBUG - send_request_headers.complete
2025-06-01 02:56:40,141 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:56:40,141 - DEBUG - send_request_body.complete
2025-06-01 02:56:40,141 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:56:48,762 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:56:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8386'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8389'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199011'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'296ms'), (b'x-request-id', b'req_7fc08ae205fc7b31ca68b16c1f5e6e06'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b706b2f214278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:56:48,763 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:56:48,763 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:56:48,763 - DEBUG - receive_response_body.complete
2025-06-01 02:56:48,763 - DEBUG - response_closed.started
2025-06-01 02:56:48,763 - DEBUG - response_closed.complete
2025-06-01 02:56:48,763 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:56:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8386', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8389', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199011', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '296ms', 'x-request-id': 'req_7fc08ae205fc7b31ca68b16c1f5e6e06', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b706b2f214278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:56:48,764 - DEBUG - request_id: req_7fc08ae205fc7b31ca68b16c1f5e6e06
2025-06-01 02:56:48,764 - INFO - Attempt 2/3
2025-06-01 02:56:48,764 - INFO - Current plan: {
  "plan_summary": "Revise the original plan to address the unfolding issue by ensuring that the definition of the minimum function is structured in a way that allows Lean’s reduction tactics (like 'unfold') to work effectively. This can be done by defining helper functions (e.g., minOfTwo) with pattern matching or simpler constructs so that their bodies are easily reducible. The revised plan includes defining a helper for two integers and then using it to construct the three-integer minimum. Additionally, make sure the overall definition is transparent enough (or marked appropriately) for tactics to unfold the definition properly.",
  "steps": [
    "1. Define an auxiliary function (minOfTwo) that takes two integers and returns the minimum. Use pattern matching or a simple if-then-else that Lean can easily reduce. Consider avoiding nested if-then-else if possible.",
    "2. Define the main function (minOfThree) which uses minOfTwo to first compute the minimum of two numbers and then compares the result with the third integer to obtain the overall minimum.",
    "3. Mark the definitions as #[inline] or ensure they are not opaque, so that Lean’s unfolding tactics can reveal their definitions properly if needed in proofs.",
    "4. Construct a lemma that confirms the returned value is less than or equal to each of the three inputs and that it corresponds to one of the original numbers. Use case analysis over the branches coming from the minOfTwo helper to facilitate the proof.",
    "5. Ensure the definitions are written in a structural and transparent way, so if Lean's 'unfold' tactic is applied, it successfully expands the functions as expected.",
    "6. Validate the approach by testing with example inputs or by running a reduction tactic on minOfThree to confirm that it unfolds correctly."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "pattern matching",
    "if-then-else",
    "inline attribute",
    "minOfTwo",
    "minOfThree",
    "transparent definition"
  ],
  "proof_keywords": [
    "case analysis",
    "tactic unfolding",
    "lemma",
    "computational reduction",
    "inductive proof",
    "specification"
  ],
  "assumptions": [
    "The use of helper functions like minOfTwo will simplify the structure of the code, making it more amenable to unfolding.",
    "Lean's reduction tactics such as 'unfold' require transparent definitions.",
    "Comparisons between integers are correctly implemented using Lean's built-in capabilities.",
    "Marking functions with attributes (like #[inline]) can influence how tactics like 'unfold' operate."
  ],
  "retry_guidance": "If issues persist with the 'unfold' tactic, verify that all helper functions are defined in a reducible manner and not hidden behind opaque definitions. Consider adjusting attributes or refactoring the structure further to remove nested conditionals that might hinder reduction. Re-run the unfolding tactic after each structural change to ensure the function definition expands as expected."
}
2025-06-01 02:56:48,764 - INFO - Updated plan: {
  "plan_summary": "Revise the original plan to address the unfolding issue by ensuring that the definition of the minimum function is structured in a way that allows Lean’s reduction tactics (like 'unfold') to work effectively. This can be done by defining helper functions (e.g., minOfTwo) with pattern matching or simpler constructs so that their bodies are easily reducible. The revised plan includes defining a helper for two integers and then using it to construct the three-integer minimum. Additionally, make sure the overall definition is transparent enough (or marked appropriately) for tactics to unfold the definition properly.",
  "steps": [
    "1. Define an auxiliary function (minOfTwo) that takes two integers and returns the minimum. Use pattern matching or a simple if-then-else that Lean can easily reduce. Consider avoiding nested if-then-else if possible.",
    "2. Define the main function (minOfThree) which uses minOfTwo to first compute the minimum of two numbers and then compares the result with the third integer to obtain the overall minimum.",
    "3. Mark the definitions as #[inline] or ensure they are not opaque, so that Lean’s unfolding tactics can reveal their definitions properly if needed in proofs.",
    "4. Construct a lemma that confirms the returned value is less than or equal to each of the three inputs and that it corresponds to one of the original numbers. Use case analysis over the branches coming from the minOfTwo helper to facilitate the proof.",
    "5. Ensure the definitions are written in a structural and transparent way, so if Lean's 'unfold' tactic is applied, it successfully expands the functions as expected.",
    "6. Validate the approach by testing with example inputs or by running a reduction tactic on minOfThree to confirm that it unfolds correctly."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "pattern matching",
    "if-then-else",
    "inline attribute",
    "minOfTwo",
    "minOfThree",
    "transparent definition"
  ],
  "proof_keywords": [
    "case analysis",
    "tactic unfolding",
    "lemma",
    "computational reduction",
    "inductive proof",
    "specification"
  ],
  "assumptions": [
    "The use of helper functions like minOfTwo will simplify the structure of the code, making it more amenable to unfolding.",
    "Lean's reduction tactics such as 'unfold' require transparent definitions.",
    "Comparisons between integers are correctly implemented using Lean's built-in capabilities.",
    "Marking functions with attributes (like #[inline]) can influence how tactics like 'unfold' operate."
  ],
  "retry_guidance": "If issues persist with the 'unfold' tactic, verify that all helper functions are defined in a reducible manner and not hidden behind opaque definitions. Consider adjusting attributes or refactoring the structure further to remove nested conditionals that might hinder reduction. Re-run the unfolding tactic after each structural change to ensure the function definition expands as expected."
}

Lean error summary:
The error indicates that the 'unfold' tactic failed to expand the definition 'minOfThree'. This prevents the spec from being evaluated properly, likely because the if-then-else expression was not reduced as expected.
Retry guidance (MUST FOLLOW):
Revise the proof by using 'dsimp' or 'simp' instead of 'unfold' to fully simplify the definitions. Recompile and check each branch of the case analysis to ensure that the goal correctly reduces to the desired properties.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 02:56:48,765 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the original plan to address the unfolding issue by ensuring that the definition of the minimum function is structured in a way that allows Lean’s reduction tactics (like \'unfold\') to work effectively. This can be done by defining helper functions (e.g., minOfTwo) with pattern matching or simpler constructs so that their bodies are easily reducible. The revised plan includes defining a helper for two integers and then using it to construct the three-integer minimum. Additionally, make sure the overall definition is transparent enough (or marked appropriately) for tactics to unfold the definition properly.",\n  "steps": [\n    "1. Define an auxiliary function (minOfTwo) that takes two integers and returns the minimum. Use pattern matching or a simple if-then-else that Lean can easily reduce. Consider avoiding nested if-then-else if possible.",\n    "2. Define the main function (minOfThree) which uses minOfTwo to first compute the minimum of two numbers and then compares the result with the third integer to obtain the overall minimum.",\n    "3. Mark the definitions as #[inline] or ensure they are not opaque, so that Lean’s unfolding tactics can reveal their definitions properly if needed in proofs.",\n    "4. Construct a lemma that confirms the returned value is less than or equal to each of the three inputs and that it corresponds to one of the original numbers. Use case analysis over the branches coming from the minOfTwo helper to facilitate the proof.",\n    "5. Ensure the definitions are written in a structural and transparent way, so if Lean\'s \'unfold\' tactic is applied, it successfully expands the functions as expected.",\n    "6. Validate the approach by testing with example inputs or by running a reduction tactic on minOfThree to confirm that it unfolds correctly."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "pattern matching",\n    "if-then-else",\n    "inline attribute",\n    "minOfTwo",\n    "minOfThree",\n    "transparent definition"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "tactic unfolding",\n    "lemma",\n    "computational reduction",\n    "inductive proof",\n    "specification"\n  ],\n  "assumptions": [\n    "The use of helper functions like minOfTwo will simplify the structure of the code, making it more amenable to unfolding.",\n    "Lean\'s reduction tactics such as \'unfold\' require transparent definitions.",\n    "Comparisons between integers are correctly implemented using Lean\'s built-in capabilities.",\n    "Marking functions with attributes (like #[inline]) can influence how tactics like \'unfold\' operate."\n  ],\n  "retry_guidance": "If issues persist with the \'unfold\' tactic, verify that all helper functions are defined in a reducible manner and not hidden behind opaque definitions. Consider adjusting attributes or refactoring the structure further to remove nested conditionals that might hinder reduction. Re-run the unfolding tactic after each structural change to ensure the function definition expands as expected."\n}\n\nLean error summary:\nThe error indicates that the \'unfold\' tactic failed to expand the definition \'minOfThree\'. This prevents the spec from being evaluated properly, likely because the if-then-else expression was not reduced as expected.\nRetry guidance (MUST FOLLOW):\nRevise the proof by using \'dsimp\' or \'simp\' instead of \'unfold\' to fully simplify the definitions. Recompile and check each branch of the case analysis to ensure that the goal correctly reduces to the desired properties.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned value is the minimum of the three input numbers\ndef minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result <= a ∧ result <= b ∧ result <= c) ∧\n  (result = a ∨ result = b ∨ result = c)\n  -- << SPEC END >>\n\ntheorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :\n  minOfThree_spec a b c (minOfThree a b c) := by\n  -- << PROOF START >>\n  unfold minOfThree minOfThree_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:56:48,766 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:56:48,767 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:56:48,767 - DEBUG - send_request_headers.complete
2025-06-01 02:56:48,767 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:56:48,790 - DEBUG - send_request_body.complete
2025-06-01 02:56:48,790 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:56:49,067 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sun, 01 Jun 2025 02:56:49 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'373'), (b'Connection', b'keep-alive'), (b'retry-after', b'4'), (b'retry-after-ms', b'3762'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'17736'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'24.526s'), (b'x-request-id', b'req_db91ff6cd68a2833f9607ebb11912d5f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b70a11dd04278-BOM'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:56:49,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 02:56:49,067 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:56:49,068 - DEBUG - receive_response_body.complete
2025-06-01 02:56:49,068 - DEBUG - response_closed.started
2025-06-01 02:56:49,068 - DEBUG - response_closed.complete
2025-06-01 02:56:49,068 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sun, 01 Jun 2025 02:56:49 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '373', 'connection': 'keep-alive', 'retry-after': '4', 'retry-after-ms': '3762', 'vary': 'Origin', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '17736', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '24.526s', 'x-request-id': 'req_db91ff6cd68a2833f9607ebb11912d5f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b70a11dd04278-BOM', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:56:49,068 - DEBUG - request_id: req_db91ff6cd68a2833f9607ebb11912d5f
2025-06-01 02:56:49,068 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/openai/_base_client.py", line 1007, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.12/dist-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-06-01 02:56:49,069 - DEBUG - Retrying due to status code 429
2025-06-01 02:56:49,070 - DEBUG - 2 retries left
2025-06-01 02:56:49,070 - INFO - Retrying request to /chat/completions in 3.762000 seconds
2025-06-01 02:56:52,832 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the original plan to address the unfolding issue by ensuring that the definition of the minimum function is structured in a way that allows Lean’s reduction tactics (like \'unfold\') to work effectively. This can be done by defining helper functions (e.g., minOfTwo) with pattern matching or simpler constructs so that their bodies are easily reducible. The revised plan includes defining a helper for two integers and then using it to construct the three-integer minimum. Additionally, make sure the overall definition is transparent enough (or marked appropriately) for tactics to unfold the definition properly.",\n  "steps": [\n    "1. Define an auxiliary function (minOfTwo) that takes two integers and returns the minimum. Use pattern matching or a simple if-then-else that Lean can easily reduce. Consider avoiding nested if-then-else if possible.",\n    "2. Define the main function (minOfThree) which uses minOfTwo to first compute the minimum of two numbers and then compares the result with the third integer to obtain the overall minimum.",\n    "3. Mark the definitions as #[inline] or ensure they are not opaque, so that Lean’s unfolding tactics can reveal their definitions properly if needed in proofs.",\n    "4. Construct a lemma that confirms the returned value is less than or equal to each of the three inputs and that it corresponds to one of the original numbers. Use case analysis over the branches coming from the minOfTwo helper to facilitate the proof.",\n    "5. Ensure the definitions are written in a structural and transparent way, so if Lean\'s \'unfold\' tactic is applied, it successfully expands the functions as expected.",\n    "6. Validate the approach by testing with example inputs or by running a reduction tactic on minOfThree to confirm that it unfolds correctly."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "pattern matching",\n    "if-then-else",\n    "inline attribute",\n    "minOfTwo",\n    "minOfThree",\n    "transparent definition"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "tactic unfolding",\n    "lemma",\n    "computational reduction",\n    "inductive proof",\n    "specification"\n  ],\n  "assumptions": [\n    "The use of helper functions like minOfTwo will simplify the structure of the code, making it more amenable to unfolding.",\n    "Lean\'s reduction tactics such as \'unfold\' require transparent definitions.",\n    "Comparisons between integers are correctly implemented using Lean\'s built-in capabilities.",\n    "Marking functions with attributes (like #[inline]) can influence how tactics like \'unfold\' operate."\n  ],\n  "retry_guidance": "If issues persist with the \'unfold\' tactic, verify that all helper functions are defined in a reducible manner and not hidden behind opaque definitions. Consider adjusting attributes or refactoring the structure further to remove nested conditionals that might hinder reduction. Re-run the unfolding tactic after each structural change to ensure the function definition expands as expected."\n}\n\nLean error summary:\nThe error indicates that the \'unfold\' tactic failed to expand the definition \'minOfThree\'. This prevents the spec from being evaluated properly, likely because the if-then-else expression was not reduced as expected.\nRetry guidance (MUST FOLLOW):\nRevise the proof by using \'dsimp\' or \'simp\' instead of \'unfold\' to fully simplify the definitions. Recompile and check each branch of the case analysis to ensure that the goal correctly reduces to the desired properties.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned value is the minimum of the three input numbers\ndef minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result <= a ∧ result <= b ∧ result <= c) ∧\n  (result = a ∨ result = b ∨ result = c)\n  -- << SPEC END >>\n\ntheorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :\n  minOfThree_spec a b c (minOfThree a b c) := by\n  -- << PROOF START >>\n  unfold minOfThree minOfThree_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:56:52,834 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:56:52,834 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:56:52,834 - DEBUG - send_request_headers.complete
2025-06-01 02:56:52,834 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:56:52,835 - DEBUG - send_request_body.complete
2025-06-01 02:56:52,835 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:56:58,296 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:56:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5152'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5155'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'154'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'59.69s'), (b'x-request-id', b'req_04708d7bd0b9ada132be7115e6d816ea'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b70ba8c5b4278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:56:58,297 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:56:58,297 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:56:58,297 - DEBUG - receive_response_body.complete
2025-06-01 02:56:58,297 - DEBUG - response_closed.started
2025-06-01 02:56:58,297 - DEBUG - response_closed.complete
2025-06-01 02:56:58,297 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:56:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5152', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5155', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '154', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '59.69s', 'x-request-id': 'req_04708d7bd0b9ada132be7115e6d816ea', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b70ba8c5b4278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:56:58,297 - DEBUG - request_id: req_04708d7bd0b9ada132be7115e6d816ea
2025-06-01 02:56:58,298 - INFO - Raw solution received: ```json
{
  "code": "#[inline] def minOfTwo (x y : Int) : Int := if x <= y then x else y\n\n#[inline] def minOfThree (a b c : Int) : Int := minOfTwo (minOfTwo a b) c",
  "proof": "unfold minOfThree minOfThree_spec\nby_cases hab : a <= b\n  case inl =>\n    by_cases hac : a <= c\n    case inl =>\n      simp [minOfTwo, hab, hac]\n      constructor\n      { repeat { apply Nat.le_trans; assumption } }\n      { left, rfl }\n    case inr =>\n      simp [minOfTwo, hab, hac]\n      constructor\n      { apply Nat.le_trans; simp [hab] }\n      { right, right, rfl }\n  case inr =>\n    by_cases hbc : b <= c\n    case inl =>\n      simp [minOfTwo, hab, hbc]\n      constructor\n      { repeat { apply Nat.le_trans; assumption } }\n      { right, left, rfl }\n    case inr =>\n      simp [minOfTwo, hab, hbc]\n      constructor\n      { apply Nat.le_trans; simp [hbc] }\n      { right, right, rfl }"
}
```
2025-06-01 02:56:58,298 - INFO - <class 'str'>
2025-06-01 02:56:58,298 - INFO - Generated solution: {'code': '#[inline] def minOfTwo (x y : Int) : Int := if x <= y then x else y\n\n#[inline] def minOfThree (a b c : Int) : Int := minOfTwo (minOfTwo a b) c', 'proof': 'unfold minOfThree minOfThree_spec\nby_cases hab : a <= b\n  case inl =>\n    by_cases hac : a <= c\n    case inl =>\n      simp [minOfTwo, hab, hac]\n      constructor\n      { repeat { apply Nat.le_trans; assumption } }\n      { left, rfl }\n    case inr =>\n      simp [minOfTwo, hab, hac]\n      constructor\n      { apply Nat.le_trans; simp [hab] }\n      { right, right, rfl }\n  case inr =>\n    by_cases hbc : b <= c\n    case inl =>\n      simp [minOfTwo, hab, hbc]\n      constructor\n      { repeat { apply Nat.le_trans; assumption } }\n      { right, left, rfl }\n    case inr =>\n      simp [minOfTwo, hab, hbc]\n      constructor\n      { apply Nat.le_trans; simp [hbc] }\n      { right, right, rfl }'}
2025-06-01 02:57:03,622 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:7:2: error: type mismatch
  #[inline]
has type
  Array (?m.18 → ?m.18) : Type ?u.14
but is expected to have type
  ℤ : Type
lean_playground/TempTest.lean:7:68: error: function expected at
  y
term has type
  ℤ
lean_playground/TempTest.lean:9:14: error: 'minOfThree' has already been declared
lean_playground/TempTest.lean:20:8: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:24:2: warning: 'unfold minOfThree minOfThree_spec' tactic does nothing
note: this linter can be disabled with `set_option linter.unusedTactic false`
lean_playground/TempTest.lean:25:0: error: unexpected identifier; expected command
2025-06-01 02:57:03,623 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned value is the minimum of the three input numbers\ndef minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result <= a ∧ result <= b ∧ result <= c) ∧\n  (result = a ∨ result = b ∨ result = c)\n  -- << SPEC END >>\n\ntheorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :\n  minOfThree_spec a b c (minOfThree a b c) := by\n  -- << PROOF START >>\n  unfold minOfThree minOfThree_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\n#[inline] def minOfTwo (x y : Int) : Int := if x <= y then x else y\n\n#[inline] def minOfThree (a b c : Int) : Int := minOfTwo (minOfTwo a b) c\n\nGenerated Proof:\nunfold minOfThree minOfThree_spec\nby_cases hab : a <= b\n  case inl =>\n    by_cases hac : a <= c\n    case inl =>\n      simp [minOfTwo, hab, hac]\n      constructor\n      { repeat { apply Nat.le_trans; assumption } }\n      { left, rfl }\n    case inr =>\n      simp [minOfTwo, hab, hac]\n      constructor\n      { apply Nat.le_trans; simp [hab] }\n      { right, right, rfl }\n  case inr =>\n    by_cases hbc : b <= c\n    case inl =>\n      simp [minOfTwo, hab, hbc]\n      constructor\n      { repeat { apply Nat.le_trans; assumption } }\n      { right, left, rfl }\n    case inr =>\n      simp [minOfTwo, hab, hbc]\n      constructor\n      { apply Nat.le_trans; simp [hbc] }\n      { right, right, rfl }\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:7:2: error: type mismatch\n  #[inline]\nhas type\n  Array (?m.18 → ?m.18) : Type ?u.14\nbut is expected to have type\n  ℤ : Type\nlean_playground/TempTest.lean:7:68: error: function expected at\n  y\nterm has type\n  ℤ\nlean_playground/TempTest.lean:9:14: error: 'minOfThree' has already been declared\nlean_playground/TempTest.lean:20:8: warning: declaration uses 'sorry'\nlean_playground/TempTest.lean:24:2: warning: 'unfold minOfThree minOfThree_spec' tactic does nothing\nnote: this linter can be disabled with `set_option linter.unusedTactic false`\nlean_playground/TempTest.lean:25:0: error: unexpected identifier; expected command"}], 'model': 'o3-mini'}}
2025-06-01 02:57:03,624 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:57:03,624 - DEBUG - close.started
2025-06-01 02:57:03,624 - DEBUG - close.complete
2025-06-01 02:57:03,624 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:57:03,630 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f92e40>
2025-06-01 02:57:03,630 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:57:03,638 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f92d20>
2025-06-01 02:57:03,638 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:57:03,638 - DEBUG - send_request_headers.complete
2025-06-01 02:57:03,638 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:57:03,638 - DEBUG - send_request_body.complete
2025-06-01 02:57:03,638 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:57:15,190 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:57:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'11327'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'11331'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198918'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'324ms'), (b'x-request-id', b'req_a0b63b67b5cce41af32cba29f58096f2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b70fded553fe6-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:57:15,190 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:57:15,190 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:57:15,192 - DEBUG - receive_response_body.complete
2025-06-01 02:57:15,192 - DEBUG - response_closed.started
2025-06-01 02:57:15,192 - DEBUG - response_closed.complete
2025-06-01 02:57:15,192 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:57:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '11327', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '11331', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198918', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '324ms', 'x-request-id': 'req_a0b63b67b5cce41af32cba29f58096f2', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b70fded553fe6-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:57:15,192 - DEBUG - request_id: req_a0b63b67b5cce41af32cba29f58096f2
2025-06-01 02:57:15,193 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "There are several issues with the generated code. First, the #[inline] attribute is causing a type mismatch – Lean seems to interpret it incorrectly, leading to the error that an array of functions is found instead of an ℤ. Second, the definition for minOfThree is a duplicate (or conflicts) with an earlier declaration. Third, in the proof, tactics like Nat.le_trans are used even though the inputs are of type Int (which may require using Int.le_trans or another appropriate argument). Finally, there is an 'unexpected identifier' error, likely due to misplaced or incomplete tactic blocks (for example, the last 'by_cases' branch is not properly finished).", 'error_type': 'syntax', 'suggested_fix': "• Remove or relocate the #[inline] attributes from the minOfTwo and minOfThree definitions (or ensure they are applied correctly) so that Lean does not misinterpret the definitions. \n• Make sure that minOfThree is defined only once in your file to avoid re-declaration conflicts. \n• Replace uses of Nat.le_trans with Int.le_trans (or adjust the proof tactics to work correctly with Int comparisons). \n• Check that each by_cases branch is correctly structured and closed, and that the proof script follows valid Lean tactic syntax. \nFor instance, you can rewrite the definitions as follows:\n\n   def minOfTwo (x y : Int) : Int := if x <= y then x else y\n\n   def minOfThree (a b c : Int) : Int := minOfTwo (minOfTwo a b) c\n\n   def minOfThree_spec (a b c result : Int) : Prop :=\n     (result <= a ∧ result <= b ∧ result <= c) ∧ (result = a ∨ result = b ∨ result = c)\n\n   theorem minOfThree_spec_satisfied (a b c : Int) :\n     minOfThree_spec a b c (minOfThree a b c) := by\n     unfold minOfThree minOfThree_spec minOfTwo\n     by_cases h1 : a <= b\n     { by_cases h2 : a <= c\n       { simp [h1, h2], constructor,\n         { -- provide a valid chain using Int.le_trans\n           exact h1 },\n         { left, rfl } }\n       { simp [h1, h2], constructor,\n         { -- use Int.le_trans again or appropriate handling\n           admit },\n         { right, right, rfl } } }\n     { by_cases h3 : b <= c\n       { simp [h1, h3], constructor,\n         { admit },\n         { right, left, rfl } }\n       { simp [h1, h3], constructor,\n         { admit },\n         { right, right, rfl } } }\n\nBe sure to replace 'admit' with valid proof steps (e.g. using Int.le_trans appropriately).", 'retry_strategy': 'Revise the code as suggested, removing the problematic attributes and duplicate declarations, and adjust the proof to use the correct operations for Int. Then re-run Lean to check for further type or syntax errors.'}
2025-06-01 02:57:15,193 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.\n\nPrevious plan:\n{\n  "plan_summary": "Revise the original plan to address the unfolding issue by ensuring that the definition of the minimum function is structured in a way that allows Lean’s reduction tactics (like \'unfold\') to work effectively. This can be done by defining helper functions (e.g., minOfTwo) with pattern matching or simpler constructs so that their bodies are easily reducible. The revised plan includes defining a helper for two integers and then using it to construct the three-integer minimum. Additionally, make sure the overall definition is transparent enough (or marked appropriately) for tactics to unfold the definition properly.",\n  "steps": [\n    "1. Define an auxiliary function (minOfTwo) that takes two integers and returns the minimum. Use pattern matching or a simple if-then-else that Lean can easily reduce. Consider avoiding nested if-then-else if possible.",\n    "2. Define the main function (minOfThree) which uses minOfTwo to first compute the minimum of two numbers and then compares the result with the third integer to obtain the overall minimum.",\n    "3. Mark the definitions as #[inline] or ensure they are not opaque, so that Lean’s unfolding tactics can reveal their definitions properly if needed in proofs.",\n    "4. Construct a lemma that confirms the returned value is less than or equal to each of the three inputs and that it corresponds to one of the original numbers. Use case analysis over the branches coming from the minOfTwo helper to facilitate the proof.",\n    "5. Ensure the definitions are written in a structural and transparent way, so if Lean\'s \'unfold\' tactic is applied, it successfully expands the functions as expected.",\n    "6. Validate the approach by testing with example inputs or by running a reduction tactic on minOfThree to confirm that it unfolds correctly."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "pattern matching",\n    "if-then-else",\n    "inline attribute",\n    "minOfTwo",\n    "minOfThree",\n    "transparent definition"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "tactic unfolding",\n    "lemma",\n    "computational reduction",\n    "inductive proof",\n    "specification"\n  ],\n  "assumptions": [\n    "The use of helper functions like minOfTwo will simplify the structure of the code, making it more amenable to unfolding.",\n    "Lean\'s reduction tactics such as \'unfold\' require transparent definitions.",\n    "Comparisons between integers are correctly implemented using Lean\'s built-in capabilities.",\n    "Marking functions with attributes (like #[inline]) can influence how tactics like \'unfold\' operate."\n  ],\n  "retry_guidance": "If issues persist with the \'unfold\' tactic, verify that all helper functions are defined in a reducible manner and not hidden behind opaque definitions. Consider adjusting attributes or refactoring the structure further to remove nested conditionals that might hinder reduction. Re-run the unfolding tactic after each structural change to ensure the function definition expands as expected."\n}\n\nLean error summary:\nThe error indicates that the \'unfold\' tactic failed to expand the definition \'minOfThree\'. This prevents the spec from being evaluated properly, likely because the if-then-else expression was not reduced as expected.\nRetry guidance (MUST FOLLOW):\nRevise the proof by using \'dsimp\' or \'simp\' instead of \'unfold\' to fully simplify the definitions. Recompile and check each branch of the case analysis to ensure that the goal correctly reduces to the desired properties.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThere are several issues with the generated code. First, the #[inline] attribute is causing a type mismatch – Lean seems to interpret it incorrectly, leading to the error that an array of functions is found instead of an ℤ. Second, the definition for minOfThree is a duplicate (or conflicts) with an earlier declaration. Third, in the proof, tactics like Nat.le_trans are used even though the inputs are of type Int (which may require using Int.le_trans or another appropriate argument). Finally, there is an \'unexpected identifier\' error, likely due to misplaced or incomplete tactic blocks (for example, the last \'by_cases\' branch is not properly finished).\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 02:57:15,194 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:57:15,194 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:57:15,194 - DEBUG - send_request_headers.complete
2025-06-01 02:57:15,194 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:57:15,194 - DEBUG - send_request_body.complete
2025-06-01 02:57:15,194 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:57:24,704 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:57:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'9267'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'9272'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'197566'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'729ms'), (b'x-request-id', b'req_391b908855733c69303b3c3dbd31cf6d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b71462e333fe6-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:57:24,704 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:57:24,704 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:57:24,706 - DEBUG - receive_response_body.complete
2025-06-01 02:57:24,706 - DEBUG - response_closed.started
2025-06-01 02:57:24,706 - DEBUG - response_closed.complete
2025-06-01 02:57:24,706 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:57:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '9267', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '9272', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '197566', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '729ms', 'x-request-id': 'req_391b908855733c69303b3c3dbd31cf6d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b71462e333fe6-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:57:24,706 - DEBUG - request_id: req_391b908855733c69303b3c3dbd31cf6d
2025-06-01 02:57:24,706 - INFO - Attempt 3/3
2025-06-01 02:57:24,706 - INFO - Current plan: {
  "plan_summary": "Revise the approach by removing conflicting attributes and duplicate definitions, and then define the helper function and main function more simply. This plan uses an explicit two-argument minimum function (minOfTwo) and then builds minOfThree using it. The proof will replace the 'unfold' tactic with 'dsimp' or 'simp' to fully reduce the definitions and will carefully use Int specific lemmas (like Int.le_trans) to accommodate integer comparisons. The plan also calls for checking that each branch is handled properly with no duplicate declarations or incorrect tactic blocks.",
  "steps": [
    "1. Remove any #[inline] or similar attributes that caused type mismatch errors and eliminate duplicate definitions by ensuring that each function (minOfTwo and minOfThree) is defined uniquely.",
    "2. Define a helper function (minOfTwo) that takes two Int values and returns the smaller one using a simple if-then-else construct. This will ensure that Lean can reduce the expression easily.",
    "3. Define the main function (minOfThree) that calls minOfTwo on the first two inputs and then compares the result with the third input to select the overall minimum.",
    "4. In the proof, replace use of the 'unfold' tactic with 'dsimp' or 'simp' to appropriately reduce the definitions. Ensure that case analysis is done on the if-then-else branches so that each branch of the proof is clearly verified.",
    "5. Modify the proof to use Int-specific lemmas. For instance, replace Nat.le_trans with Int.le_trans (or any appropriate similar tactic) ensuring the type of numbers remains consistent.",
    "6. Walk through each branch of the if-then-else in the proof and verify that the returned value is indeed one of the inputs and is less than or equal to all three numbers.",
    "7. Recompile the definitions and proof to ensure that all errors have been resolved and the reduction/simplification tactics work as expected without resulting in unexpected identifiers or incomplete tactic blocks."
  ],
  "code_keywords": [
    "Lean 4",
    "Int",
    "if-then-else",
    "minOfTwo",
    "minOfThree",
    "transparent definition"
  ],
  "proof_keywords": [
    "dsimp",
    "simp",
    "case analysis",
    "Int.le_trans",
    "proof by reduction",
    "tactic simplification"
  ],
  "assumptions": [
    "The standard library's integer comparison operators (<= and if-then-else) work as expected.",
    "Using dsimp/simp is sufficient to reduce the definitions to the desired form for proofs.",
    "Each function is uniquely defined to avoid conflicts.",
    "The functions will not be hidden behind opaque attributes that interfere with tactic reductions."
  ],
  "retry_guidance": "If errors persist, verify that no attributes (like #[inline]) that cause type mismatches are present. Confirm that function names are unique and that redundant declarations are removed. Ensure that the proof tactics use dsimp or simp instead of unfold to handle if-then-else reduction. Finally, check the proof branches individually for correct application of Int-specific lemmas to avoid type errors."
}
2025-06-01 02:57:24,706 - INFO - Updated plan: {
  "plan_summary": "Revise the approach by removing conflicting attributes and duplicate definitions, and then define the helper function and main function more simply. This plan uses an explicit two-argument minimum function (minOfTwo) and then builds minOfThree using it. The proof will replace the 'unfold' tactic with 'dsimp' or 'simp' to fully reduce the definitions and will carefully use Int specific lemmas (like Int.le_trans) to accommodate integer comparisons. The plan also calls for checking that each branch is handled properly with no duplicate declarations or incorrect tactic blocks.",
  "steps": [
    "1. Remove any #[inline] or similar attributes that caused type mismatch errors and eliminate duplicate definitions by ensuring that each function (minOfTwo and minOfThree) is defined uniquely.",
    "2. Define a helper function (minOfTwo) that takes two Int values and returns the smaller one using a simple if-then-else construct. This will ensure that Lean can reduce the expression easily.",
    "3. Define the main function (minOfThree) that calls minOfTwo on the first two inputs and then compares the result with the third input to select the overall minimum.",
    "4. In the proof, replace use of the 'unfold' tactic with 'dsimp' or 'simp' to appropriately reduce the definitions. Ensure that case analysis is done on the if-then-else branches so that each branch of the proof is clearly verified.",
    "5. Modify the proof to use Int-specific lemmas. For instance, replace Nat.le_trans with Int.le_trans (or any appropriate similar tactic) ensuring the type of numbers remains consistent.",
    "6. Walk through each branch of the if-then-else in the proof and verify that the returned value is indeed one of the inputs and is less than or equal to all three numbers.",
    "7. Recompile the definitions and proof to ensure that all errors have been resolved and the reduction/simplification tactics work as expected without resulting in unexpected identifiers or incomplete tactic blocks."
  ],
  "code_keywords": [
    "Lean 4",
    "Int",
    "if-then-else",
    "minOfTwo",
    "minOfThree",
    "transparent definition"
  ],
  "proof_keywords": [
    "dsimp",
    "simp",
    "case analysis",
    "Int.le_trans",
    "proof by reduction",
    "tactic simplification"
  ],
  "assumptions": [
    "The standard library's integer comparison operators (<= and if-then-else) work as expected.",
    "Using dsimp/simp is sufficient to reduce the definitions to the desired form for proofs.",
    "Each function is uniquely defined to avoid conflicts.",
    "The functions will not be hidden behind opaque attributes that interfere with tactic reductions."
  ],
  "retry_guidance": "If errors persist, verify that no attributes (like #[inline]) that cause type mismatches are present. Confirm that function names are unique and that redundant declarations are removed. Ensure that the proof tactics use dsimp or simp instead of unfold to handle if-then-else reduction. Finally, check the proof branches individually for correct application of Int-specific lemmas to avoid type errors."
}

Lean error summary:
There are several issues with the generated code. First, the #[inline] attribute is causing a type mismatch – Lean seems to interpret it incorrectly, leading to the error that an array of functions is found instead of an ℤ. Second, the definition for minOfThree is a duplicate (or conflicts) with an earlier declaration. Third, in the proof, tactics like Nat.le_trans are used even though the inputs are of type Int (which may require using Int.le_trans or another appropriate argument). Finally, there is an 'unexpected identifier' error, likely due to misplaced or incomplete tactic blocks (for example, the last 'by_cases' branch is not properly finished).
Retry guidance (MUST FOLLOW):
Revise the code as suggested, removing the problematic attributes and duplicate declarations, and adjust the proof to use the correct operations for Int. Then re-run Lean to check for further type or syntax errors.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 02:57:24,707 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the approach by removing conflicting attributes and duplicate definitions, and then define the helper function and main function more simply. This plan uses an explicit two-argument minimum function (minOfTwo) and then builds minOfThree using it. The proof will replace the \'unfold\' tactic with \'dsimp\' or \'simp\' to fully reduce the definitions and will carefully use Int specific lemmas (like Int.le_trans) to accommodate integer comparisons. The plan also calls for checking that each branch is handled properly with no duplicate declarations or incorrect tactic blocks.",\n  "steps": [\n    "1. Remove any #[inline] or similar attributes that caused type mismatch errors and eliminate duplicate definitions by ensuring that each function (minOfTwo and minOfThree) is defined uniquely.",\n    "2. Define a helper function (minOfTwo) that takes two Int values and returns the smaller one using a simple if-then-else construct. This will ensure that Lean can reduce the expression easily.",\n    "3. Define the main function (minOfThree) that calls minOfTwo on the first two inputs and then compares the result with the third input to select the overall minimum.",\n    "4. In the proof, replace use of the \'unfold\' tactic with \'dsimp\' or \'simp\' to appropriately reduce the definitions. Ensure that case analysis is done on the if-then-else branches so that each branch of the proof is clearly verified.",\n    "5. Modify the proof to use Int-specific lemmas. For instance, replace Nat.le_trans with Int.le_trans (or any appropriate similar tactic) ensuring the type of numbers remains consistent.",\n    "6. Walk through each branch of the if-then-else in the proof and verify that the returned value is indeed one of the inputs and is less than or equal to all three numbers.",\n    "7. Recompile the definitions and proof to ensure that all errors have been resolved and the reduction/simplification tactics work as expected without resulting in unexpected identifiers or incomplete tactic blocks."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Int",\n    "if-then-else",\n    "minOfTwo",\n    "minOfThree",\n    "transparent definition"\n  ],\n  "proof_keywords": [\n    "dsimp",\n    "simp",\n    "case analysis",\n    "Int.le_trans",\n    "proof by reduction",\n    "tactic simplification"\n  ],\n  "assumptions": [\n    "The standard library\'s integer comparison operators (<= and if-then-else) work as expected.",\n    "Using dsimp/simp is sufficient to reduce the definitions to the desired form for proofs.",\n    "Each function is uniquely defined to avoid conflicts.",\n    "The functions will not be hidden behind opaque attributes that interfere with tactic reductions."\n  ],\n  "retry_guidance": "If errors persist, verify that no attributes (like #[inline]) that cause type mismatches are present. Confirm that function names are unique and that redundant declarations are removed. Ensure that the proof tactics use dsimp or simp instead of unfold to handle if-then-else reduction. Finally, check the proof branches individually for correct application of Int-specific lemmas to avoid type errors."\n}\n\nLean error summary:\nThere are several issues with the generated code. First, the #[inline] attribute is causing a type mismatch – Lean seems to interpret it incorrectly, leading to the error that an array of functions is found instead of an ℤ. Second, the definition for minOfThree is a duplicate (or conflicts) with an earlier declaration. Third, in the proof, tactics like Nat.le_trans are used even though the inputs are of type Int (which may require using Int.le_trans or another appropriate argument). Finally, there is an \'unexpected identifier\' error, likely due to misplaced or incomplete tactic blocks (for example, the last \'by_cases\' branch is not properly finished).\nRetry guidance (MUST FOLLOW):\nRevise the code as suggested, removing the problematic attributes and duplicate declarations, and adjust the proof to use the correct operations for Int. Then re-run Lean to check for further type or syntax errors.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned value is the minimum of the three input numbers\ndef minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result <= a ∧ result <= b ∧ result <= c) ∧\n  (result = a ∨ result = b ∨ result = c)\n  -- << SPEC END >>\n\ntheorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :\n  minOfThree_spec a b c (minOfThree a b c) := by\n  -- << PROOF START >>\n  unfold minOfThree minOfThree_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:57:24,709 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:57:24,709 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:57:24,709 - DEBUG - send_request_headers.complete
2025-06-01 02:57:24,709 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:57:24,714 - DEBUG - send_request_body.complete
2025-06-01 02:57:24,714 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:57:24,962 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sun, 01 Jun 2025 02:57:24 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'373'), (b'Connection', b'keep-alive'), (b'retry-after', b'10'), (b'retry-after-ms', b'9196'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'15148'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'29.702s'), (b'x-request-id', b'req_27830c64afde7a53a07f1b77aa6af9f1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b71819e6c3fe6-BOM'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:57:24,962 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 02:57:24,962 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:57:24,963 - DEBUG - receive_response_body.complete
2025-06-01 02:57:24,963 - DEBUG - response_closed.started
2025-06-01 02:57:24,963 - DEBUG - response_closed.complete
2025-06-01 02:57:24,963 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sun, 01 Jun 2025 02:57:24 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '373', 'connection': 'keep-alive', 'retry-after': '10', 'retry-after-ms': '9196', 'vary': 'Origin', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '15148', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '29.702s', 'x-request-id': 'req_27830c64afde7a53a07f1b77aa6af9f1', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b71819e6c3fe6-BOM', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:57:24,963 - DEBUG - request_id: req_27830c64afde7a53a07f1b77aa6af9f1
2025-06-01 02:57:24,963 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/openai/_base_client.py", line 1007, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.12/dist-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-06-01 02:57:24,963 - DEBUG - Retrying due to status code 429
2025-06-01 02:57:24,963 - DEBUG - 2 retries left
2025-06-01 02:57:24,963 - INFO - Retrying request to /chat/completions in 9.196000 seconds
2025-06-01 02:57:34,160 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the approach by removing conflicting attributes and duplicate definitions, and then define the helper function and main function more simply. This plan uses an explicit two-argument minimum function (minOfTwo) and then builds minOfThree using it. The proof will replace the \'unfold\' tactic with \'dsimp\' or \'simp\' to fully reduce the definitions and will carefully use Int specific lemmas (like Int.le_trans) to accommodate integer comparisons. The plan also calls for checking that each branch is handled properly with no duplicate declarations or incorrect tactic blocks.",\n  "steps": [\n    "1. Remove any #[inline] or similar attributes that caused type mismatch errors and eliminate duplicate definitions by ensuring that each function (minOfTwo and minOfThree) is defined uniquely.",\n    "2. Define a helper function (minOfTwo) that takes two Int values and returns the smaller one using a simple if-then-else construct. This will ensure that Lean can reduce the expression easily.",\n    "3. Define the main function (minOfThree) that calls minOfTwo on the first two inputs and then compares the result with the third input to select the overall minimum.",\n    "4. In the proof, replace use of the \'unfold\' tactic with \'dsimp\' or \'simp\' to appropriately reduce the definitions. Ensure that case analysis is done on the if-then-else branches so that each branch of the proof is clearly verified.",\n    "5. Modify the proof to use Int-specific lemmas. For instance, replace Nat.le_trans with Int.le_trans (or any appropriate similar tactic) ensuring the type of numbers remains consistent.",\n    "6. Walk through each branch of the if-then-else in the proof and verify that the returned value is indeed one of the inputs and is less than or equal to all three numbers.",\n    "7. Recompile the definitions and proof to ensure that all errors have been resolved and the reduction/simplification tactics work as expected without resulting in unexpected identifiers or incomplete tactic blocks."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Int",\n    "if-then-else",\n    "minOfTwo",\n    "minOfThree",\n    "transparent definition"\n  ],\n  "proof_keywords": [\n    "dsimp",\n    "simp",\n    "case analysis",\n    "Int.le_trans",\n    "proof by reduction",\n    "tactic simplification"\n  ],\n  "assumptions": [\n    "The standard library\'s integer comparison operators (<= and if-then-else) work as expected.",\n    "Using dsimp/simp is sufficient to reduce the definitions to the desired form for proofs.",\n    "Each function is uniquely defined to avoid conflicts.",\n    "The functions will not be hidden behind opaque attributes that interfere with tactic reductions."\n  ],\n  "retry_guidance": "If errors persist, verify that no attributes (like #[inline]) that cause type mismatches are present. Confirm that function names are unique and that redundant declarations are removed. Ensure that the proof tactics use dsimp or simp instead of unfold to handle if-then-else reduction. Finally, check the proof branches individually for correct application of Int-specific lemmas to avoid type errors."\n}\n\nLean error summary:\nThere are several issues with the generated code. First, the #[inline] attribute is causing a type mismatch – Lean seems to interpret it incorrectly, leading to the error that an array of functions is found instead of an ℤ. Second, the definition for minOfThree is a duplicate (or conflicts) with an earlier declaration. Third, in the proof, tactics like Nat.le_trans are used even though the inputs are of type Int (which may require using Int.le_trans or another appropriate argument). Finally, there is an \'unexpected identifier\' error, likely due to misplaced or incomplete tactic blocks (for example, the last \'by_cases\' branch is not properly finished).\nRetry guidance (MUST FOLLOW):\nRevise the code as suggested, removing the problematic attributes and duplicate declarations, and adjust the proof to use the correct operations for Int. Then re-run Lean to check for further type or syntax errors.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned value is the minimum of the three input numbers\ndef minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result <= a ∧ result <= b ∧ result <= c) ∧\n  (result = a ∨ result = b ∨ result = c)\n  -- << SPEC END >>\n\ntheorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :\n  minOfThree_spec a b c (minOfThree a b c) := by\n  -- << PROOF START >>\n  unfold minOfThree minOfThree_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:57:34,162 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:57:34,162 - DEBUG - close.started
2025-06-01 02:57:34,162 - DEBUG - close.complete
2025-06-01 02:57:34,162 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:57:34,187 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f934d0>
2025-06-01 02:57:34,187 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:57:34,215 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f933e0>
2025-06-01 02:57:34,215 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:57:34,215 - DEBUG - send_request_headers.complete
2025-06-01 02:57:34,215 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:57:34,238 - DEBUG - send_request_body.complete
2025-06-01 02:57:34,238 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:57:40,291 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:57:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5758'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5762'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'185'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'59.628s'), (b'x-request-id', b'req_00441975cefd9f99889972cbd28d4e1a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b71bd2b194278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:57:40,291 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:57:40,291 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:57:40,292 - DEBUG - receive_response_body.complete
2025-06-01 02:57:40,292 - DEBUG - response_closed.started
2025-06-01 02:57:40,292 - DEBUG - response_closed.complete
2025-06-01 02:57:40,292 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:57:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5758', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5762', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '185', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '59.628s', 'x-request-id': 'req_00441975cefd9f99889972cbd28d4e1a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b71bd2b194278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:57:40,292 - DEBUG - request_id: req_00441975cefd9f99889972cbd28d4e1a
2025-06-01 02:57:40,293 - INFO - Raw solution received: ```json
{
  "code": "\ndef minOfTwo (x y : Int) : Int :=\n  if x <= y then x else y\n\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  minOfTwo (minOfTwo a b) c\n",
  "proof": "\nby_cases h1 : a <= b\n  by_cases h2 : minOfTwo a b <= c\n    simp [minOfThree, minOfTwo, h1, h2]\n    exact ⟨by simp [h1, h2], Or.inl rfl⟩\n  simp [minOfThree, minOfTwo, h1, h2] at *\n  exact ⟨by simp [h1, h2], Or.inr (Or.inr rfl)⟩\nby_cases h2 : minOfTwo b a <= c\n  simp [minOfThree, minOfTwo, not_le_of_gt h1, h2]\n  exact ⟨by simp [not_le_of_gt h1, h2], Or.inr rfl⟩\n  simp [minOfThree, minOfTwo, not_le_of_gt h1, h2] at *\n  exact ⟨by simp [not_le_of_gt h1, h2], Or.inr (Or.inr rfl)⟩\n"
}
```
2025-06-01 02:57:40,293 - INFO - <class 'str'>
2025-06-01 02:57:40,293 - INFO - Generated solution: {'code': '\ndef minOfTwo (x y : Int) : Int :=\n  if x <= y then x else y\n\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  minOfTwo (minOfTwo a b) c\n', 'proof': '\nby_cases h1 : a <= b\n  by_cases h2 : minOfTwo a b <= c\n    simp [minOfThree, minOfTwo, h1, h2]\n    exact ⟨by simp [h1, h2], Or.inl rfl⟩\n  simp [minOfThree, minOfTwo, h1, h2] at *\n  exact ⟨by simp [h1, h2], Or.inr (Or.inr rfl)⟩\nby_cases h2 : minOfTwo b a <= c\n  simp [minOfThree, minOfTwo, not_le_of_gt h1, h2]\n  exact ⟨by simp [not_le_of_gt h1, h2], Or.inr rfl⟩\n  simp [minOfThree, minOfTwo, not_le_of_gt h1, h2] at *\n  exact ⟨by simp [not_le_of_gt h1, h2], Or.inr (Or.inr rfl)⟩\n'}
2025-06-01 02:57:45,660 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:5:53: error: unexpected token 'def'; expected term
lean_playground/TempTest.lean:11:4: error: 'minOfThree' has already been declared
lean_playground/TempTest.lean:25:46: error: unsolved goals
a b c : ℤ
⊢ (sorry ≤ a ∧ sorry ≤ b ∧ sorry ≤ c) ∧ (sorry = a ∨ sorry = b ∨ sorry = c)
lean_playground/TempTest.lean:29:0: error: unexpected identifier; expected command
2025-06-01 02:57:45,661 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned value is the minimum of the three input numbers\ndef minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result <= a ∧ result <= b ∧ result <= c) ∧\n  (result = a ∨ result = b ∨ result = c)\n  -- << SPEC END >>\n\ntheorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :\n  minOfThree_spec a b c (minOfThree a b c) := by\n  -- << PROOF START >>\n  unfold minOfThree minOfThree_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\n\ndef minOfTwo (x y : Int) : Int :=\n  if x <= y then x else y\n\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  minOfTwo (minOfTwo a b) c\n\n\nGenerated Proof:\n\nby_cases h1 : a <= b\n  by_cases h2 : minOfTwo a b <= c\n    simp [minOfThree, minOfTwo, h1, h2]\n    exact ⟨by simp [h1, h2], Or.inl rfl⟩\n  simp [minOfThree, minOfTwo, h1, h2] at *\n  exact ⟨by simp [h1, h2], Or.inr (Or.inr rfl)⟩\nby_cases h2 : minOfTwo b a <= c\n  simp [minOfThree, minOfTwo, not_le_of_gt h1, h2]\n  exact ⟨by simp [not_le_of_gt h1, h2], Or.inr rfl⟩\n  simp [minOfThree, minOfTwo, not_le_of_gt h1, h2] at *\n  exact ⟨by simp [not_le_of_gt h1, h2], Or.inr (Or.inr rfl)⟩\n\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:5:53: error: unexpected token 'def'; expected term\nlean_playground/TempTest.lean:11:4: error: 'minOfThree' has already been declared\nlean_playground/TempTest.lean:25:46: error: unsolved goals\na b c : ℤ\n⊢ (sorry ≤ a ∧ sorry ≤ b ∧ sorry ≤ c) ∧ (sorry = a ∨ sorry = b ∨ sorry = c)\nlean_playground/TempTest.lean:29:0: error: unexpected identifier; expected command"}], 'model': 'o3-mini'}}
2025-06-01 02:57:45,662 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:57:45,662 - DEBUG - close.started
2025-06-01 02:57:45,662 - DEBUG - close.complete
2025-06-01 02:57:45,662 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:57:45,670 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f913a0>
2025-06-01 02:57:45,670 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:57:45,680 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f916d0>
2025-06-01 02:57:45,680 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:57:45,681 - DEBUG - send_request_headers.complete
2025-06-01 02:57:45,681 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:57:45,681 - DEBUG - send_request_body.complete
2025-06-01 02:57:45,681 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:57:55,426 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:57:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'9122'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'9127'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199028'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'291ms'), (b'x-request-id', b'req_6dec00f2e9f6f12cd78bd9246d8719b0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7204bf3a8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:57:55,426 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:57:55,426 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:57:55,426 - DEBUG - receive_response_body.complete
2025-06-01 02:57:55,426 - DEBUG - response_closed.started
2025-06-01 02:57:55,426 - DEBUG - response_closed.complete
2025-06-01 02:57:55,426 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:57:55 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '9122', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '9127', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199028', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '291ms', 'x-request-id': 'req_6dec00f2e9f6f12cd78bd9246d8719b0', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7204bf3a8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:57:55,426 - DEBUG - request_id: req_6dec00f2e9f6f12cd78bd9246d8719b0
2025-06-01 02:57:55,427 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The Lean output indicates several issues:\n1. An 'unexpected token def; expected term' error, which suggests that a duplicate or misplaced declaration (such as the second definition of minOfThree) is present in the file.\n2. The error 'minOfThree has already been declared' shows that there is a naming conflict from using the template's declaration together with the generated definition.\n3. The theorem proof has unsolved goals. The proof using by_cases is incomplete or incorrect, leaving holes (unsolved subgoals) that need to be resolved.\n4. An unexpected identifier error indicates that the generated proof or code structure does not properly align with Lean's expected syntax (likely due to the placeholders not being correctly replaced).", 'error_type': 'syntax', 'suggested_fix': "• Remove duplicate definitions: ensure that minOfThree (and any auxiliary functions like minOfTwo) are defined only once. Do not include multiple declarations copying the template's placeholder parts.\n• Insert the generated implementation only in the {{code}} placeholder and the generated proof only in the {{proof}} placeholder. Make sure the final file does not have redundant declarations.\n• For the theorem proof, revise the proof strategy. Instead of multiple by_cases which leave unsolved goals, consider a case-split that directly uses the definition of minOfTwo. You could prove that the final result satisfies the specification by showing: (a) it is less than or equal to a, b, and c by unfolding the definition; and (b) it is equal to one of a, b, or c. If needed, use tactics like ‘split’, ‘cases’, and ‘simp’ to simplify the reasoning.\n• Verify that the structure of your file matches the provided template (with proper placement of import statements, definitions, and theorem proofs) so that Lean does not see unexpected tokens.", 'retry_strategy': "Refactor the file by removing duplicate definitions and ensuring that the implementation and proof are inserted into the provided template placeholders. Then, rewrite the theorem proof using clear, complete case analyses (or an alternative tactic such as 'decide' if applicable) so that all subgoals are addressed. Finally, recompile to verify that no syntactic or logical errors remain."}
2025-06-01 02:57:55,427 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.\n\nPrevious plan:\n{\n  "plan_summary": "Revise the approach by removing conflicting attributes and duplicate definitions, and then define the helper function and main function more simply. This plan uses an explicit two-argument minimum function (minOfTwo) and then builds minOfThree using it. The proof will replace the \'unfold\' tactic with \'dsimp\' or \'simp\' to fully reduce the definitions and will carefully use Int specific lemmas (like Int.le_trans) to accommodate integer comparisons. The plan also calls for checking that each branch is handled properly with no duplicate declarations or incorrect tactic blocks.",\n  "steps": [\n    "1. Remove any #[inline] or similar attributes that caused type mismatch errors and eliminate duplicate definitions by ensuring that each function (minOfTwo and minOfThree) is defined uniquely.",\n    "2. Define a helper function (minOfTwo) that takes two Int values and returns the smaller one using a simple if-then-else construct. This will ensure that Lean can reduce the expression easily.",\n    "3. Define the main function (minOfThree) that calls minOfTwo on the first two inputs and then compares the result with the third input to select the overall minimum.",\n    "4. In the proof, replace use of the \'unfold\' tactic with \'dsimp\' or \'simp\' to appropriately reduce the definitions. Ensure that case analysis is done on the if-then-else branches so that each branch of the proof is clearly verified.",\n    "5. Modify the proof to use Int-specific lemmas. For instance, replace Nat.le_trans with Int.le_trans (or any appropriate similar tactic) ensuring the type of numbers remains consistent.",\n    "6. Walk through each branch of the if-then-else in the proof and verify that the returned value is indeed one of the inputs and is less than or equal to all three numbers.",\n    "7. Recompile the definitions and proof to ensure that all errors have been resolved and the reduction/simplification tactics work as expected without resulting in unexpected identifiers or incomplete tactic blocks."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Int",\n    "if-then-else",\n    "minOfTwo",\n    "minOfThree",\n    "transparent definition"\n  ],\n  "proof_keywords": [\n    "dsimp",\n    "simp",\n    "case analysis",\n    "Int.le_trans",\n    "proof by reduction",\n    "tactic simplification"\n  ],\n  "assumptions": [\n    "The standard library\'s integer comparison operators (<= and if-then-else) work as expected.",\n    "Using dsimp/simp is sufficient to reduce the definitions to the desired form for proofs.",\n    "Each function is uniquely defined to avoid conflicts.",\n    "The functions will not be hidden behind opaque attributes that interfere with tactic reductions."\n  ],\n  "retry_guidance": "If errors persist, verify that no attributes (like #[inline]) that cause type mismatches are present. Confirm that function names are unique and that redundant declarations are removed. Ensure that the proof tactics use dsimp or simp instead of unfold to handle if-then-else reduction. Finally, check the proof branches individually for correct application of Int-specific lemmas to avoid type errors."\n}\n\nLean error summary:\nThere are several issues with the generated code. First, the #[inline] attribute is causing a type mismatch – Lean seems to interpret it incorrectly, leading to the error that an array of functions is found instead of an ℤ. Second, the definition for minOfThree is a duplicate (or conflicts) with an earlier declaration. Third, in the proof, tactics like Nat.le_trans are used even though the inputs are of type Int (which may require using Int.le_trans or another appropriate argument). Finally, there is an \'unexpected identifier\' error, likely due to misplaced or incomplete tactic blocks (for example, the last \'by_cases\' branch is not properly finished).\nRetry guidance (MUST FOLLOW):\nRevise the code as suggested, removing the problematic attributes and duplicate declarations, and adjust the proof to use the correct operations for Int. Then re-run Lean to check for further type or syntax errors.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThe Lean output indicates several issues:\n1. An \'unexpected token def; expected term\' error, which suggests that a duplicate or misplaced declaration (such as the second definition of minOfThree) is present in the file.\n2. The error \'minOfThree has already been declared\' shows that there is a naming conflict from using the template\'s declaration together with the generated definition.\n3. The theorem proof has unsolved goals. The proof using by_cases is incomplete or incorrect, leaving holes (unsolved subgoals) that need to be resolved.\n4. An unexpected identifier error indicates that the generated proof or code structure does not properly align with Lean\'s expected syntax (likely due to the placeholders not being correctly replaced).\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 02:57:55,428 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:57:55,428 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:57:55,428 - DEBUG - send_request_headers.complete
2025-06-01 02:57:55,428 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:57:55,428 - DEBUG - send_request_body.complete
2025-06-01 02:57:55,429 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:58:03,295 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:58:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7597'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7599'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'197934'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'619ms'), (b'x-request-id', b'req_cc220af60efe53ee2eccd801549cfece'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b72419efe8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:58:03,295 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:58:03,295 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:58:03,296 - DEBUG - receive_response_body.complete
2025-06-01 02:58:03,296 - DEBUG - response_closed.started
2025-06-01 02:58:03,296 - DEBUG - response_closed.complete
2025-06-01 02:58:03,296 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:58:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7597', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7599', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '197934', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '619ms', 'x-request-id': 'req_cc220af60efe53ee2eccd801549cfece', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b72419efe8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:58:03,296 - DEBUG - request_id: req_cc220af60efe53ee2eccd801549cfece
2025-06-01 02:58:03,296 - INFO - Solution generated in 107.72 seconds
2025-06-01 02:58:03,296 - INFO - Generated code length: 144 characters
2025-06-01 02:58:03,296 - INFO - Generated proof length: 480 characters
2025-06-01 02:58:03,296 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:58:03,297 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:58:08,617 - INFO - Implementation test result: FAIL
2025-06-01 02:58:08,617 - ERROR - Implementation error: lean_playground/TempTest.lean:5:53: error: unexpected token 'def'; expected term
lean_playground/TempTest.lean:11:4: error: 'minOfThree' has already b...
2025-06-01 02:58:08,617 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:58:13,912 - INFO - Full solution test result: FAIL
2025-06-01 02:58:13,912 - ERROR - Proof error: lean_playground/TempTest.lean:5:53: error: unexpected token 'def'; expected term
lean_playground/TempTest.lean:11:4: error: 'minOfThree' has already b...
2025-06-01 02:58:13,913 - ERROR - ❌ Implementation fails unit tests
2025-06-01 02:58:13,913 - ERROR - ❌ Proof has errors
2025-06-01 02:58:13,913 - INFO - 
==================================================
2025-06-01 02:58:13,913 - INFO - Processing task task_id_404...
2025-06-01 02:58:13,913 - INFO - Reading problem description and code template from tasks/task_id_404...
2025-06-01 02:58:13,913 - INFO - Problem description length: 483 characters
2025-06-01 02:58:13,913 - INFO - Reading unit tests from tasks/task_id_404...
2025-06-01 02:58:13,913 - INFO - Unit tests length: 228 characters
2025-06-01 02:58:13,913 - INFO - Running main workflow to generate solution...
2025-06-01 02:58:13,913 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.

-----Input-----
The input consists of two integers:
a: The first integer.
b: The second integer.

-----Output-----
The output is an integer:
Returns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.
2025-06-01 02:58:13,913 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def myMin (a : Int) (b : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b
def myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  (result ≤ a ∧ result ≤ b) ∧
  (result = a ∨ result = b)
  -- << SPEC END >>

theorem myMin_spec_satisfied (a : Int) (b : Int) :
  myMin_spec a b (myMin a b) := by
  -- << PROOF START >>
  unfold myMin myMin_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:58:13,943 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7f4e66fe2840>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:58:13,943 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:58:13,944 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:58:13,969 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f813a0>
2025-06-01 02:58:13,969 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4e67398350> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:58:13,995 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f83a10>
2025-06-01 02:58:13,995 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:58:13,995 - DEBUG - send_request_headers.complete
2025-06-01 02:58:13,995 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:58:13,995 - DEBUG - send_request_body.complete
2025-06-01 02:58:13,995 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:58:14,553 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:58:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'40'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-74c8894ff9-ch4v7'), (b'x-envoy-upstream-service-time', b'42'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999880'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_bcb0476ac0e56ba98516b3eda4bd51c1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=X3zQeeJ6lvyTgHIPEV6iifR2j6LIX0F4Se6nuq7gSfU-1748746694-1.0.1.1-KH786QPYR7GvBJboTbSBzCDCj9.nc5Ahnpu6YVO6zPwSiNNwrXl4AYKCctvoyDDkCFIqEdK5kiSl9GtsK_Ypu8r_fOCIuMEcuEvbM0yB9Ow; path=/; expires=Sun, 01-Jun-25 03:28:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=JZJ.inbg9jhONKmmffb0Djph5zPwqrdHF0d_VimhbMU-1748746694576-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b72b5cfbc4278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:58:14,554 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:58:14,554 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:58:14,554 - DEBUG - receive_response_body.complete
2025-06-01 02:58:14,554 - DEBUG - response_closed.started
2025-06-01 02:58:14,555 - DEBUG - response_closed.complete
2025-06-01 02:58:14,555 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:58:14 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '40'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-74c8894ff9-ch4v7'), ('x-envoy-upstream-service-time', '42'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999880'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '7ms'), ('x-request-id', 'req_bcb0476ac0e56ba98516b3eda4bd51c1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=X3zQeeJ6lvyTgHIPEV6iifR2j6LIX0F4Se6nuq7gSfU-1748746694-1.0.1.1-KH786QPYR7GvBJboTbSBzCDCj9.nc5Ahnpu6YVO6zPwSiNNwrXl4AYKCctvoyDDkCFIqEdK5kiSl9GtsK_Ypu8r_fOCIuMEcuEvbM0yB9Ow; path=/; expires=Sun, 01-Jun-25 03:28:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=JZJ.inbg9jhONKmmffb0Djph5zPwqrdHF0d_VimhbMU-1748746694576-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b72b5cfbc4278-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:58:14,555 - DEBUG - request_id: req_bcb0476ac0e56ba98516b3eda4bd51c1
2025-06-01 02:58:14,560 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Interacting with Lean

You are now familiar with the fundamentals of dependent type theory, both as a
language for defining mathematical objects and a language for constructing
proofs. The one thing you are missing is a mechanism for defining new data
types. We will fill this gap in the next chapter, which introduces the notion
of an _inductive data type_. But first, in this chapter, we take a break from
the mechanics of type theory to explore some pragmatic aspects of interacting
with Lean.

Not all of the information found here will be useful to you right away. We
recommend skimming this section to get a sense of Lean's features, and then
returning to it as necessary.

## Importing Files

The goal of Lean's front end is to interpret user input, construct formal
expressions, and check that they are well-formed and type-correct. Lean also
supports the use of various editors, which provide continuous checking and
feedback. More information can be found on the Lean [documentation
pages](https://lean-lang.org/documentation/).

The definitions and theorems in Lean's standard library are spread across
multiple files. Users may also wish to make use of additional libraries, or
develop their own projects across multiple files. When Lean starts, it
automatically imports the contents of the library `Init` folder, which
includes a number of fundamental definitions and constructions. As a result,
most of the examples we present here work "out of the box."

If you want to use additional files, however, they need to be imported
manually, via an `import` statement at the beginning of a file. The command

    
    
    import Bar.Baz.Blah
    

imports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted
relative to the Lean _search path_. Information as to how the search path is
determined can be found on the [documentation pages](https://lean-
lang.org/documentation/). By default, it includes the standard library
directory, and (in some contexts) the root of the user's local project.

Importing is transitive. In other words, if you import `Foo` and `Foo` imports
`Bar`, then you also have access to the contents of `Bar`, and do not need to
import it explicitly.

## More on Sections

Lean provides various sectioning mechanisms to help structure a theory. You
saw in [Variables and Sections](./dependent_type_theory.html#variables-and-
sections) that the `section` command makes it possible not only to group
together elements of a theory that go together, but also to declare variables
that are inserted as arguments to theorems and definitions, as necessary.
Remember that the point of the `variable` command is to declare variables for
use in theorems, as in the following example:

    
    
    section
    variable (x y : Nat)
    
    def double := x + x
    
    #check double y
    #check double (2 * x)
    
    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm
    
    theorem t1 : double (x + y) = double x + double y := by
      simp [double]
    
    #check t1 y
    #check t1 (2 * x)
    
    theorem t2 : double (x * y) = double x * y := by
      simp [double, Nat.add_mul]
    
    end
    

The definition of `double` does not have to declare `x` as an argument; Lean
detects the dependence and inserts it automatically. Similarly, Lean detects
the occurrence of `x` in `t1` and `t2`, and inserts it automatically there,
too. Note that `double` does _not_ have `y` as argument. Variables are only
included in declarations where they are actually used.

## More on Namespaces

In Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We
saw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean
provides mechanisms for working with hierarchical names. The command
`namespace foo` causes `foo` to be prepended to the name of each definition
and theorem until `end foo` is encountered. The command `open foo` then
creates temporary _aliases_ to definitions and theorems that begin with prefix
`foo`.

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    
    open Foo
    
    #check bar
    #check Foo.bar
    

The following definition

    
    
    def Foo.bar : Nat := 1
    

is treated as a macro, and expands to

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    

Although the names of theorems and definitions have to be unique, the aliases
that identify them do not. When we open a namespace, an identifier may be
ambiguous. Lean tries to use type information to disambiguate the meaning in
context, but you can always disambiguate by giving the full name. To that end,
the string `_root_` is an explicit description of the empty prefix.

    
    
    def String.add (a b : String) : String :=
      a ++ b
    
    def Bool.add (a b : Bool) : Bool :=
      a != b
    
    def add (α β : Type) : Type := Sum α β
    
    open Bool
    open String
    -- #check add -- ambiguous
    #check String.add           -- String → String → String
    #check Bool.add             -- Bool → Bool → Bool
    #check _root_.add           -- Type → Type → Type
    
    #check add "hello" "world"  -- String
    #check add true false       -- Bool
    #check add Nat Nat          -- Type
    

We can prevent the shorter alias from being created by using the `protected`
keyword:

    
    
    protected def Foo.bar : Nat := 1
    
    open Foo
    
    -- #check bar -- error
    #check Foo.bar
    

This is often used for names like `Nat.rec` and `Nat.recOn`, to prevent
overloading of common names.

The `open` command admits variations. The command

    
    
    open Nat (succ zero gcd)
    #check zero     -- Nat
    #eval gcd 15 6  -- 3
    

creates aliases for only the identifiers listed. The command

    
    
    open Nat hiding succ gcd
    #check zero     -- Nat
    -- #eval gcd 15 6  -- error
    #eval Nat.gcd 15 6  -- 3
    

creates aliases for everything in the `Nat` namespace _except_ the identifiers
listed.

    
    
    open Nat renaming mul → times, add → plus
    #eval plus (times 2 2) 3  -- 7
    

creates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.

It is sometimes useful to `export` aliases from one namespace to another, or
to the top level. The command

    
    
    export Nat (succ add sub)
    

creates aliases for `succ`, `add`, and `sub` in the current namespace, so that
whenever the namespace is open, these aliases are available. If this command
is used outside a namespace, the aliases are exported to the top level.

## Attributes

The main function of Lean is to translate user input to formal expressions
that are checked by the kernel for correctness and then stored in the
environment for later use. But some commands have other effects on the
environment, either assigning attributes to objects in the environment,
defining notation, or declaring instances of type classes, as described in
[Chapter Type Classes](./type_classes.html). Most of these commands have
global effects, which is to say, they remain in effect not only in the current
file, but also in any file that imports it. However, such commands often
support the `local` modifier, which indicates that they only have effect until
the current `section` or `namespace` is closed, or until the end of the
current file.

In [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw
that theorems can be annotated with the `[simp]` attribute, which makes them
available for use by the simplifier. The following example defines the prefix
relation on lists, proves that this relation is reflexive, and assigns the
`[simp]` attribute to that theorem.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    

The simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to
`True`.

One can also assign the attribute any time after the definition takes place:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [simp] List.isPrefix_self
    

In all these cases, the attribute remains in effect in any file that imports
the one in which the declaration occurs. Adding the `local` modifier restricts
the scope:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    section
    
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [local simp] List.isPrefix_self
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    
    end
    
    -- Error:
    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by
    --  simp
    

For another example, we can use the `instance` command to assign the notation
`≤` to the `isPrefix` relation. That command, which will be explained in
[Chapter Type Classes](./type_classes.html), works by assigning an
`[instance]` attribute to the associated definition.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    instance : LE (List α) where
      le := isPrefix
    
    theorem List.isPrefix_self (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    

That assignment can also be made local:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    def instLe : LE (List α) :=
      { le := isPrefix }
    
    section
    attribute [local instance] instLe
    
    example (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    
    end
    
    -- Error:
    -- example (as : List α) : as ≤ as :=
    --  ⟨[], by simp⟩
    

In Section Notation below, we will discuss Lean's mechanisms for defining
notation, and see that they also support the `local` modifier. However, in
Section Setting Options, we will discuss Lean's mechanisms for setting
options, which does _not_ follow this pattern: options can _only_ be set
locally, which is to say, their scope is always restricted to the current
section or current file.

## More on Implicit Arguments

In [Section Implicit Arguments](./dependent_type_theory.html#implicit-
arguments), we saw that if Lean displays the type of a term `t` as `{x : α} →
β x`, then the curly brackets indicate that `x` has been marked as an
_implicit argument_ to `t`. This means that whenever you write `t`, a
placeholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you
don't want that to happen, you have to write `@t` instead.

Notice that implicit arguments are inserted eagerly. Suppose we define a
function `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,
when we write the expression `f 7` without further arguments, it is parsed as
`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that
a placeholder should only be added _before_ a subsequent explicit argument.
This annotation can also be written using as `⦃y : Nat⦄`, where the unicode
brackets are entered as `\{{` and `\}}`, respectively. With this annotation,
the expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as
`f 7 _ 3`, just as it would be with the strong annotation.

To illustrate the difference, consider the following example, which shows that
a reflexive euclidean relation is both symmetric and transitive.

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b : α}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
     th2 (th1 reflr @euclr) @euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3
    

The results are broken down into small steps: `th1` shows that a relation that
is reflexive and euclidean is symmetric, and `th2` shows that a relation that
is symmetric and euclidean is transitive. Then `th3` combines the two results.
But notice that we have to manually disable the implicit arguments in `euclr`,
because otherwise too many implicit arguments are inserted. The problem goes
away if we use weak implicit arguments:

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b : α}}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
      th2 (th1 reflr euclr) euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- euclidean r
    

There is a third kind of implicit argument that is denoted with square
brackets, `[` and `]`. These are used for type classes, as explained in
[Chapter Type Classes](./type_classes.html).

## Notation

Identifiers in Lean can include any alphanumeric characters, including Greek
characters (other than ∀ , Σ , and λ , which, as we have seen, have a special
meaning in the dependent type theory). They can also include subscripts, which
can be entered by typing `\_` followed by the desired subscripted character.

Lean's parser is extensible, which is to say, we can define new notation.

Lean's syntax can be extended and customized by users at every level, ranging
from basic "mixfix" notations to custom elaborators. In fact, all builtin
syntax is parsed and processed using the same mechanisms and APIs open to
users. In this section, we will describe and explain the various extension
points.

While introducing new notations is a relatively rare feature in programming
languages and sometimes even frowned upon because of its potential to obscure
code, it is an invaluable tool in formalization for expressing established
conventions and notations of the respective field succinctly in code. Going
beyond basic notations, Lean's ability to factor out common boilerplate code
into (well-behaved) macros and to embed entire custom domain specific
languages (DSLs) to textually encode subproblems efficiently and readably can
be of great benefit to both programmers and proof engineers alike.

### Notations and Precedence

The most basic syntax extension commands allow introducing new (or overloading
existing) prefix, infix, and postfix operators.

    
    
    infixl:65   " + " => HAdd.hAdd  -- left-associative
    infix:50    " = " => Eq         -- non-associative
    infixr:80   " ^ " => HPow.hPow  -- right-associative
    prefix:100  "-"   => Neg.neg
    set_option quotPrecheck false
    postfix:max "⁻¹"  => Inv.inv
    

After the initial command name describing the operator kind (its "fixity"), we
give the _parsing precedence_ of the operator preceded by a colon `:`, then a
new or existing token surrounded by double quotes (the whitespace is used for
pretty printing), then the function this operator should be translated to
after the arrow `=>`.

The precedence is a natural number describing how "tightly" an operator binds
to its arguments, encoding the order of operations. We can make this more
precise by looking at the commands the above unfold to:

    
    
    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs
    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs
    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs
    notation:100 "-" arg:100 => Neg.neg arg
    set_option quotPrecheck false
    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024
    

It turns out that all commands from the first code block are in fact command
_macros_ translating to the more general `notation` command. We will learn
about writing such macros below. Instead of a single token, the `notation`
command accepts a mixed sequence of tokens and named term placeholders with
precedences, which can be referenced on the right-hand side of `=>` and will
be replaced by the respective term parsed at that position. A placeholder with
precedence `p` accepts only notations with precedence at least `p` in that
place. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +
(b + c)` because the right-hand side operand of an `infixl` notation has
precedence one greater than the notation itself. In contrast, `infixr` reuses
the notation's precedence for the right-hand side operand, so `a ^ b ^ c`
_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to
introduce an infix notation like

    
    
    set_option quotPrecheck false
    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs
    

where the precedences do not sufficiently determine associativity, Lean's
parser will default to right associativity. More precisely, Lean's parser
follows a local _longest parse_ rule in the presence of ambiguous grammars:
when parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue
parsing as long as possible (as the current precedence allows), not stopping
after `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~
c)`.

As mentioned above, the `notation` command allows us to define arbitrary
_mixfix_ syntax freely mixing tokens and placeholders.

    
    
    set_option quotPrecheck false
    notation:max "(" e ")" => e
    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ
    

Placeholders without precedence default to `0`, i.e. they accept notations of
any precedence in their place. If two notations overlap, we again apply the
longest parse rule:

    
    
    notation:65 a " + " b:66 " + " c:66 => a + b - c
    #eval 1 + 2 + 3  -- 0
    

The new notation is preferred to the binary notation since the latter, before
chaining, would stop parsing after `1 + 2`. If there are multiple notations
accepting the same longest parse, the choice will be delayed until
elaboration, which will fail unless exactly one overload is type-correct.

## Coercions

In Lean, the type of natural numbers, `Nat`, is different from the type of
integers, `Int`. But there is a function `Int.ofNat` that embeds the natural
numbers in the integers, meaning that we can view any natural number as an
integer, when needed. Lean has mechanisms to detect and insert _coercions_ of
this sort.

    
    
    variable (m n : Nat)
    variable (i j : Int)
    
    #check i + m      -- i + Int.ofNat m : Int
    #check i + m + j  -- i + Int.ofNat m + j : Int
    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int
    

## Displaying Information

There are a number of ways in which you can query Lean for information about
its current state and the objects and theorems that are available in the
current context. You have already seen two of the most common ones, `#check`
and `#eval`. Remember that `#check` is often used in conjunction with the `@`
operator, which makes all of the arguments to a theorem or definition
explicit. In addition, you can use the `#print` command to get information
about any identifier. If the identifier denotes a definition or theorem, Lean
prints the type of the symbol, and its definition. If it is a constant or an
axiom, Lean indicates that fact, and shows the type.

    
    
    -- examples with equality
    #check Eq
    #check @Eq
    #check Eq.symm
    #check @Eq.symm
    
    #print Eq.symm
    
    -- examples with And
    #check And
    #check And.intro
    #check @And.intro
    
    -- a user-defined function
    def foo {α : Type u} (x : α) : α := x
    
    #check foo
    #check @foo
    #print foo
    

## Setting Options

Lean maintains a number of internal variables that can be set by users to
control its behavior. The syntax for doing so is as follows:

    
    
    set_option <name> <value>
    

One very useful family of options controls the way Lean's _pretty- printer_
displays terms. The following options take an input of true or false:

    
    
    pp.explicit  : display implicit arguments
    pp.universes : display hidden universe parameters
    pp.notation  : display output using defined notations
    

As an example, the following settings yield much longer output:

    
    
    set_option pp.explicit true
    set_option pp.universes true
    set_option pp.notation false
    
    #check 2 + 2 = 4
    #reduce (fun x => x + 2) = (fun x => x + 3)
    #check (fun x => x + 1) 1
    

The command `set_option pp.all true` carries out these settings all at once,
whereas `set_option pp.all false` reverts to the previous values. Pretty
printing additional information is often very useful when you are debugging a
proof, or trying to understand a cryptic error message. Too much information
can be overwhelming, though, and Lean's defaults are generally sufficient for
ordinary interactions.

## Using the Library

To use Lean effectively you will inevitably need to make use of definitions
and theorems in the library. Recall that the `import` command at the beginning
of a file imports previously compiled results from other files, and that
importing is transitive; if you import `Foo` and `Foo` imports `Bar`, then the
definitions and theorems from `Bar` are available to you as well. But the act
of opening a namespace, which provides shorter names, does not carry over. In
each file, you need to open the namespaces you wish to use.

In general, it is important for you to be familiar with the library and its
contents, so you know what theorems, definitions, notations, and resources are
available to you. Below we will see that Lean's editor modes can also help you
find things you need, but studying the contents of the library directly is
often unavoidable. Lean's standard library can be found online, on GitHub:

  * <https://github.com/leanprover/lean4/tree/master/src/Init>

  * <https://github.com/leanprover/std4/tree/main/Std>

You can see the contents of these directories and files using GitHub's browser
interface. If you have installed Lean on your own computer, you can find the
library in the `lean` folder, and explore it with your file manager. Comment
headers at the top of each file provide additional information.

Lean's library developers follow general naming guidelines to make it easier
to guess the name of a theorem you need, or to find it using tab completion in
editors with a Lean mode that supports this, which is discussed in the next
section. Identifiers are generally `camelCase`, and types are `CamelCase`. For
theorem names, we rely on descriptive names where the different components are
separated by `_`s. Often the name of theorem simply describes the conclusion:

    
    
    #check Nat.succ_ne_zero
    #check Nat.zero_add
    #check Nat.mul_one
    #check Nat.le_of_succ_le_succ
    

Remember that identifiers in Lean can be organized into hierarchical
namespaces. For example, the theorem named `le_of_succ_le_succ` in the
namespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name
is made available by the command `open Nat` (for names not marked as
`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)
and [Chapter Structures and Records](./structures_and_records.html) that
defining structures and inductive data types in Lean generates associated
operations, and these are stored in a namespace with the same name as the type
under definition. For example, the product type comes with the following
operations:

    
    
    #check @Prod.mk
    #check @Prod.fst
    #check @Prod.snd
    #check @Prod.rec
    

The first is used to construct a pair, whereas the next two, `Prod.fst` and
`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another
mechanism for defining functions on a product in terms of a function on the
two components. Names like `Prod.rec` are _protected_ , which means that one
has to use the full name even when the `Prod` namespace is open.

With the propositions as types correspondence, logical connectives are also
instances of inductive types, and so we tend to use dot notation for them as
well:

    
    
    #check @And.intro
    #check @And.casesOn
    #check @And.left
    #check @And.right
    #check @Or.inl
    #check @Or.inr
    #check @Or.elim
    #check @Exists.intro
    #check @Exists.elim
    #check @Eq.refl
    #check @Eq.subst
    

## Auto Bound Implicit Arguments

In the previous section, we have shown how implicit arguments make functions
more convenient to use. However, functions such as `compose` are still quite
verbose to define. Note that the universe polymorphic `compose` is even more
verbose than the one previously defined.

    
    
    universe u v w
    def compose {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

You can avoid the `universe` command by providing the universe parameters when
defining `compose`.

    
    
    def compose.{u, v, w}
                {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

Lean 4 supports a new feature called _auto bound implicit arguments_. It makes
functions such as `compose` much more convenient to write. When Lean processes
the header of a declaration, any unbound identifier is automatically added as
an implicit argument _if_ it is a single lower case or greek letter. With this
feature we can write `compose` as

    
    
    def compose (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    
    #check @compose
    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ
    

Note that Lean inferred a more general type using `Sort` instead of `Type`.

Although we love this feature and use it extensively when implementing Lean,
we realize some users may feel uncomfortable with it. Thus, you can disable it
using the command `set_option autoImplicit false`.

    
    
    set_option autoImplicit false
    /- The following definition produces `unknown identifier` errors -/
    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=
    --   g (f x)
    

## Implicit Lambdas

In Lean 3 stdlib, we find many
[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)
of the dreadful `@`+`_` idiom. It is often used when the expected type is a
function type with implicit arguments, and we have a constant (`reader_t.pure`
in the example) which also takes implicit arguments. In Lean 4, the elaborator
automatically introduces lambdas for consuming implicit arguments. We are
still exploring this feature and analyzing its impact, but the experience so
far has been very positive. Here is the example from the link above using Lean
4 implicit lambdas.

    
    
    variable (ρ : Type) (m : Type → Type) [Monad m]
    instance : Monad (ReaderT ρ m) where
      pure := ReaderT.pure
      bind := ReaderT.bind
    

Users can disable the implicit lambda feature by using `@` or writing a lambda
expression with `{}` or `[]` binder annotations. Here are few examples

    
    
    namespace ex2
    def id1 : {α : Type} → α → α :=
      fun x => x
    
    def listId : List ({α : Type} → α → α) :=
      (fun x => x) :: []
    
    -- In this example, implicit lambda introduction has been disabled because
    -- we use `@` before `fun`
    def id2 : {α : Type} → α → α :=
      @fun α (x : α) => id1 x
    
    def id3 : {α : Type} → α → α :=
      @fun α x => id1 x
    
    def id4 : {α : Type} → α → α :=
      fun x => id1 x
    
    -- In this example, implicit lambda introduction has been disabled
    -- because we used the binder annotation `{...}`
    def id5 : {α : Type} → α → α :=
      fun {α} x => id1 x
    end ex2
    

## Sugar for Simple Functions

In Lean 3, we can create simple functions from infix operators by using
parentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we
generalize this notation using `·` as a placeholder. Here are a few examples:

    
    
    namespace ex3
    #check (· + 1)
    -- fun a => a + 1
    #check (2 - ·)
    -- fun a => 2 - a
    #eval [1, 2, 3, 4, 5].foldl (·*·) 1
    -- 120
    
    def f (x y z : Nat) :=
      x + y + z
    
    #check (f · 1 ·)
    -- fun a b => f a 1 b
    
    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)
    -- [1, 3, 5]
    end ex3
    

As in Lean 3, the notation is activated using parentheses, and the lambda
abstraction is created by collecting the nested `·`s. The collection is
interrupted by nested parentheses. In the following example, two different
lambda expressions are created.

    
    
    #check (Prod.mk · (· + 1))
    -- fun a => (a, fun b => b + 1)
    

## Named Arguments

Named arguments enable you to specify an argument for a parameter by matching
the argument with its name rather than with its position in the parameter
list. If you don't remember the order of the parameters but know their names,
you can send the arguments in any order. You may also provide the value for an
implicit parameter when
2025-06-01 02:58:14,564 - DEBUG - close.started
2025-06-01 02:58:14,565 - DEBUG - close.complete
2025-06-01 02:58:14,579 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.'}], 'model': 'o3-mini'}}
2025-06-01 02:58:14,580 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:58:14,580 - DEBUG - close.started
2025-06-01 02:58:14,580 - DEBUG - close.complete
2025-06-01 02:58:14,580 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:58:14,605 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f81b50>
2025-06-01 02:58:14,605 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:58:14,633 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f82960>
2025-06-01 02:58:14,633 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:58:14,634 - DEBUG - send_request_headers.complete
2025-06-01 02:58:14,634 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:58:14,634 - DEBUG - send_request_body.complete
2025-06-01 02:58:14,634 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:58:19,884 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:58:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4999'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5002'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199578'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'126ms'), (b'x-request-id', b'req_92654365e14c3d28757e50fb5c566bfa'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b72b9cbbb46f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:58:19,884 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:58:19,885 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:58:19,885 - DEBUG - receive_response_body.complete
2025-06-01 02:58:19,885 - DEBUG - response_closed.started
2025-06-01 02:58:19,885 - DEBUG - response_closed.complete
2025-06-01 02:58:19,885 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:58:19 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4999', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5002', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199578', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '126ms', 'x-request-id': 'req_92654365e14c3d28757e50fb5c566bfa', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b72b9cbbb46f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:58:19,885 - DEBUG - request_id: req_92654365e14c3d28757e50fb5c566bfa
2025-06-01 02:58:19,886 - INFO - Attempt 1/3
2025-06-01 02:58:19,886 - INFO - Current plan: {
  "plan_summary": "We need to implement a Lean 4 function that returns the minimum of two integers. The plan involves defining the function signature, using a conditional construct to compare the two integers, and ensuring that the result adheres to the property of being less than or equal to both inputs.",
  "steps": [
    "Define the function signature with two integer inputs and one integer output.",
    "Implement the function using a simple if/else conditional: if a is less than or equal to b, return a; otherwise, return b.",
    "Optionally, provide a short justification or lemma in Lean that verifies the output is less than or equal to both inputs.",
    "Check that when the numbers are equal, returning either one is valid.",
    "Test the function with several examples to verify its correctness."
  ],
  "code_keywords": [
    "Lean 4",
    "conditional",
    "if/else",
    "integer",
    "function definition"
  ],
  "proof_keywords": [
    "proof by cases",
    "property-based verification",
    "lemma",
    "inequality"
  ],
  "assumptions": [
    "Inputs are Lean integers (Int)",
    "Both numbers can be compared using Lean's built-in <= operator",
    "Returning a when both numbers are equal is acceptable"
  ],
  "retry_guidance": "If encountering type-related errors or issues with the conditional structure, verify that the input types match Lean's integer type and consult Lean's documentation for the syntax of the if/else expressions."
}
2025-06-01 02:58:19,886 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "We need to implement a Lean 4 function that returns the minimum of two integers. The plan involves defining the function signature, using a conditional construct to compare the two integers, and ensuring that the result adheres to the property of being less than or equal to both inputs.",\n  "steps": [\n    "Define the function signature with two integer inputs and one integer output.",\n    "Implement the function using a simple if/else conditional: if a is less than or equal to b, return a; otherwise, return b.",\n    "Optionally, provide a short justification or lemma in Lean that verifies the output is less than or equal to both inputs.",\n    "Check that when the numbers are equal, returning either one is valid.",\n    "Test the function with several examples to verify its correctness."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "conditional",\n    "if/else",\n    "integer",\n    "function definition"\n  ],\n  "proof_keywords": [\n    "proof by cases",\n    "property-based verification",\n    "lemma",\n    "inequality"\n  ],\n  "assumptions": [\n    "Inputs are Lean integers (Int)",\n    "Both numbers can be compared using Lean\'s built-in <= operator",\n    "Returning a when both numbers are equal is acceptable"\n  ],\n  "retry_guidance": "If encountering type-related errors or issues with the conditional structure, verify that the input types match Lean\'s integer type and consult Lean\'s documentation for the syntax of the if/else expressions."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef myMin (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b\ndef myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result ≤ a ∧ result ≤ b) ∧\n  (result = a ∨ result = b)\n  -- << SPEC END >>\n\ntheorem myMin_spec_satisfied (a : Int) (b : Int) :\n  myMin_spec a b (myMin a b) := by\n  -- << PROOF START >>\n  unfold myMin myMin_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:58:19,888 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:58:19,888 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:58:19,888 - DEBUG - send_request_headers.complete
2025-06-01 02:58:19,888 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:58:19,911 - DEBUG - send_request_body.complete
2025-06-01 02:58:19,911 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:58:22,507 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:58:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2316'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2318'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'3040'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'53.919s'), (b'x-request-id', b'req_ecbd4ba3fd40d03f2c4822887280d2a4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b72da985b46f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:58:22,507 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:58:22,508 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:58:22,508 - DEBUG - receive_response_body.complete
2025-06-01 02:58:22,508 - DEBUG - response_closed.started
2025-06-01 02:58:22,508 - DEBUG - response_closed.complete
2025-06-01 02:58:22,508 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:58:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2316', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2318', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '3040', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '53.919s', 'x-request-id': 'req_ecbd4ba3fd40d03f2c4822887280d2a4', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b72da985b46f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:58:22,508 - DEBUG - request_id: req_ecbd4ba3fd40d03f2c4822887280d2a4
2025-06-01 02:58:22,509 - INFO - Raw solution received: ```json
{
  "code": "if a <= b then a else b",
  "proof": "by_cases h : a <= b\n  simp [h, or_true, and_self]\n  have : b < a := (not_le.mp h)\n  simp [this, le_of_lt, or_true, and_self]"
}
```
2025-06-01 02:58:22,509 - INFO - <class 'str'>
2025-06-01 02:58:22,509 - INFO - Generated solution: {'code': 'if a <= b then a else b', 'proof': 'by_cases h : a <= b\n  simp [h, or_true, and_self]\n  have : b < a := (not_le.mp h)\n  simp [this, le_of_lt, or_true, and_self]'}
2025-06-01 02:58:27,846 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:19:32: error: unsolved goals
case neg
a b : ℤ
h : ¬a ≤ b
this : b < a
⊢ (if a ≤ b then a else b) ≤ a ∧ (if a ≤ b then a else b) ≤ b
2025-06-01 02:58:27,847 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef myMin (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b\ndef myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result ≤ a ∧ result ≤ b) ∧\n  (result = a ∨ result = b)\n  -- << SPEC END >>\n\ntheorem myMin_spec_satisfied (a : Int) (b : Int) :\n  myMin_spec a b (myMin a b) := by\n  -- << PROOF START >>\n  unfold myMin myMin_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a <= b then a else b\n\nGenerated Proof:\nby_cases h : a <= b\n  simp [h, or_true, and_self]\n  have : b < a := (not_le.mp h)\n  simp [this, le_of_lt, or_true, and_self]\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:19:32: error: unsolved goals\ncase neg\na b : ℤ\nh : ¬a ≤ b\nthis : b < a\n⊢ (if a ≤ b then a else b) ≤ a ∧ (if a ≤ b then a else b) ≤ b'}], 'model': 'o3-mini'}}
2025-06-01 02:58:27,848 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:58:27,848 - DEBUG - close.started
2025-06-01 02:58:27,848 - DEBUG - close.complete
2025-06-01 02:58:27,848 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:58:27,873 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a6f90>
2025-06-01 02:58:27,873 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:58:27,899 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a5940>
2025-06-01 02:58:27,899 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:58:27,899 - DEBUG - send_request_headers.complete
2025-06-01 02:58:27,899 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:58:27,899 - DEBUG - send_request_body.complete
2025-06-01 02:58:27,899 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:58:36,190 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:58:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8050'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8056'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199260'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'222ms'), (b'x-request-id', b'req_23436cc87d2f13d26c0799b07b609179'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b730cae184278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:58:36,190 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:58:36,190 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:58:36,191 - DEBUG - receive_response_body.complete
2025-06-01 02:58:36,191 - DEBUG - response_closed.started
2025-06-01 02:58:36,191 - DEBUG - response_closed.complete
2025-06-01 02:58:36,191 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:58:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8050', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8056', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199260', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '222ms', 'x-request-id': 'req_23436cc87d2f13d26c0799b07b609179', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b730cae184278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:58:36,191 - DEBUG - request_id: req_23436cc87d2f13d26c0799b07b609179
2025-06-01 02:58:36,191 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': 'In the negative branch (when ¬(a ≤ b)), the proof does not fully solve the goals. The unsolved goal arises when trying to show that (if a ≤ b then a else b), which reduces to b in this branch, satisfies b ≤ a ∧ b ≤ b. Although the proof correctly derives b < a from ¬(a ≤ b), the subsequent simp tactic does not automatically resolve the goal.', 'error_type': 'proof', 'suggested_fix': "Explicitly split the goal and apply the necessary lemmas in the negative branch. For example, in the branch where ¬(a ≤ b) holds, first note that b < a implies b ≤ a (using le_of_lt) and b ≤ b by reflexivity. Then, split the conjunction and explicitly show that one of the disjunctions holds (b = b). Here is an example revision of the proof:\n\nby_cases h : a ≤ b\n  · -- Case when a ≤ b, so myMin a b = a\n    simp [h]\n    split\n    · exact h\n    · left; rfl\n  · -- Case when ¬(a ≤ b), so myMin a b = b\n    have h' : b < a := lt_of_not_ge h\n    simp [h']\n    split\n    · split\n      · exact le_of_lt h'\n      · exact le_refl b\n    · right; rfl", 'retry_strategy': 'Revise the proof by performing explicit splits for the conjunction and disjunction in both branches. In the negative branch, replace the simp tactic with explicit applications of le_of_lt and splitting tactics to handle the individual components of the goal.'}
2025-06-01 02:58:36,192 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.\n\nPrevious plan:\n{\n  "plan_summary": "We need to implement a Lean 4 function that returns the minimum of two integers. The plan involves defining the function signature, using a conditional construct to compare the two integers, and ensuring that the result adheres to the property of being less than or equal to both inputs.",\n  "steps": [\n    "Define the function signature with two integer inputs and one integer output.",\n    "Implement the function using a simple if/else conditional: if a is less than or equal to b, return a; otherwise, return b.",\n    "Optionally, provide a short justification or lemma in Lean that verifies the output is less than or equal to both inputs.",\n    "Check that when the numbers are equal, returning either one is valid.",\n    "Test the function with several examples to verify its correctness."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "conditional",\n    "if/else",\n    "integer",\n    "function definition"\n  ],\n  "proof_keywords": [\n    "proof by cases",\n    "property-based verification",\n    "lemma",\n    "inequality"\n  ],\n  "assumptions": [\n    "Inputs are Lean integers (Int)",\n    "Both numbers can be compared using Lean\'s built-in <= operator",\n    "Returning a when both numbers are equal is acceptable"\n  ],\n  "retry_guidance": "If encountering type-related errors or issues with the conditional structure, verify that the input types match Lean\'s integer type and consult Lean\'s documentation for the syntax of the if/else expressions."\n}\n\nLean error:\nIn the negative branch (when ¬(a ≤ b)), the proof does not fully solve the goals. The unsolved goal arises when trying to show that (if a ≤ b then a else b), which reduces to b in this branch, satisfies b ≤ a ∧ b ≤ b. Although the proof correctly derives b < a from ¬(a ≤ b), the subsequent simp tactic does not automatically resolve the goal.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 02:58:36,192 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:58:36,193 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:58:36,193 - DEBUG - send_request_headers.complete
2025-06-01 02:58:36,193 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:58:36,193 - DEBUG - send_request_body.complete
2025-06-01 02:58:36,193 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:58:42,733 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:58:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6290'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6293'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198816'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'355ms'), (b'x-request-id', b'req_f022a71a8deeaf2bf637fb4f054b6ea5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b73407e754278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:58:42,733 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:58:42,733 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:58:42,733 - DEBUG - receive_response_body.complete
2025-06-01 02:58:42,733 - DEBUG - response_closed.started
2025-06-01 02:58:42,733 - DEBUG - response_closed.complete
2025-06-01 02:58:42,734 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:58:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6290', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6293', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198816', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '355ms', 'x-request-id': 'req_f022a71a8deeaf2bf637fb4f054b6ea5', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b73407e754278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:58:42,734 - DEBUG - request_id: req_f022a71a8deeaf2bf637fb4f054b6ea5
2025-06-01 02:58:42,734 - INFO - Attempt 2/3
2025-06-01 02:58:42,734 - INFO - Current plan: {
  "plan_summary": "Revise the function implementation to account for the explicit proof obligations in Lean's type checking. In the branch where a ≤ b fails, we have b as output, and we must manually show that b satisfies both b ≤ a (by converting b < a to b ≤ a) and b ≤ b (by reflexivity). This plan includes adding an explicit lemma or tactic application to convert the inequality for b ≤ a in the negative branch.",
  "steps": [
    "Define the function signature with two integer inputs and one integer output.",
    "Implement the function using an if/else conditional. In the if branch (a ≤ b), return a. In the else branch (¬(a ≤ b)), return b.",
    "In the else branch, add an explicit proof step that converts the given b < a (obtained from the negation ¬(a ≤ b)) to b ≤ a. This can be done using an explicit lemma such as 'lt_implies_le' or a custom lemma.",
    "Prove that b ≤ b using reflexivity.",
    "As an alternative strategy, consider using a 'by_cases' style proof to handle the two cases with explicit justification.",
    "Test the function with examples to ensure that the function behaves correctly and the proof obligations are fully discharged."
  ],
  "code_keywords": [
    "Lean 4",
    "if/else",
    "function definition",
    "integer comparison",
    "conditional expression"
  ],
  "proof_keywords": [
    "proof by cases",
    "explicit lemma for inequality",
    "using lt_implies_le",
    "reflexivity",
    "tactic libraries"
  ],
  "assumptions": [
    "Inputs are Lean integers (Int).",
    "Lean supports proof steps inside function definitions (if necessary) or through auxiliary lemmas.",
    "Using a lemma such as lt_implies_le is acceptable to convert a strict inequality to a non-strict inequality."
  ],
  "retry_guidance": "If the negative branch still poses issues, confirm that the explicit lemma or tactic (lt_implies_le) is available and correctly imported. Consider isolating the contradictory proof obligation into a separate lemma and referencing it. Check Lean's documentation for managing proof obligations in conditional expressions."
}
2025-06-01 02:58:42,734 - INFO - Updated plan: {
  "plan_summary": "Revise the function implementation to account for the explicit proof obligations in Lean's type checking. In the branch where a ≤ b fails, we have b as output, and we must manually show that b satisfies both b ≤ a (by converting b < a to b ≤ a) and b ≤ b (by reflexivity). This plan includes adding an explicit lemma or tactic application to convert the inequality for b ≤ a in the negative branch.",
  "steps": [
    "Define the function signature with two integer inputs and one integer output.",
    "Implement the function using an if/else conditional. In the if branch (a ≤ b), return a. In the else branch (¬(a ≤ b)), return b.",
    "In the else branch, add an explicit proof step that converts the given b < a (obtained from the negation ¬(a ≤ b)) to b ≤ a. This can be done using an explicit lemma such as 'lt_implies_le' or a custom lemma.",
    "Prove that b ≤ b using reflexivity.",
    "As an alternative strategy, consider using a 'by_cases' style proof to handle the two cases with explicit justification.",
    "Test the function with examples to ensure that the function behaves correctly and the proof obligations are fully discharged."
  ],
  "code_keywords": [
    "Lean 4",
    "if/else",
    "function definition",
    "integer comparison",
    "conditional expression"
  ],
  "proof_keywords": [
    "proof by cases",
    "explicit lemma for inequality",
    "using lt_implies_le",
    "reflexivity",
    "tactic libraries"
  ],
  "assumptions": [
    "Inputs are Lean integers (Int).",
    "Lean supports proof steps inside function definitions (if necessary) or through auxiliary lemmas.",
    "Using a lemma such as lt_implies_le is acceptable to convert a strict inequality to a non-strict inequality."
  ],
  "retry_guidance": "If the negative branch still poses issues, confirm that the explicit lemma or tactic (lt_implies_le) is available and correctly imported. Consider isolating the contradictory proof obligation into a separate lemma and referencing it. Check Lean's documentation for managing proof obligations in conditional expressions."
}

Lean error summary:
In the negative branch (when ¬(a ≤ b)), the proof does not fully solve the goals. The unsolved goal arises when trying to show that (if a ≤ b then a else b), which reduces to b in this branch, satisfies b ≤ a ∧ b ≤ b. Although the proof correctly derives b < a from ¬(a ≤ b), the subsequent simp tactic does not automatically resolve the goal.
Retry guidance (MUST FOLLOW):
Revise the proof by performing explicit splits for the conjunction and disjunction in both branches. In the negative branch, replace the simp tactic with explicit applications of le_of_lt and splitting tactics to handle the individual components of the goal.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 02:58:42,735 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the function implementation to account for the explicit proof obligations in Lean\'s type checking. In the branch where a ≤ b fails, we have b as output, and we must manually show that b satisfies both b ≤ a (by converting b < a to b ≤ a) and b ≤ b (by reflexivity). This plan includes adding an explicit lemma or tactic application to convert the inequality for b ≤ a in the negative branch.",\n  "steps": [\n    "Define the function signature with two integer inputs and one integer output.",\n    "Implement the function using an if/else conditional. In the if branch (a ≤ b), return a. In the else branch (¬(a ≤ b)), return b.",\n    "In the else branch, add an explicit proof step that converts the given b < a (obtained from the negation ¬(a ≤ b)) to b ≤ a. This can be done using an explicit lemma such as \'lt_implies_le\' or a custom lemma.",\n    "Prove that b ≤ b using reflexivity.",\n    "As an alternative strategy, consider using a \'by_cases\' style proof to handle the two cases with explicit justification.",\n    "Test the function with examples to ensure that the function behaves correctly and the proof obligations are fully discharged."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "if/else",\n    "function definition",\n    "integer comparison",\n    "conditional expression"\n  ],\n  "proof_keywords": [\n    "proof by cases",\n    "explicit lemma for inequality",\n    "using lt_implies_le",\n    "reflexivity",\n    "tactic libraries"\n  ],\n  "assumptions": [\n    "Inputs are Lean integers (Int).",\n    "Lean supports proof steps inside function definitions (if necessary) or through auxiliary lemmas.",\n    "Using a lemma such as lt_implies_le is acceptable to convert a strict inequality to a non-strict inequality."\n  ],\n  "retry_guidance": "If the negative branch still poses issues, confirm that the explicit lemma or tactic (lt_implies_le) is available and correctly imported. Consider isolating the contradictory proof obligation into a separate lemma and referencing it. Check Lean\'s documentation for managing proof obligations in conditional expressions."\n}\n\nLean error summary:\nIn the negative branch (when ¬(a ≤ b)), the proof does not fully solve the goals. The unsolved goal arises when trying to show that (if a ≤ b then a else b), which reduces to b in this branch, satisfies b ≤ a ∧ b ≤ b. Although the proof correctly derives b < a from ¬(a ≤ b), the subsequent simp tactic does not automatically resolve the goal.\nRetry guidance (MUST FOLLOW):\nRevise the proof by performing explicit splits for the conjunction and disjunction in both branches. In the negative branch, replace the simp tactic with explicit applications of le_of_lt and splitting tactics to handle the individual components of the goal.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef myMin (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b\ndef myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result ≤ a ∧ result ≤ b) ∧\n  (result = a ∨ result = b)\n  -- << SPEC END >>\n\ntheorem myMin_spec_satisfied (a : Int) (b : Int) :\n  myMin_spec a b (myMin a b) := by\n  -- << PROOF START >>\n  unfold myMin myMin_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:58:42,736 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:58:42,737 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:58:42,737 - DEBUG - send_request_headers.complete
2025-06-01 02:58:42,737 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:58:42,759 - DEBUG - send_request_body.complete
2025-06-01 02:58:42,759 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:58:43,026 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sun, 01 Jun 2025 02:58:43 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'374'), (b'Connection', b'keep-alive'), (b'retry-after', b'12'), (b'retry-after-ms', b'11476'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'13674'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'32.65s'), (b'x-request-id', b'req_51a611c2b659168c88acb9787ca50b7b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b73696f0d4278-BOM'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:58:43,026 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 02:58:43,027 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:58:43,027 - DEBUG - receive_response_body.complete
2025-06-01 02:58:43,027 - DEBUG - response_closed.started
2025-06-01 02:58:43,027 - DEBUG - response_closed.complete
2025-06-01 02:58:43,027 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sun, 01 Jun 2025 02:58:43 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '374', 'connection': 'keep-alive', 'retry-after': '12', 'retry-after-ms': '11476', 'vary': 'Origin', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '13674', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '32.65s', 'x-request-id': 'req_51a611c2b659168c88acb9787ca50b7b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b73696f0d4278-BOM', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:58:43,027 - DEBUG - request_id: req_51a611c2b659168c88acb9787ca50b7b
2025-06-01 02:58:43,027 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/openai/_base_client.py", line 1007, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.12/dist-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-06-01 02:58:43,027 - DEBUG - Retrying due to status code 429
2025-06-01 02:58:43,027 - DEBUG - 2 retries left
2025-06-01 02:58:43,028 - INFO - Retrying request to /chat/completions in 11.476000 seconds
2025-06-01 02:58:54,504 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the function implementation to account for the explicit proof obligations in Lean\'s type checking. In the branch where a ≤ b fails, we have b as output, and we must manually show that b satisfies both b ≤ a (by converting b < a to b ≤ a) and b ≤ b (by reflexivity). This plan includes adding an explicit lemma or tactic application to convert the inequality for b ≤ a in the negative branch.",\n  "steps": [\n    "Define the function signature with two integer inputs and one integer output.",\n    "Implement the function using an if/else conditional. In the if branch (a ≤ b), return a. In the else branch (¬(a ≤ b)), return b.",\n    "In the else branch, add an explicit proof step that converts the given b < a (obtained from the negation ¬(a ≤ b)) to b ≤ a. This can be done using an explicit lemma such as \'lt_implies_le\' or a custom lemma.",\n    "Prove that b ≤ b using reflexivity.",\n    "As an alternative strategy, consider using a \'by_cases\' style proof to handle the two cases with explicit justification.",\n    "Test the function with examples to ensure that the function behaves correctly and the proof obligations are fully discharged."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "if/else",\n    "function definition",\n    "integer comparison",\n    "conditional expression"\n  ],\n  "proof_keywords": [\n    "proof by cases",\n    "explicit lemma for inequality",\n    "using lt_implies_le",\n    "reflexivity",\n    "tactic libraries"\n  ],\n  "assumptions": [\n    "Inputs are Lean integers (Int).",\n    "Lean supports proof steps inside function definitions (if necessary) or through auxiliary lemmas.",\n    "Using a lemma such as lt_implies_le is acceptable to convert a strict inequality to a non-strict inequality."\n  ],\n  "retry_guidance": "If the negative branch still poses issues, confirm that the explicit lemma or tactic (lt_implies_le) is available and correctly imported. Consider isolating the contradictory proof obligation into a separate lemma and referencing it. Check Lean\'s documentation for managing proof obligations in conditional expressions."\n}\n\nLean error summary:\nIn the negative branch (when ¬(a ≤ b)), the proof does not fully solve the goals. The unsolved goal arises when trying to show that (if a ≤ b then a else b), which reduces to b in this branch, satisfies b ≤ a ∧ b ≤ b. Although the proof correctly derives b < a from ¬(a ≤ b), the subsequent simp tactic does not automatically resolve the goal.\nRetry guidance (MUST FOLLOW):\nRevise the proof by performing explicit splits for the conjunction and disjunction in both branches. In the negative branch, replace the simp tactic with explicit applications of le_of_lt and splitting tactics to handle the individual components of the goal.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef myMin (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b\ndef myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result ≤ a ∧ result ≤ b) ∧\n  (result = a ∨ result = b)\n  -- << SPEC END >>\n\ntheorem myMin_spec_satisfied (a : Int) (b : Int) :\n  myMin_spec a b (myMin a b) := by\n  -- << PROOF START >>\n  unfold myMin myMin_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:58:54,506 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:58:54,506 - DEBUG - close.started
2025-06-01 02:58:54,506 - DEBUG - close.complete
2025-06-01 02:58:54,506 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:58:54,513 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f93860>
2025-06-01 02:58:54,513 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:58:54,521 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f93da0>
2025-06-01 02:58:54,521 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:58:54,521 - DEBUG - send_request_headers.complete
2025-06-01 02:58:54,521 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:58:54,526 - DEBUG - send_request_body.complete
2025-06-01 02:58:54,526 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:58:57,010 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:58:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2175'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2180'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'161'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'59.677s'), (b'x-request-id', b'req_242cf8f3dceda3aa51d63ac2fe801e13'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b73b2fbd73fe6-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:58:57,011 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:58:57,011 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:58:57,013 - DEBUG - receive_response_body.complete
2025-06-01 02:58:57,013 - DEBUG - response_closed.started
2025-06-01 02:58:57,013 - DEBUG - response_closed.complete
2025-06-01 02:58:57,013 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:58:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2175', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2180', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '161', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '59.677s', 'x-request-id': 'req_242cf8f3dceda3aa51d63ac2fe801e13', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b73b2fbd73fe6-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:58:57,013 - DEBUG - request_id: req_242cf8f3dceda3aa51d63ac2fe801e13
2025-06-01 02:58:57,014 - INFO - Raw solution received: ```json
{
  "code": "if a <= b then a else b",
  "proof": "by_cases h : a <= b\n  case pos =>\n    simp [h]\n  case neg =>\n    simp [h]\n    constructor\n    . apply le_of_lt\n      exact lt_of_not_ge h\n    . refl"
}
```
2025-06-01 02:58:57,014 - INFO - <class 'str'>
2025-06-01 02:58:57,014 - INFO - Generated solution: {'code': 'if a <= b then a else b', 'proof': 'by_cases h : a <= b\n  case pos =>\n    simp [h]\n  case neg =>\n    simp [h]\n    constructor\n    . apply le_of_lt\n      exact lt_of_not_ge h\n    . refl'}
2025-06-01 02:59:02,310 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:30:7: error: unknown tactic
lean_playground/TempTest.lean:27:4: error: tactic 'constructor' failed, no applicable constructor found
a b : ℤ
h : ¬a ≤ b
⊢ b ≤ a
2025-06-01 02:59:02,311 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef myMin (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b\ndef myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result ≤ a ∧ result ≤ b) ∧\n  (result = a ∨ result = b)\n  -- << SPEC END >>\n\ntheorem myMin_spec_satisfied (a : Int) (b : Int) :\n  myMin_spec a b (myMin a b) := by\n  -- << PROOF START >>\n  unfold myMin myMin_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a <= b then a else b\n\nGenerated Proof:\nby_cases h : a <= b\n  case pos =>\n    simp [h]\n  case neg =>\n    simp [h]\n    constructor\n    . apply le_of_lt\n      exact lt_of_not_ge h\n    . refl\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:30:7: error: unknown tactic\nlean_playground/TempTest.lean:27:4: error: tactic 'constructor' failed, no applicable constructor found\na b : ℤ\nh : ¬a ≤ b\n⊢ b ≤ a"}], 'model': 'o3-mini'}}
2025-06-01 02:59:02,311 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:59:02,311 - DEBUG - close.started
2025-06-01 02:59:02,312 - DEBUG - close.complete
2025-06-01 02:59:02,312 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:59:02,318 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737f8f0>
2025-06-01 02:59:02,318 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:59:02,328 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737ede0>
2025-06-01 02:59:02,328 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:59:02,328 - DEBUG - send_request_headers.complete
2025-06-01 02:59:02,328 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:59:02,328 - DEBUG - send_request_body.complete
2025-06-01 02:59:02,328 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:59:15,045 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:59:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'12087'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'12091'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199250'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'225ms'), (b'x-request-id', b'req_4818d5f4d3c422660d30af3227efe1f3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b73e3bd218fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:59:15,046 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:59:15,046 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:59:15,046 - DEBUG - receive_response_body.complete
2025-06-01 02:59:15,046 - DEBUG - response_closed.started
2025-06-01 02:59:15,046 - DEBUG - response_closed.complete
2025-06-01 02:59:15,046 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:59:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '12087', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '12091', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199250', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '225ms', 'x-request-id': 'req_4818d5f4d3c422660d30af3227efe1f3', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b73e3bd218fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:59:15,047 - DEBUG - request_id: req_4818d5f4d3c422660d30af3227efe1f3
2025-06-01 02:59:15,047 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails in the branch when a > b. The tactic 'constructor' does not match the goal's structure (a conjunction of a pair and a disjunction), and Lean reports that no applicable constructor is found. In addition, the inequality b ≤ a is not directly proven; rather, one must derive it from the assumption ¬(a ≤ b), which gives a > b.", 'error_type': 'proof', 'suggested_fix': "Replace the use of 'constructor' with explicit 'split' tactics to break down the conjunction. In the first case (when a ≤ b), prove that a ≤ a (using reflexivity) and a ≤ b (from the hypothesis), and show a = a by left reflexivity. In the second case (when ¬(a ≤ b)), prove that b ≤ b by reflexivity and that b ≤ a by applying 'Int.le_of_lt (Int.lt_of_not_ge h)' (given that ¬(a ≤ b) implies a > b), and finally, choose the right disjunct (b = b). For example:\n\n  theorem myMin_spec_satisfied (a b : Int) :\n    myMin_spec a b (myMin a b) := by\n    unfold myMin myMin_spec\n    by_cases h : a ≤ b\n    case pos {\n      simp [h]\n      split\n      case left {\n        split\n        case left { exact Int.le_refl a }\n        case right { exact h }\n      }\n      case right {\n        left\n        exact rfl\n      }\n    }\n    case neg {\n      simp [h]\n      split\n      case left {\n        split\n        case left { apply Int.le_of_lt; exact Int.lt_of_not_ge h }\n        case right { exact Int.le_refl b }\n      }\n      case right {\n        right\n        exact rfl\n      }\n    }\nThis refines the proof by explicitly splitting the conjunction and handling each component. Adjust the inequality reasoning if needed based on Lean’s library for Int.", 'retry_strategy': "Revise the proof script by replacing 'constructor' with 'split' and inserting explicit proofs for each conjunction and disjunction component. Then, run Lean 4 to validate the corrected proof."}
2025-06-01 02:59:15,048 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.\n\nPrevious plan:\n{\n  "plan_summary": "Revise the function implementation to account for the explicit proof obligations in Lean\'s type checking. In the branch where a ≤ b fails, we have b as output, and we must manually show that b satisfies both b ≤ a (by converting b < a to b ≤ a) and b ≤ b (by reflexivity). This plan includes adding an explicit lemma or tactic application to convert the inequality for b ≤ a in the negative branch.",\n  "steps": [\n    "Define the function signature with two integer inputs and one integer output.",\n    "Implement the function using an if/else conditional. In the if branch (a ≤ b), return a. In the else branch (¬(a ≤ b)), return b.",\n    "In the else branch, add an explicit proof step that converts the given b < a (obtained from the negation ¬(a ≤ b)) to b ≤ a. This can be done using an explicit lemma such as \'lt_implies_le\' or a custom lemma.",\n    "Prove that b ≤ b using reflexivity.",\n    "As an alternative strategy, consider using a \'by_cases\' style proof to handle the two cases with explicit justification.",\n    "Test the function with examples to ensure that the function behaves correctly and the proof obligations are fully discharged."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "if/else",\n    "function definition",\n    "integer comparison",\n    "conditional expression"\n  ],\n  "proof_keywords": [\n    "proof by cases",\n    "explicit lemma for inequality",\n    "using lt_implies_le",\n    "reflexivity",\n    "tactic libraries"\n  ],\n  "assumptions": [\n    "Inputs are Lean integers (Int).",\n    "Lean supports proof steps inside function definitions (if necessary) or through auxiliary lemmas.",\n    "Using a lemma such as lt_implies_le is acceptable to convert a strict inequality to a non-strict inequality."\n  ],\n  "retry_guidance": "If the negative branch still poses issues, confirm that the explicit lemma or tactic (lt_implies_le) is available and correctly imported. Consider isolating the contradictory proof obligation into a separate lemma and referencing it. Check Lean\'s documentation for managing proof obligations in conditional expressions."\n}\n\nLean error summary:\nIn the negative branch (when ¬(a ≤ b)), the proof does not fully solve the goals. The unsolved goal arises when trying to show that (if a ≤ b then a else b), which reduces to b in this branch, satisfies b ≤ a ∧ b ≤ b. Although the proof correctly derives b < a from ¬(a ≤ b), the subsequent simp tactic does not automatically resolve the goal.\nRetry guidance (MUST FOLLOW):\nRevise the proof by performing explicit splits for the conjunction and disjunction in both branches. In the negative branch, replace the simp tactic with explicit applications of le_of_lt and splitting tactics to handle the individual components of the goal.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThe proof fails in the branch when a > b. The tactic \'constructor\' does not match the goal\'s structure (a conjunction of a pair and a disjunction), and Lean reports that no applicable constructor is found. In addition, the inequality b ≤ a is not directly proven; rather, one must derive it from the assumption ¬(a ≤ b), which gives a > b.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 02:59:15,048 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:59:15,048 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:59:15,049 - DEBUG - send_request_headers.complete
2025-06-01 02:59:15,049 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:59:15,049 - DEBUG - send_request_body.complete
2025-06-01 02:59:15,049 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:59:22,590 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:59:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7318'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7321'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'197890'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'632ms'), (b'x-request-id', b'req_34dd39c1c8d497e23a771fa067bf804f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b74333e928fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:59:22,590 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:59:22,590 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:59:22,591 - DEBUG - receive_response_body.complete
2025-06-01 02:59:22,591 - DEBUG - response_closed.started
2025-06-01 02:59:22,591 - DEBUG - response_closed.complete
2025-06-01 02:59:22,591 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:59:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7318', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7321', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '197890', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '632ms', 'x-request-id': 'req_34dd39c1c8d497e23a771fa067bf804f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b74333e928fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:59:22,591 - DEBUG - request_id: req_34dd39c1c8d497e23a771fa067bf804f
2025-06-01 02:59:22,591 - INFO - Attempt 3/3
2025-06-01 02:59:22,591 - INFO - Current plan: {
  "plan_summary": "Revise the approach by explicitly splitting the proof goals in both the if and else branches. In the else branch (when a > b), manually construct the proof obligations by splitting the conjunction into two parts: one to prove b ≤ a (by using a > b and converting it via le_of_lt) and one to prove b ≤ b via reflexivity. In the then branch (a ≤ b), similarly split and show a ≤ a by reflexivity and a ≤ b by the given assumption. This plan explicitly applies splitting tactics to handle the conjunction and avoids reliance on simp or non-applicable constructors.",
  "steps": [
    "Define the function signature taking two integer inputs and returning an integer.",
    "Implement the function with an if/else conditional: if a ≤ b then return a else return b.",
    "For the then branch (a ≤ b):",
    "  - Use an explicit split tactic to break the goal into showing that a ≤ a (reflexivity) and a ≤ b (from the assumption).",
    "For the else branch (¬(a ≤ b), equivalent to a > b):",
    "  - Explicitly split the conjunction into two goals.",
    "  - For the first goal (b ≤ a): derive a > b from the negation of a ≤ b, then apply a lemma (or the tactic le_of_lt) to convert b < a into b ≤ a.",
    "  - For the second goal (b ≤ b): prove it using reflexivity.",
    "Double-check that the explicit splits and applications address the unsolved goals from the previous error.",
    "Test the function to ensure that all proof obligations are completely discharged without relying on simp in the else branch or using an inappropriate constructor."
  ],
  "code_keywords": [
    "Lean 4",
    "if/else",
    "function definition",
    "integer comparison",
    "proof splitting"
  ],
  "proof_keywords": [
    "split conjunction",
    "le_of_lt",
    "reflexivity",
    "by_cases",
    "explicit proof steps"
  ],
  "assumptions": [
    "Integers are defined as Lean's built-in Int type.",
    "The conversion from strict inequality to non-strict inequality can be performed using le_of_lt or a similar lemma.",
    "Explicit splitting of goals is acceptable and necessary to satisfy Lean's proof obligations."
  ],
  "retry_guidance": "If further issues arise, ensure to confirm that the lemma le_of_lt (or an equivalent) is correctly imported and applied. Additionally, verify that the explicit split of the conjunction is done using tactics such as 'split' and 'constructor' only when the goal's structure matches. Each case's proof should independently discharge both parts of the required conjunction."
}
2025-06-01 02:59:22,591 - INFO - Updated plan: {
  "plan_summary": "Revise the approach by explicitly splitting the proof goals in both the if and else branches. In the else branch (when a > b), manually construct the proof obligations by splitting the conjunction into two parts: one to prove b ≤ a (by using a > b and converting it via le_of_lt) and one to prove b ≤ b via reflexivity. In the then branch (a ≤ b), similarly split and show a ≤ a by reflexivity and a ≤ b by the given assumption. This plan explicitly applies splitting tactics to handle the conjunction and avoids reliance on simp or non-applicable constructors.",
  "steps": [
    "Define the function signature taking two integer inputs and returning an integer.",
    "Implement the function with an if/else conditional: if a ≤ b then return a else return b.",
    "For the then branch (a ≤ b):",
    "  - Use an explicit split tactic to break the goal into showing that a ≤ a (reflexivity) and a ≤ b (from the assumption).",
    "For the else branch (¬(a ≤ b), equivalent to a > b):",
    "  - Explicitly split the conjunction into two goals.",
    "  - For the first goal (b ≤ a): derive a > b from the negation of a ≤ b, then apply a lemma (or the tactic le_of_lt) to convert b < a into b ≤ a.",
    "  - For the second goal (b ≤ b): prove it using reflexivity.",
    "Double-check that the explicit splits and applications address the unsolved goals from the previous error.",
    "Test the function to ensure that all proof obligations are completely discharged without relying on simp in the else branch or using an inappropriate constructor."
  ],
  "code_keywords": [
    "Lean 4",
    "if/else",
    "function definition",
    "integer comparison",
    "proof splitting"
  ],
  "proof_keywords": [
    "split conjunction",
    "le_of_lt",
    "reflexivity",
    "by_cases",
    "explicit proof steps"
  ],
  "assumptions": [
    "Integers are defined as Lean's built-in Int type.",
    "The conversion from strict inequality to non-strict inequality can be performed using le_of_lt or a similar lemma.",
    "Explicit splitting of goals is acceptable and necessary to satisfy Lean's proof obligations."
  ],
  "retry_guidance": "If further issues arise, ensure to confirm that the lemma le_of_lt (or an equivalent) is correctly imported and applied. Additionally, verify that the explicit split of the conjunction is done using tactics such as 'split' and 'constructor' only when the goal's structure matches. Each case's proof should independently discharge both parts of the required conjunction."
}

Lean error summary:
The proof fails in the branch when a > b. The tactic 'constructor' does not match the goal's structure (a conjunction of a pair and a disjunction), and Lean reports that no applicable constructor is found. In addition, the inequality b ≤ a is not directly proven; rather, one must derive it from the assumption ¬(a ≤ b), which gives a > b.
Retry guidance (MUST FOLLOW):
Revise the proof script by replacing 'constructor' with 'split' and inserting explicit proofs for each conjunction and disjunction component. Then, run Lean 4 to validate the corrected proof.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 02:59:22,592 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the approach by explicitly splitting the proof goals in both the if and else branches. In the else branch (when a > b), manually construct the proof obligations by splitting the conjunction into two parts: one to prove b ≤ a (by using a > b and converting it via le_of_lt) and one to prove b ≤ b via reflexivity. In the then branch (a ≤ b), similarly split and show a ≤ a by reflexivity and a ≤ b by the given assumption. This plan explicitly applies splitting tactics to handle the conjunction and avoids reliance on simp or non-applicable constructors.",\n  "steps": [\n    "Define the function signature taking two integer inputs and returning an integer.",\n    "Implement the function with an if/else conditional: if a ≤ b then return a else return b.",\n    "For the then branch (a ≤ b):",\n    "  - Use an explicit split tactic to break the goal into showing that a ≤ a (reflexivity) and a ≤ b (from the assumption).",\n    "For the else branch (¬(a ≤ b), equivalent to a > b):",\n    "  - Explicitly split the conjunction into two goals.",\n    "  - For the first goal (b ≤ a): derive a > b from the negation of a ≤ b, then apply a lemma (or the tactic le_of_lt) to convert b < a into b ≤ a.",\n    "  - For the second goal (b ≤ b): prove it using reflexivity.",\n    "Double-check that the explicit splits and applications address the unsolved goals from the previous error.",\n    "Test the function to ensure that all proof obligations are completely discharged without relying on simp in the else branch or using an inappropriate constructor."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "if/else",\n    "function definition",\n    "integer comparison",\n    "proof splitting"\n  ],\n  "proof_keywords": [\n    "split conjunction",\n    "le_of_lt",\n    "reflexivity",\n    "by_cases",\n    "explicit proof steps"\n  ],\n  "assumptions": [\n    "Integers are defined as Lean\'s built-in Int type.",\n    "The conversion from strict inequality to non-strict inequality can be performed using le_of_lt or a similar lemma.",\n    "Explicit splitting of goals is acceptable and necessary to satisfy Lean\'s proof obligations."\n  ],\n  "retry_guidance": "If further issues arise, ensure to confirm that the lemma le_of_lt (or an equivalent) is correctly imported and applied. Additionally, verify that the explicit split of the conjunction is done using tactics such as \'split\' and \'constructor\' only when the goal\'s structure matches. Each case\'s proof should independently discharge both parts of the required conjunction."\n}\n\nLean error summary:\nThe proof fails in the branch when a > b. The tactic \'constructor\' does not match the goal\'s structure (a conjunction of a pair and a disjunction), and Lean reports that no applicable constructor is found. In addition, the inequality b ≤ a is not directly proven; rather, one must derive it from the assumption ¬(a ≤ b), which gives a > b.\nRetry guidance (MUST FOLLOW):\nRevise the proof script by replacing \'constructor\' with \'split\' and inserting explicit proofs for each conjunction and disjunction component. Then, run Lean 4 to validate the corrected proof.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef myMin (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b\ndef myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result ≤ a ∧ result ≤ b) ∧\n  (result = a ∨ result = b)\n  -- << SPEC END >>\n\ntheorem myMin_spec_satisfied (a : Int) (b : Int) :\n  myMin_spec a b (myMin a b) := by\n  -- << PROOF START >>\n  unfold myMin myMin_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:59:22,594 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:59:22,594 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:59:22,594 - DEBUG - send_request_headers.complete
2025-06-01 02:59:22,594 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:59:22,599 - DEBUG - send_request_body.complete
2025-06-01 02:59:22,599 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:59:23,042 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sun, 01 Jun 2025 02:59:23 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'374'), (b'Connection', b'keep-alive'), (b'retry-after', b'12'), (b'retry-after-ms', b'11984'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'13510'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'32.978s'), (b'x-request-id', b'req_344c502a94b60349f861871443fe995f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b74626c548fcd-BOM'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:59:23,043 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 02:59:23,043 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:59:23,043 - DEBUG - receive_response_body.complete
2025-06-01 02:59:23,043 - DEBUG - response_closed.started
2025-06-01 02:59:23,043 - DEBUG - response_closed.complete
2025-06-01 02:59:23,043 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sun, 01 Jun 2025 02:59:23 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '374', 'connection': 'keep-alive', 'retry-after': '12', 'retry-after-ms': '11984', 'vary': 'Origin', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '13510', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '32.978s', 'x-request-id': 'req_344c502a94b60349f861871443fe995f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b74626c548fcd-BOM', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:59:23,043 - DEBUG - request_id: req_344c502a94b60349f861871443fe995f
2025-06-01 02:59:23,043 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/openai/_base_client.py", line 1007, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.12/dist-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-06-01 02:59:23,044 - DEBUG - Retrying due to status code 429
2025-06-01 02:59:23,044 - DEBUG - 2 retries left
2025-06-01 02:59:23,044 - INFO - Retrying request to /chat/completions in 11.984000 seconds
2025-06-01 02:59:35,028 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the approach by explicitly splitting the proof goals in both the if and else branches. In the else branch (when a > b), manually construct the proof obligations by splitting the conjunction into two parts: one to prove b ≤ a (by using a > b and converting it via le_of_lt) and one to prove b ≤ b via reflexivity. In the then branch (a ≤ b), similarly split and show a ≤ a by reflexivity and a ≤ b by the given assumption. This plan explicitly applies splitting tactics to handle the conjunction and avoids reliance on simp or non-applicable constructors.",\n  "steps": [\n    "Define the function signature taking two integer inputs and returning an integer.",\n    "Implement the function with an if/else conditional: if a ≤ b then return a else return b.",\n    "For the then branch (a ≤ b):",\n    "  - Use an explicit split tactic to break the goal into showing that a ≤ a (reflexivity) and a ≤ b (from the assumption).",\n    "For the else branch (¬(a ≤ b), equivalent to a > b):",\n    "  - Explicitly split the conjunction into two goals.",\n    "  - For the first goal (b ≤ a): derive a > b from the negation of a ≤ b, then apply a lemma (or the tactic le_of_lt) to convert b < a into b ≤ a.",\n    "  - For the second goal (b ≤ b): prove it using reflexivity.",\n    "Double-check that the explicit splits and applications address the unsolved goals from the previous error.",\n    "Test the function to ensure that all proof obligations are completely discharged without relying on simp in the else branch or using an inappropriate constructor."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "if/else",\n    "function definition",\n    "integer comparison",\n    "proof splitting"\n  ],\n  "proof_keywords": [\n    "split conjunction",\n    "le_of_lt",\n    "reflexivity",\n    "by_cases",\n    "explicit proof steps"\n  ],\n  "assumptions": [\n    "Integers are defined as Lean\'s built-in Int type.",\n    "The conversion from strict inequality to non-strict inequality can be performed using le_of_lt or a similar lemma.",\n    "Explicit splitting of goals is acceptable and necessary to satisfy Lean\'s proof obligations."\n  ],\n  "retry_guidance": "If further issues arise, ensure to confirm that the lemma le_of_lt (or an equivalent) is correctly imported and applied. Additionally, verify that the explicit split of the conjunction is done using tactics such as \'split\' and \'constructor\' only when the goal\'s structure matches. Each case\'s proof should independently discharge both parts of the required conjunction."\n}\n\nLean error summary:\nThe proof fails in the branch when a > b. The tactic \'constructor\' does not match the goal\'s structure (a conjunction of a pair and a disjunction), and Lean reports that no applicable constructor is found. In addition, the inequality b ≤ a is not directly proven; rather, one must derive it from the assumption ¬(a ≤ b), which gives a > b.\nRetry guidance (MUST FOLLOW):\nRevise the proof script by replacing \'constructor\' with \'split\' and inserting explicit proofs for each conjunction and disjunction component. Then, run Lean 4 to validate the corrected proof.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef myMin (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b\ndef myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result ≤ a ∧ result ≤ b) ∧\n  (result = a ∨ result = b)\n  -- << SPEC END >>\n\ntheorem myMin_spec_satisfied (a : Int) (b : Int) :\n  myMin_spec a b (myMin a b) := by\n  -- << PROOF START >>\n  unfold myMin myMin_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:59:35,030 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:59:35,030 - DEBUG - close.started
2025-06-01 02:59:35,030 - DEBUG - close.complete
2025-06-01 02:59:35,030 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:59:35,057 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fdb9b0>
2025-06-01 02:59:35,057 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:59:35,083 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737c890>
2025-06-01 02:59:35,083 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:59:35,083 - DEBUG - send_request_headers.complete
2025-06-01 02:59:35,083 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:59:35,106 - DEBUG - send_request_body.complete
2025-06-01 02:59:35,106 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:59:39,468 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:59:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'3578'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4081'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'178'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'59.643s'), (b'x-request-id', b'req_64055bed7d8c7665be1c08fd52191ae5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b74b09c804278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:59:39,468 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:59:39,468 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:59:39,472 - DEBUG - receive_response_body.complete
2025-06-01 02:59:39,472 - DEBUG - response_closed.started
2025-06-01 02:59:39,472 - DEBUG - response_closed.complete
2025-06-01 02:59:39,472 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:59:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '3578', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4081', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '178', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '59.643s', 'x-request-id': 'req_64055bed7d8c7665be1c08fd52191ae5', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b74b09c804278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:59:39,473 - DEBUG - request_id: req_64055bed7d8c7665be1c08fd52191ae5
2025-06-01 02:59:39,473 - INFO - Raw solution received: ```json
{
  "code": "if a ≤ b then a else b",
  "proof": "  by_cases h : a ≤ b\n  case pos =>\n    split\n    exact h\n    constructor\n    . exact rfl\n    . exact Or.inl rfl\n  case neg =>\n    split\n    constructor\n    . simp at h\n      apply Int.le_of_lt\n      exact h\n    . exact le_refl b\n    constructor\n    . exact Or.inr rfl"
}
```
2025-06-01 02:59:39,473 - INFO - <class 'str'>
2025-06-01 02:59:39,473 - INFO - Generated solution: {'code': 'if a ≤ b then a else b', 'proof': '  by_cases h : a ≤ b\n  case pos =>\n    split\n    exact h\n    constructor\n    . exact rfl\n    . exact Or.inl rfl\n  case neg =>\n    split\n    constructor\n    . simp at h\n      apply Int.le_of_lt\n      exact h\n    . exact le_refl b\n    constructor\n    . exact Or.inr rfl'}
2025-06-01 02:59:44,589 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:22:4: error: tactic 'unfold' failed to unfold 'by_cases' at
  ((if a ≤ b then a else b) ≤ a ∧ (if a ≤ b then a else b) ≤ b) ∧
    ((if a ≤ b then a else b) = a ∨ (if a ≤ b then a else b) = b)
lean_playground/TempTest.lean:22:15: error: unexpected token ':'; expected command
2025-06-01 02:59:44,590 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef myMin (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b\ndef myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result ≤ a ∧ result ≤ b) ∧\n  (result = a ∨ result = b)\n  -- << SPEC END >>\n\ntheorem myMin_spec_satisfied (a : Int) (b : Int) :\n  myMin_spec a b (myMin a b) := by\n  -- << PROOF START >>\n  unfold myMin myMin_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a ≤ b then a else b\n\nGenerated Proof:\n  by_cases h : a ≤ b\n  case pos =>\n    split\n    exact h\n    constructor\n    . exact rfl\n    . exact Or.inl rfl\n  case neg =>\n    split\n    constructor\n    . simp at h\n      apply Int.le_of_lt\n      exact h\n    . exact le_refl b\n    constructor\n    . exact Or.inr rfl\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:22:4: error: tactic 'unfold' failed to unfold 'by_cases' at\n  ((if a ≤ b then a else b) ≤ a ∧ (if a ≤ b then a else b) ≤ b) ∧\n    ((if a ≤ b then a else b) = a ∨ (if a ≤ b then a else b) = b)\nlean_playground/TempTest.lean:22:15: error: unexpected token ':'; expected command"}], 'model': 'o3-mini'}}
2025-06-01 02:59:44,591 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:59:44,591 - DEBUG - close.started
2025-06-01 02:59:44,591 - DEBUG - close.complete
2025-06-01 02:59:44,591 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:59:44,598 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fe4ef0>
2025-06-01 02:59:44,598 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:59:44,605 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fe4e00>
2025-06-01 02:59:44,605 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:59:44,606 - DEBUG - send_request_headers.complete
2025-06-01 02:59:44,606 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:59:44,606 - DEBUG - send_request_body.complete
2025-06-01 02:59:44,606 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:59:56,102 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:59:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'11170'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'11175'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199187'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'243ms'), (b'x-request-id', b'req_42773363d696cd9633da51b49473aa08'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b74ebff2d3fe6-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:59:56,102 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:59:56,102 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:59:56,103 - DEBUG - receive_response_body.complete
2025-06-01 02:59:56,103 - DEBUG - response_closed.started
2025-06-01 02:59:56,103 - DEBUG - response_closed.complete
2025-06-01 02:59:56,103 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:59:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '11170', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '11175', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199187', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '243ms', 'x-request-id': 'req_42773363d696cd9633da51b49473aa08', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b74ebff2d3fe6-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:59:56,103 - DEBUG - request_id: req_42773363d696cd9633da51b49473aa08
2025-06-01 02:59:56,103 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails due to two issues. First, the 'unfold myMin myMin_spec' tactic does not properly simplify the if-then-else expression (the 'by_cases' is not unfolded), causing an error when it encounters its structure. Second, the syntax 'by_cases h : a ≤ b' produces an 'unexpected token' error. In Lean 4 the by_cases tactic is used with a slightly different syntax.", 'error_type': 'syntax', 'suggested_fix': "Replace the 'unfold' tactic with 'dsimp' or 'simp' to simplify the definitions and the if-then-else. Also, change the by_cases syntax to the Lean 4 style. For example, you can write the proof as:\n\n  theorem myMin_spec_satisfied (a : Int) (b : Int) : myMin_spec a b (myMin a b) := by\n    dsimp [myMin, myMin_spec]\n    by_cases h : a ≤ b\n    · split\n      · exact h\n      · right; rfl\n    · have h' : b < a := not_le.mp h\n      split\n      · apply Int.le_of_lt; exact h'\n      · left; rfl\n\nThis version uses dsimp to simplify the definitions and writes the by_cases cases using the modern Lean 4 block keywords (·) to delineate the cases.", 'retry_strategy': 'Revise the proof by replacing the unfolding tactic with dsimp/simp and updating the by_cases syntax as shown above. Then re-run the code to check if the errors are resolved.'}
2025-06-01 02:59:56,104 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.\n\nPrevious plan:\n{\n  "plan_summary": "Revise the approach by explicitly splitting the proof goals in both the if and else branches. In the else branch (when a > b), manually construct the proof obligations by splitting the conjunction into two parts: one to prove b ≤ a (by using a > b and converting it via le_of_lt) and one to prove b ≤ b via reflexivity. In the then branch (a ≤ b), similarly split and show a ≤ a by reflexivity and a ≤ b by the given assumption. This plan explicitly applies splitting tactics to handle the conjunction and avoids reliance on simp or non-applicable constructors.",\n  "steps": [\n    "Define the function signature taking two integer inputs and returning an integer.",\n    "Implement the function with an if/else conditional: if a ≤ b then return a else return b.",\n    "For the then branch (a ≤ b):",\n    "  - Use an explicit split tactic to break the goal into showing that a ≤ a (reflexivity) and a ≤ b (from the assumption).",\n    "For the else branch (¬(a ≤ b), equivalent to a > b):",\n    "  - Explicitly split the conjunction into two goals.",\n    "  - For the first goal (b ≤ a): derive a > b from the negation of a ≤ b, then apply a lemma (or the tactic le_of_lt) to convert b < a into b ≤ a.",\n    "  - For the second goal (b ≤ b): prove it using reflexivity.",\n    "Double-check that the explicit splits and applications address the unsolved goals from the previous error.",\n    "Test the function to ensure that all proof obligations are completely discharged without relying on simp in the else branch or using an inappropriate constructor."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "if/else",\n    "function definition",\n    "integer comparison",\n    "proof splitting"\n  ],\n  "proof_keywords": [\n    "split conjunction",\n    "le_of_lt",\n    "reflexivity",\n    "by_cases",\n    "explicit proof steps"\n  ],\n  "assumptions": [\n    "Integers are defined as Lean\'s built-in Int type.",\n    "The conversion from strict inequality to non-strict inequality can be performed using le_of_lt or a similar lemma.",\n    "Explicit splitting of goals is acceptable and necessary to satisfy Lean\'s proof obligations."\n  ],\n  "retry_guidance": "If further issues arise, ensure to confirm that the lemma le_of_lt (or an equivalent) is correctly imported and applied. Additionally, verify that the explicit split of the conjunction is done using tactics such as \'split\' and \'constructor\' only when the goal\'s structure matches. Each case\'s proof should independently discharge both parts of the required conjunction."\n}\n\nLean error summary:\nThe proof fails in the branch when a > b. The tactic \'constructor\' does not match the goal\'s structure (a conjunction of a pair and a disjunction), and Lean reports that no applicable constructor is found. In addition, the inequality b ≤ a is not directly proven; rather, one must derive it from the assumption ¬(a ≤ b), which gives a > b.\nRetry guidance (MUST FOLLOW):\nRevise the proof script by replacing \'constructor\' with \'split\' and inserting explicit proofs for each conjunction and disjunction component. Then, run Lean 4 to validate the corrected proof.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThe proof fails due to two issues. First, the \'unfold myMin myMin_spec\' tactic does not properly simplify the if-then-else expression (the \'by_cases\' is not unfolded), causing an error when it encounters its structure. Second, the syntax \'by_cases h : a ≤ b\' produces an \'unexpected token\' error. In Lean 4 the by_cases tactic is used with a slightly different syntax.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 02:59:56,105 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:59:56,105 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:59:56,105 - DEBUG - send_request_headers.complete
2025-06-01 02:59:56,105 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:59:56,105 - DEBUG - send_request_body.complete
2025-06-01 02:59:56,105 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:00:06,017 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:00:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'9691'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'9695'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'197972'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'608ms'), (b'x-request-id', b'req_b023f62d0113a50db619b30c58e0f790'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7533dc843fe6-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:00:06,017 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:00:06,017 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:00:06,018 - DEBUG - receive_response_body.complete
2025-06-01 03:00:06,018 - DEBUG - response_closed.started
2025-06-01 03:00:06,018 - DEBUG - response_closed.complete
2025-06-01 03:00:06,018 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:00:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '9691', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '9695', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '197972', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '608ms', 'x-request-id': 'req_b023f62d0113a50db619b30c58e0f790', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7533dc843fe6-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:00:06,018 - DEBUG - request_id: req_b023f62d0113a50db619b30c58e0f790
2025-06-01 03:00:06,018 - INFO - Solution generated in 112.11 seconds
2025-06-01 03:00:06,019 - INFO - Generated code length: 22 characters
2025-06-01 03:00:06,019 - INFO - Generated proof length: 267 characters
2025-06-01 03:00:06,019 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 03:00:06,019 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 03:00:11,289 - INFO - Implementation test result: PASS
2025-06-01 03:00:11,289 - INFO - Executing Lean code with implementation and proof...
2025-06-01 03:00:16,578 - INFO - Full solution test result: FAIL
2025-06-01 03:00:16,578 - ERROR - Proof error: lean_playground/TempTest.lean:22:4: error: tactic 'unfold' failed to unfold 'by_cases' at
  ((if a ≤ b then a else b) ≤ a ∧ (if a ≤ b then a else b) ≤...
2025-06-01 03:00:16,578 - INFO - ✅ Implementation passes unit tests
2025-06-01 03:00:16,578 - ERROR - ❌ Proof has errors
2025-06-01 03:00:16,579 - INFO - 
==================================================
2025-06-01 03:00:16,579 - INFO - Processing task task_id_431...
2025-06-01 03:00:16,579 - INFO - Reading problem description and code template from tasks/task_id_431...
2025-06-01 03:00:16,579 - INFO - Problem description length: 597 characters
2025-06-01 03:00:16,579 - INFO - Reading unit tests from tasks/task_id_431...
2025-06-01 03:00:16,579 - INFO - Unit tests length: 465 characters
2025-06-01 03:00:16,579 - INFO - Running main workflow to generate solution...
2025-06-01 03:00:16,579 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.

-----Input-----
The input consists of:
a: An array of integers.
b: An array of integers.

-----Output-----
The output is a Boolean value:
Returns true if there is at least one common element between the two arrays.
Returns false if there are no common elements shared by the arrays or at least one array is empty.
2025-06-01 03:00:16,579 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def hasCommonElement (a : Array Int) (b : Array Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: If the method returns true, there exists at least one common element between the two arrays; If the method returns false, there are no common elements between the two arrays
def hasCommonElement_spec (a : Array Int) (b : Array Int) (result : Bool) : Prop :=
  -- << SPEC START >>
  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ result
  -- << SPEC END >>

theorem hasCommonElement_spec_satisfied (a : Array Int) (b : Array Int) :
  hasCommonElement_spec a b (hasCommonElement a b) := by
  -- << PROOF START >>
  unfold hasCommonElement hasCommonElement_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 03:00:16,608 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7f4e66fe27a0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 03:00:16,609 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 03:00:16,609 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:00:16,634 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fda8d0>
2025-06-01 03:00:16,634 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4e67398050> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:00:16,660 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fd84a0>
2025-06-01 03:00:16,661 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:00:16,661 - DEBUG - send_request_headers.complete
2025-06-01 03:00:16,661 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:00:16,661 - DEBUG - send_request_body.complete
2025-06-01 03:00:16,661 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:00:16,977 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:00:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'64'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-678485f6b9-q9brq'), (b'x-envoy-upstream-service-time', b'68'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999851'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_e094045a8acc1830b29a8ce91a29dd9e'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.avSO.ibAuYKvYQzXsI6aESdrLKXW4UEC0llMuGNzTI-1748746816-1.0.1.1-kt_Xnelbr9bddUxsPm0bD_Z29PMSgc_cRWc_zwkITE3JH8gb3m21iucpJ8BsgwPz7ZDu824WHBRm4dTNhwQU9LapoV.xvTkXXOAWX1T8Qg4; path=/; expires=Sun, 01-Jun-25 03:30:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=jGNOAQjCGFpKmStH63fBBZ6cfw7.41BhYlM1bbzhEqo-1748746816999-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b75b46f034278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:00:16,978 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 03:00:16,978 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:00:16,978 - DEBUG - receive_response_body.complete
2025-06-01 03:00:16,978 - DEBUG - response_closed.started
2025-06-01 03:00:16,978 - DEBUG - response_closed.complete
2025-06-01 03:00:16,978 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 03:00:17 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '64'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-678485f6b9-q9brq'), ('x-envoy-upstream-service-time', '68'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999851'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_e094045a8acc1830b29a8ce91a29dd9e'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=.avSO.ibAuYKvYQzXsI6aESdrLKXW4UEC0llMuGNzTI-1748746816-1.0.1.1-kt_Xnelbr9bddUxsPm0bD_Z29PMSgc_cRWc_zwkITE3JH8gb3m21iucpJ8BsgwPz7ZDu824WHBRm4dTNhwQU9LapoV.xvTkXXOAWX1T8Qg4; path=/; expires=Sun, 01-Jun-25 03:30:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=jGNOAQjCGFpKmStH63fBBZ6cfw7.41BhYlM1bbzhEqo-1748746816999-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b75b46f034278-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 03:00:16,978 - DEBUG - request_id: req_e094045a8acc1830b29a8ce91a29dd9e
2025-06-01 03:00:16,983 - INFO - Retrieved context:  the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Propositions and Proofs

By now, you have seen some ways of defining objects and functions in Lean. In
this chapter, we will begin to explain how to write mathematical assertions
and proofs in the language of dependent type theory as well.

## Propositions as Types

One strategy for proving assertions about objects defined in the language of
dependent type theory is to layer an assertion language and a proof language
on top of the definition language. But there is no reason to multiply
languages in this way: dependent type theory is flexible and expressive, and
there is no reason we cannot represent assertions and proofs in the same
general framework.

For example, we could introduce a new type, `Prop`, to represent propositions,
and introduce constructors to build new propositions from others.

    
    
    def Implies (p q : Prop) : Prop := p → q
    #check And     -- Prop → Prop → Prop
    #check Or      -- Prop → Prop → Prop
    #check Not     -- Prop → Prop
    #check Implies -- Prop → Prop → Prop
    
    variable (p q r : Prop)
    #check And p q                      -- Prop
    #check Or (And p q) r               -- Prop
    #check Implies (And p q) (And q p)  -- Prop
    

We could then introduce, for each element `p : Prop`, another type `Proof p`,
for the type of proofs of `p`. An "axiom" would be a constant of such a type.

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    #check Proof   -- Proof : Prop → Type
    
    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))
    
    variable (p q : Prop)
    #check and_comm p q     -- Proof (Implies (And p q) (And q p))
    

In addition to axioms, however, we would also need rules to build new proofs
from old ones. For example, in many proof systems for propositional logic, we
have the rule of _modus ponens_ :

> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.

We could represent this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q
    

Systems of natural deduction for propositional logic also typically rely on
the following rule:

> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we
> can "cancel" the hypothesis and obtain a proof of `Implies p q`.

We could render this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)
    

This approach would provide us with a reasonable way of building assertions
and proofs. Determining that an expression `t` is a correct proof of assertion
`p` would then simply be a matter of checking that `t` has type `Proof p`.

Some simplifications are possible, however. To start with, we can avoid
writing the term `Proof` repeatedly by conflating `Proof p` with `p` itself.
In other words, whenever we have `p : Prop`, we can interpret `p` as a type,
namely, the type of its proofs. We can then read `t : p` as the assertion that
`t` is a proof of `p`.

Moreover, once we make this identification, the rules for implication show
that we can pass back and forth between `Implies p q` and `p → q`. In other
words, implication between propositions `p` and `q` corresponds to having a
function that takes any element of `p` to an element of `q`. As a result, the
introduction of the connective `Implies` is entirely redundant: we can use the
usual function space constructor `p → q` from dependent type theory as our
notion of implication.

This is the approach followed in the Calculus of Constructions, and hence in
Lean as well. The fact that the rules for implication in a proof system for
natural deduction correspond exactly to the rules governing abstraction and
application for functions is an instance of the _Curry-Howard isomorphism_ ,
sometimes known as the _propositions-as-types_ paradigm. In fact, the type
`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy
described in the last chapter. Moreover, `Type u` is also just syntactic sugar
for `Sort (u+1)`. `Prop` has some special features, but like the other type
universes, it is closed under the arrow constructor: if we have `p q : Prop`,
then `p → q : Prop`.

There are at least two ways of thinking about propositions as types. To some
who take a constructive view of logic and mathematics, this is a faithful
rendering of what it means to be a proposition: a proposition `p` represents a
sort of data type, namely, a specification of the type of data that
constitutes a proof. A proof of `p` is then simply an object `t : p` of the
right type.

Those not inclined to this ideology can view it, rather, as a simple coding
trick. To each proposition `p` we associate a type that is empty if `p` is
false and has a single element, say `*`, if `p` is true. In the latter case,
let us say that (the type associated with) `p` is _inhabited_. It just so
happens that the rules for function application and abstraction can
conveniently help us keep track of which elements of `Prop` are inhabited. So
constructing an element `t : p` tells us that `p` is indeed true. You can
think of the inhabitant of `p` as being the "fact that `p` is true." A proof
of `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is
true."

Indeed, if `p : Prop` is any proposition, Lean's kernel treats any two
elements `t1 t2 : p` as being definitionally equal, much the same way as it
treats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as
_proof irrelevance,_ and is consistent with the interpretation in the last
paragraph. It means that even though we can treat proofs `t : p` as ordinary
objects in the language of dependent type theory, they carry no information
beyond the fact that `p` is true.

The two ways we have suggested thinking about the propositions-as-types
paradigm differ in a fundamental way. From the constructive point of view,
proofs are abstract mathematical objects that are _denoted_ by suitable
expressions in dependent type theory. In contrast, if we think in terms of the
coding trick described above, then the expressions themselves do not denote
anything interesting. Rather, it is the fact that we can write them down and
check that they are well-typed that ensures that the proposition in question
is true. In other words, the expressions _themselves_ are the proofs.

In the exposition below, we will slip back and forth between these two ways of
talking, at times saying that an expression "constructs" or "produces" or
"returns" a proof of a proposition, and at other times simply saying that it
"is" such a proof. This is similar to the way that computer scientists
occasionally blur the distinction between syntax and semantics by saying, at
times, that a program "computes" a certain function, and at other times
speaking as though the program "is" the function in question.

In any case, all that really matters is the bottom line. To formally express a
mathematical assertion in the language of dependent type theory, we need to
exhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a
term `t : p`. Lean's task, as a proof assistant, is to help us to construct
such a term, `t`, and to verify that it is well-formed and has the correct
type.

## Working with Propositions as Types

In the propositions-as-types paradigm, theorems involving only `→` can be
proved using lambda abstraction and application. In Lean, the `theorem`
command introduces a new theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    

Compare this proof to the expression `fun x : α => fun y : β => x` of type `α
→ β → α`, where `α` and `β` are data types. This describes the function that
takes arguments `x` and `y` of type `α` and `β`, respectively, and returns
`x`. The proof of `t1` has the same form, the only difference being that `p`
and `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of
`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis
(trivially) to establish that the conclusion, `p`, is true.

Note that the `theorem` command is really a version of the `def` command:
under the propositions and types correspondence, proving the theorem `p → q →
p` is really the same as defining an element of the associated type. To the
kernel type checker, there is no difference between the two.

There are a few pragmatic differences between definitions and theorems,
however. In normal circumstances, it is never necessary to unfold the
"definition" of a theorem; by proof irrelevance, any two proofs of that
theorem are definitionally equal. Once the proof of a theorem is complete,
typically we only need to know that the proof exists; it doesn't matter what
the proof is. In light of that fact, Lean tags proofs as _irreducible_ , which
serves as a hint to the parser (more precisely, the _elaborator_) that there
is generally no need to unfold them when processing a file. In fact, Lean is
generally able to process and check proofs in parallel, since assessing the
correctness of one proof does not require knowing the details of another.

As with definitions, the `#print` command will show you the proof of a
theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    
    #print t1
    

Notice that the lambda abstractions `hp : p` and `hq : q` can be viewed as
temporary assumptions in the proof of `t1`. Lean also allows us to specify the
type of the final term `hp`, explicitly, with a `show` statement:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p :=
      fun hp : p =>
      fun hq : q =>
      show p from hp
    

Adding such extra information can improve the clarity of a proof and help
detect errors when writing a proof. The `show` command does nothing more than
annotate the type, and, internally, all the presentations of `t1` that we have
seen produce the same term.

As with ordinary definitions, we can move the lambda-abstracted variables to
the left of the colon:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    #print t1    -- p → q → p
    

We can use the theorem `t1` just as a function application:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    axiom hp : p
    
    theorem t2 : q → p := t1 hp
    

The `axiom` declaration postulates the existence of an element of the given
type and may compromise logical consistency. For example, we can use it to
postulate that the empty type `False` has an element:

    
    
    axiom unsound : False
    -- Everything follows from false
    theorem ex : 1 = 0 :=
      False.elim unsound
    

Declaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as
witnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`
that `p` is true yields the theorem `t1 hp : q → p`.

Recall that we can also write theorem `t1` as follows:

    
    
    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp
    
    #print t1
    

The type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the
assertion "for every pair of propositions `p q`, we have `p → q → p`." For
example, we can move all parameters to the right of the colon:

    
    
    theorem t1 : ∀ {p q : Prop}, p → q → p :=
      fun {p q : Prop} (hp : p) (hq : q) => hp
    

If `p` and `q` have been declared as variables, Lean will generalize them for
us automatically:

    
    
    variable {p q : Prop}
    
    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp
    

In fact, by the propositions-as-types correspondence, we can declare the
assumption `hp` that `p` holds, as another variable:

    
    
    variable {p q : Prop}
    variable (hp : p)
    
    theorem t1 : q → p := fun (hq : q) => hp
    

Lean detects that the proof uses `hp` and automatically adds `hp : p` as a
premise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →
q → p`. Remember that this type can just as well be written `∀ (p q : Prop)
(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type
in which the target does not depend on the bound variable.

When we generalize `t1` in such a way, we can then apply it to different pairs
of propositions, to obtain different instances of the general theorem.

    
    
    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp
    
    variable (p q r s : Prop)
    
    #check t1 p q                -- p → q → p
    #check t1 r s                -- r → s → r
    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s
    
    variable (h : r → s)
    #check t1 (r → s) (s → r) h  -- (s → r) → r → s
    

Once again, using the propositions-as-types correspondence, the variable `h`
of type `r → s` can be viewed as the hypothesis, or premise, that `r → s`
holds.

As another example, let us consider the composition function discussed in the
last chapter, now with propositions instead of types.

    
    
    variable (p q r s : Prop)
    
    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=
      fun h₃ : p =>
      show r from h₁ (h₂ h₃)
    

As a theorem of propositional logic, what does `t2` say?

Note that it is often useful to use numeric unicode subscripts, entered as
`\0`, `\1`, `\2`, ..., for hypotheses, as we did in this example.

## Propositional Logic

Lean defines all the standard logical connectives and notation. The
propositional connectives come with the following notation:

Ascii| Unicode| Editor shortcut| Definition  
---|---|---|---  
True| | | True  
False| | | False  
Not| ¬| `\not`, `\neg`| Not  
/\| ∧| `\and`| And  
\/| ∨| `\or`| Or  
->| →| `\to`, `\r`, `\imp`|   
<->| ↔| `\iff`, `\lr`| Iff  
  
They all take values in `Prop`.

    
    
    variable (p q : Prop)
    
    #check p → q → p ∧ q
    #check ¬p → p ↔ False
    #check p ∨ q → q ∨ p
    

The order of operations is as follows: unary negation `¬` binds most strongly,
then `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧
e` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right
(nothing changes now that the arguments are elements of `Prop`, instead of
some other `Type`), as do the other binary connectives. So if we have `p q r :
Prop`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This
is just the "curried" form of `p ∧ q → r`.

In the last chapter we observed that lambda abstraction can be viewed as an
"introduction rule" for `→`. In the current setting, it shows how to
"introduce" or establish an implication. Application can be viewed as an
"elimination rule," showing how to "eliminate" or use an implication in a
proof. The other propositional connectives are defined in Lean's library in
the file `Prelude.core` (see [importing
files](./interacting_with_lean.html#importing-files) for more information on
the library hierarchy), and each connective comes with its canonical
introduction and elimination rules.

### Conjunction

The expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :
p` and `h2 : q`. It is common to describe `And.intro` as the _and-
introduction_ rule. In the next example we use `And.intro` to create a proof
of `p → q → p ∧ q`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq
    
    #check fun (hp : p) (hq : q) => And.intro hp hq
    

The `example` command states a theorem without naming it or storing it in the
permanent context. Essentially, it just checks that the given term has the
indicated type. It is convenient for illustration, and we will use it often.

The expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.
Similarly, `And.right h` is a proof of `q`. They are commonly known as the
left and right _and-elimination_ rules.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : p := And.left h
    example (h : p ∧ q) : q := And.right h
    

We can now prove `p ∧ q → q ∧ p` with the following proof term.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      And.intro (And.right h) (And.left h)
    

Notice that and-introduction and and-elimination are similar to the pairing
and projection operations for the Cartesian product. The difference is that
given `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while
`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is
another instance of the Curry-Howard isomorphism, but in contrast to
implication and the function space constructor, `∧` and `×` are treated
separately in Lean. With the analogy, however, the proof we have just
constructed is similar to a function that swaps the elements of a pair.

We will see in [Chapter Structures and Records](./structures_and_records.html)
that certain types in Lean are _structures_ , which is to say, the type is
defined with a single canonical _constructor_ which builds an element of the
type from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is
an example: the canonical way to construct an element is to apply `And.intro`
to suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous
constructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the
relevant type is an inductive type and can be inferred from the context. In
particular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:

    
    
    variable (p q : Prop)
    variable (hp : p) (hq : q)
    
    #check (⟨hp, hq⟩ : p ∧ q)
    

These angle brackets are obtained by typing `\<` and `\>`, respectively.

Lean provides another useful syntactic gadget. Given an expression `e` of an
inductive type `Foo` (possibly applied to some arguments), the notation
`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of
accessing functions without opening a namespace. For example, the following
two expressions mean the same thing:

    
    
    variable (xs : List Nat)
    
    #check List.length xs
    #check xs.length
    

As a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and
`h.right` for `And.right h`. We can therefore rewrite the sample proof above
conveniently as follows:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      ⟨h.right, h.left⟩
    

There is a fine line between brevity and obfuscation, and omitting information
in this way can sometimes make a proof harder to read. But for straightforward
constructions like the one above, when the type of `h` and the goal of the
construction are salient, the notation is clean and effective.

It is common to iterate constructions like "And." Lean also allows you to
flatten nested constructors that associate to the right, so that these two
proofs are equivalent:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, ⟨h.left, h.right⟩⟩
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, h.left, h.right⟩
    

This is often useful as well.

### Disjunction

The expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof
`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a
proof `hq : q`. These are the left and right _or-introduction_ rules.

    
    
    variable (p q : Prop)
    example (hp : p) : p ∨ q := Or.intro_left q hp
    example (hq : q) : p ∨ q := Or.intro_right p hq
    

The _or-elimination_ rule is slightly more complicated. The idea is that we
can prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`
follows from `q`. In other words, it is a proof by cases. In the expression
`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :
p → r` and `hqr : q → r`, and produces a proof of `r`. In the following
example, we use `Or.elim` to prove `p ∨ q → q ∨ p`.

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h
        (fun hp : p =>
          show q ∨ p from Or.intro_right q hp)
        (fun hq : q =>
          show q ∨ p from Or.intro_left p hq)
    

In most cases, the first argument of `Or.intro_right` and `Or.intro_left` can
be inferred automatically by Lean. Lean therefore provides `Or.inr` and
`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and
`Or.intro_left _`. Thus the proof term above could be written more concisely:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Notice that there is enough information in the full expression for Lean to
infer the types of `hp` and `hq` as well. But using the type annotations in
the longer version makes the proof more readable, and can help catch and debug
errors.

Because `Or` has two constructors, we cannot use anonymous constructor
notation. But we can still write `h.elim` instead of `Or.elim h`:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Once again, you should exercise judgment as to whether such abbreviations
enhance or diminish readability.

### Negation and Falsity

Negation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by
deriving a contradiction from `p`. Similarly, the expression `hnp hp` produces
a proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both
these rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is
produced by typing `\not` or `\neg`.)

    
    
    variable (p q : Prop)
    
    example (hpq : p → q) (hnq : ¬q) : ¬p :=
      fun hp : p =>
      show False from hnq (hpq hp)
    

The connective `False` has a single elimination rule, `False.elim`, which
expresses the fact that anything follows from a contradiction. This rule is
sometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the
_principle of explosion_.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)
    

The arbitrary fact, `q`, that follows from falsity is an implicit argument in
`False.elim` and is inferred automatically. This pattern, deriving an
arbitrary fact from contradictory hypotheses, is quite common, and is
represented by `absurd`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := absurd hp hnp
    

Here, for example, is a proof of `¬p → q → (q → p) → r`:

    
    
    variable (p q r : Prop)
    
    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=
      absurd (hqp hq) hnp
    

Incidentally, just as `False` has only an elimination rule, `True` has only an
introduction rule, `True.intro : true`. In other words, `True` is simply true,
and has a canonical proof, `True.intro`.

### Logical Equivalence

The expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`
and `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from
`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔
q`. Here is a proof of `p ∧ q ↔ q ∧ p`:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      Iff.intro
        (fun h : p ∧ q =>
         show q ∧ p from And.intro (And.right h) (And.left h))
        (fun h : q ∧ p =>
         show p ∧ q from And.intro (And.right h) (And.left h))
    
    #check and_swap p q    -- p ∧ q ↔ q ∧ p
    
    variable (h : p ∧ q)
    example : q ∧ p := Iff.mp (and_swap p q) h
    

We can use the anonymous constructor notation to construct a proof of `p ↔ q`
from proofs of the forward and backward directions, and we can also use `.`
notation with `mp` and `mpr`. The previous examples can therefore be written
concisely as follows:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩
    
    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h
    

## Introducing Auxiliary Subgoals

This is a good place to introduce another device Lean offers to help structure
long proofs, namely, the `have` construct, which introduces an auxiliary
subgoal in a proof. Here is a small example, adapted from the last section:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      have hq : q := h.right
      show q ∧ p from And.intro hq hp
    

Internally, the expression `have h : p := s; t` produces the term `(fun (h :
p) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the
desired conclusion assuming `h : p`, and the two are combined by a lambda
abstraction and application. This simple device is extremely useful when it
comes to structuring long proofs, since we can use intermediate `have`'s as
stepping stones leading to the final goal.

Lean also supports a structured way of reasoning backwards from a goal, which
models the "suffices to show" construction in ordinary mathematics. The next
example simply permutes the last two lines in the previous proof.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      suffices hq : q from And.intro hq hp
      show q from And.right h
    

Writing `suffices hq : q` leaves us with two goals. First, we have to show
that it indeed suffices to show `q`, by proving the original goal of `q ∧ p`
with the additional hypothesis `hq : q`. Finally, we have to show `q`.

## Classical Logic

The introduction and elimination rules we have seen so far are all
constructive, which is to say, they reflect a computational understanding of
the logical connectives based on the propositions-as-types correspondence.
Ordinary classical logic adds to this the law of the excluded middle, `p ∨
¬p`. To use this principle, you have to open the classical namespace.

    
    
    open Classical
    
    variable (p : Prop)
    #check em p
    

Intuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts
to knowing which is the case. If `RH` represents the Riemann hypothesis, a
classical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot
yet assert either disjunct.

One consequence of the law of the excluded middle is the principle of double-
negation elimination:

    
    
    open Classical
    
    theorem dne {p : Prop} (h : ¬¬p) : p :=
      Or.elim (em p)
        (fun hp : p => hp)
        (fun hnp : ¬p => absurd hnp h)
    

Double-negation elimination allows one to prove any proposition, `p`, by
assuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In
other words, double-negation elimination allows one to carry out a proof by
contradiction, something which is not generally possible in constructive
logic. As an exercise, you might try proving the converse, that is, showing
that `em` can be proved from `dne`.

The classical axioms also give you access to additional patterns of proof that
can be justified by appeal to `em`. For example, one can carry out a proof by
cases:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byCases
        (fun h1 : p => h1)
        (fun h1 : ¬p => absurd h1 h)
    

Or you can carry out a proof by contradiction:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byContradiction
        (fun h1 : ¬p =>
         show False from h h1)
    

If you are not used to thinking constructively, it may take some time for you
to get a sense of where classical reasoning is used. It is needed in the
following example because, from a constructive standpoint, knowing that `p`
and `q` are not both true does not necessarily tell you which one is false:

    
    
    open Classical
    variable (p q : Prop)
    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=
      Or.elim (em p)
        (fun hp : p =>
          Or.inr
            (show ¬q from
              fun hq : q =>
              h ⟨hp, hq⟩))
        (fun hp : ¬p =>
          Or.inl hp)
    

We will see later that there _are_ situations in constructive logic where
principles like excluded middle and double-negation elimination are
permissible, and Lean supports the use of classical reasoning in such contexts
without relying on excluded middle.

The full list of axioms that are used in Lean to support classical reasoning
are discussed in [Axioms and Computation](./axioms_and_computation.html).

## Examples of Propositional Validities

Lean's standard library contains proofs of many valid statements of
propositional logic, all of which you are free to use in proofs of your own.
The following list includes a number of common identities.

Commutativity:

  1. `p ∧ q ↔ q ∧ p`
  2. `p ∨ q ↔ q ∨ p`

Associativity:

  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`
  4. `(p ∨ q) ∨ r ↔ p ∨ (q �
2025-06-01 03:00:16,987 - DEBUG - close.started
2025-06-01 03:00:16,987 - DEBUG - close.complete
2025-06-01 03:00:16,999 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.'}], 'model': 'o3-mini'}}
2025-06-01 03:00:16,999 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:00:16,999 - DEBUG - close.started
2025-06-01 03:00:17,000 - DEBUG - close.complete
2025-06-01 03:00:17,000 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:00:17,006 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737f890>
2025-06-01 03:00:17,006 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:00:17,014 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737d760>
2025-06-01 03:00:17,014 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:00:17,014 - DEBUG - send_request_headers.complete
2025-06-01 03:00:17,014 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:00:17,014 - DEBUG - send_request_body.complete
2025-06-01 03:00:17,014 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:00:24,256 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:00:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7018'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7021'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199550'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'135ms'), (b'x-request-id', b'req_fb22acdfd06f86d57dbf11b284a5413b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b75b6884cff9b-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:00:24,256 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:00:24,256 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:00:24,256 - DEBUG - receive_response_body.complete
2025-06-01 03:00:24,256 - DEBUG - response_closed.started
2025-06-01 03:00:24,257 - DEBUG - response_closed.complete
2025-06-01 03:00:24,257 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:00:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7018', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7021', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199550', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '135ms', 'x-request-id': 'req_fb22acdfd06f86d57dbf11b284a5413b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b75b6884cff9b-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:00:24,257 - DEBUG - request_id: req_fb22acdfd06f86d57dbf11b284a5413b
2025-06-01 03:00:24,257 - INFO - Attempt 1/3
2025-06-01 03:00:24,257 - INFO - Current plan: {
  "plan_summary": "The plan is to implement a Lean 4 function that checks if two arrays of integers share any common element. The function will first check for the edge-case where one or both arrays are empty and return false immediately. If both arrays have elements, the strategy is to iterate over the first array and use a membership test to check if any element exists in the second array. If such an element is found, the function returns true; if not, it returns false.",
  "steps": [
    "Check if either of the arrays is empty. If so, return false.",
    "Iterate over each element of the first array.",
    "For each element, check membership in the second array using an appropriate Lean 4 membership function or predicate.",
    "If any common element is found, return true as soon as possible (short-circuit evaluation).",
    "After the iteration, if no common element is found, return false."
  ],
  "code_keywords": [
    "Lean 4",
    "Array",
    "Integer",
    "membership",
    "exists",
    "iteration"
  ],
  "proof_keywords": [
    "case analysis",
    "edge cases",
    "short-circuit evaluation"
  ],
  "assumptions": [
    "The input arrays are of type 'Array Int' or similar.",
    "A membership function (or predicate) is available or can be implemented for array types in Lean 4.",
    "Short-circuit evaluation (or early return) is possible in the Lean 4 implementation."
  ],
  "retry_guidance": "If errors occur, particularly related to the use of array iteration or membership testing in Lean 4, reevaluate the available array operations and consider using built-in functions like 'Array.any' or similar. Also, check that the types and syntax align with Lean 4's current array API."
}
2025-06-01 03:00:24,258 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "The plan is to implement a Lean 4 function that checks if two arrays of integers share any common element. The function will first check for the edge-case where one or both arrays are empty and return false immediately. If both arrays have elements, the strategy is to iterate over the first array and use a membership test to check if any element exists in the second array. If such an element is found, the function returns true; if not, it returns false.",\n  "steps": [\n    "Check if either of the arrays is empty. If so, return false.",\n    "Iterate over each element of the first array.",\n    "For each element, check membership in the second array using an appropriate Lean 4 membership function or predicate.",\n    "If any common element is found, return true as soon as possible (short-circuit evaluation).",\n    "After the iteration, if no common element is found, return false."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array",\n    "Integer",\n    "membership",\n    "exists",\n    "iteration"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "edge cases",\n    "short-circuit evaluation"\n  ],\n  "assumptions": [\n    "The input arrays are of type \'Array Int\' or similar.",\n    "A membership function (or predicate) is available or can be implemented for array types in Lean 4.",\n    "Short-circuit evaluation (or early return) is possible in the Lean 4 implementation."\n  ],\n  "retry_guidance": "If errors occur, particularly related to the use of array iteration or membership testing in Lean 4, reevaluate the available array operations and consider using built-in functions like \'Array.any\' or similar. Also, check that the types and syntax align with Lean 4\'s current array API."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasCommonElement (a : Array Int) (b : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the method returns true, there exists at least one common element between the two arrays; If the method returns false, there are no common elements between the two arrays\ndef hasCommonElement_spec (a : Array Int) (b : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ result\n  -- << SPEC END >>\n\ntheorem hasCommonElement_spec_satisfied (a : Array Int) (b : Array Int) :\n  hasCommonElement_spec a b (hasCommonElement a b) := by\n  -- << PROOF START >>\n  unfold hasCommonElement hasCommonElement_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Propositions and Proofs\n\nBy now, you have seen some ways of defining objects and functions in Lean. In\nthis chapter, we will begin to explain how to write mathematical assertions\nand proofs in the language of dependent type theory as well.\n\n## Propositions as Types\n\nOne strategy for proving assertions about objects defined in the language of\ndependent type theory is to layer an assertion language and a proof language\non top of the definition language. But there is no reason to multiply\nlanguages in this way: dependent type theory is flexible and expressive, and\nthere is no reason we cannot represent assertions and proofs in the same\ngeneral framework.\n\nFor example, we could introduce a new type, `Prop`, to represent propositions,\nand introduce constructors to build new propositions from others.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    #check And     -- Prop → Prop → Prop\n    #check Or      -- Prop → Prop → Prop\n    #check Not     -- Prop → Prop\n    #check Implies -- Prop → Prop → Prop\n    \n    variable (p q r : Prop)\n    #check And p q                      -- Prop\n    #check Or (And p q) r               -- Prop\n    #check Implies (And p q) (And q p)  -- Prop\n    \n\nWe could then introduce, for each element `p : Prop`, another type `Proof p`,\nfor the type of proofs of `p`. An "axiom" would be a constant of such a type.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    #check Proof   -- Proof : Prop → Type\n    \n    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))\n    \n    variable (p q : Prop)\n    #check and_comm p q     -- Proof (Implies (And p q) (And q p))\n    \n\nIn addition to axioms, however, we would also need rules to build new proofs\nfrom old ones. For example, in many proof systems for propositional logic, we\nhave the rule of _modus ponens_ :\n\n> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.\n\nWe could represent this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q\n    \n\nSystems of natural deduction for propositional logic also typically rely on\nthe following rule:\n\n> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we\n> can "cancel" the hypothesis and obtain a proof of `Implies p q`.\n\nWe could render this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)\n    \n\nThis approach would provide us with a reasonable way of building assertions\nand proofs. Determining that an expression `t` is a correct proof of assertion\n`p` would then simply be a matter of checking that `t` has type `Proof p`.\n\nSome simplifications are possible, however. To start with, we can avoid\nwriting the term `Proof` repeatedly by conflating `Proof p` with `p` itself.\nIn other words, whenever we have `p : Prop`, we can interpret `p` as a type,\nnamely, the type of its proofs. We can then read `t : p` as the assertion that\n`t` is a proof of `p`.\n\nMoreover, once we make this identification, the rules for implication show\nthat we can pass back and forth between `Implies p q` and `p → q`. In other\nwords, implication between propositions `p` and `q` corresponds to having a\nfunction that takes any element of `p` to an element of `q`. As a result, the\nintroduction of the connective `Implies` is entirely redundant: we can use the\nusual function space constructor `p → q` from dependent type theory as our\nnotion of implication.\n\nThis is the approach followed in the Calculus of Constructions, and hence in\nLean as well. The fact that the rules for implication in a proof system for\nnatural deduction correspond exactly to the rules governing abstraction and\napplication for functions is an instance of the _Curry-Howard isomorphism_ ,\nsometimes known as the _propositions-as-types_ paradigm. In fact, the type\n`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy\ndescribed in the last chapter. Moreover, `Type u` is also just syntactic sugar\nfor `Sort (u+1)`. `Prop` has some special features, but like the other type\nuniverses, it is closed under the arrow constructor: if we have `p q : Prop`,\nthen `p → q : Prop`.\n\nThere are at least two ways of thinking about propositions as types. To some\nwho take a constructive view of logic and mathematics, this is a faithful\nrendering of what it means to be a proposition: a proposition `p` represents a\nsort of data type, namely, a specification of the type of data that\nconstitutes a proof. A proof of `p` is then simply an object `t : p` of the\nright type.\n\nThose not inclined to this ideology can view it, rather, as a simple coding\ntrick. To each proposition `p` we associate a type that is empty if `p` is\nfalse and has a single element, say `*`, if `p` is true. In the latter case,\nlet us say that (the type associated with) `p` is _inhabited_. It just so\nhappens that the rules for function application and abstraction can\nconveniently help us keep track of which elements of `Prop` are inhabited. So\nconstructing an element `t : p` tells us that `p` is indeed true. You can\nthink of the inhabitant of `p` as being the "fact that `p` is true." A proof\nof `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is\ntrue."\n\nIndeed, if `p : Prop` is any proposition, Lean\'s kernel treats any two\nelements `t1 t2 : p` as being definitionally equal, much the same way as it\ntreats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as\n_proof irrelevance,_ and is consistent with the interpretation in the last\nparagraph. It means that even though we can treat proofs `t : p` as ordinary\nobjects in the language of dependent type theory, they carry no information\nbeyond the fact that `p` is true.\n\nThe two ways we have suggested thinking about the propositions-as-types\nparadigm differ in a fundamental way. From the constructive point of view,\nproofs are abstract mathematical objects that are _denoted_ by suitable\nexpressions in dependent type theory. In contrast, if we think in terms of the\ncoding trick described above, then the expressions themselves do not denote\nanything interesting. Rather, it is the fact that we can write them down and\ncheck that they are well-typed that ensures that the proposition in question\nis true. In other words, the expressions _themselves_ are the proofs.\n\nIn the exposition below, we will slip back and forth between these two ways of\ntalking, at times saying that an expression "constructs" or "produces" or\n"returns" a proof of a proposition, and at other times simply saying that it\n"is" such a proof. This is similar to the way that computer scientists\noccasionally blur the distinction between syntax and semantics by saying, at\ntimes, that a program "computes" a certain function, and at other times\nspeaking as though the program "is" the function in question.\n\nIn any case, all that really matters is the bottom line. To formally express a\nmathematical assertion in the language of dependent type theory, we need to\nexhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a\nterm `t : p`. Lean\'s task, as a proof assistant, is to help us to construct\nsuch a term, `t`, and to verify that it is well-formed and has the correct\ntype.\n\n## Working with Propositions as Types\n\nIn the propositions-as-types paradigm, theorems involving only `→` can be\nproved using lambda abstraction and application. In Lean, the `theorem`\ncommand introduces a new theorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    \n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n\nCompare this proof to the expression `fun x : α => fun y : β => x` of type `α\n→ β → α`, where `α` and `β` are data types. This describes the function that\ntakes arguments `x` and `y` of type `α` and `β`, respectively, and returns\n`x`. The proof of `t1` has the same form, the only difference being that `p`\nand `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of\n`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis\n(trivially) to establish that the conclusion, `p`, is true.\n\nNote that the `theorem` command is really a version of the `def` command:\nunder the propositions and types correspondence, proving the theorem `p → q →\np` is really the same as defining an element of the associated type. To the\nkernel type checker, there is no difference between the two.\n\nThere are a few pragmatic differences between definitions and theorems,\nhowever. In normal circumstances, it is never necessary to unfold the\n"definition" of a theorem; by proof irrelevance, any two proofs of that\ntheorem are definitionally equal. Once the proof of a theorem is complete,\ntypically we only need to know that the proof exists; it doesn\'t matter what\nthe proof is. In light of that fact, Lean tags proofs as _irreducible_ , which\nserves as a hint to the parser (more precisely, the _elaborator_) that there\nis generally no need to unfold them when processing a file. In fact, Lean is\ngenerally able to process and check proofs in parallel, since assessing the\ncorrectness of one proof does not require knowing the details of another.\n\nAs with definitions, the `#print` command will show you the proof of a\ntheorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n    #print t1\n    \n\nNotice that the lambda abstractions `hp : p` and `hq : q` can be viewed as\ntemporary assumptions in the proof of `t1`. Lean also allows us to specify the\ntype of the final term `hp`, explicitly, with a `show` statement:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p :=\n      fun hp : p =>\n      fun hq : q =>\n      show p from hp\n    \n\nAdding such extra information can improve the clarity of a proof and help\ndetect errors when writing a proof. The `show` command does nothing more than\nannotate the type, and, internally, all the presentations of `t1` that we have\nseen produce the same term.\n\nAs with ordinary definitions, we can move the lambda-abstracted variables to\nthe left of the colon:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    #print t1    -- p → q → p\n    \n\nWe can use the theorem `t1` just as a function application:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    axiom hp : p\n    \n    theorem t2 : q → p := t1 hp\n    \n\nThe `axiom` declaration postulates the existence of an element of the given\ntype and may compromise logical consistency. For example, we can use it to\npostulate that the empty type `False` has an element:\n\n    \n    \n    axiom unsound : False\n    -- Everything follows from false\n    theorem ex : 1 = 0 :=\n      False.elim unsound\n    \n\nDeclaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as\nwitnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`\nthat `p` is true yields the theorem `t1 hp : q → p`.\n\nRecall that we can also write theorem `t1` as follows:\n\n    \n    \n    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp\n    \n    #print t1\n    \n\nThe type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the\nassertion "for every pair of propositions `p q`, we have `p → q → p`." For\nexample, we can move all parameters to the right of the colon:\n\n    \n    \n    theorem t1 : ∀ {p q : Prop}, p → q → p :=\n      fun {p q : Prop} (hp : p) (hq : q) => hp\n    \n\nIf `p` and `q` have been declared as variables, Lean will generalize them for\nus automatically:\n\n    \n    \n    variable {p q : Prop}\n    \n    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp\n    \n\nIn fact, by the propositions-as-types correspondence, we can declare the\nassumption `hp` that `p` holds, as another variable:\n\n    \n    \n    variable {p q : Prop}\n    variable (hp : p)\n    \n    theorem t1 : q → p := fun (hq : q) => hp\n    \n\nLean detects that the proof uses `hp` and automatically adds `hp : p` as a\npremise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →\nq → p`. Remember that this type can just as well be written `∀ (p q : Prop)\n(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type\nin which the target does not depend on the bound variable.\n\nWhen we generalize `t1` in such a way, we can then apply it to different pairs\nof propositions, to obtain different instances of the general theorem.\n\n    \n    \n    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp\n    \n    variable (p q r s : Prop)\n    \n    #check t1 p q                -- p → q → p\n    #check t1 r s                -- r → s → r\n    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s\n    \n    variable (h : r → s)\n    #check t1 (r → s) (s → r) h  -- (s → r) → r → s\n    \n\nOnce again, using the propositions-as-types correspondence, the variable `h`\nof type `r → s` can be viewed as the hypothesis, or premise, that `r → s`\nholds.\n\nAs another example, let us consider the composition function discussed in the\nlast chapter, now with propositions instead of types.\n\n    \n    \n    variable (p q r s : Prop)\n    \n    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=\n      fun h₃ : p =>\n      show r from h₁ (h₂ h₃)\n    \n\nAs a theorem of propositional logic, what does `t2` say?\n\nNote that it is often useful to use numeric unicode subscripts, entered as\n`\\0`, `\\1`, `\\2`, ..., for hypotheses, as we did in this example.\n\n## Propositional Logic\n\nLean defines all the standard logical connectives and notation. The\npropositional connectives come with the following notation:\n\nAscii| Unicode| Editor shortcut| Definition  \n---|---|---|---  \nTrue| | | True  \nFalse| | | False  \nNot| ¬| `\\not`, `\\neg`| Not  \n/\\| ∧| `\\and`| And  \n\\/| ∨| `\\or`| Or  \n->| →| `\\to`, `\\r`, `\\imp`|   \n<->| ↔| `\\iff`, `\\lr`| Iff  \n  \nThey all take values in `Prop`.\n\n    \n    \n    variable (p q : Prop)\n    \n    #check p → q → p ∧ q\n    #check ¬p → p ↔ False\n    #check p ∨ q → q ∨ p\n    \n\nThe order of operations is as follows: unary negation `¬` binds most strongly,\nthen `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧\ne` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right\n(nothing changes now that the arguments are elements of `Prop`, instead of\nsome other `Type`), as do the other binary connectives. So if we have `p q r :\nProp`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This\nis just the "curried" form of `p ∧ q → r`.\n\nIn the last chapter we observed that lambda abstraction can be viewed as an\n"introduction rule" for `→`. In the current setting, it shows how to\n"introduce" or establish an implication. Application can be viewed as an\n"elimination rule," showing how to "eliminate" or use an implication in a\nproof. The other propositional connectives are defined in Lean\'s library in\nthe file `Prelude.core` (see [importing\nfiles](./interacting_with_lean.html#importing-files) for more information on\nthe library hierarchy), and each connective comes with its canonical\nintroduction and elimination rules.\n\n### Conjunction\n\nThe expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :\np` and `h2 : q`. It is common to describe `And.intro` as the _and-\nintroduction_ rule. In the next example we use `And.intro` to create a proof\nof `p → q → p ∧ q`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq\n    \n    #check fun (hp : p) (hq : q) => And.intro hp hq\n    \n\nThe `example` command states a theorem without naming it or storing it in the\npermanent context. Essentially, it just checks that the given term has the\nindicated type. It is convenient for illustration, and we will use it often.\n\nThe expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.\nSimilarly, `And.right h` is a proof of `q`. They are commonly known as the\nleft and right _and-elimination_ rules.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : p := And.left h\n    example (h : p ∧ q) : q := And.right h\n    \n\nWe can now prove `p ∧ q → q ∧ p` with the following proof term.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      And.intro (And.right h) (And.left h)\n    \n\nNotice that and-introduction and and-elimination are similar to the pairing\nand projection operations for the Cartesian product. The difference is that\ngiven `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while\n`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is\nanother instance of the Curry-Howard isomorphism, but in contrast to\nimplication and the function space constructor, `∧` and `×` are treated\nseparately in Lean. With the analogy, however, the proof we have just\nconstructed is similar to a function that swaps the elements of a pair.\n\nWe will see in [Chapter Structures and Records](./structures_and_records.html)\nthat certain types in Lean are _structures_ , which is to say, the type is\ndefined with a single canonical _constructor_ which builds an element of the\ntype from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is\nan example: the canonical way to construct an element is to apply `And.intro`\nto suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous\nconstructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the\nrelevant type is an inductive type and can be inferred from the context. In\nparticular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:\n\n    \n    \n    variable (p q : Prop)\n    variable (hp : p) (hq : q)\n    \n    #check (⟨hp, hq⟩ : p ∧ q)\n    \n\nThese angle brackets are obtained by typing `\\<` and `\\>`, respectively.\n\nLean provides another useful syntactic gadget. Given an expression `e` of an\ninductive type `Foo` (possibly applied to some arguments), the notation\n`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of\naccessing functions without opening a namespace. For example, the following\ntwo expressions mean the same thing:\n\n    \n    \n    variable (xs : List Nat)\n    \n    #check List.length xs\n    #check xs.length\n    \n\nAs a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and\n`h.right` for `And.right h`. We can therefore rewrite the sample proof above\nconveniently as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      ⟨h.right, h.left⟩\n    \n\nThere is a fine line between brevity and obfuscation, and omitting information\nin this way can sometimes make a proof harder to read. But for straightforward\nconstructions like the one above, when the type of `h` and the goal of the\nconstruction are salient, the notation is clean and effective.\n\nIt is common to iterate constructions like "And." Lean also allows you to\nflatten nested constructors that associate to the right, so that these two\nproofs are equivalent:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, ⟨h.left, h.right⟩⟩\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, h.left, h.right⟩\n    \n\nThis is often useful as well.\n\n### Disjunction\n\nThe expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof\n`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a\nproof `hq : q`. These are the left and right _or-introduction_ rules.\n\n    \n    \n    variable (p q : Prop)\n    example (hp : p) : p ∨ q := Or.intro_left q hp\n    example (hq : q) : p ∨ q := Or.intro_right p hq\n    \n\nThe _or-elimination_ rule is slightly more complicated. The idea is that we\ncan prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`\nfollows from `q`. In other words, it is a proof by cases. In the expression\n`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :\np → r` and `hqr : q → r`, and produces a proof of `r`. In the following\nexample, we use `Or.elim` to prove `p ∨ q → q ∨ p`.\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h\n        (fun hp : p =>\n          show q ∨ p from Or.intro_right q hp)\n        (fun hq : q =>\n          show q ∨ p from Or.intro_left p hq)\n    \n\nIn most cases, the first argument of `Or.intro_right` and `Or.intro_left` can\nbe inferred automatically by Lean. Lean therefore provides `Or.inr` and\n`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and\n`Or.intro_left _`. Thus the proof term above could be written more concisely:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nNotice that there is enough information in the full expression for Lean to\ninfer the types of `hp` and `hq` as well. But using the type annotations in\nthe longer version makes the proof more readable, and can help catch and debug\nerrors.\n\nBecause `Or` has two constructors, we cannot use anonymous constructor\nnotation. But we can still write `h.elim` instead of `Or.elim h`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nOnce again, you should exercise judgment as to whether such abbreviations\nenhance or diminish readability.\n\n### Negation and Falsity\n\nNegation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by\nderiving a contradiction from `p`. Similarly, the expression `hnp hp` produces\na proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both\nthese rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is\nproduced by typing `\\not` or `\\neg`.)\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hpq : p → q) (hnq : ¬q) : ¬p :=\n      fun hp : p =>\n      show False from hnq (hpq hp)\n    \n\nThe connective `False` has a single elimination rule, `False.elim`, which\nexpresses the fact that anything follows from a contradiction. This rule is\nsometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the\n_principle of explosion_.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)\n    \n\nThe arbitrary fact, `q`, that follows from falsity is an implicit argument in\n`False.elim` and is inferred automatically. This pattern, deriving an\narbitrary fact from contradictory hypotheses, is quite common, and is\nrepresented by `absurd`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := absurd hp hnp\n    \n\nHere, for example, is a proof of `¬p → q → (q → p) → r`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=\n      absurd (hqp hq) hnp\n    \n\nIncidentally, just as `False` has only an elimination rule, `True` has only an\nintroduction rule, `True.intro : true`. In other words, `True` is simply true,\nand has a canonical proof, `True.intro`.\n\n### Logical Equivalence\n\nThe expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`\nand `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from\n`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔\nq`. Here is a proof of `p ∧ q ↔ q ∧ p`:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      Iff.intro\n        (fun h : p ∧ q =>\n         show q ∧ p from And.intro (And.right h) (And.left h))\n        (fun h : q ∧ p =>\n         show p ∧ q from And.intro (And.right h) (And.left h))\n    \n    #check and_swap p q    -- p ∧ q ↔ q ∧ p\n    \n    variable (h : p ∧ q)\n    example : q ∧ p := Iff.mp (and_swap p q) h\n    \n\nWe can use the anonymous constructor notation to construct a proof of `p ↔ q`\nfrom proofs of the forward and backward directions, and we can also use `.`\nnotation with `mp` and `mpr`. The previous examples can therefore be written\nconcisely as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩\n    \n    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h\n    \n\n## Introducing Auxiliary Subgoals\n\nThis is a good place to introduce another device Lean offers to help structure\nlong proofs, namely, the `have` construct, which introduces an auxiliary\nsubgoal in a proof. Here is a small example, adapted from the last section:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      have hq : q := h.right\n      show q ∧ p from And.intro hq hp\n    \n\nInternally, the expression `have h : p := s; t` produces the term `(fun (h :\np) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the\ndesired conclusion assuming `h : p`, and the two are combined by a lambda\nabstraction and application. This simple device is extremely useful when it\ncomes to structuring long proofs, since we can use intermediate `have`\'s as\nstepping stones leading to the final goal.\n\nLean also supports a structured way of reasoning backwards from a goal, which\nmodels the "suffices to show" construction in ordinary mathematics. The next\nexample simply permutes the last two lines in the previous proof.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      suffices hq : q from And.intro hq hp\n      show q from And.right h\n    \n\nWriting `suffices hq : q` leaves us with two goals. First, we have to show\nthat it indeed suffices to show `q`, by proving the original goal of `q ∧ p`\nwith the additional hypothesis `hq : q`. Finally, we have to show `q`.\n\n## Classical Logic\n\nThe introduction and elimination rules we have seen so far are all\nconstructive, which is to say, they reflect a computational understanding of\nthe logical connectives based on the propositions-as-types correspondence.\nOrdinary classical logic adds to this the law of the excluded middle, `p ∨\n¬p`. To use this principle, you have to open the classical namespace.\n\n    \n    \n    open Classical\n    \n    variable (p : Prop)\n    #check em p\n    \n\nIntuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts\nto knowing which is the case. If `RH` represents the Riemann hypothesis, a\nclassical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot\nyet assert either disjunct.\n\nOne consequence of the law of the excluded middle is the principle of double-\nnegation elimination:\n\n    \n    \n    open Classical\n    \n    theorem dne {p : Prop} (h : ¬¬p) : p :=\n      Or.elim (em p)\n        (fun hp : p => hp)\n        (fun hnp : ¬p => absurd hnp h)\n    \n\nDouble-negation elimination allows one to prove any proposition, `p`, by\nassuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In\nother words, double-negation elimination allows one to carry out a proof by\ncontradiction, something which is not generally possible in constructive\nlogic. As an exercise, you might try proving the converse, that is, showing\nthat `em` can be proved from `dne`.\n\nThe classical axioms also give you access to additional patterns of proof that\ncan be justified by appeal to `em`. For example, one can carry out a proof by\ncases:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byCases\n        (fun h1 : p => h1)\n        (fun h1 : ¬p => absurd h1 h)\n    \n\nOr you can carry out a proof by contradiction:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byContradiction\n        (fun h1 : ¬p =>\n         show False from h h1)\n    \n\nIf you are not used to thinking constructively, it may take some time for you\nto get a sense of where classical reasoning is used. It is needed in the\nfollowing example because, from a constructive standpoint, knowing that `p`\nand `q` are not both true does not necessarily tell you which one is false:\n\n    \n    \n    open Classical\n    variable (p q : Prop)\n    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=\n      Or.elim (em p)\n        (fun hp : p =>\n          Or.inr\n            (show ¬q from\n              fun hq : q =>\n              h ⟨hp, hq⟩))\n        (fun hp : ¬p =>\n          Or.inl hp)\n    \n\nWe will see later that there _are_ situations in constructive logic where\nprinciples like excluded middle and double-negation elimination are\npermissible, and Lean supports the use of classical reasoning in such contexts\nwithout relying on excluded middle.\n\nThe full list of axioms that are used in Lean to support classical reasoning\nare discussed in [Axioms and Computation](./axioms_and_computation.html).\n\n## Examples of Propositional Validities\n\nLean\'s standard library contains proofs of many valid statements of\npropositional logic, all of which you are free to use in proofs of your own.\nThe following list includes a number of common identities.\n\nCommutativity:\n\n  1. `p ∧ q ↔ q ∧ p`\n  2. `p ∨ q ↔ q ∨ p`\n\nAssociativity:\n\n  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`\n  4. `(p ∨ q) ∨ r ↔ p ∨ (q �'}], 'model': 'gpt-4o'}}
2025-06-01 03:00:24,259 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:00:24,259 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:00:24,259 - DEBUG - send_request_headers.complete
2025-06-01 03:00:24,259 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:00:24,264 - DEBUG - send_request_body.complete
2025-06-01 03:00:24,264 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:00:29,507 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:00:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5008'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5018'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'9919'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'40.161s'), (b'x-request-id', b'req_91c299e0e2b2638efaabd29bcdb33eac'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b75e3cd50ff9b-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:00:29,508 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:00:29,508 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:00:29,511 - DEBUG - receive_response_body.complete
2025-06-01 03:00:29,511 - DEBUG - response_closed.started
2025-06-01 03:00:29,512 - DEBUG - response_closed.complete
2025-06-01 03:00:29,512 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:00:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5008', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5018', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '9919', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '40.161s', 'x-request-id': 'req_91c299e0e2b2638efaabd29bcdb33eac', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b75e3cd50ff9b-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:00:29,512 - DEBUG - request_id: req_91c299e0e2b2638efaabd29bcdb33eac
2025-06-01 03:00:29,512 - INFO - Raw solution received: ```json
{
  "code": "if a.isEmpty || b.isEmpty then\n    false\n  else\n    a.any (fun x => b.contains x)",
  "proof": "by_cases h : a.isEmpty || b.isEmpty\n  case pos =>\n    simp_all\n  case neg =>\n    simp only [Array.any_eq_exists, Array.contains_eq_exists]\n    by_cases ex : ∃ y, y ∈ a ∧ ∃ x, x ∈ b ∧ x = y\n    { obtain ⟨w, ⟨hwa, ⟨w1, ⟨hwb, hw1w⟩⟩⟩⟩ := ex\n      exact ⟨⟨w1, hwb⟩, hwa⟩ }\n    { simp only [exists_and_distrib_right, exists_prop, exists_eq_right] at ex\n      push_neg at ex\n      exact fun ⟨⟨y, hy⟩, hy_in_a⟩ => ex y hy hy_in_a }"
}
```
2025-06-01 03:00:29,512 - INFO - <class 'str'>
2025-06-01 03:00:29,512 - INFO - Generated solution: {'code': 'if a.isEmpty || b.isEmpty then\n    false\n  else\n    a.any (fun x => b.contains x)', 'proof': 'by_cases h : a.isEmpty || b.isEmpty\n  case pos =>\n    simp_all\n  case neg =>\n    simp only [Array.any_eq_exists, Array.contains_eq_exists]\n    by_cases ex : ∃ y, y ∈ a ∧ ∃ x, x ∈ b ∧ x = y\n    { obtain ⟨w, ⟨hwa, ⟨w1, ⟨hwb, hw1w⟩⟩⟩⟩ := ex\n      exact ⟨⟨w1, hwb⟩, hwa⟩ }\n    { simp only [exists_and_distrib_right, exists_prop, exists_eq_right] at ex\n      push_neg at ex\n      exact fun ⟨⟨y, hy⟩, hy_in_a⟩ => ex y hy hy_in_a }'}
2025-06-01 03:00:35,019 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:25:11: error: unsolved goals
a b : Array ℤ
h : a = #[] ∨ b = #[]
⊢ ∀ x < a.size, ∀ x_1 < b.size, ¬a[x]! = b[x_1]!
lean_playground/TempTest.lean:28:15: error: unknown constant 'Array.any_eq_exists'
lean_playground/TempTest.lean:28:36: error: unknown constant 'Array.contains_eq_exists'
lean_playground/TempTest.lean:28:4: error: simp made no progress
2025-06-01 03:00:35,020 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasCommonElement (a : Array Int) (b : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the method returns true, there exists at least one common element between the two arrays; If the method returns false, there are no common elements between the two arrays\ndef hasCommonElement_spec (a : Array Int) (b : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ result\n  -- << SPEC END >>\n\ntheorem hasCommonElement_spec_satisfied (a : Array Int) (b : Array Int) :\n  hasCommonElement_spec a b (hasCommonElement a b) := by\n  -- << PROOF START >>\n  unfold hasCommonElement hasCommonElement_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a.isEmpty || b.isEmpty then\n    false\n  else\n    a.any (fun x => b.contains x)\n\nGenerated Proof:\nby_cases h : a.isEmpty || b.isEmpty\n  case pos =>\n    simp_all\n  case neg =>\n    simp only [Array.any_eq_exists, Array.contains_eq_exists]\n    by_cases ex : ∃ y, y ∈ a ∧ ∃ x, x ∈ b ∧ x = y\n    { obtain ⟨w, ⟨hwa, ⟨w1, ⟨hwb, hw1w⟩⟩⟩⟩ := ex\n      exact ⟨⟨w1, hwb⟩, hwa⟩ }\n    { simp only [exists_and_distrib_right, exists_prop, exists_eq_right] at ex\n      push_neg at ex\n      exact fun ⟨⟨y, hy⟩, hy_in_a⟩ => ex y hy hy_in_a }\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:25:11: error: unsolved goals\na b : Array ℤ\nh : a = #[] ∨ b = #[]\n⊢ ∀ x < a.size, ∀ x_1 < b.size, ¬a[x]! = b[x_1]!\nlean_playground/TempTest.lean:28:15: error: unknown constant 'Array.any_eq_exists'\nlean_playground/TempTest.lean:28:36: error: unknown constant 'Array.contains_eq_exists'\nlean_playground/TempTest.lean:28:4: error: simp made no progress"}], 'model': 'o3-mini'}}
2025-06-01 03:00:35,021 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:00:35,021 - DEBUG - close.started
2025-06-01 03:00:35,021 - DEBUG - close.complete
2025-06-01 03:00:35,021 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:00:35,027 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fdb860>
2025-06-01 03:00:35,027 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:00:35,037 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fdb6e0>
2025-06-01 03:00:35,037 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:00:35,037 - DEBUG - send_request_headers.complete
2025-06-01 03:00:35,037 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:00:35,037 - DEBUG - send_request_body.complete
2025-06-01 03:00:35,037 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:01:00,772 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:01:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'25504'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'25507'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199027'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'291ms'), (b'x-request-id', b'req_3bcb39c2994b315fd9f943f109a15417'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b762728398fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:01:00,772 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:01:00,772 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:01:00,772 - DEBUG - receive_response_body.complete
2025-06-01 03:01:00,772 - DEBUG - response_closed.started
2025-06-01 03:01:00,773 - DEBUG - response_closed.complete
2025-06-01 03:01:00,773 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:01:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '25504', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '25507', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199027', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '291ms', 'x-request-id': 'req_3bcb39c2994b315fd9f943f109a15417', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b762728398fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:01:00,773 - DEBUG - request_id: req_3bcb39c2994b315fd9f943f109a15417
2025-06-01 03:01:00,773 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails mainly because it incorrectly uses unknown constants 'Array.any_eq_exists' and 'Array.contains_eq_exists' (and a related unsolved goal). In addition, the proof does not fully unfold the definitions of Array.any and Array.contains to show the equivalence between 'a.any (λ x => b.contains x)' and the existence of indices i and j satisfying the spec.", 'error_type': 'proof', 'suggested_fix': "Avoid using undefined lemmas (like Array.any_eq_exists and Array.contains_eq_exists) and directly unfold the definitions. For example, note that by definition 'a.any f' returns true if and only if ∃ i with i < a.size and f (a.get! i) = true, and that 'b.contains x' means ∃ j with j < b.size and b.get! j = x. Split the proof into two cases based on whether a or b is empty, and in the non‐empty case, use a direct argument (by applying Iff.intro, then using the definition of exists) to show the equivalence. A revised proof may first perform a by_cases on (a.isEmpty ∨ b.isEmpty), then for the nonempty case, explicitly rewrite the statement:\n\n  (∃ i, i < a.size ∧ (∃ j, j < b.size ∧ a.get! i = b.get! j))\n  ↔\n  (∃ i, i < a.size ∧ b.contains (a.get! i))\n\nby unfolding the definition of b.contains.  Finally, use this to conclude the equivalence with the return value of the function.", 'retry_strategy': 'Revise the proof by explicitly expanding the definitions of Array.any and Array.contains, use basic tactics such as by_cases to handle emptiness cases, and apply Iff.intro to prove both directions of the equivalence. This approach avoids relying on unknown lemmas and should help in closing the proof obligations.'}
2025-06-01 03:01:00,774 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.\n\nPrevious plan:\n{\n  "plan_summary": "The plan is to implement a Lean 4 function that checks if two arrays of integers share any common element. The function will first check for the edge-case where one or both arrays are empty and return false immediately. If both arrays have elements, the strategy is to iterate over the first array and use a membership test to check if any element exists in the second array. If such an element is found, the function returns true; if not, it returns false.",\n  "steps": [\n    "Check if either of the arrays is empty. If so, return false.",\n    "Iterate over each element of the first array.",\n    "For each element, check membership in the second array using an appropriate Lean 4 membership function or predicate.",\n    "If any common element is found, return true as soon as possible (short-circuit evaluation).",\n    "After the iteration, if no common element is found, return false."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array",\n    "Integer",\n    "membership",\n    "exists",\n    "iteration"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "edge cases",\n    "short-circuit evaluation"\n  ],\n  "assumptions": [\n    "The input arrays are of type \'Array Int\' or similar.",\n    "A membership function (or predicate) is available or can be implemented for array types in Lean 4.",\n    "Short-circuit evaluation (or early return) is possible in the Lean 4 implementation."\n  ],\n  "retry_guidance": "If errors occur, particularly related to the use of array iteration or membership testing in Lean 4, reevaluate the available array operations and consider using built-in functions like \'Array.any\' or similar. Also, check that the types and syntax align with Lean 4\'s current array API."\n}\n\nLean error:\nThe proof fails mainly because it incorrectly uses unknown constants \'Array.any_eq_exists\' and \'Array.contains_eq_exists\' (and a related unsolved goal). In addition, the proof does not fully unfold the definitions of Array.any and Array.contains to show the equivalence between \'a.any (λ x => b.contains x)\' and the existence of indices i and j satisfying the spec.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 03:01:00,774 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:01:00,774 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:01:00,775 - DEBUG - send_request_headers.complete
2025-06-01 03:01:00,775 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:01:00,775 - DEBUG - send_request_body.complete
2025-06-01 03:01:00,775 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:01:08,269 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:01:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6880'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6883'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'197423'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'772ms'), (b'x-request-id', b'req_b08c3b71d620e3c7cb14ef37d818220d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b76c80ec78fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:01:08,269 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:01:08,269 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:01:08,271 - DEBUG - receive_response_body.complete
2025-06-01 03:01:08,271 - DEBUG - response_closed.started
2025-06-01 03:01:08,271 - DEBUG - response_closed.complete
2025-06-01 03:01:08,271 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:01:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6880', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6883', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '197423', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '772ms', 'x-request-id': 'req_b08c3b71d620e3c7cb14ef37d818220d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b76c80ec78fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:01:08,271 - DEBUG - request_id: req_b08c3b71d620e3c7cb14ef37d818220d
2025-06-01 03:01:08,271 - INFO - Attempt 2/3
2025-06-01 03:01:08,272 - INFO - Current plan: {
  "plan_summary": "Revise the implementation to avoid using unknown constants tied to built-in functions and instead directly use (or define) an iterative approach whose correctness is proved by explicit unfolding of definitions. In this revised plan, we avoid relying on the unproven equivalences of Array.any and Array.contains and develop an approach (and associated auxiliary lemmas) that explicitly show the equivalence between a common element existing and the iterative check returning true.",
  "steps": [
    "Handle initial edge case: check if either array is empty and return false immediately.",
    "Implement an iterative (or recursive) function that traverses the first array. For each element, manually check for membership in the second array by iterating over it.",
    "Avoid relying on Array.any or Array.contains’s built-in equivalences. Instead, define a helper function (if needed) that takes an element and a second array and returns true only if the element is explicitly found within the structure.",
    "After iterating through all elements, if no match is found, return false.",
    "Develop auxiliary lemmas that unfold the definitions of the helper functions to prove that the function returns true if and only if there exist indices i and j such that the i-th element of the first array equals the j-th element of the second array. Use explicit case analysis or induction on the structure of arrays to achieve this.",
    "Optionally, when proving the correctness, use induction on the length of the first array to show that if no element in the list passes the membership test, then there is no common element, and vice versa."
  ],
  "code_keywords": [
    "Lean 4",
    "Array",
    "Integer",
    "membership",
    "iteration",
    "recursive function"
  ],
  "proof_keywords": [
    "unfolding definitions",
    "inductive proof",
    "auxiliary lemmas",
    "case analysis",
    "correctness proof"
  ],
  "assumptions": [
    "The arrays are of type Array Int.",
    "Manual recursion or iteration is allowed over array elements.",
    "It is acceptable to define custom helper functions for membership checking to avoid dependency on unknown constants.",
    "Explicit induction on the array length is a viable strategy for proving correctness."
  ],
  "retry_guidance": "If further issues arise, ensure that you fully expand the definitions used for membership testing and array iteration. Avoid referencing non-existent built-in equivalences; instead, provide detailed inductions or case splits that capture the intended logical equivalences in lean."
}
2025-06-01 03:01:08,272 - INFO - Updated plan: {
  "plan_summary": "Revise the implementation to avoid using unknown constants tied to built-in functions and instead directly use (or define) an iterative approach whose correctness is proved by explicit unfolding of definitions. In this revised plan, we avoid relying on the unproven equivalences of Array.any and Array.contains and develop an approach (and associated auxiliary lemmas) that explicitly show the equivalence between a common element existing and the iterative check returning true.",
  "steps": [
    "Handle initial edge case: check if either array is empty and return false immediately.",
    "Implement an iterative (or recursive) function that traverses the first array. For each element, manually check for membership in the second array by iterating over it.",
    "Avoid relying on Array.any or Array.contains’s built-in equivalences. Instead, define a helper function (if needed) that takes an element and a second array and returns true only if the element is explicitly found within the structure.",
    "After iterating through all elements, if no match is found, return false.",
    "Develop auxiliary lemmas that unfold the definitions of the helper functions to prove that the function returns true if and only if there exist indices i and j such that the i-th element of the first array equals the j-th element of the second array. Use explicit case analysis or induction on the structure of arrays to achieve this.",
    "Optionally, when proving the correctness, use induction on the length of the first array to show that if no element in the list passes the membership test, then there is no common element, and vice versa."
  ],
  "code_keywords": [
    "Lean 4",
    "Array",
    "Integer",
    "membership",
    "iteration",
    "recursive function"
  ],
  "proof_keywords": [
    "unfolding definitions",
    "inductive proof",
    "auxiliary lemmas",
    "case analysis",
    "correctness proof"
  ],
  "assumptions": [
    "The arrays are of type Array Int.",
    "Manual recursion or iteration is allowed over array elements.",
    "It is acceptable to define custom helper functions for membership checking to avoid dependency on unknown constants.",
    "Explicit induction on the array length is a viable strategy for proving correctness."
  ],
  "retry_guidance": "If further issues arise, ensure that you fully expand the definitions used for membership testing and array iteration. Avoid referencing non-existent built-in equivalences; instead, provide detailed inductions or case splits that capture the intended logical equivalences in lean."
}

Lean error summary:
The proof fails mainly because it incorrectly uses unknown constants 'Array.any_eq_exists' and 'Array.contains_eq_exists' (and a related unsolved goal). In addition, the proof does not fully unfold the definitions of Array.any and Array.contains to show the equivalence between 'a.any (λ x => b.contains x)' and the existence of indices i and j satisfying the spec.
Retry guidance (MUST FOLLOW):
Revise the proof by explicitly expanding the definitions of Array.any and Array.contains, use basic tactics such as by_cases to handle emptiness cases, and apply Iff.intro to prove both directions of the equivalence. This approach avoids relying on unknown lemmas and should help in closing the proof obligations.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 03:01:08,272 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the implementation to avoid using unknown constants tied to built-in functions and instead directly use (or define) an iterative approach whose correctness is proved by explicit unfolding of definitions. In this revised plan, we avoid relying on the unproven equivalences of Array.any and Array.contains and develop an approach (and associated auxiliary lemmas) that explicitly show the equivalence between a common element existing and the iterative check returning true.",\n  "steps": [\n    "Handle initial edge case: check if either array is empty and return false immediately.",\n    "Implement an iterative (or recursive) function that traverses the first array. For each element, manually check for membership in the second array by iterating over it.",\n    "Avoid relying on Array.any or Array.contains’s built-in equivalences. Instead, define a helper function (if needed) that takes an element and a second array and returns true only if the element is explicitly found within the structure.",\n    "After iterating through all elements, if no match is found, return false.",\n    "Develop auxiliary lemmas that unfold the definitions of the helper functions to prove that the function returns true if and only if there exist indices i and j such that the i-th element of the first array equals the j-th element of the second array. Use explicit case analysis or induction on the structure of arrays to achieve this.",\n    "Optionally, when proving the correctness, use induction on the length of the first array to show that if no element in the list passes the membership test, then there is no common element, and vice versa."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array",\n    "Integer",\n    "membership",\n    "iteration",\n    "recursive function"\n  ],\n  "proof_keywords": [\n    "unfolding definitions",\n    "inductive proof",\n    "auxiliary lemmas",\n    "case analysis",\n    "correctness proof"\n  ],\n  "assumptions": [\n    "The arrays are of type Array Int.",\n    "Manual recursion or iteration is allowed over array elements.",\n    "It is acceptable to define custom helper functions for membership checking to avoid dependency on unknown constants.",\n    "Explicit induction on the array length is a viable strategy for proving correctness."\n  ],\n  "retry_guidance": "If further issues arise, ensure that you fully expand the definitions used for membership testing and array iteration. Avoid referencing non-existent built-in equivalences; instead, provide detailed inductions or case splits that capture the intended logical equivalences in lean."\n}\n\nLean error summary:\nThe proof fails mainly because it incorrectly uses unknown constants \'Array.any_eq_exists\' and \'Array.contains_eq_exists\' (and a related unsolved goal). In addition, the proof does not fully unfold the definitions of Array.any and Array.contains to show the equivalence between \'a.any (λ x => b.contains x)\' and the existence of indices i and j satisfying the spec.\nRetry guidance (MUST FOLLOW):\nRevise the proof by explicitly expanding the definitions of Array.any and Array.contains, use basic tactics such as by_cases to handle emptiness cases, and apply Iff.intro to prove both directions of the equivalence. This approach avoids relying on unknown lemmas and should help in closing the proof obligations.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasCommonElement (a : Array Int) (b : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the method returns true, there exists at least one common element between the two arrays; If the method returns false, there are no common elements between the two arrays\ndef hasCommonElement_spec (a : Array Int) (b : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ result\n  -- << SPEC END >>\n\ntheorem hasCommonElement_spec_satisfied (a : Array Int) (b : Array Int) :\n  hasCommonElement_spec a b (hasCommonElement a b) := by\n  -- << PROOF START >>\n  unfold hasCommonElement hasCommonElement_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Propositions and Proofs\n\nBy now, you have seen some ways of defining objects and functions in Lean. In\nthis chapter, we will begin to explain how to write mathematical assertions\nand proofs in the language of dependent type theory as well.\n\n## Propositions as Types\n\nOne strategy for proving assertions about objects defined in the language of\ndependent type theory is to layer an assertion language and a proof language\non top of the definition language. But there is no reason to multiply\nlanguages in this way: dependent type theory is flexible and expressive, and\nthere is no reason we cannot represent assertions and proofs in the same\ngeneral framework.\n\nFor example, we could introduce a new type, `Prop`, to represent propositions,\nand introduce constructors to build new propositions from others.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    #check And     -- Prop → Prop → Prop\n    #check Or      -- Prop → Prop → Prop\n    #check Not     -- Prop → Prop\n    #check Implies -- Prop → Prop → Prop\n    \n    variable (p q r : Prop)\n    #check And p q                      -- Prop\n    #check Or (And p q) r               -- Prop\n    #check Implies (And p q) (And q p)  -- Prop\n    \n\nWe could then introduce, for each element `p : Prop`, another type `Proof p`,\nfor the type of proofs of `p`. An "axiom" would be a constant of such a type.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    #check Proof   -- Proof : Prop → Type\n    \n    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))\n    \n    variable (p q : Prop)\n    #check and_comm p q     -- Proof (Implies (And p q) (And q p))\n    \n\nIn addition to axioms, however, we would also need rules to build new proofs\nfrom old ones. For example, in many proof systems for propositional logic, we\nhave the rule of _modus ponens_ :\n\n> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.\n\nWe could represent this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q\n    \n\nSystems of natural deduction for propositional logic also typically rely on\nthe following rule:\n\n> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we\n> can "cancel" the hypothesis and obtain a proof of `Implies p q`.\n\nWe could render this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)\n    \n\nThis approach would provide us with a reasonable way of building assertions\nand proofs. Determining that an expression `t` is a correct proof of assertion\n`p` would then simply be a matter of checking that `t` has type `Proof p`.\n\nSome simplifications are possible, however. To start with, we can avoid\nwriting the term `Proof` repeatedly by conflating `Proof p` with `p` itself.\nIn other words, whenever we have `p : Prop`, we can interpret `p` as a type,\nnamely, the type of its proofs. We can then read `t : p` as the assertion that\n`t` is a proof of `p`.\n\nMoreover, once we make this identification, the rules for implication show\nthat we can pass back and forth between `Implies p q` and `p → q`. In other\nwords, implication between propositions `p` and `q` corresponds to having a\nfunction that takes any element of `p` to an element of `q`. As a result, the\nintroduction of the connective `Implies` is entirely redundant: we can use the\nusual function space constructor `p → q` from dependent type theory as our\nnotion of implication.\n\nThis is the approach followed in the Calculus of Constructions, and hence in\nLean as well. The fact that the rules for implication in a proof system for\nnatural deduction correspond exactly to the rules governing abstraction and\napplication for functions is an instance of the _Curry-Howard isomorphism_ ,\nsometimes known as the _propositions-as-types_ paradigm. In fact, the type\n`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy\ndescribed in the last chapter. Moreover, `Type u` is also just syntactic sugar\nfor `Sort (u+1)`. `Prop` has some special features, but like the other type\nuniverses, it is closed under the arrow constructor: if we have `p q : Prop`,\nthen `p → q : Prop`.\n\nThere are at least two ways of thinking about propositions as types. To some\nwho take a constructive view of logic and mathematics, this is a faithful\nrendering of what it means to be a proposition: a proposition `p` represents a\nsort of data type, namely, a specification of the type of data that\nconstitutes a proof. A proof of `p` is then simply an object `t : p` of the\nright type.\n\nThose not inclined to this ideology can view it, rather, as a simple coding\ntrick. To each proposition `p` we associate a type that is empty if `p` is\nfalse and has a single element, say `*`, if `p` is true. In the latter case,\nlet us say that (the type associated with) `p` is _inhabited_. It just so\nhappens that the rules for function application and abstraction can\nconveniently help us keep track of which elements of `Prop` are inhabited. So\nconstructing an element `t : p` tells us that `p` is indeed true. You can\nthink of the inhabitant of `p` as being the "fact that `p` is true." A proof\nof `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is\ntrue."\n\nIndeed, if `p : Prop` is any proposition, Lean\'s kernel treats any two\nelements `t1 t2 : p` as being definitionally equal, much the same way as it\ntreats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as\n_proof irrelevance,_ and is consistent with the interpretation in the last\nparagraph. It means that even though we can treat proofs `t : p` as ordinary\nobjects in the language of dependent type theory, they carry no information\nbeyond the fact that `p` is true.\n\nThe two ways we have suggested thinking about the propositions-as-types\nparadigm differ in a fundamental way. From the constructive point of view,\nproofs are abstract mathematical objects that are _denoted_ by suitable\nexpressions in dependent type theory. In contrast, if we think in terms of the\ncoding trick described above, then the expressions themselves do not denote\nanything interesting. Rather, it is the fact that we can write them down and\ncheck that they are well-typed that ensures that the proposition in question\nis true. In other words, the expressions _themselves_ are the proofs.\n\nIn the exposition below, we will slip back and forth between these two ways of\ntalking, at times saying that an expression "constructs" or "produces" or\n"returns" a proof of a proposition, and at other times simply saying that it\n"is" such a proof. This is similar to the way that computer scientists\noccasionally blur the distinction between syntax and semantics by saying, at\ntimes, that a program "computes" a certain function, and at other times\nspeaking as though the program "is" the function in question.\n\nIn any case, all that really matters is the bottom line. To formally express a\nmathematical assertion in the language of dependent type theory, we need to\nexhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a\nterm `t : p`. Lean\'s task, as a proof assistant, is to help us to construct\nsuch a term, `t`, and to verify that it is well-formed and has the correct\ntype.\n\n## Working with Propositions as Types\n\nIn the propositions-as-types paradigm, theorems involving only `→` can be\nproved using lambda abstraction and application. In Lean, the `theorem`\ncommand introduces a new theorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    \n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n\nCompare this proof to the expression `fun x : α => fun y : β => x` of type `α\n→ β → α`, where `α` and `β` are data types. This describes the function that\ntakes arguments `x` and `y` of type `α` and `β`, respectively, and returns\n`x`. The proof of `t1` has the same form, the only difference being that `p`\nand `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of\n`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis\n(trivially) to establish that the conclusion, `p`, is true.\n\nNote that the `theorem` command is really a version of the `def` command:\nunder the propositions and types correspondence, proving the theorem `p → q →\np` is really the same as defining an element of the associated type. To the\nkernel type checker, there is no difference between the two.\n\nThere are a few pragmatic differences between definitions and theorems,\nhowever. In normal circumstances, it is never necessary to unfold the\n"definition" of a theorem; by proof irrelevance, any two proofs of that\ntheorem are definitionally equal. Once the proof of a theorem is complete,\ntypically we only need to know that the proof exists; it doesn\'t matter what\nthe proof is. In light of that fact, Lean tags proofs as _irreducible_ , which\nserves as a hint to the parser (more precisely, the _elaborator_) that there\nis generally no need to unfold them when processing a file. In fact, Lean is\ngenerally able to process and check proofs in parallel, since assessing the\ncorrectness of one proof does not require knowing the details of another.\n\nAs with definitions, the `#print` command will show you the proof of a\ntheorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n    #print t1\n    \n\nNotice that the lambda abstractions `hp : p` and `hq : q` can be viewed as\ntemporary assumptions in the proof of `t1`. Lean also allows us to specify the\ntype of the final term `hp`, explicitly, with a `show` statement:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p :=\n      fun hp : p =>\n      fun hq : q =>\n      show p from hp\n    \n\nAdding such extra information can improve the clarity of a proof and help\ndetect errors when writing a proof. The `show` command does nothing more than\nannotate the type, and, internally, all the presentations of `t1` that we have\nseen produce the same term.\n\nAs with ordinary definitions, we can move the lambda-abstracted variables to\nthe left of the colon:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    #print t1    -- p → q → p\n    \n\nWe can use the theorem `t1` just as a function application:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    axiom hp : p\n    \n    theorem t2 : q → p := t1 hp\n    \n\nThe `axiom` declaration postulates the existence of an element of the given\ntype and may compromise logical consistency. For example, we can use it to\npostulate that the empty type `False` has an element:\n\n    \n    \n    axiom unsound : False\n    -- Everything follows from false\n    theorem ex : 1 = 0 :=\n      False.elim unsound\n    \n\nDeclaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as\nwitnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`\nthat `p` is true yields the theorem `t1 hp : q → p`.\n\nRecall that we can also write theorem `t1` as follows:\n\n    \n    \n    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp\n    \n    #print t1\n    \n\nThe type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the\nassertion "for every pair of propositions `p q`, we have `p → q → p`." For\nexample, we can move all parameters to the right of the colon:\n\n    \n    \n    theorem t1 : ∀ {p q : Prop}, p → q → p :=\n      fun {p q : Prop} (hp : p) (hq : q) => hp\n    \n\nIf `p` and `q` have been declared as variables, Lean will generalize them for\nus automatically:\n\n    \n    \n    variable {p q : Prop}\n    \n    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp\n    \n\nIn fact, by the propositions-as-types correspondence, we can declare the\nassumption `hp` that `p` holds, as another variable:\n\n    \n    \n    variable {p q : Prop}\n    variable (hp : p)\n    \n    theorem t1 : q → p := fun (hq : q) => hp\n    \n\nLean detects that the proof uses `hp` and automatically adds `hp : p` as a\npremise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →\nq → p`. Remember that this type can just as well be written `∀ (p q : Prop)\n(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type\nin which the target does not depend on the bound variable.\n\nWhen we generalize `t1` in such a way, we can then apply it to different pairs\nof propositions, to obtain different instances of the general theorem.\n\n    \n    \n    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp\n    \n    variable (p q r s : Prop)\n    \n    #check t1 p q                -- p → q → p\n    #check t1 r s                -- r → s → r\n    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s\n    \n    variable (h : r → s)\n    #check t1 (r → s) (s → r) h  -- (s → r) → r → s\n    \n\nOnce again, using the propositions-as-types correspondence, the variable `h`\nof type `r → s` can be viewed as the hypothesis, or premise, that `r → s`\nholds.\n\nAs another example, let us consider the composition function discussed in the\nlast chapter, now with propositions instead of types.\n\n    \n    \n    variable (p q r s : Prop)\n    \n    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=\n      fun h₃ : p =>\n      show r from h₁ (h₂ h₃)\n    \n\nAs a theorem of propositional logic, what does `t2` say?\n\nNote that it is often useful to use numeric unicode subscripts, entered as\n`\\0`, `\\1`, `\\2`, ..., for hypotheses, as we did in this example.\n\n## Propositional Logic\n\nLean defines all the standard logical connectives and notation. The\npropositional connectives come with the following notation:\n\nAscii| Unicode| Editor shortcut| Definition  \n---|---|---|---  \nTrue| | | True  \nFalse| | | False  \nNot| ¬| `\\not`, `\\neg`| Not  \n/\\| ∧| `\\and`| And  \n\\/| ∨| `\\or`| Or  \n->| →| `\\to`, `\\r`, `\\imp`|   \n<->| ↔| `\\iff`, `\\lr`| Iff  \n  \nThey all take values in `Prop`.\n\n    \n    \n    variable (p q : Prop)\n    \n    #check p → q → p ∧ q\n    #check ¬p → p ↔ False\n    #check p ∨ q → q ∨ p\n    \n\nThe order of operations is as follows: unary negation `¬` binds most strongly,\nthen `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧\ne` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right\n(nothing changes now that the arguments are elements of `Prop`, instead of\nsome other `Type`), as do the other binary connectives. So if we have `p q r :\nProp`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This\nis just the "curried" form of `p ∧ q → r`.\n\nIn the last chapter we observed that lambda abstraction can be viewed as an\n"introduction rule" for `→`. In the current setting, it shows how to\n"introduce" or establish an implication. Application can be viewed as an\n"elimination rule," showing how to "eliminate" or use an implication in a\nproof. The other propositional connectives are defined in Lean\'s library in\nthe file `Prelude.core` (see [importing\nfiles](./interacting_with_lean.html#importing-files) for more information on\nthe library hierarchy), and each connective comes with its canonical\nintroduction and elimination rules.\n\n### Conjunction\n\nThe expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :\np` and `h2 : q`. It is common to describe `And.intro` as the _and-\nintroduction_ rule. In the next example we use `And.intro` to create a proof\nof `p → q → p ∧ q`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq\n    \n    #check fun (hp : p) (hq : q) => And.intro hp hq\n    \n\nThe `example` command states a theorem without naming it or storing it in the\npermanent context. Essentially, it just checks that the given term has the\nindicated type. It is convenient for illustration, and we will use it often.\n\nThe expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.\nSimilarly, `And.right h` is a proof of `q`. They are commonly known as the\nleft and right _and-elimination_ rules.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : p := And.left h\n    example (h : p ∧ q) : q := And.right h\n    \n\nWe can now prove `p ∧ q → q ∧ p` with the following proof term.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      And.intro (And.right h) (And.left h)\n    \n\nNotice that and-introduction and and-elimination are similar to the pairing\nand projection operations for the Cartesian product. The difference is that\ngiven `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while\n`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is\nanother instance of the Curry-Howard isomorphism, but in contrast to\nimplication and the function space constructor, `∧` and `×` are treated\nseparately in Lean. With the analogy, however, the proof we have just\nconstructed is similar to a function that swaps the elements of a pair.\n\nWe will see in [Chapter Structures and Records](./structures_and_records.html)\nthat certain types in Lean are _structures_ , which is to say, the type is\ndefined with a single canonical _constructor_ which builds an element of the\ntype from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is\nan example: the canonical way to construct an element is to apply `And.intro`\nto suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous\nconstructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the\nrelevant type is an inductive type and can be inferred from the context. In\nparticular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:\n\n    \n    \n    variable (p q : Prop)\n    variable (hp : p) (hq : q)\n    \n    #check (⟨hp, hq⟩ : p ∧ q)\n    \n\nThese angle brackets are obtained by typing `\\<` and `\\>`, respectively.\n\nLean provides another useful syntactic gadget. Given an expression `e` of an\ninductive type `Foo` (possibly applied to some arguments), the notation\n`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of\naccessing functions without opening a namespace. For example, the following\ntwo expressions mean the same thing:\n\n    \n    \n    variable (xs : List Nat)\n    \n    #check List.length xs\n    #check xs.length\n    \n\nAs a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and\n`h.right` for `And.right h`. We can therefore rewrite the sample proof above\nconveniently as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      ⟨h.right, h.left⟩\n    \n\nThere is a fine line between brevity and obfuscation, and omitting information\nin this way can sometimes make a proof harder to read. But for straightforward\nconstructions like the one above, when the type of `h` and the goal of the\nconstruction are salient, the notation is clean and effective.\n\nIt is common to iterate constructions like "And." Lean also allows you to\nflatten nested constructors that associate to the right, so that these two\nproofs are equivalent:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, ⟨h.left, h.right⟩⟩\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, h.left, h.right⟩\n    \n\nThis is often useful as well.\n\n### Disjunction\n\nThe expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof\n`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a\nproof `hq : q`. These are the left and right _or-introduction_ rules.\n\n    \n    \n    variable (p q : Prop)\n    example (hp : p) : p ∨ q := Or.intro_left q hp\n    example (hq : q) : p ∨ q := Or.intro_right p hq\n    \n\nThe _or-elimination_ rule is slightly more complicated. The idea is that we\ncan prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`\nfollows from `q`. In other words, it is a proof by cases. In the expression\n`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :\np → r` and `hqr : q → r`, and produces a proof of `r`. In the following\nexample, we use `Or.elim` to prove `p ∨ q → q ∨ p`.\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h\n        (fun hp : p =>\n          show q ∨ p from Or.intro_right q hp)\n        (fun hq : q =>\n          show q ∨ p from Or.intro_left p hq)\n    \n\nIn most cases, the first argument of `Or.intro_right` and `Or.intro_left` can\nbe inferred automatically by Lean. Lean therefore provides `Or.inr` and\n`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and\n`Or.intro_left _`. Thus the proof term above could be written more concisely:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nNotice that there is enough information in the full expression for Lean to\ninfer the types of `hp` and `hq` as well. But using the type annotations in\nthe longer version makes the proof more readable, and can help catch and debug\nerrors.\n\nBecause `Or` has two constructors, we cannot use anonymous constructor\nnotation. But we can still write `h.elim` instead of `Or.elim h`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nOnce again, you should exercise judgment as to whether such abbreviations\nenhance or diminish readability.\n\n### Negation and Falsity\n\nNegation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by\nderiving a contradiction from `p`. Similarly, the expression `hnp hp` produces\na proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both\nthese rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is\nproduced by typing `\\not` or `\\neg`.)\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hpq : p → q) (hnq : ¬q) : ¬p :=\n      fun hp : p =>\n      show False from hnq (hpq hp)\n    \n\nThe connective `False` has a single elimination rule, `False.elim`, which\nexpresses the fact that anything follows from a contradiction. This rule is\nsometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the\n_principle of explosion_.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)\n    \n\nThe arbitrary fact, `q`, that follows from falsity is an implicit argument in\n`False.elim` and is inferred automatically. This pattern, deriving an\narbitrary fact from contradictory hypotheses, is quite common, and is\nrepresented by `absurd`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := absurd hp hnp\n    \n\nHere, for example, is a proof of `¬p → q → (q → p) → r`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=\n      absurd (hqp hq) hnp\n    \n\nIncidentally, just as `False` has only an elimination rule, `True` has only an\nintroduction rule, `True.intro : true`. In other words, `True` is simply true,\nand has a canonical proof, `True.intro`.\n\n### Logical Equivalence\n\nThe expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`\nand `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from\n`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔\nq`. Here is a proof of `p ∧ q ↔ q ∧ p`:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      Iff.intro\n        (fun h : p ∧ q =>\n         show q ∧ p from And.intro (And.right h) (And.left h))\n        (fun h : q ∧ p =>\n         show p ∧ q from And.intro (And.right h) (And.left h))\n    \n    #check and_swap p q    -- p ∧ q ↔ q ∧ p\n    \n    variable (h : p ∧ q)\n    example : q ∧ p := Iff.mp (and_swap p q) h\n    \n\nWe can use the anonymous constructor notation to construct a proof of `p ↔ q`\nfrom proofs of the forward and backward directions, and we can also use `.`\nnotation with `mp` and `mpr`. The previous examples can therefore be written\nconcisely as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩\n    \n    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h\n    \n\n## Introducing Auxiliary Subgoals\n\nThis is a good place to introduce another device Lean offers to help structure\nlong proofs, namely, the `have` construct, which introduces an auxiliary\nsubgoal in a proof. Here is a small example, adapted from the last section:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      have hq : q := h.right\n      show q ∧ p from And.intro hq hp\n    \n\nInternally, the expression `have h : p := s; t` produces the term `(fun (h :\np) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the\ndesired conclusion assuming `h : p`, and the two are combined by a lambda\nabstraction and application. This simple device is extremely useful when it\ncomes to structuring long proofs, since we can use intermediate `have`\'s as\nstepping stones leading to the final goal.\n\nLean also supports a structured way of reasoning backwards from a goal, which\nmodels the "suffices to show" construction in ordinary mathematics. The next\nexample simply permutes the last two lines in the previous proof.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      suffices hq : q from And.intro hq hp\n      show q from And.right h\n    \n\nWriting `suffices hq : q` leaves us with two goals. First, we have to show\nthat it indeed suffices to show `q`, by proving the original goal of `q ∧ p`\nwith the additional hypothesis `hq : q`. Finally, we have to show `q`.\n\n## Classical Logic\n\nThe introduction and elimination rules we have seen so far are all\nconstructive, which is to say, they reflect a computational understanding of\nthe logical connectives based on the propositions-as-types correspondence.\nOrdinary classical logic adds to this the law of the excluded middle, `p ∨\n¬p`. To use this principle, you have to open the classical namespace.\n\n    \n    \n    open Classical\n    \n    variable (p : Prop)\n    #check em p\n    \n\nIntuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts\nto knowing which is the case. If `RH` represents the Riemann hypothesis, a\nclassical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot\nyet assert either disjunct.\n\nOne consequence of the law of the excluded middle is the principle of double-\nnegation elimination:\n\n    \n    \n    open Classical\n    \n    theorem dne {p : Prop} (h : ¬¬p) : p :=\n      Or.elim (em p)\n        (fun hp : p => hp)\n        (fun hnp : ¬p => absurd hnp h)\n    \n\nDouble-negation elimination allows one to prove any proposition, `p`, by\nassuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In\nother words, double-negation elimination allows one to carry out a proof by\ncontradiction, something which is not generally possible in constructive\nlogic. As an exercise, you might try proving the converse, that is, showing\nthat `em` can be proved from `dne`.\n\nThe classical axioms also give you access to additional patterns of proof that\ncan be justified by appeal to `em`. For example, one can carry out a proof by\ncases:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byCases\n        (fun h1 : p => h1)\n        (fun h1 : ¬p => absurd h1 h)\n    \n\nOr you can carry out a proof by contradiction:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byContradiction\n        (fun h1 : ¬p =>\n         show False from h h1)\n    \n\nIf you are not used to thinking constructively, it may take some time for you\nto get a sense of where classical reasoning is used. It is needed in the\nfollowing example because, from a constructive standpoint, knowing that `p`\nand `q` are not both true does not necessarily tell you which one is false:\n\n    \n    \n    open Classical\n    variable (p q : Prop)\n    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=\n      Or.elim (em p)\n        (fun hp : p =>\n          Or.inr\n            (show ¬q from\n              fun hq : q =>\n              h ⟨hp, hq⟩))\n        (fun hp : ¬p =>\n          Or.inl hp)\n    \n\nWe will see later that there _are_ situations in constructive logic where\nprinciples like excluded middle and double-negation elimination are\npermissible, and Lean supports the use of classical reasoning in such contexts\nwithout relying on excluded middle.\n\nThe full list of axioms that are used in Lean to support classical reasoning\nare discussed in [Axioms and Computation](./axioms_and_computation.html).\n\n## Examples of Propositional Validities\n\nLean\'s standard library contains proofs of many valid statements of\npropositional logic, all of which you are free to use in proofs of your own.\nThe following list includes a number of common identities.\n\nCommutativity:\n\n  1. `p ∧ q ↔ q ∧ p`\n  2. `p ∨ q ↔ q ∨ p`\n\nAssociativity:\n\n  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`\n  4. `(p ∨ q) ∨ r ↔ p ∨ (q �'}], 'model': 'gpt-4o'}}
2025-06-01 03:01:08,274 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:01:08,274 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:01:08,274 - DEBUG - send_request_headers.complete
2025-06-01 03:01:08,274 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:01:08,279 - DEBUG - send_request_body.complete
2025-06-01 03:01:08,279 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:01:20,317 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:01:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'11616'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'11620'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'15547'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'28.906s'), (b'x-request-id', b'req_2aa149b842be747edd9b781dab64ce65'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b76f6ef4e8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:01:20,317 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:01:20,317 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:01:20,321 - DEBUG - receive_response_body.complete
2025-06-01 03:01:20,321 - DEBUG - response_closed.started
2025-06-01 03:01:20,321 - DEBUG - response_closed.complete
2025-06-01 03:01:20,321 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:01:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '11616', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '11620', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '15547', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '28.906s', 'x-request-id': 'req_2aa149b842be747edd9b781dab64ce65', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b76f6ef4e8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:01:20,322 - DEBUG - request_id: req_2aa149b842be747edd9b781dab64ce65
2025-06-01 03:01:20,322 - INFO - Raw solution received: ```json
{
  "code": "if a.isEmpty || b.isEmpty then\n    false\n  else\n    let rec iterate (i : Nat) : Bool :=\n      if i < a.size then\n        let rec checkMembership (j : Nat) : Bool :=\n          if j < b.size then\n            if a[i]! = b[j]! then true\n            else checkMembership (j + 1)\n          else false\n        checkMembership 0 || iterate (i + 1)\n      else\n        false\n    iterate 0",
  "proof": "by_cases h : a.isEmpty || b.isEmpty\n  case inl =>\n    simp [h, hasCommonElement_spec]\n  case inr =>\n    simp [h] at h\n    let ⟨hneA, hneB⟩ := not_or_distrib.mp h\n    induction a using Array.induction_on with\n    | base =>\n      exfalso; exact hneA rfl\n    | step a hd tl ih =>\n      cases b using Array.revBox with\n      | nil =>\n        exfalso; exact hneB rfl\n      | cons b bs =>\n        -- Unfold the function and apply structural recursion to check membership\n        unfold hasCommonElement\n        suffices h' : (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ hd = b ∨ tl.contains b\n        from simp [h']\n        apply Iff.intro\n        -- Forward direction: assume existence of common element\n        case mp =>\n          rintro ⟨i, j, hi, hj, h_eq⟩\n          cases a.size_eq_zero_or_pos i with\n          | inr hiZero =>\n            exact Or.inl h_eq.symm\n          | inl hiEq =>\n            apply Or.inr\n            unfold iterate at ih\n            simp [ih]\n            use i, j\n            simp [hi, hj, h_eq]\n        -- Backward direction: use exists introduction\n        case mpr =>\n          intro h\n          cases h with\n          | inl h_eq =>\n            use 0, 0\n            simp [h_eq.symm]\n          | inr h_tl =>\n            use 1, 0\n            simp [h_tl]\n            apply ih.mpr h_tl\n          done"
}
```
2025-06-01 03:01:20,322 - INFO - <class 'str'>
2025-06-01 03:01:20,322 - INFO - Generated solution: {'code': 'if a.isEmpty || b.isEmpty then\n    false\n  else\n    let rec iterate (i : Nat) : Bool :=\n      if i < a.size then\n        let rec checkMembership (j : Nat) : Bool :=\n          if j < b.size then\n            if a[i]! = b[j]! then true\n            else checkMembership (j + 1)\n          else false\n        checkMembership 0 || iterate (i + 1)\n      else\n        false\n    iterate 0', 'proof': "by_cases h : a.isEmpty || b.isEmpty\n  case inl =>\n    simp [h, hasCommonElement_spec]\n  case inr =>\n    simp [h] at h\n    let ⟨hneA, hneB⟩ := not_or_distrib.mp h\n    induction a using Array.induction_on with\n    | base =>\n      exfalso; exact hneA rfl\n    | step a hd tl ih =>\n      cases b using Array.revBox with\n      | nil =>\n        exfalso; exact hneB rfl\n      | cons b bs =>\n        -- Unfold the function and apply structural recursion to check membership\n        unfold hasCommonElement\n        suffices h' : (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ hd = b ∨ tl.contains b\n        from simp [h']\n        apply Iff.intro\n        -- Forward direction: assume existence of common element\n        case mp =>\n          rintro ⟨i, j, hi, hj, h_eq⟩\n          cases a.size_eq_zero_or_pos i with\n          | inr hiZero =>\n            exact Or.inl h_eq.symm\n          | inl hiEq =>\n            apply Or.inr\n            unfold iterate at ih\n            simp [ih]\n            use i, j\n            simp [hi, hj, h_eq]\n        -- Backward direction: use exists introduction\n        case mpr =>\n          intro h\n          cases h with\n          | inl h_eq =>\n            use 0, 0\n            simp [h_eq.symm]\n          | inr h_tl =>\n            use 1, 0\n            simp [h_tl]\n            apply ih.mpr h_tl\n          done"}
2025-06-01 03:01:26,805 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:35:2: error: Case tag 'inl' not found.

Available tags: 'pos._@.lean_playground.TempTest._hyg.2137', 'neg._@.lean_playground.TempTest._hyg.2137'
2025-06-01 03:01:26,806 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasCommonElement (a : Array Int) (b : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the method returns true, there exists at least one common element between the two arrays; If the method returns false, there are no common elements between the two arrays\ndef hasCommonElement_spec (a : Array Int) (b : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ result\n  -- << SPEC END >>\n\ntheorem hasCommonElement_spec_satisfied (a : Array Int) (b : Array Int) :\n  hasCommonElement_spec a b (hasCommonElement a b) := by\n  -- << PROOF START >>\n  unfold hasCommonElement hasCommonElement_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a.isEmpty || b.isEmpty then\n    false\n  else\n    let rec iterate (i : Nat) : Bool :=\n      if i < a.size then\n        let rec checkMembership (j : Nat) : Bool :=\n          if j < b.size then\n            if a[i]! = b[j]! then true\n            else checkMembership (j + 1)\n          else false\n        checkMembership 0 || iterate (i + 1)\n      else\n        false\n    iterate 0\n\nGenerated Proof:\nby_cases h : a.isEmpty || b.isEmpty\n  case inl =>\n    simp [h, hasCommonElement_spec]\n  case inr =>\n    simp [h] at h\n    let ⟨hneA, hneB⟩ := not_or_distrib.mp h\n    induction a using Array.induction_on with\n    | base =>\n      exfalso; exact hneA rfl\n    | step a hd tl ih =>\n      cases b using Array.revBox with\n      | nil =>\n        exfalso; exact hneB rfl\n      | cons b bs =>\n        -- Unfold the function and apply structural recursion to check membership\n        unfold hasCommonElement\n        suffices h' : (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ hd = b ∨ tl.contains b\n        from simp [h']\n        apply Iff.intro\n        -- Forward direction: assume existence of common element\n        case mp =>\n          rintro ⟨i, j, hi, hj, h_eq⟩\n          cases a.size_eq_zero_or_pos i with\n          | inr hiZero =>\n            exact Or.inl h_eq.symm\n          | inl hiEq =>\n            apply Or.inr\n            unfold iterate at ih\n            simp [ih]\n            use i, j\n            simp [hi, hj, h_eq]\n        -- Backward direction: use exists introduction\n        case mpr =>\n          intro h\n          cases h with\n          | inl h_eq =>\n            use 0, 0\n            simp [h_eq.symm]\n          | inr h_tl =>\n            use 1, 0\n            simp [h_tl]\n            apply ih.mpr h_tl\n          done\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:35:2: error: Case tag 'inl' not found.\n\nAvailable tags: 'pos._@.lean_playground.TempTest._hyg.2137', 'neg._@.lean_playground.TempTest._hyg.2137'"}], 'model': 'o3-mini'}}
2025-06-01 03:01:26,806 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:01:26,806 - DEBUG - close.started
2025-06-01 03:01:26,807 - DEBUG - close.complete
2025-06-01 03:01:26,807 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:01:26,815 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a5970>
2025-06-01 03:01:26,816 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:01:26,825 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a5c40>
2025-06-01 03:01:26,825 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:01:26,825 - DEBUG - send_request_headers.complete
2025-06-01 03:01:26,826 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:01:26,826 - DEBUG - send_request_body.complete
2025-06-01 03:01:26,826 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:01:33,810 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:01:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6698'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6752'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198786'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'363ms'), (b'x-request-id', b'req_cb3c8eecdda5126e5144a8d7ad138045'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b776ada4046f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:01:33,810 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:01:33,810 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:01:33,811 - DEBUG - receive_response_body.complete
2025-06-01 03:01:33,811 - DEBUG - response_closed.started
2025-06-01 03:01:33,811 - DEBUG - response_closed.complete
2025-06-01 03:01:33,811 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:01:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6698', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6752', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198786', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '363ms', 'x-request-id': 'req_cb3c8eecdda5126e5144a8d7ad138045', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b776ada4046f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:01:33,811 - DEBUG - request_id: req_cb3c8eecdda5126e5144a8d7ad138045
2025-06-01 03:01:33,811 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof uses case tags 'inl' and 'inr' for the 'by_cases' on h : a.isEmpty || b.isEmpty, but Lean 4 names these cases as 'pos' for the true branch and 'neg' for the false branch. This mismatch leads to a case tag not found error.", 'error_type': 'syntax', 'suggested_fix': "Replace the case tags 'inl' and 'inr' with 'pos' and 'neg' respectively. For example, change 'by_cases h : a.isEmpty || b.isEmpty' to use 'case pos =>' for the true branch and 'case neg =>' for the false branch.", 'retry_strategy': 'Update the by_cases case names and re-run the proof. Verify that other parts of the proof (especially the induction and case analysis on arrays) conform with the expected Lean 4 syntax and semantics.'}
2025-06-01 03:01:33,812 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.\n\nPrevious plan:\n{\n  "plan_summary": "Revise the implementation to avoid using unknown constants tied to built-in functions and instead directly use (or define) an iterative approach whose correctness is proved by explicit unfolding of definitions. In this revised plan, we avoid relying on the unproven equivalences of Array.any and Array.contains and develop an approach (and associated auxiliary lemmas) that explicitly show the equivalence between a common element existing and the iterative check returning true.",\n  "steps": [\n    "Handle initial edge case: check if either array is empty and return false immediately.",\n    "Implement an iterative (or recursive) function that traverses the first array. For each element, manually check for membership in the second array by iterating over it.",\n    "Avoid relying on Array.any or Array.contains’s built-in equivalences. Instead, define a helper function (if needed) that takes an element and a second array and returns true only if the element is explicitly found within the structure.",\n    "After iterating through all elements, if no match is found, return false.",\n    "Develop auxiliary lemmas that unfold the definitions of the helper functions to prove that the function returns true if and only if there exist indices i and j such that the i-th element of the first array equals the j-th element of the second array. Use explicit case analysis or induction on the structure of arrays to achieve this.",\n    "Optionally, when proving the correctness, use induction on the length of the first array to show that if no element in the list passes the membership test, then there is no common element, and vice versa."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array",\n    "Integer",\n    "membership",\n    "iteration",\n    "recursive function"\n  ],\n  "proof_keywords": [\n    "unfolding definitions",\n    "inductive proof",\n    "auxiliary lemmas",\n    "case analysis",\n    "correctness proof"\n  ],\n  "assumptions": [\n    "The arrays are of type Array Int.",\n    "Manual recursion or iteration is allowed over array elements.",\n    "It is acceptable to define custom helper functions for membership checking to avoid dependency on unknown constants.",\n    "Explicit induction on the array length is a viable strategy for proving correctness."\n  ],\n  "retry_guidance": "If further issues arise, ensure that you fully expand the definitions used for membership testing and array iteration. Avoid referencing non-existent built-in equivalences; instead, provide detailed inductions or case splits that capture the intended logical equivalences in lean."\n}\n\nLean error summary:\nThe proof fails mainly because it incorrectly uses unknown constants \'Array.any_eq_exists\' and \'Array.contains_eq_exists\' (and a related unsolved goal). In addition, the proof does not fully unfold the definitions of Array.any and Array.contains to show the equivalence between \'a.any (λ x => b.contains x)\' and the existence of indices i and j satisfying the spec.\nRetry guidance (MUST FOLLOW):\nRevise the proof by explicitly expanding the definitions of Array.any and Array.contains, use basic tactics such as by_cases to handle emptiness cases, and apply Iff.intro to prove both directions of the equivalence. This approach avoids relying on unknown lemmas and should help in closing the proof obligations.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThe proof uses case tags \'inl\' and \'inr\' for the \'by_cases\' on h : a.isEmpty || b.isEmpty, but Lean 4 names these cases as \'pos\' for the true branch and \'neg\' for the false branch. This mismatch leads to a case tag not found error.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 03:01:33,813 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:01:33,813 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:01:33,813 - DEBUG - send_request_headers.complete
2025-06-01 03:01:33,813 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:01:33,813 - DEBUG - send_request_body.complete
2025-06-01 03:01:33,813 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:01:42,025 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:01:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7987'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7992'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198576'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'427ms'), (b'x-request-id', b'req_dad4cb318891f696d5ef32c57921e860'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b77968fd946f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:01:42,026 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:01:42,026 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:01:42,026 - DEBUG - receive_response_body.complete
2025-06-01 03:01:42,026 - DEBUG - response_closed.started
2025-06-01 03:01:42,027 - DEBUG - response_closed.complete
2025-06-01 03:01:42,027 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:01:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7987', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7992', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198576', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '427ms', 'x-request-id': 'req_dad4cb318891f696d5ef32c57921e860', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b77968fd946f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:01:42,027 - DEBUG - request_id: req_dad4cb318891f696d5ef32c57921e860
2025-06-01 03:01:42,027 - INFO - Attempt 3/3
2025-06-01 03:01:42,027 - INFO - Current plan: {
  "plan_summary": "Revise the previous plan by eliminating reliance on unknown lemmas and expanding definitions manually. Make sure to correct the case tags in the by_cases tactic to 'pos' for the true branch and 'neg' for the false branch. The plan includes handling edge cases for empty arrays and using explicit iteration (or recursion), with an auxiliary membership check and induction to prove correctness.",
  "steps": [
    "Handle the edge cases: use a by_cases on whether a.isEmpty || b.isEmpty and use the correct branch tags 'pos' (when true) and 'neg' (when false) to check these cases.",
    "Define a helper function (or explicitly write the logic) to iterate over the first array. For each element, iterate over the second array to check for membership without relying on Array.any or Array.contains.",
    "Explicitly expand the definitions of Array.any and Array.contains if they are used, ensuring that each equivalence is established through case analysis.",
    "Develop auxiliary lemmas that show the existence of a common element if and only if the iterative check returns true. In these lemmas, use induction on the length of the array and explicit case splits.",
    "Use tactics such as by_cases with the proper branch tags and Iff.intro for proving both directions of the equivalence between the existence of indices with equal elements and a true return value.",
    "Ensure all proofs are complete, without any use of 'sorry', and that case labels match Lean 4's expected tags to avoid errors."
  ],
  "code_keywords": [
    "Lean 4",
    "Array",
    "Integer",
    "iteration",
    "recursion",
    "helper function",
    "by_cases"
  ],
  "proof_keywords": [
    "inductive proof",
    "auxiliary lemmas",
    "Iff.intro",
    "case analysis",
    "definition unfolding",
    "edge case handling"
  ],
  "assumptions": [
    "Arrays are of type Array Int.",
    "It's acceptable to define helper functions for membership checking.",
    "Explicit unfolding of definitions is preferred over using unknown built-in equivalences.",
    "Using by_cases with correct branch tag names ('pos' and 'neg') is compatible with Lean 4."
  ],
  "retry_guidance": "Make sure that all case distinctions especially in by_cases use the correct Lean 4 branch tags ('pos' for the true case and 'neg' for the false case). Expand the definitions of array membership explicitly and use basic tactics like by_cases and Iff.intro to eliminate reliance on unknown constants. Verify that all indices and recurrences align with the induction hypothesis to ensure the main correctness proof successfully closes."
}
2025-06-01 03:01:42,027 - INFO - Updated plan: {
  "plan_summary": "Revise the previous plan by eliminating reliance on unknown lemmas and expanding definitions manually. Make sure to correct the case tags in the by_cases tactic to 'pos' for the true branch and 'neg' for the false branch. The plan includes handling edge cases for empty arrays and using explicit iteration (or recursion), with an auxiliary membership check and induction to prove correctness.",
  "steps": [
    "Handle the edge cases: use a by_cases on whether a.isEmpty || b.isEmpty and use the correct branch tags 'pos' (when true) and 'neg' (when false) to check these cases.",
    "Define a helper function (or explicitly write the logic) to iterate over the first array. For each element, iterate over the second array to check for membership without relying on Array.any or Array.contains.",
    "Explicitly expand the definitions of Array.any and Array.contains if they are used, ensuring that each equivalence is established through case analysis.",
    "Develop auxiliary lemmas that show the existence of a common element if and only if the iterative check returns true. In these lemmas, use induction on the length of the array and explicit case splits.",
    "Use tactics such as by_cases with the proper branch tags and Iff.intro for proving both directions of the equivalence between the existence of indices with equal elements and a true return value.",
    "Ensure all proofs are complete, without any use of 'sorry', and that case labels match Lean 4's expected tags to avoid errors."
  ],
  "code_keywords": [
    "Lean 4",
    "Array",
    "Integer",
    "iteration",
    "recursion",
    "helper function",
    "by_cases"
  ],
  "proof_keywords": [
    "inductive proof",
    "auxiliary lemmas",
    "Iff.intro",
    "case analysis",
    "definition unfolding",
    "edge case handling"
  ],
  "assumptions": [
    "Arrays are of type Array Int.",
    "It's acceptable to define helper functions for membership checking.",
    "Explicit unfolding of definitions is preferred over using unknown built-in equivalences.",
    "Using by_cases with correct branch tag names ('pos' and 'neg') is compatible with Lean 4."
  ],
  "retry_guidance": "Make sure that all case distinctions especially in by_cases use the correct Lean 4 branch tags ('pos' for the true case and 'neg' for the false case). Expand the definitions of array membership explicitly and use basic tactics like by_cases and Iff.intro to eliminate reliance on unknown constants. Verify that all indices and recurrences align with the induction hypothesis to ensure the main correctness proof successfully closes."
}

Lean error summary:
The proof uses case tags 'inl' and 'inr' for the 'by_cases' on h : a.isEmpty || b.isEmpty, but Lean 4 names these cases as 'pos' for the true branch and 'neg' for the false branch. This mismatch leads to a case tag not found error.
Retry guidance (MUST FOLLOW):
Update the by_cases case names and re-run the proof. Verify that other parts of the proof (especially the induction and case analysis on arrays) conform with the expected Lean 4 syntax and semantics.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 03:01:42,028 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the previous plan by eliminating reliance on unknown lemmas and expanding definitions manually. Make sure to correct the case tags in the by_cases tactic to \'pos\' for the true branch and \'neg\' for the false branch. The plan includes handling edge cases for empty arrays and using explicit iteration (or recursion), with an auxiliary membership check and induction to prove correctness.",\n  "steps": [\n    "Handle the edge cases: use a by_cases on whether a.isEmpty || b.isEmpty and use the correct branch tags \'pos\' (when true) and \'neg\' (when false) to check these cases.",\n    "Define a helper function (or explicitly write the logic) to iterate over the first array. For each element, iterate over the second array to check for membership without relying on Array.any or Array.contains.",\n    "Explicitly expand the definitions of Array.any and Array.contains if they are used, ensuring that each equivalence is established through case analysis.",\n    "Develop auxiliary lemmas that show the existence of a common element if and only if the iterative check returns true. In these lemmas, use induction on the length of the array and explicit case splits.",\n    "Use tactics such as by_cases with the proper branch tags and Iff.intro for proving both directions of the equivalence between the existence of indices with equal elements and a true return value.",\n    "Ensure all proofs are complete, without any use of \'sorry\', and that case labels match Lean 4\'s expected tags to avoid errors."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array",\n    "Integer",\n    "iteration",\n    "recursion",\n    "helper function",\n    "by_cases"\n  ],\n  "proof_keywords": [\n    "inductive proof",\n    "auxiliary lemmas",\n    "Iff.intro",\n    "case analysis",\n    "definition unfolding",\n    "edge case handling"\n  ],\n  "assumptions": [\n    "Arrays are of type Array Int.",\n    "It\'s acceptable to define helper functions for membership checking.",\n    "Explicit unfolding of definitions is preferred over using unknown built-in equivalences.",\n    "Using by_cases with correct branch tag names (\'pos\' and \'neg\') is compatible with Lean 4."\n  ],\n  "retry_guidance": "Make sure that all case distinctions especially in by_cases use the correct Lean 4 branch tags (\'pos\' for the true case and \'neg\' for the false case). Expand the definitions of array membership explicitly and use basic tactics like by_cases and Iff.intro to eliminate reliance on unknown constants. Verify that all indices and recurrences align with the induction hypothesis to ensure the main correctness proof successfully closes."\n}\n\nLean error summary:\nThe proof uses case tags \'inl\' and \'inr\' for the \'by_cases\' on h : a.isEmpty || b.isEmpty, but Lean 4 names these cases as \'pos\' for the true branch and \'neg\' for the false branch. This mismatch leads to a case tag not found error.\nRetry guidance (MUST FOLLOW):\nUpdate the by_cases case names and re-run the proof. Verify that other parts of the proof (especially the induction and case analysis on arrays) conform with the expected Lean 4 syntax and semantics.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasCommonElement (a : Array Int) (b : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the method returns true, there exists at least one common element between the two arrays; If the method returns false, there are no common elements between the two arrays\ndef hasCommonElement_spec (a : Array Int) (b : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ result\n  -- << SPEC END >>\n\ntheorem hasCommonElement_spec_satisfied (a : Array Int) (b : Array Int) :\n  hasCommonElement_spec a b (hasCommonElement a b) := by\n  -- << PROOF START >>\n  unfold hasCommonElement hasCommonElement_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Propositions and Proofs\n\nBy now, you have seen some ways of defining objects and functions in Lean. In\nthis chapter, we will begin to explain how to write mathematical assertions\nand proofs in the language of dependent type theory as well.\n\n## Propositions as Types\n\nOne strategy for proving assertions about objects defined in the language of\ndependent type theory is to layer an assertion language and a proof language\non top of the definition language. But there is no reason to multiply\nlanguages in this way: dependent type theory is flexible and expressive, and\nthere is no reason we cannot represent assertions and proofs in the same\ngeneral framework.\n\nFor example, we could introduce a new type, `Prop`, to represent propositions,\nand introduce constructors to build new propositions from others.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    #check And     -- Prop → Prop → Prop\n    #check Or      -- Prop → Prop → Prop\n    #check Not     -- Prop → Prop\n    #check Implies -- Prop → Prop → Prop\n    \n    variable (p q r : Prop)\n    #check And p q                      -- Prop\n    #check Or (And p q) r               -- Prop\n    #check Implies (And p q) (And q p)  -- Prop\n    \n\nWe could then introduce, for each element `p : Prop`, another type `Proof p`,\nfor the type of proofs of `p`. An "axiom" would be a constant of such a type.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    #check Proof   -- Proof : Prop → Type\n    \n    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))\n    \n    variable (p q : Prop)\n    #check and_comm p q     -- Proof (Implies (And p q) (And q p))\n    \n\nIn addition to axioms, however, we would also need rules to build new proofs\nfrom old ones. For example, in many proof systems for propositional logic, we\nhave the rule of _modus ponens_ :\n\n> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.\n\nWe could represent this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q\n    \n\nSystems of natural deduction for propositional logic also typically rely on\nthe following rule:\n\n> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we\n> can "cancel" the hypothesis and obtain a proof of `Implies p q`.\n\nWe could render this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)\n    \n\nThis approach would provide us with a reasonable way of building assertions\nand proofs. Determining that an expression `t` is a correct proof of assertion\n`p` would then simply be a matter of checking that `t` has type `Proof p`.\n\nSome simplifications are possible, however. To start with, we can avoid\nwriting the term `Proof` repeatedly by conflating `Proof p` with `p` itself.\nIn other words, whenever we have `p : Prop`, we can interpret `p` as a type,\nnamely, the type of its proofs. We can then read `t : p` as the assertion that\n`t` is a proof of `p`.\n\nMoreover, once we make this identification, the rules for implication show\nthat we can pass back and forth between `Implies p q` and `p → q`. In other\nwords, implication between propositions `p` and `q` corresponds to having a\nfunction that takes any element of `p` to an element of `q`. As a result, the\nintroduction of the connective `Implies` is entirely redundant: we can use the\nusual function space constructor `p → q` from dependent type theory as our\nnotion of implication.\n\nThis is the approach followed in the Calculus of Constructions, and hence in\nLean as well. The fact that the rules for implication in a proof system for\nnatural deduction correspond exactly to the rules governing abstraction and\napplication for functions is an instance of the _Curry-Howard isomorphism_ ,\nsometimes known as the _propositions-as-types_ paradigm. In fact, the type\n`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy\ndescribed in the last chapter. Moreover, `Type u` is also just syntactic sugar\nfor `Sort (u+1)`. `Prop` has some special features, but like the other type\nuniverses, it is closed under the arrow constructor: if we have `p q : Prop`,\nthen `p → q : Prop`.\n\nThere are at least two ways of thinking about propositions as types. To some\nwho take a constructive view of logic and mathematics, this is a faithful\nrendering of what it means to be a proposition: a proposition `p` represents a\nsort of data type, namely, a specification of the type of data that\nconstitutes a proof. A proof of `p` is then simply an object `t : p` of the\nright type.\n\nThose not inclined to this ideology can view it, rather, as a simple coding\ntrick. To each proposition `p` we associate a type that is empty if `p` is\nfalse and has a single element, say `*`, if `p` is true. In the latter case,\nlet us say that (the type associated with) `p` is _inhabited_. It just so\nhappens that the rules for function application and abstraction can\nconveniently help us keep track of which elements of `Prop` are inhabited. So\nconstructing an element `t : p` tells us that `p` is indeed true. You can\nthink of the inhabitant of `p` as being the "fact that `p` is true." A proof\nof `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is\ntrue."\n\nIndeed, if `p : Prop` is any proposition, Lean\'s kernel treats any two\nelements `t1 t2 : p` as being definitionally equal, much the same way as it\ntreats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as\n_proof irrelevance,_ and is consistent with the interpretation in the last\nparagraph. It means that even though we can treat proofs `t : p` as ordinary\nobjects in the language of dependent type theory, they carry no information\nbeyond the fact that `p` is true.\n\nThe two ways we have suggested thinking about the propositions-as-types\nparadigm differ in a fundamental way. From the constructive point of view,\nproofs are abstract mathematical objects that are _denoted_ by suitable\nexpressions in dependent type theory. In contrast, if we think in terms of the\ncoding trick described above, then the expressions themselves do not denote\nanything interesting. Rather, it is the fact that we can write them down and\ncheck that they are well-typed that ensures that the proposition in question\nis true. In other words, the expressions _themselves_ are the proofs.\n\nIn the exposition below, we will slip back and forth between these two ways of\ntalking, at times saying that an expression "constructs" or "produces" or\n"returns" a proof of a proposition, and at other times simply saying that it\n"is" such a proof. This is similar to the way that computer scientists\noccasionally blur the distinction between syntax and semantics by saying, at\ntimes, that a program "computes" a certain function, and at other times\nspeaking as though the program "is" the function in question.\n\nIn any case, all that really matters is the bottom line. To formally express a\nmathematical assertion in the language of dependent type theory, we need to\nexhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a\nterm `t : p`. Lean\'s task, as a proof assistant, is to help us to construct\nsuch a term, `t`, and to verify that it is well-formed and has the correct\ntype.\n\n## Working with Propositions as Types\n\nIn the propositions-as-types paradigm, theorems involving only `→` can be\nproved using lambda abstraction and application. In Lean, the `theorem`\ncommand introduces a new theorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    \n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n\nCompare this proof to the expression `fun x : α => fun y : β => x` of type `α\n→ β → α`, where `α` and `β` are data types. This describes the function that\ntakes arguments `x` and `y` of type `α` and `β`, respectively, and returns\n`x`. The proof of `t1` has the same form, the only difference being that `p`\nand `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of\n`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis\n(trivially) to establish that the conclusion, `p`, is true.\n\nNote that the `theorem` command is really a version of the `def` command:\nunder the propositions and types correspondence, proving the theorem `p → q →\np` is really the same as defining an element of the associated type. To the\nkernel type checker, there is no difference between the two.\n\nThere are a few pragmatic differences between definitions and theorems,\nhowever. In normal circumstances, it is never necessary to unfold the\n"definition" of a theorem; by proof irrelevance, any two proofs of that\ntheorem are definitionally equal. Once the proof of a theorem is complete,\ntypically we only need to know that the proof exists; it doesn\'t matter what\nthe proof is. In light of that fact, Lean tags proofs as _irreducible_ , which\nserves as a hint to the parser (more precisely, the _elaborator_) that there\nis generally no need to unfold them when processing a file. In fact, Lean is\ngenerally able to process and check proofs in parallel, since assessing the\ncorrectness of one proof does not require knowing the details of another.\n\nAs with definitions, the `#print` command will show you the proof of a\ntheorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n    #print t1\n    \n\nNotice that the lambda abstractions `hp : p` and `hq : q` can be viewed as\ntemporary assumptions in the proof of `t1`. Lean also allows us to specify the\ntype of the final term `hp`, explicitly, with a `show` statement:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p :=\n      fun hp : p =>\n      fun hq : q =>\n      show p from hp\n    \n\nAdding such extra information can improve the clarity of a proof and help\ndetect errors when writing a proof. The `show` command does nothing more than\nannotate the type, and, internally, all the presentations of `t1` that we have\nseen produce the same term.\n\nAs with ordinary definitions, we can move the lambda-abstracted variables to\nthe left of the colon:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    #print t1    -- p → q → p\n    \n\nWe can use the theorem `t1` just as a function application:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    axiom hp : p\n    \n    theorem t2 : q → p := t1 hp\n    \n\nThe `axiom` declaration postulates the existence of an element of the given\ntype and may compromise logical consistency. For example, we can use it to\npostulate that the empty type `False` has an element:\n\n    \n    \n    axiom unsound : False\n    -- Everything follows from false\n    theorem ex : 1 = 0 :=\n      False.elim unsound\n    \n\nDeclaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as\nwitnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`\nthat `p` is true yields the theorem `t1 hp : q → p`.\n\nRecall that we can also write theorem `t1` as follows:\n\n    \n    \n    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp\n    \n    #print t1\n    \n\nThe type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the\nassertion "for every pair of propositions `p q`, we have `p → q → p`." For\nexample, we can move all parameters to the right of the colon:\n\n    \n    \n    theorem t1 : ∀ {p q : Prop}, p → q → p :=\n      fun {p q : Prop} (hp : p) (hq : q) => hp\n    \n\nIf `p` and `q` have been declared as variables, Lean will generalize them for\nus automatically:\n\n    \n    \n    variable {p q : Prop}\n    \n    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp\n    \n\nIn fact, by the propositions-as-types correspondence, we can declare the\nassumption `hp` that `p` holds, as another variable:\n\n    \n    \n    variable {p q : Prop}\n    variable (hp : p)\n    \n    theorem t1 : q → p := fun (hq : q) => hp\n    \n\nLean detects that the proof uses `hp` and automatically adds `hp : p` as a\npremise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →\nq → p`. Remember that this type can just as well be written `∀ (p q : Prop)\n(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type\nin which the target does not depend on the bound variable.\n\nWhen we generalize `t1` in such a way, we can then apply it to different pairs\nof propositions, to obtain different instances of the general theorem.\n\n    \n    \n    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp\n    \n    variable (p q r s : Prop)\n    \n    #check t1 p q                -- p → q → p\n    #check t1 r s                -- r → s → r\n    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s\n    \n    variable (h : r → s)\n    #check t1 (r → s) (s → r) h  -- (s → r) → r → s\n    \n\nOnce again, using the propositions-as-types correspondence, the variable `h`\nof type `r → s` can be viewed as the hypothesis, or premise, that `r → s`\nholds.\n\nAs another example, let us consider the composition function discussed in the\nlast chapter, now with propositions instead of types.\n\n    \n    \n    variable (p q r s : Prop)\n    \n    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=\n      fun h₃ : p =>\n      show r from h₁ (h₂ h₃)\n    \n\nAs a theorem of propositional logic, what does `t2` say?\n\nNote that it is often useful to use numeric unicode subscripts, entered as\n`\\0`, `\\1`, `\\2`, ..., for hypotheses, as we did in this example.\n\n## Propositional Logic\n\nLean defines all the standard logical connectives and notation. The\npropositional connectives come with the following notation:\n\nAscii| Unicode| Editor shortcut| Definition  \n---|---|---|---  \nTrue| | | True  \nFalse| | | False  \nNot| ¬| `\\not`, `\\neg`| Not  \n/\\| ∧| `\\and`| And  \n\\/| ∨| `\\or`| Or  \n->| →| `\\to`, `\\r`, `\\imp`|   \n<->| ↔| `\\iff`, `\\lr`| Iff  \n  \nThey all take values in `Prop`.\n\n    \n    \n    variable (p q : Prop)\n    \n    #check p → q → p ∧ q\n    #check ¬p → p ↔ False\n    #check p ∨ q → q ∨ p\n    \n\nThe order of operations is as follows: unary negation `¬` binds most strongly,\nthen `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧\ne` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right\n(nothing changes now that the arguments are elements of `Prop`, instead of\nsome other `Type`), as do the other binary connectives. So if we have `p q r :\nProp`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This\nis just the "curried" form of `p ∧ q → r`.\n\nIn the last chapter we observed that lambda abstraction can be viewed as an\n"introduction rule" for `→`. In the current setting, it shows how to\n"introduce" or establish an implication. Application can be viewed as an\n"elimination rule," showing how to "eliminate" or use an implication in a\nproof. The other propositional connectives are defined in Lean\'s library in\nthe file `Prelude.core` (see [importing\nfiles](./interacting_with_lean.html#importing-files) for more information on\nthe library hierarchy), and each connective comes with its canonical\nintroduction and elimination rules.\n\n### Conjunction\n\nThe expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :\np` and `h2 : q`. It is common to describe `And.intro` as the _and-\nintroduction_ rule. In the next example we use `And.intro` to create a proof\nof `p → q → p ∧ q`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq\n    \n    #check fun (hp : p) (hq : q) => And.intro hp hq\n    \n\nThe `example` command states a theorem without naming it or storing it in the\npermanent context. Essentially, it just checks that the given term has the\nindicated type. It is convenient for illustration, and we will use it often.\n\nThe expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.\nSimilarly, `And.right h` is a proof of `q`. They are commonly known as the\nleft and right _and-elimination_ rules.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : p := And.left h\n    example (h : p ∧ q) : q := And.right h\n    \n\nWe can now prove `p ∧ q → q ∧ p` with the following proof term.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      And.intro (And.right h) (And.left h)\n    \n\nNotice that and-introduction and and-elimination are similar to the pairing\nand projection operations for the Cartesian product. The difference is that\ngiven `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while\n`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is\nanother instance of the Curry-Howard isomorphism, but in contrast to\nimplication and the function space constructor, `∧` and `×` are treated\nseparately in Lean. With the analogy, however, the proof we have just\nconstructed is similar to a function that swaps the elements of a pair.\n\nWe will see in [Chapter Structures and Records](./structures_and_records.html)\nthat certain types in Lean are _structures_ , which is to say, the type is\ndefined with a single canonical _constructor_ which builds an element of the\ntype from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is\nan example: the canonical way to construct an element is to apply `And.intro`\nto suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous\nconstructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the\nrelevant type is an inductive type and can be inferred from the context. In\nparticular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:\n\n    \n    \n    variable (p q : Prop)\n    variable (hp : p) (hq : q)\n    \n    #check (⟨hp, hq⟩ : p ∧ q)\n    \n\nThese angle brackets are obtained by typing `\\<` and `\\>`, respectively.\n\nLean provides another useful syntactic gadget. Given an expression `e` of an\ninductive type `Foo` (possibly applied to some arguments), the notation\n`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of\naccessing functions without opening a namespace. For example, the following\ntwo expressions mean the same thing:\n\n    \n    \n    variable (xs : List Nat)\n    \n    #check List.length xs\n    #check xs.length\n    \n\nAs a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and\n`h.right` for `And.right h`. We can therefore rewrite the sample proof above\nconveniently as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      ⟨h.right, h.left⟩\n    \n\nThere is a fine line between brevity and obfuscation, and omitting information\nin this way can sometimes make a proof harder to read. But for straightforward\nconstructions like the one above, when the type of `h` and the goal of the\nconstruction are salient, the notation is clean and effective.\n\nIt is common to iterate constructions like "And." Lean also allows you to\nflatten nested constructors that associate to the right, so that these two\nproofs are equivalent:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, ⟨h.left, h.right⟩⟩\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, h.left, h.right⟩\n    \n\nThis is often useful as well.\n\n### Disjunction\n\nThe expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof\n`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a\nproof `hq : q`. These are the left and right _or-introduction_ rules.\n\n    \n    \n    variable (p q : Prop)\n    example (hp : p) : p ∨ q := Or.intro_left q hp\n    example (hq : q) : p ∨ q := Or.intro_right p hq\n    \n\nThe _or-elimination_ rule is slightly more complicated. The idea is that we\ncan prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`\nfollows from `q`. In other words, it is a proof by cases. In the expression\n`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :\np → r` and `hqr : q → r`, and produces a proof of `r`. In the following\nexample, we use `Or.elim` to prove `p ∨ q → q ∨ p`.\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h\n        (fun hp : p =>\n          show q ∨ p from Or.intro_right q hp)\n        (fun hq : q =>\n          show q ∨ p from Or.intro_left p hq)\n    \n\nIn most cases, the first argument of `Or.intro_right` and `Or.intro_left` can\nbe inferred automatically by Lean. Lean therefore provides `Or.inr` and\n`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and\n`Or.intro_left _`. Thus the proof term above could be written more concisely:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nNotice that there is enough information in the full expression for Lean to\ninfer the types of `hp` and `hq` as well. But using the type annotations in\nthe longer version makes the proof more readable, and can help catch and debug\nerrors.\n\nBecause `Or` has two constructors, we cannot use anonymous constructor\nnotation. But we can still write `h.elim` instead of `Or.elim h`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nOnce again, you should exercise judgment as to whether such abbreviations\nenhance or diminish readability.\n\n### Negation and Falsity\n\nNegation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by\nderiving a contradiction from `p`. Similarly, the expression `hnp hp` produces\na proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both\nthese rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is\nproduced by typing `\\not` or `\\neg`.)\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hpq : p → q) (hnq : ¬q) : ¬p :=\n      fun hp : p =>\n      show False from hnq (hpq hp)\n    \n\nThe connective `False` has a single elimination rule, `False.elim`, which\nexpresses the fact that anything follows from a contradiction. This rule is\nsometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the\n_principle of explosion_.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)\n    \n\nThe arbitrary fact, `q`, that follows from falsity is an implicit argument in\n`False.elim` and is inferred automatically. This pattern, deriving an\narbitrary fact from contradictory hypotheses, is quite common, and is\nrepresented by `absurd`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := absurd hp hnp\n    \n\nHere, for example, is a proof of `¬p → q → (q → p) → r`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=\n      absurd (hqp hq) hnp\n    \n\nIncidentally, just as `False` has only an elimination rule, `True` has only an\nintroduction rule, `True.intro : true`. In other words, `True` is simply true,\nand has a canonical proof, `True.intro`.\n\n### Logical Equivalence\n\nThe expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`\nand `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from\n`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔\nq`. Here is a proof of `p ∧ q ↔ q ∧ p`:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      Iff.intro\n        (fun h : p ∧ q =>\n         show q ∧ p from And.intro (And.right h) (And.left h))\n        (fun h : q ∧ p =>\n         show p ∧ q from And.intro (And.right h) (And.left h))\n    \n    #check and_swap p q    -- p ∧ q ↔ q ∧ p\n    \n    variable (h : p ∧ q)\n    example : q ∧ p := Iff.mp (and_swap p q) h\n    \n\nWe can use the anonymous constructor notation to construct a proof of `p ↔ q`\nfrom proofs of the forward and backward directions, and we can also use `.`\nnotation with `mp` and `mpr`. The previous examples can therefore be written\nconcisely as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩\n    \n    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h\n    \n\n## Introducing Auxiliary Subgoals\n\nThis is a good place to introduce another device Lean offers to help structure\nlong proofs, namely, the `have` construct, which introduces an auxiliary\nsubgoal in a proof. Here is a small example, adapted from the last section:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      have hq : q := h.right\n      show q ∧ p from And.intro hq hp\n    \n\nInternally, the expression `have h : p := s; t` produces the term `(fun (h :\np) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the\ndesired conclusion assuming `h : p`, and the two are combined by a lambda\nabstraction and application. This simple device is extremely useful when it\ncomes to structuring long proofs, since we can use intermediate `have`\'s as\nstepping stones leading to the final goal.\n\nLean also supports a structured way of reasoning backwards from a goal, which\nmodels the "suffices to show" construction in ordinary mathematics. The next\nexample simply permutes the last two lines in the previous proof.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      suffices hq : q from And.intro hq hp\n      show q from And.right h\n    \n\nWriting `suffices hq : q` leaves us with two goals. First, we have to show\nthat it indeed suffices to show `q`, by proving the original goal of `q ∧ p`\nwith the additional hypothesis `hq : q`. Finally, we have to show `q`.\n\n## Classical Logic\n\nThe introduction and elimination rules we have seen so far are all\nconstructive, which is to say, they reflect a computational understanding of\nthe logical connectives based on the propositions-as-types correspondence.\nOrdinary classical logic adds to this the law of the excluded middle, `p ∨\n¬p`. To use this principle, you have to open the classical namespace.\n\n    \n    \n    open Classical\n    \n    variable (p : Prop)\n    #check em p\n    \n\nIntuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts\nto knowing which is the case. If `RH` represents the Riemann hypothesis, a\nclassical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot\nyet assert either disjunct.\n\nOne consequence of the law of the excluded middle is the principle of double-\nnegation elimination:\n\n    \n    \n    open Classical\n    \n    theorem dne {p : Prop} (h : ¬¬p) : p :=\n      Or.elim (em p)\n        (fun hp : p => hp)\n        (fun hnp : ¬p => absurd hnp h)\n    \n\nDouble-negation elimination allows one to prove any proposition, `p`, by\nassuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In\nother words, double-negation elimination allows one to carry out a proof by\ncontradiction, something which is not generally possible in constructive\nlogic. As an exercise, you might try proving the converse, that is, showing\nthat `em` can be proved from `dne`.\n\nThe classical axioms also give you access to additional patterns of proof that\ncan be justified by appeal to `em`. For example, one can carry out a proof by\ncases:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byCases\n        (fun h1 : p => h1)\n        (fun h1 : ¬p => absurd h1 h)\n    \n\nOr you can carry out a proof by contradiction:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byContradiction\n        (fun h1 : ¬p =>\n         show False from h h1)\n    \n\nIf you are not used to thinking constructively, it may take some time for you\nto get a sense of where classical reasoning is used. It is needed in the\nfollowing example because, from a constructive standpoint, knowing that `p`\nand `q` are not both true does not necessarily tell you which one is false:\n\n    \n    \n    open Classical\n    variable (p q : Prop)\n    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=\n      Or.elim (em p)\n        (fun hp : p =>\n          Or.inr\n            (show ¬q from\n              fun hq : q =>\n              h ⟨hp, hq⟩))\n        (fun hp : ¬p =>\n          Or.inl hp)\n    \n\nWe will see later that there _are_ situations in constructive logic where\nprinciples like excluded middle and double-negation elimination are\npermissible, and Lean supports the use of classical reasoning in such contexts\nwithout relying on excluded middle.\n\nThe full list of axioms that are used in Lean to support classical reasoning\nare discussed in [Axioms and Computation](./axioms_and_computation.html).\n\n## Examples of Propositional Validities\n\nLean\'s standard library contains proofs of many valid statements of\npropositional logic, all of which you are free to use in proofs of your own.\nThe following list includes a number of common identities.\n\nCommutativity:\n\n  1. `p ∧ q ↔ q ∧ p`\n  2. `p ∨ q ↔ q ∨ p`\n\nAssociativity:\n\n  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`\n  4. `(p ∨ q) ∨ r ↔ p ∨ (q �'}], 'model': 'gpt-4o'}}
2025-06-01 03:01:42,030 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:01:42,030 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:01:42,030 - DEBUG - send_request_headers.complete
2025-06-01 03:01:42,030 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:01:42,030 - DEBUG - send_request_body.complete
2025-06-01 03:01:42,031 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:01:59,141 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:01:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'16854'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'16857'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'15605'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'28.79s'), (b'x-request-id', b'req_231dd375f25ef7cb4a3c7e58243f5138'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b77c9e8b346f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:01:59,142 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:01:59,142 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:01:59,143 - DEBUG - receive_response_body.complete
2025-06-01 03:01:59,143 - DEBUG - response_closed.started
2025-06-01 03:01:59,143 - DEBUG - response_closed.complete
2025-06-01 03:01:59,143 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:01:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '16854', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '16857', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '15605', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '28.79s', 'x-request-id': 'req_231dd375f25ef7cb4a3c7e58243f5138', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b77c9e8b346f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:01:59,143 - DEBUG - request_id: req_231dd375f25ef7cb4a3c7e58243f5138
2025-06-01 03:01:59,144 - INFO - Raw solution received: ```json
{
  "code": "if a.isEmpty || b.isEmpty then false else\nlet iterate :=\n  fun (i : Nat) (found : Bool) =>\n    if found then true\n    else if i < a.size then\n      let checkMembership :=\n        fun (j : Nat) (mem : Bool) =>\n          if mem then true\n          else if j < b.size then\n            checkMembership (j + 1) (a[i]! == b[j]!)\n          else\n            false\n      iterate (i + 1) (checkMembership 0 false)\n    else\n      false\niterate 0 false",
  "proof": "by\n  unfold hasCommonElement hasCommonElement_spec\n  by_cases h : a.isEmpty || b.isEmpty\n  case pos =>\n    simp [h]\n    split_ifs\n    case hp1 => exact ⟨0, 0, Nat.zero_le _, Nat.zero_le _, rfl⟩\n    case hp2 => exfalso; exact not_false (Or.inl rfl) h\n  case neg =>\n    simp [h]\n    induction a generalizing b\n    case nil =>\n      exfalso; simp at h; exact h.1 rfl\n    case cons head tail ih =>\n      simp\n      split_ifs with hem\n      case neg1 =>\n        apply Iff.intro\n        case mp =>\n          intro ⟨i, j, hia, hjb, h_eq⟩\n          by_cases hi : i = 0\n          case pos =>\n            apply congrArg (== head); exact h_eq\n          case neg =>\n            have : i - 1 < tail.size := by linarith\n            apply ih <;> assumption\n        case mpr =>\n          intro h_iter\n          induction b\n          case nil =>\n            exfalso; simp at h_iter; suffices : false by exact absurd rfl this\n            apply not_false; assumption\n          case cons head_b tail_b ihb =>\n            simp\n            by_cases head = head_b\n            case pos =>\n              exact ⟨0, 0, Nat.zero_le _, Nat.zero_le _, h⟩\n            case neg =>\n              simp at h_iter\n              specialize ih b rfl\n              rcases ih with ⟨i, j, hi, hj, hij⟩\n              exact ⟨i + 1, j + 1, Nat.succ_lt_succ hi, Nat.succ_lt_succ hj, hij⟩\n      case pos =>\n        simp at hem\n        exact ⟨0, 0, Nat.zero_le _, Nat.zero_le _, hem⟩"
}
```
2025-06-01 03:01:59,144 - INFO - <class 'str'>
2025-06-01 03:01:59,144 - INFO - Generated solution: {'code': 'if a.isEmpty || b.isEmpty then false else\nlet iterate :=\n  fun (i : Nat) (found : Bool) =>\n    if found then true\n    else if i < a.size then\n      let checkMembership :=\n        fun (j : Nat) (mem : Bool) =>\n          if mem then true\n          else if j < b.size then\n            checkMembership (j + 1) (a[i]! == b[j]!)\n          else\n            false\n      iterate (i + 1) (checkMembership 0 false)\n    else\n      false\niterate 0 false', 'proof': 'by\n  unfold hasCommonElement hasCommonElement_spec\n  by_cases h : a.isEmpty || b.isEmpty\n  case pos =>\n    simp [h]\n    split_ifs\n    case hp1 => exact ⟨0, 0, Nat.zero_le _, Nat.zero_le _, rfl⟩\n    case hp2 => exfalso; exact not_false (Or.inl rfl) h\n  case neg =>\n    simp [h]\n    induction a generalizing b\n    case nil =>\n      exfalso; simp at h; exact h.1 rfl\n    case cons head tail ih =>\n      simp\n      split_ifs with hem\n      case neg1 =>\n        apply Iff.intro\n        case mp =>\n          intro ⟨i, j, hia, hjb, h_eq⟩\n          by_cases hi : i = 0\n          case pos =>\n            apply congrArg (== head); exact h_eq\n          case neg =>\n            have : i - 1 < tail.size := by linarith\n            apply ih <;> assumption\n        case mpr =>\n          intro h_iter\n          induction b\n          case nil =>\n            exfalso; simp at h_iter; suffices : false by exact absurd rfl this\n            apply not_false; assumption\n          case cons head_b tail_b ihb =>\n            simp\n            by_cases head = head_b\n            case pos =>\n              exact ⟨0, 0, Nat.zero_le _, Nat.zero_le _, h⟩\n            case neg =>\n              simp at h_iter\n              specialize ih b rfl\n              rcases ih with ⟨i, j, hi, hj, hij⟩\n              exact ⟨i + 1, j + 1, Nat.succ_lt_succ hi, Nat.succ_lt_succ hj, hij⟩\n      case pos =>\n        simp at hem\n        exact ⟨0, 0, Nat.zero_le _, Nat.zero_le _, hem⟩'}
2025-06-01 03:02:04,435 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:16:12: error: unknown identifier 'checkMembership'
lean_playground/TempTest.lean:19:6: error: unknown identifier 'iterate'
lean_playground/TempTest.lean:33:54: error: unsolved goals
a b : Array ℤ
⊢ (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔
    (if (a.isEmpty || b.isEmpty) = true then false
      else
        let iterate := fun i found =>
          if found = true then true
          else
            if i < a.size then
              let checkMembership := fun j mem => if mem = true then true else if j < b.size then sorry else false;
              sorry
            else false;
        iterate 0 false) =
      true
lean_playground/TempTest.lean:36:2: error: unexpected token 'by'; expected command
2025-06-01 03:02:04,436 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasCommonElement (a : Array Int) (b : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the method returns true, there exists at least one common element between the two arrays; If the method returns false, there are no common elements between the two arrays\ndef hasCommonElement_spec (a : Array Int) (b : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ result\n  -- << SPEC END >>\n\ntheorem hasCommonElement_spec_satisfied (a : Array Int) (b : Array Int) :\n  hasCommonElement_spec a b (hasCommonElement a b) := by\n  -- << PROOF START >>\n  unfold hasCommonElement hasCommonElement_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a.isEmpty || b.isEmpty then false else\nlet iterate :=\n  fun (i : Nat) (found : Bool) =>\n    if found then true\n    else if i < a.size then\n      let checkMembership :=\n        fun (j : Nat) (mem : Bool) =>\n          if mem then true\n          else if j < b.size then\n            checkMembership (j + 1) (a[i]! == b[j]!)\n          else\n            false\n      iterate (i + 1) (checkMembership 0 false)\n    else\n      false\niterate 0 false\n\nGenerated Proof:\nby\n  unfold hasCommonElement hasCommonElement_spec\n  by_cases h : a.isEmpty || b.isEmpty\n  case pos =>\n    simp [h]\n    split_ifs\n    case hp1 => exact ⟨0, 0, Nat.zero_le _, Nat.zero_le _, rfl⟩\n    case hp2 => exfalso; exact not_false (Or.inl rfl) h\n  case neg =>\n    simp [h]\n    induction a generalizing b\n    case nil =>\n      exfalso; simp at h; exact h.1 rfl\n    case cons head tail ih =>\n      simp\n      split_ifs with hem\n      case neg1 =>\n        apply Iff.intro\n        case mp =>\n          intro ⟨i, j, hia, hjb, h_eq⟩\n          by_cases hi : i = 0\n          case pos =>\n            apply congrArg (== head); exact h_eq\n          case neg =>\n            have : i - 1 < tail.size := by linarith\n            apply ih <;> assumption\n        case mpr =>\n          intro h_iter\n          induction b\n          case nil =>\n            exfalso; simp at h_iter; suffices : false by exact absurd rfl this\n            apply not_false; assumption\n          case cons head_b tail_b ihb =>\n            simp\n            by_cases head = head_b\n            case pos =>\n              exact ⟨0, 0, Nat.zero_le _, Nat.zero_le _, h⟩\n            case neg =>\n              simp at h_iter\n              specialize ih b rfl\n              rcases ih with ⟨i, j, hi, hj, hij⟩\n              exact ⟨i + 1, j + 1, Nat.succ_lt_succ hi, Nat.succ_lt_succ hj, hij⟩\n      case pos =>\n        simp at hem\n        exact ⟨0, 0, Nat.zero_le _, Nat.zero_le _, hem⟩\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:16:12: error: unknown identifier 'checkMembership'\nlean_playground/TempTest.lean:19:6: error: unknown identifier 'iterate'\nlean_playground/TempTest.lean:33:54: error: unsolved goals\na b : Array ℤ\n⊢ (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔\n    (if (a.isEmpty || b.isEmpty) = true then false\n      else\n        let iterate := fun i found =>\n          if found = true then true\n          else\n            if i < a.size then\n              let checkMembership := fun j mem => if mem = true then true else if j < b.size then sorry else false;\n              sorry\n            else false;\n        iterate 0 false) =\n      true\nlean_playground/TempTest.lean:36:2: error: unexpected token 'by'; expected command"}], 'model': 'o3-mini'}}
2025-06-01 03:02:04,436 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:02:04,436 - DEBUG - close.started
2025-06-01 03:02:04,436 - DEBUG - close.complete
2025-06-01 03:02:04,437 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:02:04,444 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f80410>
2025-06-01 03:02:04,444 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:02:04,454 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f82cf0>
2025-06-01 03:02:04,454 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:02:04,454 - DEBUG - send_request_headers.complete
2025-06-01 03:02:04,454 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:02:04,454 - DEBUG - send_request_body.complete
2025-06-01 03:02:04,454 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:02:12,986 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:02:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8248'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8251'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198598'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'420ms'), (b'x-request-id', b'req_0022d48dc70e4e3018d6520bfba21a6d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b785608e78fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:02:12,987 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:02:12,987 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:02:12,987 - DEBUG - receive_response_body.complete
2025-06-01 03:02:12,987 - DEBUG - response_closed.started
2025-06-01 03:02:12,987 - DEBUG - response_closed.complete
2025-06-01 03:02:12,987 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:02:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8248', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8251', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198598', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '420ms', 'x-request-id': 'req_0022d48dc70e4e3018d6520bfba21a6d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b785608e78fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:02:12,987 - DEBUG - request_id: req_0022d48dc70e4e3018d6520bfba21a6d
2025-06-01 03:02:12,988 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "There are multiple issues in both the implementation and the proof. In the implementation, Lean complains that the identifiers 'checkMembership' and 'iterate' are unknown – this is because the recursive functions are defined inline but then referenced recursively without proper declaration, causing a syntax error. In addition, the proof contains unsolved goals and uses an incorrect proof structure (e.g., unexpected token 'by') which indicates that the tactics and structure do not properly match the defined function. This leads to unsolved goals in establishing the spec.", 'error_type': 'syntax', 'suggested_fix': "For the implementation, instead of manually writing nested recursive functions, consider using built-in functions such as 'Array.any'. A simpler correct definition is: \n\n  def hasCommonElement (a : Array Int) (b : Array Int) : Bool := a.any (fun x => b.any (fun y => x = y))\n\nThis avoids the recursive definition issues. For the proof, you must adjust it to match the new definition. For example, prove that 'a.any (λ x, b.any (λ y, x = y))' returns true if and only if there exist indices i and j with a common element. You can use lemmas about 'Array.any' or, if those are not available, restructure your proof to do an induction on the arrays with proper pattern-matching and case analysis. Also, ensure that the proof block has the correct structure (avoid unexpected tokens like an extra 'by').", 'retry_strategy': "Refactor the function using built-in array methods like 'any' to eliminate the recursive definitions, then rework the proof to follow the new implementation. Use well-known lemmas or perform structural induction on the arrays, ensuring that every 'by_cases' and 'induction' is closed properly."}
2025-06-01 03:02:12,988 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.\n\nPrevious plan:\n{\n  "plan_summary": "Revise the previous plan by eliminating reliance on unknown lemmas and expanding definitions manually. Make sure to correct the case tags in the by_cases tactic to \'pos\' for the true branch and \'neg\' for the false branch. The plan includes handling edge cases for empty arrays and using explicit iteration (or recursion), with an auxiliary membership check and induction to prove correctness.",\n  "steps": [\n    "Handle the edge cases: use a by_cases on whether a.isEmpty || b.isEmpty and use the correct branch tags \'pos\' (when true) and \'neg\' (when false) to check these cases.",\n    "Define a helper function (or explicitly write the logic) to iterate over the first array. For each element, iterate over the second array to check for membership without relying on Array.any or Array.contains.",\n    "Explicitly expand the definitions of Array.any and Array.contains if they are used, ensuring that each equivalence is established through case analysis.",\n    "Develop auxiliary lemmas that show the existence of a common element if and only if the iterative check returns true. In these lemmas, use induction on the length of the array and explicit case splits.",\n    "Use tactics such as by_cases with the proper branch tags and Iff.intro for proving both directions of the equivalence between the existence of indices with equal elements and a true return value.",\n    "Ensure all proofs are complete, without any use of \'sorry\', and that case labels match Lean 4\'s expected tags to avoid errors."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array",\n    "Integer",\n    "iteration",\n    "recursion",\n    "helper function",\n    "by_cases"\n  ],\n  "proof_keywords": [\n    "inductive proof",\n    "auxiliary lemmas",\n    "Iff.intro",\n    "case analysis",\n    "definition unfolding",\n    "edge case handling"\n  ],\n  "assumptions": [\n    "Arrays are of type Array Int.",\n    "It\'s acceptable to define helper functions for membership checking.",\n    "Explicit unfolding of definitions is preferred over using unknown built-in equivalences.",\n    "Using by_cases with correct branch tag names (\'pos\' and \'neg\') is compatible with Lean 4."\n  ],\n  "retry_guidance": "Make sure that all case distinctions especially in by_cases use the correct Lean 4 branch tags (\'pos\' for the true case and \'neg\' for the false case). Expand the definitions of array membership explicitly and use basic tactics like by_cases and Iff.intro to eliminate reliance on unknown constants. Verify that all indices and recurrences align with the induction hypothesis to ensure the main correctness proof successfully closes."\n}\n\nLean error summary:\nThe proof uses case tags \'inl\' and \'inr\' for the \'by_cases\' on h : a.isEmpty || b.isEmpty, but Lean 4 names these cases as \'pos\' for the true branch and \'neg\' for the false branch. This mismatch leads to a case tag not found error.\nRetry guidance (MUST FOLLOW):\nUpdate the by_cases case names and re-run the proof. Verify that other parts of the proof (especially the induction and case analysis on arrays) conform with the expected Lean 4 syntax and semantics.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThere are multiple issues in both the implementation and the proof. In the implementation, Lean complains that the identifiers \'checkMembership\' and \'iterate\' are unknown – this is because the recursive functions are defined inline but then referenced recursively without proper declaration, causing a syntax error. In addition, the proof contains unsolved goals and uses an incorrect proof structure (e.g., unexpected token \'by\') which indicates that the tactics and structure do not properly match the defined function. This leads to unsolved goals in establishing the spec.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 03:02:12,989 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:02:12,989 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:02:12,989 - DEBUG - send_request_headers.complete
2025-06-01 03:02:12,989 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:02:12,989 - DEBUG - send_request_body.complete
2025-06-01 03:02:12,989 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:02:23,349 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:02:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'10121'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'10124'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198191'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'542ms'), (b'x-request-id', b'req_24bd160b9696e3beaf80c2cc87f6a61f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b788b683c8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:02:23,349 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:02:23,349 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:02:23,350 - DEBUG - receive_response_body.complete
2025-06-01 03:02:23,350 - DEBUG - response_closed.started
2025-06-01 03:02:23,350 - DEBUG - response_closed.complete
2025-06-01 03:02:23,350 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:02:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '10121', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '10124', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198191', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '542ms', 'x-request-id': 'req_24bd160b9696e3beaf80c2cc87f6a61f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b788b683c8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:02:23,350 - DEBUG - request_id: req_24bd160b9696e3beaf80c2cc87f6a61f
2025-06-01 03:02:23,350 - INFO - Solution generated in 126.77 seconds
2025-06-01 03:02:23,350 - INFO - Generated code length: 440 characters
2025-06-01 03:02:23,350 - INFO - Generated proof length: 1436 characters
2025-06-01 03:02:23,350 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 03:02:23,351 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 03:02:28,757 - INFO - Implementation test result: FAIL
2025-06-01 03:02:28,757 - ERROR - Implementation error: lean_playground/TempTest.lean:16:12: error: unknown identifier 'checkMembership'
lean_playground/TempTest.lean:19:6: error: unknown identifier 'iterat...
2025-06-01 03:02:28,757 - INFO - Executing Lean code with implementation and proof...
2025-06-01 03:02:34,023 - INFO - Full solution test result: FAIL
2025-06-01 03:02:34,023 - ERROR - Proof error: lean_playground/TempTest.lean:16:12: error: unknown identifier 'checkMembership'
lean_playground/TempTest.lean:19:6: error: unknown identifier 'iterat...
2025-06-01 03:02:34,023 - ERROR - ❌ Implementation fails unit tests
2025-06-01 03:02:34,023 - ERROR - ❌ Proof has errors
2025-06-01 03:02:34,023 - INFO - 
==================================================
2025-06-01 03:02:34,023 - INFO - Processing task task_id_433...
2025-06-01 03:02:34,023 - INFO - Reading problem description and code template from tasks/task_id_433...
2025-06-01 03:02:34,024 - INFO - Problem description length: 646 characters
2025-06-01 03:02:34,024 - INFO - Reading unit tests from tasks/task_id_433...
2025-06-01 03:02:34,024 - INFO - Unit tests length: 367 characters
2025-06-01 03:02:34,024 - INFO - Running main workflow to generate solution...
2025-06-01 03:02:34,024 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.

-----Input-----
The input consists of:
n: An integer.
a: An array of integers.

-----Output-----
The output is a Boolean value:
Returns true if the integer is greater than all elements in the array.
Returns false if there is at least one element in the array that is greater than or equal to the integer.

-----Note-----
The array is assumed to be non-null.
2025-06-01 03:02:34,024 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def isGreater (n : Int) (a : Array Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: If the result is true, then n is greater than all elements in the array; If the result is false, then there exists at least one element in the array that is greater than or equal to n
def isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=
  -- << SPEC START >>
  (∀ i, i < a.size → n > a[i]!) ↔ result
  -- << SPEC END >>

theorem isGreater_spec_satisfied (n : Int) (a : Array Int) :
  isGreater_spec n a (isGreater n a) := by
  -- << PROOF START >>
  unfold isGreater isGreater_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 03:02:34,053 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7f4e66fea840>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 03:02:34,053 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 03:02:34,053 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:02:34,060 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f82630>
2025-06-01 03:02:34,060 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4e6759c6d0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:02:34,068 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f82c60>
2025-06-01 03:02:34,068 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:02:34,068 - DEBUG - send_request_headers.complete
2025-06-01 03:02:34,068 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:02:34,069 - DEBUG - send_request_body.complete
2025-06-01 03:02:34,069 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:02:34,434 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:02:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'41'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-74c8894ff9-hw4wx'), (b'x-envoy-upstream-service-time', b'43'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999839'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_fbfec9df9ef97e9a28c8883ad67b9a2a'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=8KMpnuApsQ6U4MN_jh.5uM8SmI0PpAD4y.bEGXDdjXo-1748746954-1.0.1.1-4VdiRCBHYmA86XfQ3IZo.N9wlaLrN82kEUzFobx2J55W_mA_wIVbXGqHzXTnqrc9K0AqJgLVMgIHifjnC_jBOppzsHBtutCcpgbpeEWR6gs; path=/; expires=Sun, 01-Jun-25 03:32:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=rQc9z6Cc0ZhRW7Uk25n6S.he9YehgXmTqkuDnyssNzs-1748746954454-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b790f1c943bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:02:34,434 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 03:02:34,434 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:02:34,671 - DEBUG - receive_response_body.complete
2025-06-01 03:02:34,671 - DEBUG - response_closed.started
2025-06-01 03:02:34,671 - DEBUG - response_closed.complete
2025-06-01 03:02:34,672 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 03:02:34 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '41'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-74c8894ff9-hw4wx'), ('x-envoy-upstream-service-time', '43'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999839'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '9ms'), ('x-request-id', 'req_fbfec9df9ef97e9a28c8883ad67b9a2a'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=8KMpnuApsQ6U4MN_jh.5uM8SmI0PpAD4y.bEGXDdjXo-1748746954-1.0.1.1-4VdiRCBHYmA86XfQ3IZo.N9wlaLrN82kEUzFobx2J55W_mA_wIVbXGqHzXTnqrc9K0AqJgLVMgIHifjnC_jBOppzsHBtutCcpgbpeEWR6gs; path=/; expires=Sun, 01-Jun-25 03:32:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=rQc9z6Cc0ZhRW7Uk25n6S.he9YehgXmTqkuDnyssNzs-1748746954454-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b790f1c943bfe-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 03:02:34,672 - DEBUG - request_id: req_fbfec9df9ef97e9a28c8883ad67b9a2a
2025-06-01 03:02:34,677 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
 the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
2025-06-01 03:02:34,691 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.'}], 'model': 'o3-mini'}}
2025-06-01 03:02:34,692 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:02:34,692 - DEBUG - close.started
2025-06-01 03:02:34,692 - DEBUG - close.complete
2025-06-01 03:02:34,693 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:02:34,700 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a5eb0>
2025-06-01 03:02:34,700 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:02:34,709 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a7260>
2025-06-01 03:02:34,709 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:02:34,710 - DEBUG - send_request_headers.complete
2025-06-01 03:02:34,710 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:02:34,710 - DEBUG - send_request_body.complete
2025-06-01 03:02:34,710 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:02:40,882 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:02:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5891'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5894'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199538'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'138ms'), (b'x-request-id', b'req_dfe4e0a95b93ee27dda95d880c9d4953'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b79132b9b46f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:02:40,882 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:02:40,882 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:02:40,882 - DEBUG - receive_response_body.complete
2025-06-01 03:02:40,882 - DEBUG - response_closed.started
2025-06-01 03:02:40,882 - DEBUG - response_closed.complete
2025-06-01 03:02:40,883 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:02:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5891', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5894', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199538', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '138ms', 'x-request-id': 'req_dfe4e0a95b93ee27dda95d880c9d4953', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b79132b9b46f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:02:40,883 - DEBUG - request_id: req_dfe4e0a95b93ee27dda95d880c9d4953
2025-06-01 03:02:40,883 - INFO - Attempt 1/3
2025-06-01 03:02:40,883 - INFO - Current plan: {
  "plan_summary": "Design a method in Lean 4 that, given an integer and an array of integers, checks whether the integer is strictly greater than every element in the array. The approach involves iterating over the array and comparing each element with the given integer, using a built-in function or an explicit loop, and returning a Boolean value indicating the result.",
  "steps": [
    "Define the function signature according to Lean 4 conventions, accepting an integer 'n' and an array 'a' of integers.",
    "Iterate over the array elements. This can be achieved by using a higher-order function like 'Array.all' or a recursive function that traverses the array.",
    "For each element in the array, check if the element is strictly less than the integer 'n'.",
    "If any element is found that is greater than or equal to 'n', immediately return false.",
    "If the end of the array is reached without finding any such element, return true.",
    "Optionally, include proofs or comments verifying that the method correctly implements the specification."
  ],
  "code_keywords": [
    "Lean 4",
    "Array",
    "forAll",
    "recursive function",
    "iteration",
    "comparison",
    "Boolean"
  ],
  "proof_keywords": [
    "inductive reasoning",
    "recursive proof",
    "base case",
    "inductive step",
    "termination proof"
  ],
  "assumptions": [
    "The array 'a' is non-null.",
    "Integers in Lean 4 have a well-defined total order.",
    "Array traversal and higher-order functions are available in the Lean 4 standard library."
  ],
  "retry_guidance": "If errors arise regarding array traversal or function definitions in Lean 4, reconsider using built-in array methods such as 'Array.all' or ensure correct handling of indices if a recursive solution is chosen. Also, check that comparisons between integers are correctly implemented."
}
2025-06-01 03:02:40,884 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Design a method in Lean 4 that, given an integer and an array of integers, checks whether the integer is strictly greater than every element in the array. The approach involves iterating over the array and comparing each element with the given integer, using a built-in function or an explicit loop, and returning a Boolean value indicating the result.",\n  "steps": [\n    "Define the function signature according to Lean 4 conventions, accepting an integer \'n\' and an array \'a\' of integers.",\n    "Iterate over the array elements. This can be achieved by using a higher-order function like \'Array.all\' or a recursive function that traverses the array.",\n    "For each element in the array, check if the element is strictly less than the integer \'n\'.",\n    "If any element is found that is greater than or equal to \'n\', immediately return false.",\n    "If the end of the array is reached without finding any such element, return true.",\n    "Optionally, include proofs or comments verifying that the method correctly implements the specification."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array",\n    "forAll",\n    "recursive function",\n    "iteration",\n    "comparison",\n    "Boolean"\n  ],\n  "proof_keywords": [\n    "inductive reasoning",\n    "recursive proof",\n    "base case",\n    "inductive step",\n    "termination proof"\n  ],\n  "assumptions": [\n    "The array \'a\' is non-null.",\n    "Integers in Lean 4 have a well-defined total order.",\n    "Array traversal and higher-order functions are available in the Lean 4 standard library."\n  ],\n  "retry_guidance": "If errors arise regarding array traversal or function definitions in Lean 4, reconsider using built-in array methods such as \'Array.all\' or ensure correct handling of indices if a recursive solution is chosen. Also, check that comparisons between integers are correctly implemented."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isGreater (n : Int) (a : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the result is true, then n is greater than all elements in the array; If the result is false, then there exists at least one element in the array that is greater than or equal to n\ndef isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∀ i, i < a.size → n > a[i]!) ↔ result\n  -- << SPEC END >>\n\ntheorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n  isGreater_spec n a (isGreater n a) := by\n  -- << PROOF START >>\n  unfold isGreater isGreater_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The'}], 'model': 'gpt-4o'}}
2025-06-01 03:02:40,885 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:02:40,885 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:02:40,885 - DEBUG - send_request_headers.complete
2025-06-01 03:02:40,885 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:02:40,891 - DEBUG - send_request_body.complete
2025-06-01 03:02:40,891 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:02:45,730 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:02:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4523'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4527'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'16073'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'27.854s'), (b'x-request-id', b'req_4757464452836780682ae43c0e53e7ac'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7939b81746f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:02:45,731 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:02:45,731 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:02:45,731 - DEBUG - receive_response_body.complete
2025-06-01 03:02:45,731 - DEBUG - response_closed.started
2025-06-01 03:02:45,731 - DEBUG - response_closed.complete
2025-06-01 03:02:45,731 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:02:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4523', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4527', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '16073', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '27.854s', 'x-request-id': 'req_4757464452836780682ae43c0e53e7ac', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7939b81746f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:02:45,731 - DEBUG - request_id: req_4757464452836780682ae43c0e53e7ac
2025-06-01 03:02:45,732 - INFO - Raw solution received: ```json
{
  "code": "a.forAll (fun x => n > x)",
  "proof": "by\n  unfold isGreater isGreater_spec\n  by_cases ha: a.forAll (fun x => n > x)\n  simp [ha]\n  exact ha\n  by_cases hex: ∃ i, i < a.size ∧ n ≤ a[i]!\n  simp [Array.exists_imp_forall_not hex, ha]\n  case inl => exfalso\n  apply hex\n  trivial\n  case inr hf =>\n  exfalso\n  apply hf\n  intro i h\n  exact ⟨i, h, ha h⟩"
}
```
2025-06-01 03:02:45,732 - INFO - <class 'str'>
2025-06-01 03:02:45,732 - INFO - Generated solution: {'code': 'a.forAll (fun x => n > x)', 'proof': 'by\n  unfold isGreater isGreater_spec\n  by_cases ha: a.forAll (fun x => n > x)\n  simp [ha]\n  exact ha\n  by_cases hex: ∃ i, i < a.size ∧ n ≤ a[i]!\n  simp [Array.exists_imp_forall_not hex, ha]\n  case inl => exfalso\n  apply hex\n  trivial\n  case inr hf =>\n  exfalso\n  apply hf\n  intro i h\n  exact ⟨i, h, ha h⟩'}
2025-06-01 03:02:51,079 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:7:2: error: invalid field 'forAll', the environment does not contain 'Array.forAll'
  a
has type
  Array ℤ
lean_playground/TempTest.lean:18:40: error: unsolved goals
n : ℤ
a : Array ℤ
⊢ (∀ i < a.size, n > a[i]!) ↔ sorry = true
lean_playground/TempTest.lean:21:2: error: unexpected token 'by'; expected command
2025-06-01 03:02:51,080 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isGreater (n : Int) (a : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the result is true, then n is greater than all elements in the array; If the result is false, then there exists at least one element in the array that is greater than or equal to n\ndef isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∀ i, i < a.size → n > a[i]!) ↔ result\n  -- << SPEC END >>\n\ntheorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n  isGreater_spec n a (isGreater n a) := by\n  -- << PROOF START >>\n  unfold isGreater isGreater_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na.forAll (fun x => n > x)\n\nGenerated Proof:\nby\n  unfold isGreater isGreater_spec\n  by_cases ha: a.forAll (fun x => n > x)\n  simp [ha]\n  exact ha\n  by_cases hex: ∃ i, i < a.size ∧ n ≤ a[i]!\n  simp [Array.exists_imp_forall_not hex, ha]\n  case inl => exfalso\n  apply hex\n  trivial\n  case inr hf =>\n  exfalso\n  apply hf\n  intro i h\n  exact ⟨i, h, ha h⟩\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:7:2: error: invalid field 'forAll', the environment does not contain 'Array.forAll'\n  a\nhas type\n  Array ℤ\nlean_playground/TempTest.lean:18:40: error: unsolved goals\nn : ℤ\na : Array ℤ\n⊢ (∀ i < a.size, n > a[i]!) ↔ sorry = true\nlean_playground/TempTest.lean:21:2: error: unexpected token 'by'; expected command"}], 'model': 'o3-mini'}}
2025-06-01 03:02:51,080 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:02:51,081 - DEBUG - close.started
2025-06-01 03:02:51,081 - DEBUG - close.complete
2025-06-01 03:02:51,081 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:02:51,088 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f92a20>
2025-06-01 03:02:51,088 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:02:51,097 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f92300>
2025-06-01 03:02:51,097 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:02:51,098 - DEBUG - send_request_headers.complete
2025-06-01 03:02:51,098 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:02:51,098 - DEBUG - send_request_body.complete
2025-06-01 03:02:51,098 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:03:05,439 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:03:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'13724'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'13727'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199096'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'271ms'), (b'x-request-id', b'req_d5c5a7579cd0e116db6d225a066805a3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7979884e8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:03:05,440 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:03:05,440 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:03:05,440 - DEBUG - receive_response_body.complete
2025-06-01 03:03:05,440 - DEBUG - response_closed.started
2025-06-01 03:03:05,440 - DEBUG - response_closed.complete
2025-06-01 03:03:05,440 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:03:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '13724', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '13727', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199096', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '271ms', 'x-request-id': 'req_d5c5a7579cd0e116db6d225a066805a3', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7979884e8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:03:05,440 - DEBUG - request_id: req_d5c5a7579cd0e116db6d225a066805a3
2025-06-01 03:03:05,441 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "There are two main issues. First, the implementation uses 'a.forAll' but Lean 4’s Array type does not provide a 'forAll' field. Second, the provided proof is incomplete and not well structured: it uses tactic cases that lead to unsolved goals and misuses the equivalence between the list-based predicate and the array predicate. In short, the code does not compile due to the undefined 'forAll' and the proof has gaps.", 'error_type': 'syntax', 'suggested_fix': "Replace the use of 'a.forAll (fun x => n > x)' with 'a.toList.all (fun x => n > x)', which converts the array to a list and checks the predicate on each element. For the proof, prove the equivalence between '(∀ i, i < a.size → n > a[i]!)' and 'a.toList.all (fun x => n > x)'. You can use the fact that every element of 'a' appears in 'a.toList' (via a lemma such as 'Array.mem_toList') and vice versa. For example, structure the proof by showing that if every index i satisfies n > a[i]!, then every element of a.toList satisfies n > x, and conversely, if the list all predicate holds then for any valid index i, n > a[i]!.", 'retry_strategy': 'Revise both the implementation and the proof. Use the array-to-list conversion for implementation and write a complete proof that explicitly uses the equivalence between the list predicate and the array predicate. Then, run Lean again to verify that the code compiles and the proof is complete.'}
2025-06-01 03:03:05,441 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.\n\nPrevious plan:\n{\n  "plan_summary": "Design a method in Lean 4 that, given an integer and an array of integers, checks whether the integer is strictly greater than every element in the array. The approach involves iterating over the array and comparing each element with the given integer, using a built-in function or an explicit loop, and returning a Boolean value indicating the result.",\n  "steps": [\n    "Define the function signature according to Lean 4 conventions, accepting an integer \'n\' and an array \'a\' of integers.",\n    "Iterate over the array elements. This can be achieved by using a higher-order function like \'Array.all\' or a recursive function that traverses the array.",\n    "For each element in the array, check if the element is strictly less than the integer \'n\'.",\n    "If any element is found that is greater than or equal to \'n\', immediately return false.",\n    "If the end of the array is reached without finding any such element, return true.",\n    "Optionally, include proofs or comments verifying that the method correctly implements the specification."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array",\n    "forAll",\n    "recursive function",\n    "iteration",\n    "comparison",\n    "Boolean"\n  ],\n  "proof_keywords": [\n    "inductive reasoning",\n    "recursive proof",\n    "base case",\n    "inductive step",\n    "termination proof"\n  ],\n  "assumptions": [\n    "The array \'a\' is non-null.",\n    "Integers in Lean 4 have a well-defined total order.",\n    "Array traversal and higher-order functions are available in the Lean 4 standard library."\n  ],\n  "retry_guidance": "If errors arise regarding array traversal or function definitions in Lean 4, reconsider using built-in array methods such as \'Array.all\' or ensure correct handling of indices if a recursive solution is chosen. Also, check that comparisons between integers are correctly implemented."\n}\n\nLean error:\nThere are two main issues. First, the implementation uses \'a.forAll\' but Lean 4’s Array type does not provide a \'forAll\' field. Second, the provided proof is incomplete and not well structured: it uses tactic cases that lead to unsolved goals and misuses the equivalence between the list-based predicate and the array predicate. In short, the code does not compile due to the undefined \'forAll\' and the proof has gaps.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 03:03:05,442 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:03:05,442 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:03:05,442 - DEBUG - send_request_headers.complete
2025-06-01 03:03:05,442 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:03:05,443 - DEBUG - send_request_body.complete
2025-06-01 03:03:05,443 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:03:14,686 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:03:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8992'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8999'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'197835'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'649ms'), (b'x-request-id', b'req_0166f8407b243f9832e9b369d0a21a76'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b79d33fb78fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:03:14,686 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:03:14,686 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:03:14,686 - DEBUG - receive_response_body.complete
2025-06-01 03:03:14,686 - DEBUG - response_closed.started
2025-06-01 03:03:14,687 - DEBUG - response_closed.complete
2025-06-01 03:03:14,687 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:03:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8992', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8999', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '197835', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '649ms', 'x-request-id': 'req_0166f8407b243f9832e9b369d0a21a76', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b79d33fb78fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:03:14,687 - DEBUG - request_id: req_0166f8407b243f9832e9b369d0a21a76
2025-06-01 03:03:14,687 - INFO - Attempt 2/3
2025-06-01 03:03:14,687 - INFO - Current plan: {
  "plan_summary": "Revise the implementation so that instead of relying on a non-existent 'forAll' method of Lean 4's Array type, the function uses a valid mechanism for traversing the array. Two approaches can be considered: (1) Use a recursive definition or a fold (such as Array.foldl) that iterates over array indices, comparing each element with the given integer; or (2) Convert the array to a list (using Array.toList) and then apply a list-based predicate (e.g., List.all) to test if the integer is strictly greater than every element. In addition, structure the proof in terms of either recursion or induction on the list representation, clearly handling the base and inductive cases. This ensures that the correctness proof is well-framed and that the required equivalence between the array traversal and the list-based predicate is explicitly shown.",
  "steps": [
    "Define the function signature accepting an integer 'n' and an array 'a' of integers.",
    "Decide on the traversal strategy: either use recursion/A fold function to iterate over the array, or convert the array to a list and use the list's built-in all function.",
    "Implement the comparison logic: for each element in the array (or list), check that the element is strictly less than 'n'.",
    "Ensure that the traversal stops early if any element fails the condition (for efficiency) or fully traverses if needed.",
    "Include a proof that the function correctly returns true if and only if every array element is less than 'n'. In the proof, use inductive reasoning: demonstrate the base case (empty array or list) and then show that if the property holds for a list/array of length k, it holds for length k+1.",
    "Address and clearly document the equivalence between the array-based check and the list-based predicate if conversion is used, making sure the proof handles this transformation.",
    "Test or validate that the revised code compiles by using proper Lean 4 array and list utilities."
  ],
  "code_keywords": [
    "Lean 4",
    "Array",
    "Array.foldl",
    "Array.toList",
    "recursion",
    "list.all",
    "conditional check",
    "Boolean"
  ],
  "proof_keywords": [
    "inductive reasoning",
    "base case",
    "inductive step",
    "recursive proof",
    "correctness proof",
    "equivalence proof"
  ],
  "assumptions": [
    "The array is non-null.",
    "Lean 4's standard library does not provide a 'forAll' method for Array, so alternative methods must be used.",
    "Integer comparison is well-defined.",
    "Conversion from Array to List preserves element order and allows using List predicates."
  ],
  "retry_guidance": "If further errors occur, check that the chosen traversal method is correctly implemented with respect to Lean 4's Array API. Verify that the conversion to a list (if used) is done properly, and ensure that the proof clearly distinguishes between array-based reasoning and list-based inductive proofs. Consider adding intermediate lemmas to bridge the gap between the array and list representations if necessary."
}
2025-06-01 03:03:14,687 - INFO - Updated plan: {
  "plan_summary": "Revise the implementation so that instead of relying on a non-existent 'forAll' method of Lean 4's Array type, the function uses a valid mechanism for traversing the array. Two approaches can be considered: (1) Use a recursive definition or a fold (such as Array.foldl) that iterates over array indices, comparing each element with the given integer; or (2) Convert the array to a list (using Array.toList) and then apply a list-based predicate (e.g., List.all) to test if the integer is strictly greater than every element. In addition, structure the proof in terms of either recursion or induction on the list representation, clearly handling the base and inductive cases. This ensures that the correctness proof is well-framed and that the required equivalence between the array traversal and the list-based predicate is explicitly shown.",
  "steps": [
    "Define the function signature accepting an integer 'n' and an array 'a' of integers.",
    "Decide on the traversal strategy: either use recursion/A fold function to iterate over the array, or convert the array to a list and use the list's built-in all function.",
    "Implement the comparison logic: for each element in the array (or list), check that the element is strictly less than 'n'.",
    "Ensure that the traversal stops early if any element fails the condition (for efficiency) or fully traverses if needed.",
    "Include a proof that the function correctly returns true if and only if every array element is less than 'n'. In the proof, use inductive reasoning: demonstrate the base case (empty array or list) and then show that if the property holds for a list/array of length k, it holds for length k+1.",
    "Address and clearly document the equivalence between the array-based check and the list-based predicate if conversion is used, making sure the proof handles this transformation.",
    "Test or validate that the revised code compiles by using proper Lean 4 array and list utilities."
  ],
  "code_keywords": [
    "Lean 4",
    "Array",
    "Array.foldl",
    "Array.toList",
    "recursion",
    "list.all",
    "conditional check",
    "Boolean"
  ],
  "proof_keywords": [
    "inductive reasoning",
    "base case",
    "inductive step",
    "recursive proof",
    "correctness proof",
    "equivalence proof"
  ],
  "assumptions": [
    "The array is non-null.",
    "Lean 4's standard library does not provide a 'forAll' method for Array, so alternative methods must be used.",
    "Integer comparison is well-defined.",
    "Conversion from Array to List preserves element order and allows using List predicates."
  ],
  "retry_guidance": "If further errors occur, check that the chosen traversal method is correctly implemented with respect to Lean 4's Array API. Verify that the conversion to a list (if used) is done properly, and ensure that the proof clearly distinguishes between array-based reasoning and list-based inductive proofs. Consider adding intermediate lemmas to bridge the gap between the array and list representations if necessary."
}

Lean error summary:
There are two main issues. First, the implementation uses 'a.forAll' but Lean 4’s Array type does not provide a 'forAll' field. Second, the provided proof is incomplete and not well structured: it uses tactic cases that lead to unsolved goals and misuses the equivalence between the list-based predicate and the array predicate. In short, the code does not compile due to the undefined 'forAll' and the proof has gaps.
Retry guidance (MUST FOLLOW):
Revise both the implementation and the proof. Use the array-to-list conversion for implementation and write a complete proof that explicitly uses the equivalence between the list predicate and the array predicate. Then, run Lean again to verify that the code compiles and the proof is complete.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 03:03:14,688 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the implementation so that instead of relying on a non-existent \'forAll\' method of Lean 4\'s Array type, the function uses a valid mechanism for traversing the array. Two approaches can be considered: (1) Use a recursive definition or a fold (such as Array.foldl) that iterates over array indices, comparing each element with the given integer; or (2) Convert the array to a list (using Array.toList) and then apply a list-based predicate (e.g., List.all) to test if the integer is strictly greater than every element. In addition, structure the proof in terms of either recursion or induction on the list representation, clearly handling the base and inductive cases. This ensures that the correctness proof is well-framed and that the required equivalence between the array traversal and the list-based predicate is explicitly shown.",\n  "steps": [\n    "Define the function signature accepting an integer \'n\' and an array \'a\' of integers.",\n    "Decide on the traversal strategy: either use recursion/A fold function to iterate over the array, or convert the array to a list and use the list\'s built-in all function.",\n    "Implement the comparison logic: for each element in the array (or list), check that the element is strictly less than \'n\'.",\n    "Ensure that the traversal stops early if any element fails the condition (for efficiency) or fully traverses if needed.",\n    "Include a proof that the function correctly returns true if and only if every array element is less than \'n\'. In the proof, use inductive reasoning: demonstrate the base case (empty array or list) and then show that if the property holds for a list/array of length k, it holds for length k+1.",\n    "Address and clearly document the equivalence between the array-based check and the list-based predicate if conversion is used, making sure the proof handles this transformation.",\n    "Test or validate that the revised code compiles by using proper Lean 4 array and list utilities."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array",\n    "Array.foldl",\n    "Array.toList",\n    "recursion",\n    "list.all",\n    "conditional check",\n    "Boolean"\n  ],\n  "proof_keywords": [\n    "inductive reasoning",\n    "base case",\n    "inductive step",\n    "recursive proof",\n    "correctness proof",\n    "equivalence proof"\n  ],\n  "assumptions": [\n    "The array is non-null.",\n    "Lean 4\'s standard library does not provide a \'forAll\' method for Array, so alternative methods must be used.",\n    "Integer comparison is well-defined.",\n    "Conversion from Array to List preserves element order and allows using List predicates."\n  ],\n  "retry_guidance": "If further errors occur, check that the chosen traversal method is correctly implemented with respect to Lean 4\'s Array API. Verify that the conversion to a list (if used) is done properly, and ensure that the proof clearly distinguishes between array-based reasoning and list-based inductive proofs. Consider adding intermediate lemmas to bridge the gap between the array and list representations if necessary."\n}\n\nLean error summary:\nThere are two main issues. First, the implementation uses \'a.forAll\' but Lean 4’s Array type does not provide a \'forAll\' field. Second, the provided proof is incomplete and not well structured: it uses tactic cases that lead to unsolved goals and misuses the equivalence between the list-based predicate and the array predicate. In short, the code does not compile due to the undefined \'forAll\' and the proof has gaps.\nRetry guidance (MUST FOLLOW):\nRevise both the implementation and the proof. Use the array-to-list conversion for implementation and write a complete proof that explicitly uses the equivalence between the list predicate and the array predicate. Then, run Lean again to verify that the code compiles and the proof is complete.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isGreater (n : Int) (a : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the result is true, then n is greater than all elements in the array; If the result is false, then there exists at least one element in the array that is greater than or equal to n\ndef isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∀ i, i < a.size → n > a[i]!) ↔ result\n  -- << SPEC END >>\n\ntheorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n  isGreater_spec n a (isGreater n a) := by\n  -- << PROOF START >>\n  unfold isGreater isGreater_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The'}], 'model': 'gpt-4o'}}
2025-06-01 03:03:14,689 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:03:14,689 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:03:14,690 - DEBUG - send_request_headers.complete
2025-06-01 03:03:14,690 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:03:14,690 - DEBUG - send_request_body.complete
2025-06-01 03:03:14,690 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:03:18,507 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:03:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2921'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2927'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'15548'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'28.904s'), (b'x-request-id', b'req_6edbf3f9cbc47a9b8488332014bcadc3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7a0d0a2e8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:03:18,507 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:03:18,507 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:03:18,508 - DEBUG - receive_response_body.complete
2025-06-01 03:03:18,509 - DEBUG - response_closed.started
2025-06-01 03:03:18,509 - DEBUG - response_closed.complete
2025-06-01 03:03:18,509 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:03:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2921', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2927', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '15548', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '28.904s', 'x-request-id': 'req_6edbf3f9cbc47a9b8488332014bcadc3', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7a0d0a2e8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:03:18,509 - DEBUG - request_id: req_6edbf3f9cbc47a9b8488332014bcadc3
2025-06-01 03:03:18,509 - INFO - Raw solution received: ```json
{
  "code": "a.toList.all (fun x => n > x)",
  "proof": "apply Iff.intro\n  intro h\n  unfold List.all\n  intro x hlt\n  have ha : x < a.size := hlt\n  specialize h x hlt\n  assumption\n\n  intro h\n  unfold List.all at h\n  intro i hlt\n  apply h\n  assumption\n"
}
```
2025-06-01 03:03:18,509 - INFO - <class 'str'>
2025-06-01 03:03:18,509 - INFO - Generated solution: {'code': 'a.toList.all (fun x => n > x)', 'proof': 'apply Iff.intro\n  intro h\n  unfold List.all\n  intro x hlt\n  have ha : x < a.size := hlt\n  specialize h x hlt\n  assumption\n\n  intro h\n  unfold List.all at h\n  intro i hlt\n  apply h\n  assumption\n'}
2025-06-01 03:03:23,809 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:24:8: error: tactic 'introN' failed, insufficient number of binders
case mp
n : ℤ
a : Array ℤ
h : ∀ i < a.size, n > a[i]!
⊢ (match a.toList, fun x => decide (n > x) with
    | [], x => true
    | h :: t, p => p h && t.all p) =
    true
2025-06-01 03:03:23,810 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isGreater (n : Int) (a : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the result is true, then n is greater than all elements in the array; If the result is false, then there exists at least one element in the array that is greater than or equal to n\ndef isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∀ i, i < a.size → n > a[i]!) ↔ result\n  -- << SPEC END >>\n\ntheorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n  isGreater_spec n a (isGreater n a) := by\n  -- << PROOF START >>\n  unfold isGreater isGreater_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na.toList.all (fun x => n > x)\n\nGenerated Proof:\napply Iff.intro\n  intro h\n  unfold List.all\n  intro x hlt\n  have ha : x < a.size := hlt\n  specialize h x hlt\n  assumption\n\n  intro h\n  unfold List.all at h\n  intro i hlt\n  apply h\n  assumption\n\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:24:8: error: tactic 'introN' failed, insufficient number of binders\ncase mp\nn : ℤ\na : Array ℤ\nh : ∀ i < a.size, n > a[i]!\n⊢ (match a.toList, fun x => decide (n > x) with\n    | [], x => true\n    | h :: t, p => p h && t.all p) =\n    true"}], 'model': 'o3-mini'}}
2025-06-01 03:03:23,811 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:03:23,811 - DEBUG - close.started
2025-06-01 03:03:23,811 - DEBUG - close.complete
2025-06-01 03:03:23,811 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:03:23,818 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e710fce60>
2025-06-01 03:03:23,819 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:03:23,828 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fdb4d0>
2025-06-01 03:03:23,828 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:03:23,828 - DEBUG - send_request_headers.complete
2025-06-01 03:03:23,828 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:03:23,828 - DEBUG - send_request_body.complete
2025-06-01 03:03:23,828 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:03:46,190 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:03:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'22133'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'22139'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199145'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'256ms'), (b'x-request-id', b'req_b0ea566e666555af9e65ca323d2283a0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7a46295446f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:03:46,190 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:03:46,190 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:03:46,191 - DEBUG - receive_response_body.complete
2025-06-01 03:03:46,191 - DEBUG - response_closed.started
2025-06-01 03:03:46,191 - DEBUG - response_closed.complete
2025-06-01 03:03:46,191 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:03:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '22133', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '22139', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199145', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '256ms', 'x-request-id': 'req_b0ea566e666555af9e65ca323d2283a0', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7a46295446f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:03:46,191 - DEBUG - request_id: req_b0ea566e666555af9e65ca323d2283a0
2025-06-01 03:03:46,191 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof failed because the tactic 'introN' (invoked via apply Iff.intro) did not receive the expected number of binders. In other words, the proof does not correctly bridge the gap between the index‐based formulation (∀ i, i < a.size → n > a[i]!) and the Boolean condition produced by a.toList.all. The current proof attempts to directly introduce variables for a pattern match on a.toList without accounting for the conversion between array indices and list elements.", 'error_type': 'proof', 'suggested_fix': 'Rewrite the proof to explicitly use the equivalence lemma List.all_iff_forall (which states that for a decidable predicate p on a list l, l.all p = true ↔ ∀ x ∈ l, p x) and the lemmas Array.mem_toList and Array.toList_nth to convert between indices and list membership. For example, a corrected proof is given below:\n\n-------------------------------------------------\nimport Mathlib\nimport Aesop\nimport Mathlib.Data.List.Basic\n\n-- Implementation\ndef isGreater (n : Int) (a : Array Int) : Bool :=\n  a.toList.all (fun x => n > x)\n\n-- Specification: n is greater than all elements in a if and only if isGreater n a returns true\ndef isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=\n  (∀ i, i < a.size → n > a[i]!) ↔ result\n\n-- Corrected Proof\ntheorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n  isGreater_spec n a (isGreater n a) := by\n  unfold isGreater isGreater_spec\n  apply Iff.intro\n  · -- Forward direction: assume ∀ i, i < a.size → n > a[i]! and prove that a.toList.all (fun x => n > x) = true\n    intro H\n    rw List.all_iff_forall\n    intro x hx\n    obtain ⟨i, hi, rfl⟩ := Array.mem_toList.mp hx\n    exact H i hi\n  · -- Backward direction: assume a.toList.all (fun x => n > x) = true and prove ∀ i, i < a.size → n > a[i]!\n    intro H i hi\n    have nth_eq : (a.toList).nth i = some (a[i]!) := Array.toList_nth a i hi\n    rw List.all_iff_forall at H\n    apply H (a[i]!)\n    rw nth_eq\n    simp\n-------------------------------------------------\nThis revised approach explicitly rewrites the Boolean condition in terms of a universal property over the elements of a.toList and then relates each element back to an index in the array.', 'retry_strategy': 'Revise the proof using the provided skeleton. Replace the faulty induction and direct introduction tactics with an application of List.all_iff_forall together with Array.mem_toList and Array.toList_nth to properly relate the array indices and list elements. Then re-run the proof.'}
2025-06-01 03:03:46,192 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.\n\nPrevious plan:\n{\n  "plan_summary": "Revise the implementation so that instead of relying on a non-existent \'forAll\' method of Lean 4\'s Array type, the function uses a valid mechanism for traversing the array. Two approaches can be considered: (1) Use a recursive definition or a fold (such as Array.foldl) that iterates over array indices, comparing each element with the given integer; or (2) Convert the array to a list (using Array.toList) and then apply a list-based predicate (e.g., List.all) to test if the integer is strictly greater than every element. In addition, structure the proof in terms of either recursion or induction on the list representation, clearly handling the base and inductive cases. This ensures that the correctness proof is well-framed and that the required equivalence between the array traversal and the list-based predicate is explicitly shown.",\n  "steps": [\n    "Define the function signature accepting an integer \'n\' and an array \'a\' of integers.",\n    "Decide on the traversal strategy: either use recursion/A fold function to iterate over the array, or convert the array to a list and use the list\'s built-in all function.",\n    "Implement the comparison logic: for each element in the array (or list), check that the element is strictly less than \'n\'.",\n    "Ensure that the traversal stops early if any element fails the condition (for efficiency) or fully traverses if needed.",\n    "Include a proof that the function correctly returns true if and only if every array element is less than \'n\'. In the proof, use inductive reasoning: demonstrate the base case (empty array or list) and then show that if the property holds for a list/array of length k, it holds for length k+1.",\n    "Address and clearly document the equivalence between the array-based check and the list-based predicate if conversion is used, making sure the proof handles this transformation.",\n    "Test or validate that the revised code compiles by using proper Lean 4 array and list utilities."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array",\n    "Array.foldl",\n    "Array.toList",\n    "recursion",\n    "list.all",\n    "conditional check",\n    "Boolean"\n  ],\n  "proof_keywords": [\n    "inductive reasoning",\n    "base case",\n    "inductive step",\n    "recursive proof",\n    "correctness proof",\n    "equivalence proof"\n  ],\n  "assumptions": [\n    "The array is non-null.",\n    "Lean 4\'s standard library does not provide a \'forAll\' method for Array, so alternative methods must be used.",\n    "Integer comparison is well-defined.",\n    "Conversion from Array to List preserves element order and allows using List predicates."\n  ],\n  "retry_guidance": "If further errors occur, check that the chosen traversal method is correctly implemented with respect to Lean 4\'s Array API. Verify that the conversion to a list (if used) is done properly, and ensure that the proof clearly distinguishes between array-based reasoning and list-based inductive proofs. Consider adding intermediate lemmas to bridge the gap between the array and list representations if necessary."\n}\n\nLean error summary:\nThere are two main issues. First, the implementation uses \'a.forAll\' but Lean 4’s Array type does not provide a \'forAll\' field. Second, the provided proof is incomplete and not well structured: it uses tactic cases that lead to unsolved goals and misuses the equivalence between the list-based predicate and the array predicate. In short, the code does not compile due to the undefined \'forAll\' and the proof has gaps.\nRetry guidance (MUST FOLLOW):\nRevise both the implementation and the proof. Use the array-to-list conversion for implementation and write a complete proof that explicitly uses the equivalence between the list predicate and the array predicate. Then, run Lean again to verify that the code compiles and the proof is complete.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThe proof failed because the tactic \'introN\' (invoked via apply Iff.intro) did not receive the expected number of binders. In other words, the proof does not correctly bridge the gap between the index‐based formulation (∀ i, i < a.size → n > a[i]!) and the Boolean condition produced by a.toList.all. The current proof attempts to directly introduce variables for a pattern match on a.toList without accounting for the conversion between array indices and list elements.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 03:03:46,192 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:03:46,193 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:03:46,193 - DEBUG - send_request_headers.complete
2025-06-01 03:03:46,193 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:03:46,193 - DEBUG - send_request_body.complete
2025-06-01 03:03:46,193 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:03:54,516 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:03:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8077'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8091'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'196054'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'1.183s'), (b'x-request-id', b'req_7c78d2856372082fd3a5e58263b4ea87'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7ad1eed346f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:03:54,517 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:03:54,517 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:03:54,519 - DEBUG - receive_response_body.complete
2025-06-01 03:03:54,519 - DEBUG - response_closed.started
2025-06-01 03:03:54,519 - DEBUG - response_closed.complete
2025-06-01 03:03:54,519 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:03:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8077', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8091', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '196054', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '1.183s', 'x-request-id': 'req_7c78d2856372082fd3a5e58263b4ea87', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7ad1eed346f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:03:54,519 - DEBUG - request_id: req_7c78d2856372082fd3a5e58263b4ea87
2025-06-01 03:03:54,520 - INFO - Attempt 3/3
2025-06-01 03:03:54,520 - INFO - Current plan: {
  "plan_summary": "Revise the implementation by converting the array to a list and then using List.all to check if every element is strictly less than the given integer. Additionally, prove the equivalence between the index-based predicate and the list-based predicate via induction on the list structure, making sure to correctly introduce binders and correctly handle the base case and the inductive step.",
  "steps": [
    "Define the function signature that accepts an integer 'n' and an Array of integers 'a'.",
    "Convert the array 'a' to a list using Array.toList, and then use List.all with the predicate (λ x, n > x) as the check.",
    "Implement a lemma that formally proves the equivalence between the index-based condition (∀ i, i < a.size → n > a[i]!) and the list-based predicate (a.toList.all (λ x, n > x)).",
    "For the lemma, perform induction on the list produced by a.toList:",
    "  - Base Case: When the list is empty, show that the index-based condition holds trivially.",
    "  - Inductive Step: Assume the equivalence holds for a list 'l'. Then, for a list constructed as (x :: l), prove that n > x and the equivalence for l implies the index-based condition for the entire array.",
    "Ensure the proof does not misuse tactics such as 'introN' by explicitly matching the structure of the list and carefully introducing the correct binders.",
    "Integrate the lemma into the overall function implementation so that the code compiles and the proof is complete.",
    "Avoid using 'sorry' by ensuring that all cases, including any conversions between array indices and list elements, are fully handled through induction or by auxiliary lemmas."
  ],
  "code_keywords": [
    "Lean 4",
    "Array.toList",
    "List.all",
    "boolean",
    "array traversal",
    "recursion"
  ],
  "proof_keywords": [
    "induction",
    "base case",
    "inductive hypothesis",
    "equivalence proof",
    "lemma",
    "array-to-list conversion",
    "pattern matching"
  ],
  "assumptions": [
    "The array is non-null.",
    "Array.toList accurately converts the array to a list with preserved order.",
    "Integer comparison is well-defined.",
    "Lean 4's Array type does not include a 'forAll', so a conversion and list-based approach is necessary."
  ],
  "retry_guidance": "Ensure that during the conversion proof you explicitly pattern match on the list to introduce the correct number of binders. Pay attention to the inductive structure so that the equivalence between the index-based version and the list-based predicate is clear. If any errors arise regarding tactic binding (such as with 'introN'), confirm that all variables are properly introduced by matching the structure of the list and handling the base and inductive cases separately."
}
2025-06-01 03:03:54,520 - INFO - Updated plan: {
  "plan_summary": "Revise the implementation by converting the array to a list and then using List.all to check if every element is strictly less than the given integer. Additionally, prove the equivalence between the index-based predicate and the list-based predicate via induction on the list structure, making sure to correctly introduce binders and correctly handle the base case and the inductive step.",
  "steps": [
    "Define the function signature that accepts an integer 'n' and an Array of integers 'a'.",
    "Convert the array 'a' to a list using Array.toList, and then use List.all with the predicate (λ x, n > x) as the check.",
    "Implement a lemma that formally proves the equivalence between the index-based condition (∀ i, i < a.size → n > a[i]!) and the list-based predicate (a.toList.all (λ x, n > x)).",
    "For the lemma, perform induction on the list produced by a.toList:",
    "  - Base Case: When the list is empty, show that the index-based condition holds trivially.",
    "  - Inductive Step: Assume the equivalence holds for a list 'l'. Then, for a list constructed as (x :: l), prove that n > x and the equivalence for l implies the index-based condition for the entire array.",
    "Ensure the proof does not misuse tactics such as 'introN' by explicitly matching the structure of the list and carefully introducing the correct binders.",
    "Integrate the lemma into the overall function implementation so that the code compiles and the proof is complete.",
    "Avoid using 'sorry' by ensuring that all cases, including any conversions between array indices and list elements, are fully handled through induction or by auxiliary lemmas."
  ],
  "code_keywords": [
    "Lean 4",
    "Array.toList",
    "List.all",
    "boolean",
    "array traversal",
    "recursion"
  ],
  "proof_keywords": [
    "induction",
    "base case",
    "inductive hypothesis",
    "equivalence proof",
    "lemma",
    "array-to-list conversion",
    "pattern matching"
  ],
  "assumptions": [
    "The array is non-null.",
    "Array.toList accurately converts the array to a list with preserved order.",
    "Integer comparison is well-defined.",
    "Lean 4's Array type does not include a 'forAll', so a conversion and list-based approach is necessary."
  ],
  "retry_guidance": "Ensure that during the conversion proof you explicitly pattern match on the list to introduce the correct number of binders. Pay attention to the inductive structure so that the equivalence between the index-based version and the list-based predicate is clear. If any errors arise regarding tactic binding (such as with 'introN'), confirm that all variables are properly introduced by matching the structure of the list and handling the base and inductive cases separately."
}

Lean error summary:
The proof failed because the tactic 'introN' (invoked via apply Iff.intro) did not receive the expected number of binders. In other words, the proof does not correctly bridge the gap between the index‐based formulation (∀ i, i < a.size → n > a[i]!) and the Boolean condition produced by a.toList.all. The current proof attempts to directly introduce variables for a pattern match on a.toList without accounting for the conversion between array indices and list elements.
Retry guidance (MUST FOLLOW):
Revise the proof using the provided skeleton. Replace the faulty induction and direct introduction tactics with an application of List.all_iff_forall together with Array.mem_toList and Array.toList_nth to properly relate the array indices and list elements. Then re-run the proof.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 03:03:54,521 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the implementation by converting the array to a list and then using List.all to check if every element is strictly less than the given integer. Additionally, prove the equivalence between the index-based predicate and the list-based predicate via induction on the list structure, making sure to correctly introduce binders and correctly handle the base case and the inductive step.",\n  "steps": [\n    "Define the function signature that accepts an integer \'n\' and an Array of integers \'a\'.",\n    "Convert the array \'a\' to a list using Array.toList, and then use List.all with the predicate (λ x, n > x) as the check.",\n    "Implement a lemma that formally proves the equivalence between the index-based condition (∀ i, i < a.size → n > a[i]!) and the list-based predicate (a.toList.all (λ x, n > x)).",\n    "For the lemma, perform induction on the list produced by a.toList:",\n    "  - Base Case: When the list is empty, show that the index-based condition holds trivially.",\n    "  - Inductive Step: Assume the equivalence holds for a list \'l\'. Then, for a list constructed as (x :: l), prove that n > x and the equivalence for l implies the index-based condition for the entire array.",\n    "Ensure the proof does not misuse tactics such as \'introN\' by explicitly matching the structure of the list and carefully introducing the correct binders.",\n    "Integrate the lemma into the overall function implementation so that the code compiles and the proof is complete.",\n    "Avoid using \'sorry\' by ensuring that all cases, including any conversions between array indices and list elements, are fully handled through induction or by auxiliary lemmas."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array.toList",\n    "List.all",\n    "boolean",\n    "array traversal",\n    "recursion"\n  ],\n  "proof_keywords": [\n    "induction",\n    "base case",\n    "inductive hypothesis",\n    "equivalence proof",\n    "lemma",\n    "array-to-list conversion",\n    "pattern matching"\n  ],\n  "assumptions": [\n    "The array is non-null.",\n    "Array.toList accurately converts the array to a list with preserved order.",\n    "Integer comparison is well-defined.",\n    "Lean 4\'s Array type does not include a \'forAll\', so a conversion and list-based approach is necessary."\n  ],\n  "retry_guidance": "Ensure that during the conversion proof you explicitly pattern match on the list to introduce the correct number of binders. Pay attention to the inductive structure so that the equivalence between the index-based version and the list-based predicate is clear. If any errors arise regarding tactic binding (such as with \'introN\'), confirm that all variables are properly introduced by matching the structure of the list and handling the base and inductive cases separately."\n}\n\nLean error summary:\nThe proof failed because the tactic \'introN\' (invoked via apply Iff.intro) did not receive the expected number of binders. In other words, the proof does not correctly bridge the gap between the index‐based formulation (∀ i, i < a.size → n > a[i]!) and the Boolean condition produced by a.toList.all. The current proof attempts to directly introduce variables for a pattern match on a.toList without accounting for the conversion between array indices and list elements.\nRetry guidance (MUST FOLLOW):\nRevise the proof using the provided skeleton. Replace the faulty induction and direct introduction tactics with an application of List.all_iff_forall together with Array.mem_toList and Array.toList_nth to properly relate the array indices and list elements. Then re-run the proof.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isGreater (n : Int) (a : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the result is true, then n is greater than all elements in the array; If the result is false, then there exists at least one element in the array that is greater than or equal to n\ndef isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∀ i, i < a.size → n > a[i]!) ↔ result\n  -- << SPEC END >>\n\ntheorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n  isGreater_spec n a (isGreater n a) := by\n  -- << PROOF START >>\n  unfold isGreater isGreater_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The'}], 'model': 'gpt-4o'}}
2025-06-01 03:03:54,522 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:03:54,522 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:03:54,522 - DEBUG - send_request_headers.complete
2025-06-01 03:03:54,522 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:03:54,522 - DEBUG - send_request_body.complete
2025-06-01 03:03:54,522 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:04:01,362 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:04:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6580'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6585'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'15608'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'28.784s'), (b'x-request-id', b'req_1402583d856abf45079806d085d54905'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7b05fee046f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:04:01,363 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:04:01,363 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:04:01,364 - DEBUG - receive_response_body.complete
2025-06-01 03:04:01,364 - DEBUG - response_closed.started
2025-06-01 03:04:01,364 - DEBUG - response_closed.complete
2025-06-01 03:04:01,364 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:04:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6580', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6585', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '15608', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '28.784s', 'x-request-id': 'req_1402583d856abf45079806d085d54905', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7b05fee046f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:04:01,365 - DEBUG - request_id: req_1402583d856abf45079806d085d54905
2025-06-01 03:04:01,365 - INFO - Raw solution received: ```json
{
  "code": "a.toList.all (fun x => n > x)",
  "proof": "by\n  unfold isGreater isGreater_spec\n  split_ifs with h\n  apply Iff.intro\n  {\n    intro H\n    apply List.all_iff_forall.mpr\n    intro x hx\n    have ⟨i, hi, heq⟩ := Array.mem_toList.mp hx\n    rw [← heq, Array.get_elem_eq]\n    apply H\n    exact hi\n  }\n  {\n    intro H\n    intro i hi\n    specialize H (a.get ⟨i, hi⟩) (Array.mem_toList.2 ⟨i, hi, rfl⟩)\n    exact H\n  }\n  {\n    apply Iff.intro\n    {\n      intro H\n      exfalso\n      obtain ⟨i, hi⟩ := not_forall.mp H\n      have := a.toList_nth ⟨i, hi.1⟩ hi.2\n      exact hi.3 this\n    }\n    {\n      intro H\n      exfalso\n      exact H (List.not_all.mp h)\n    }\n  }"
}
```
2025-06-01 03:04:01,365 - INFO - <class 'str'>
2025-06-01 03:04:01,365 - INFO - Generated solution: {'code': 'a.toList.all (fun x => n > x)', 'proof': 'by\n  unfold isGreater isGreater_spec\n  split_ifs with h\n  apply Iff.intro\n  {\n    intro H\n    apply List.all_iff_forall.mpr\n    intro x hx\n    have ⟨i, hi, heq⟩ := Array.mem_toList.mp hx\n    rw [← heq, Array.get_elem_eq]\n    apply H\n    exact hi\n  }\n  {\n    intro H\n    intro i hi\n    specialize H (a.get ⟨i, hi⟩) (Array.mem_toList.2 ⟨i, hi, rfl⟩)\n    exact H\n  }\n  {\n    apply Iff.intro\n    {\n      intro H\n      exfalso\n      obtain ⟨i, hi⟩ := not_forall.mp H\n      have := a.toList_nth ⟨i, hi.1⟩ hi.2\n      exact hi.3 this\n    }\n    {\n      intro H\n      exfalso\n      exact H (List.not_all.mp h)\n    }\n  }'}
2025-06-01 03:04:06,715 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:18:40: error: unsolved goals
n : ℤ
a : Array ℤ
⊢ (∀ i < a.size, n > a[i]!) ↔ (a.toList.all fun x => decide (n > x)) = true
lean_playground/TempTest.lean:21:2: error: unexpected token 'by'; expected command
2025-06-01 03:04:06,715 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isGreater (n : Int) (a : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the result is true, then n is greater than all elements in the array; If the result is false, then there exists at least one element in the array that is greater than or equal to n\ndef isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∀ i, i < a.size → n > a[i]!) ↔ result\n  -- << SPEC END >>\n\ntheorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n  isGreater_spec n a (isGreater n a) := by\n  -- << PROOF START >>\n  unfold isGreater isGreater_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na.toList.all (fun x => n > x)\n\nGenerated Proof:\nby\n  unfold isGreater isGreater_spec\n  split_ifs with h\n  apply Iff.intro\n  {\n    intro H\n    apply List.all_iff_forall.mpr\n    intro x hx\n    have ⟨i, hi, heq⟩ := Array.mem_toList.mp hx\n    rw [← heq, Array.get_elem_eq]\n    apply H\n    exact hi\n  }\n  {\n    intro H\n    intro i hi\n    specialize H (a.get ⟨i, hi⟩) (Array.mem_toList.2 ⟨i, hi, rfl⟩)\n    exact H\n  }\n  {\n    apply Iff.intro\n    {\n      intro H\n      exfalso\n      obtain ⟨i, hi⟩ := not_forall.mp H\n      have := a.toList_nth ⟨i, hi.1⟩ hi.2\n      exact hi.3 this\n    }\n    {\n      intro H\n      exfalso\n      exact H (List.not_all.mp h)\n    }\n  }\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:18:40: error: unsolved goals\nn : ℤ\na : Array ℤ\n⊢ (∀ i < a.size, n > a[i]!) ↔ (a.toList.all fun x => decide (n > x)) = true\nlean_playground/TempTest.lean:21:2: error: unexpected token 'by'; expected command"}], 'model': 'o3-mini'}}
2025-06-01 03:04:06,716 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:04:06,716 - DEBUG - close.started
2025-06-01 03:04:06,716 - DEBUG - close.complete
2025-06-01 03:04:06,716 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:04:06,723 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e67008680>
2025-06-01 03:04:06,723 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:04:06,734 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e67008560>
2025-06-01 03:04:06,734 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:04:06,735 - DEBUG - send_request_headers.complete
2025-06-01 03:04:06,735 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:04:06,735 - DEBUG - send_request_body.complete
2025-06-01 03:04:06,735 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:04:16,471 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:04:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'9135'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'9139'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199042'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'287ms'), (b'x-request-id', b'req_bed812e5a015d8c4e45de1a28cc008aa'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7b524de58fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:04:16,471 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:04:16,471 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:04:16,472 - DEBUG - receive_response_body.complete
2025-06-01 03:04:16,472 - DEBUG - response_closed.started
2025-06-01 03:04:16,472 - DEBUG - response_closed.complete
2025-06-01 03:04:16,472 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:04:16 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '9135', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '9139', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199042', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '287ms', 'x-request-id': 'req_bed812e5a015d8c4e45de1a28cc008aa', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7b524de58fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:04:16,472 - DEBUG - request_id: req_bed812e5a015d8c4e45de1a28cc008aa
2025-06-01 03:04:16,472 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof script contains unsolved goals and an unexpected token error. In particular, the use of 'split_ifs with h' does not match the implementation (which does not use any if-statements) and results in unsolved goals. Additionally, the tactic script has an unexpected 'by' token indicating a structural issue with the proof script.", 'error_type': 'proof', 'suggested_fix': "Revise the proof to directly relate the definition of 'isGreater' (which is implemented as 'a.toList.all (fun x => n > x)') with the specification. For example, you can rewrite the theorem as follows:\n\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isGreater (n : Int) (a : Array Int) : Bool :=\n  a.toList.all (fun x => n > x)\n\n-- Theorem Specification\ndef isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=\n  (∀ i, i < a.size → n > a[i]!) ↔ result\n\n-- Revised Theorem Proof\ntheorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n  isGreater_spec n a (isGreater n a) := by\n  rw [isGreater, isGreater_spec]\n  -- Using the lemma that 'List.all f = true' is equivalent to '∀ x ∈ a.toList, f x'\n  rw [List.all_iff_forall]\n  exact Iff.rfl\n\nThis strategy removes unnecessary case splits and directly applies the equivalence lemma 'List.all_iff_forall'.", 'retry_strategy': 'Apply the above revised proof using rewrites and the equivalence lemma to match the implementation. Remove the unnecessary if-splits and ensure that the proof script directly unfolds the definitions to bridge the specification.'}
2025-06-01 03:04:16,473 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.\n\nPrevious plan:\n{\n  "plan_summary": "Revise the implementation by converting the array to a list and then using List.all to check if every element is strictly less than the given integer. Additionally, prove the equivalence between the index-based predicate and the list-based predicate via induction on the list structure, making sure to correctly introduce binders and correctly handle the base case and the inductive step.",\n  "steps": [\n    "Define the function signature that accepts an integer \'n\' and an Array of integers \'a\'.",\n    "Convert the array \'a\' to a list using Array.toList, and then use List.all with the predicate (λ x, n > x) as the check.",\n    "Implement a lemma that formally proves the equivalence between the index-based condition (∀ i, i < a.size → n > a[i]!) and the list-based predicate (a.toList.all (λ x, n > x)).",\n    "For the lemma, perform induction on the list produced by a.toList:",\n    "  - Base Case: When the list is empty, show that the index-based condition holds trivially.",\n    "  - Inductive Step: Assume the equivalence holds for a list \'l\'. Then, for a list constructed as (x :: l), prove that n > x and the equivalence for l implies the index-based condition for the entire array.",\n    "Ensure the proof does not misuse tactics such as \'introN\' by explicitly matching the structure of the list and carefully introducing the correct binders.",\n    "Integrate the lemma into the overall function implementation so that the code compiles and the proof is complete.",\n    "Avoid using \'sorry\' by ensuring that all cases, including any conversions between array indices and list elements, are fully handled through induction or by auxiliary lemmas."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array.toList",\n    "List.all",\n    "boolean",\n    "array traversal",\n    "recursion"\n  ],\n  "proof_keywords": [\n    "induction",\n    "base case",\n    "inductive hypothesis",\n    "equivalence proof",\n    "lemma",\n    "array-to-list conversion",\n    "pattern matching"\n  ],\n  "assumptions": [\n    "The array is non-null.",\n    "Array.toList accurately converts the array to a list with preserved order.",\n    "Integer comparison is well-defined.",\n    "Lean 4\'s Array type does not include a \'forAll\', so a conversion and list-based approach is necessary."\n  ],\n  "retry_guidance": "Ensure that during the conversion proof you explicitly pattern match on the list to introduce the correct number of binders. Pay attention to the inductive structure so that the equivalence between the index-based version and the list-based predicate is clear. If any errors arise regarding tactic binding (such as with \'introN\'), confirm that all variables are properly introduced by matching the structure of the list and handling the base and inductive cases separately."\n}\n\nLean error summary:\nThe proof failed because the tactic \'introN\' (invoked via apply Iff.intro) did not receive the expected number of binders. In other words, the proof does not correctly bridge the gap between the index‐based formulation (∀ i, i < a.size → n > a[i]!) and the Boolean condition produced by a.toList.all. The current proof attempts to directly introduce variables for a pattern match on a.toList without accounting for the conversion between array indices and list elements.\nRetry guidance (MUST FOLLOW):\nRevise the proof using the provided skeleton. Replace the faulty induction and direct introduction tactics with an application of List.all_iff_forall together with Array.mem_toList and Array.toList_nth to properly relate the array indices and list elements. Then re-run the proof.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThe proof script contains unsolved goals and an unexpected token error. In particular, the use of \'split_ifs with h\' does not match the implementation (which does not use any if-statements) and results in unsolved goals. Additionally, the tactic script has an unexpected \'by\' token indicating a structural issue with the proof script.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 03:04:16,474 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:04:16,474 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:04:16,474 - DEBUG - send_request_headers.complete
2025-06-01 03:04:16,474 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:04:16,474 - DEBUG - send_request_body.complete
2025-06-01 03:04:16,474 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:04:24,121 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:04:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7419'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7423'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198004'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'598ms'), (b'x-request-id', b'req_e8c765e64be2745496f07c2805e09905'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7b8f29978fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:04:24,121 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:04:24,121 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:04:24,122 - DEBUG - receive_response_body.complete
2025-06-01 03:04:24,122 - DEBUG - response_closed.started
2025-06-01 03:04:24,122 - DEBUG - response_closed.complete
2025-06-01 03:04:24,122 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:04:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7419', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7423', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198004', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '598ms', 'x-request-id': 'req_e8c765e64be2745496f07c2805e09905', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7b8f29978fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:04:24,122 - DEBUG - request_id: req_e8c765e64be2745496f07c2805e09905
2025-06-01 03:04:24,123 - INFO - Solution generated in 110.10 seconds
2025-06-01 03:04:24,123 - INFO - Generated code length: 29 characters
2025-06-01 03:04:24,123 - INFO - Generated proof length: 609 characters
2025-06-01 03:04:24,123 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 03:04:24,123 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 03:04:29,605 - INFO - Implementation test result: PASS
2025-06-01 03:04:29,605 - INFO - Executing Lean code with implementation and proof...
2025-06-01 03:04:35,113 - INFO - Full solution test result: FAIL
2025-06-01 03:04:35,113 - ERROR - Proof error: lean_playground/TempTest.lean:18:40: error: unsolved goals
n : ℤ
a : Array ℤ
⊢ (∀ i < a.size, n > a[i]!) ↔ (a.toList.all fun x => decide (n > x)) = tr...
2025-06-01 03:04:35,113 - INFO - ✅ Implementation passes unit tests
2025-06-01 03:04:35,114 - ERROR - ❌ Proof has errors
2025-06-01 03:04:35,114 - INFO - 
==================================================
2025-06-01 03:04:35,114 - INFO - Processing task task_id_435...
2025-06-01 03:04:35,114 - INFO - Reading problem description and code template from tasks/task_id_435...
2025-06-01 03:04:35,114 - INFO - Problem description length: 596 characters
2025-06-01 03:04:35,114 - INFO - Reading unit tests from tasks/task_id_435...
2025-06-01 03:04:35,114 - INFO - Unit tests length: 231 characters
2025-06-01 03:04:35,114 - INFO - Running main workflow to generate solution...
2025-06-01 03:04:35,114 - INFO - Problem description: -----Description-----  
This task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.

-----Input-----  
The input consists of a single value:  
n: A non-negative integer.

-----Output-----  
The output is an integer:  
Returns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.

-----Note-----  
It is assumed that the input number n is non-negative.
2025-06-01 03:04:35,114 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def lastDigit (n : Nat) : Nat :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The returned digit d should be between 0 and 9; d should be the last digit of the input number n
def lastDigit_spec (n : Nat) (result : Nat) : Prop :=
  -- << SPEC START >>
  (0 ≤ result ∧ result < 10) ∧
  (n % 10 = result)
  -- << SPEC END >>

theorem lastDigit_spec_satisfied (n : Nat) :
  lastDigit_spec n (lastDigit n) := by
  -- << PROOF START >>
  unfold lastDigit lastDigit_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 03:04:35,143 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7f4e67001620>, 'json_data': {'input': '-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 03:04:35,143 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 03:04:35,143 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:04:35,151 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fdbb00>
2025-06-01 03:04:35,151 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4e66fcbad0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:04:35,160 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fda780>
2025-06-01 03:04:35,160 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:04:35,160 - DEBUG - send_request_headers.complete
2025-06-01 03:04:35,161 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:04:35,161 - DEBUG - send_request_body.complete
2025-06-01 03:04:35,161 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:04:35,455 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:04:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'65'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-568fcbbc46-gfhzj'), (b'x-envoy-upstream-service-time', b'68'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999851'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_6a6afd90add0528ec45c74be2d2e821b'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=x98SjgWf_2fmbImUcg_vOlPOZvyaWauwtC5oU8K40ss-1748747075-1.0.1.1-21B3_uR2RpEbPjylBrlijE3IFUsCtA2UopudrijCgaxDnv0Bg6o.eInWhcVUsCVuxwqhjaFGDPvz9zfDcw7hRSjM9y4cl9Jj0mhvrPOa_s4; path=/; expires=Sun, 01-Jun-25 03:34:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=lRwlOKpcjPrBRYBn6xxU_pPdxPUq5GOPUPTrbn.OcOs-1748747075480-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7c03fe1346f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:04:35,455 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 03:04:35,455 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:04:35,455 - DEBUG - receive_response_body.complete
2025-06-01 03:04:35,455 - DEBUG - response_closed.started
2025-06-01 03:04:35,456 - DEBUG - response_closed.complete
2025-06-01 03:04:35,456 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 03:04:35 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '65'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-568fcbbc46-gfhzj'), ('x-envoy-upstream-service-time', '68'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999851'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_6a6afd90add0528ec45c74be2d2e821b'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=x98SjgWf_2fmbImUcg_vOlPOZvyaWauwtC5oU8K40ss-1748747075-1.0.1.1-21B3_uR2RpEbPjylBrlijE3IFUsCtA2UopudrijCgaxDnv0Bg6o.eInWhcVUsCVuxwqhjaFGDPvz9zfDcw7hRSjM9y4cl9Jj0mhvrPOa_s4; path=/; expires=Sun, 01-Jun-25 03:34:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=lRwlOKpcjPrBRYBn6xxU_pPdxPUq5GOPUPTrbn.OcOs-1748747075480-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b7c03fe1346f0-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 03:04:35,456 - DEBUG - request_id: req_6a6afd90add0528ec45c74be2d2e821b
2025-06-01 03:04:35,461 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
 modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
2025-06-01 03:04:35,482 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\nIf your function uses Boolean logic or `if...then...else`, always plan to:\n  - Use `by_cases` or `split_ifs` on the Boolean condition(s) in the proof.\n  - Use `simp` in each branch to reduce the goal to true ↔ true or false ↔ false.\n  - Close each goal with `trivial`, `exact`, or `exfalso` depending on context.\nDo not plan to use `case inl`/`case inr` (Lean 3-style); use `case pos`/`case neg` in Lean 4.\nNever rely on `sorry` or incomplete proofs; all goals must be discharged.\nIf the function's return type is `Bool` and the specification is a `↔` with a Prop, then include a plan to handle the `if` structure explicitly using `by_cases` or `split_ifs`.\nLean 4 requires `pos`/`neg` tags for `by_cases`. Do not mention `inl` or `inr`.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.'}], 'model': 'o3-mini'}}
2025-06-01 03:04:35,483 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:04:35,483 - DEBUG - close.started
2025-06-01 03:04:35,483 - DEBUG - close.complete
2025-06-01 03:04:35,483 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:04:35,491 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a6030>
2025-06-01 03:04:35,491 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:04:35,500 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a59d0>
2025-06-01 03:04:35,500 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:04:35,500 - DEBUG - send_request_headers.complete
2025-06-01 03:04:35,500 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:04:35,501 - DEBUG - send_request_body.complete
2025-06-01 03:04:35,501 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:04:43,185 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:04:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7427'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7436'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199363'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'190ms'), (b'x-request-id', b'req_326dca7b6aefc0a6670bcd1292ec30f7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7c06192147bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:04:43,185 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:04:43,185 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:04:43,186 - DEBUG - receive_response_body.complete
2025-06-01 03:04:43,186 - DEBUG - response_closed.started
2025-06-01 03:04:43,186 - DEBUG - response_closed.complete
2025-06-01 03:04:43,186 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:04:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7427', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7436', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199363', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '190ms', 'x-request-id': 'req_326dca7b6aefc0a6670bcd1292ec30f7', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7c06192147bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:04:43,186 - DEBUG - request_id: req_326dca7b6aefc0a6670bcd1292ec30f7
2025-06-01 03:04:43,186 - INFO - Attempt 1/3
2025-06-01 03:04:43,186 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that computes the last digit of a non-negative integer by returning n mod 10. The plan involves defining the function with the appropriate type (using Nat), employing the modulus operator, and optionally proving that the result lies between 0 and 9.",
  "steps": [
    "Define a function with an appropriate signature (e.g., last_digit : Nat -> Nat).",
    "Within the function, compute the result as n % 10 using Lean's built-in modulus operator.",
    "Optionally, prove or show that n % 10 is always in the range [0, 9] when n is non-negative.",
    "If a proof is required, use arithmetic lemmas (such as nat.mod_lt) to argue that the result is less than 10.",
    "Ensure that your proof steps simplify the goal (e.g., using simp) and close each case appropriately."
  ],
  "code_keywords": [
    "Nat",
    "mod",
    "n % 10",
    "non-negative",
    "function definition",
    "Lean 4"
  ],
  "proof_keywords": [
    "nat.mod_lt",
    "simp",
    "arithmetic",
    "non-negative integer",
    "range"
  ],
  "assumptions": [
    "The input n is a non-negative natural number.",
    "Built-in Lean operators for natural numbers, especially %, are used.",
    "The module or theorem proving that n % 10 lies in [0,9] is either built-in or available."
  ],
  "retry_guidance": "If you encounter errors related to type mismatches or proofs not being discharged, verify that the function signature correctly uses Nat and that all cases in any proof (if provided) have been handled using tactics like 'by_cases' or 'simp' as necessary."
}
2025-06-01 03:04:43,187 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that computes the last digit of a non-negative integer by returning n mod 10. The plan involves defining the function with the appropriate type (using Nat), employing the modulus operator, and optionally proving that the result lies between 0 and 9.",\n  "steps": [\n    "Define a function with an appropriate signature (e.g., last_digit : Nat -> Nat).",\n    "Within the function, compute the result as n % 10 using Lean\'s built-in modulus operator.",\n    "Optionally, prove or show that n % 10 is always in the range [0, 9] when n is non-negative.",\n    "If a proof is required, use arithmetic lemmas (such as nat.mod_lt) to argue that the result is less than 10.",\n    "Ensure that your proof steps simplify the goal (e.g., using simp) and close each case appropriately."\n  ],\n  "code_keywords": [\n    "Nat",\n    "mod",\n    "n % 10",\n    "non-negative",\n    "function definition",\n    "Lean 4"\n  ],\n  "proof_keywords": [\n    "nat.mod_lt",\n    "simp",\n    "arithmetic",\n    "non-negative integer",\n    "range"\n  ],\n  "assumptions": [\n    "The input n is a non-negative natural number.",\n    "Built-in Lean operators for natural numbers, especially %, are used.",\n    "The module or theorem proving that n % 10 lies in [0,9] is either built-in or available."\n  ],\n  "retry_guidance": "If you encounter errors related to type mismatches or proofs not being discharged, verify that the function signature correctly uses Nat and that all cases in any proof (if provided) have been handled using tactics like \'by_cases\' or \'simp\' as necessary."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef lastDigit (n : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned digit d should be between 0 and 9; d should be the last digit of the input number n\ndef lastDigit_spec (n : Nat) (result : Nat) : Prop :=\n  -- << SPEC START >>\n  (0 ≤ result ∧ result < 10) ∧\n  (n % 10 = result)\n  -- << SPEC END >>\n\ntheorem lastDigit_spec_satisfied (n : Nat) :\n  lastDigit_spec n (lastDigit n) := by\n  -- << PROOF START >>\n  unfold lastDigit lastDigit_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 03:04:43,189 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:04:43,189 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:04:43,189 - DEBUG - send_request_headers.complete
2025-06-01 03:04:43,189 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:04:43,194 - DEBUG - send_request_body.complete
2025-06-01 03:04:43,194 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:04:48,415 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:04:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4899'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4904'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'12115'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'35.77s'), (b'x-request-id', b'req_8d08a9f5feb1fb4f9ea32eeb24162e94'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7c362fc947bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:04:48,415 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:04:48,415 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:04:48,419 - DEBUG - receive_response_body.complete
2025-06-01 03:04:48,419 - DEBUG - response_closed.started
2025-06-01 03:04:48,419 - DEBUG - response_closed.complete
2025-06-01 03:04:48,419 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:04:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4899', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4904', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '12115', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '35.77s', 'x-request-id': 'req_8d08a9f5feb1fb4f9ea32eeb24162e94', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7c362fc947bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:04:48,420 - DEBUG - request_id: req_8d08a9f5feb1fb4f9ea32eeb24162e94
2025-06-01 03:04:48,420 - INFO - Raw solution received: ```json
{
  "code": "n % 10",
  "proof": "\n  have h1 : 0 < 10 := Nat.zero_lt_succ 9\n  exact ⟨Nat.zero_le (n % 10), Nat.mod_lt n h1, rfl⟩\n"
}
```
2025-06-01 03:04:48,420 - INFO - <class 'str'>
2025-06-01 03:04:48,420 - INFO - Generated solution: {'code': 'n % 10', 'proof': '\n  have h1 : 0 < 10 := Nat.zero_lt_succ 9\n  exact ⟨Nat.zero_le (n % 10), Nat.mod_lt n h1, rfl⟩\n'}
2025-06-01 03:04:53,804 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:24:9: error: application type mismatch
  And.intro (Nat.zero_le (n % 10))
argument
  Nat.zero_le (n % 10)
has type
  0 ≤ n % 10 : Prop
but is expected to have type
  0 ≤ n % 10 ∧ n % 10 < 10 : Prop
lean_playground/TempTest.lean:24:8: error: invalid constructor ⟨...⟩, insufficient number of arguments, constructs 'Eq.refl' does not have explicit fields, but #2 provided
2025-06-01 03:04:53,805 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef lastDigit (n : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned digit d should be between 0 and 9; d should be the last digit of the input number n\ndef lastDigit_spec (n : Nat) (result : Nat) : Prop :=\n  -- << SPEC START >>\n  (0 ≤ result ∧ result < 10) ∧\n  (n % 10 = result)\n  -- << SPEC END >>\n\ntheorem lastDigit_spec_satisfied (n : Nat) :\n  lastDigit_spec n (lastDigit n) := by\n  -- << PROOF START >>\n  unfold lastDigit lastDigit_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nn % 10\n\nGenerated Proof:\n\n  have h1 : 0 < 10 := Nat.zero_lt_succ 9\n  exact ⟨Nat.zero_le (n % 10), Nat.mod_lt n h1, rfl⟩\n\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:24:9: error: application type mismatch\n  And.intro (Nat.zero_le (n % 10))\nargument\n  Nat.zero_le (n % 10)\nhas type\n  0 ≤ n % 10 : Prop\nbut is expected to have type\n  0 ≤ n % 10 ∧ n % 10 < 10 : Prop\nlean_playground/TempTest.lean:24:8: error: invalid constructor ⟨...⟩, insufficient number of arguments, constructs 'Eq.refl' does not have explicit fields, but #2 provided"}], 'model': 'o3-mini'}}
2025-06-01 03:04:53,806 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:04:53,806 - DEBUG - close.started
2025-06-01 03:04:53,806 - DEBUG - close.complete
2025-06-01 03:04:53,806 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:04:53,814 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737ce00>
2025-06-01 03:04:53,814 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:04:53,823 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f93b30>
2025-06-01 03:04:53,823 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:04:53,823 - DEBUG - send_request_headers.complete
2025-06-01 03:04:53,823 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:04:53,823 - DEBUG - send_request_body.complete
2025-06-01 03:04:53,823 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:05:01,197 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:05:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6763'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6766'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199185'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'244ms'), (b'x-request-id', b'req_67ff6b4e100de9be3bb771b34c48a162'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7c789afc8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:05:01,198 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:05:01,198 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:05:01,198 - DEBUG - receive_response_body.complete
2025-06-01 03:05:01,198 - DEBUG - response_closed.started
2025-06-01 03:05:01,198 - DEBUG - response_closed.complete
2025-06-01 03:05:01,198 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:05:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6763', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6766', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199185', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '244ms', 'x-request-id': 'req_67ff6b4e100de9be3bb771b34c48a162', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7c789afc8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:05:01,198 - DEBUG - request_id: req_67ff6b4e100de9be3bb771b34c48a162
2025-06-01 03:05:01,199 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': 'The proof fails due to a tuple construction error. The constructor for the outer conjunction expects exactly two components: one for (0 ≤ n % 10 ∧ n % 10 < 10) and one for n % 10 = lastDigit n. The generated proof provided three separate arguments instead of nesting the first two into a pair.', 'error_type': 'proof', 'suggested_fix': "Change the tuple constructor to nest the proofs of the bounds into a single pair. For example, replace the line with 'exact ⟨(Nat.zero_le (n % 10), Nat.mod_lt n h1), rfl⟩' instead of '⟨Nat.zero_le (n % 10), Nat.mod_lt n h1, rfl⟩'. This correctly builds the conjunction required by lastDigit_spec.", 'retry_strategy': 'Correct the tuple construction by grouping the proof of (0 ≤ n % 10 ∧ n % 10 < 10) into a single pair. Then verify the proof compiles and meets the specification.'}
2025-06-01 03:05:01,199 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\nIf your function uses Boolean logic or `if...then...else`, always plan to:\n  - Use `by_cases` or `split_ifs` on the Boolean condition(s) in the proof.\n  - Use `simp` in each branch to reduce the goal to true ↔ true or false ↔ false.\n  - Close each goal with `trivial`, `exact`, or `exfalso` depending on context.\nDo not plan to use `case inl`/`case inr` (Lean 3-style); use `case pos`/`case neg` in Lean 4.\nNever rely on `sorry` or incomplete proofs; all goals must be discharged.\nIf the function's return type is `Bool` and the specification is a `↔` with a Prop, then include a plan to handle the `if` structure explicitly using `by_cases` or `split_ifs`.\nLean 4 requires `pos`/`neg` tags for `by_cases`. Do not mention `inl` or `inr`.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.\n\nPrevious plan:\n{\n  "plan_summary": "Define a Lean 4 function that computes the last digit of a non-negative integer by returning n mod 10. The plan involves defining the function with the appropriate type (using Nat), employing the modulus operator, and optionally proving that the result lies between 0 and 9.",\n  "steps": [\n    "Define a function with an appropriate signature (e.g., last_digit : Nat -> Nat).",\n    "Within the function, compute the result as n % 10 using Lean\'s built-in modulus operator.",\n    "Optionally, prove or show that n % 10 is always in the range [0, 9] when n is non-negative.",\n    "If a proof is required, use arithmetic lemmas (such as nat.mod_lt) to argue that the result is less than 10.",\n    "Ensure that your proof steps simplify the goal (e.g., using simp) and close each case appropriately."\n  ],\n  "code_keywords": [\n    "Nat",\n    "mod",\n    "n % 10",\n    "non-negative",\n    "function definition",\n    "Lean 4"\n  ],\n  "proof_keywords": [\n    "nat.mod_lt",\n    "simp",\n    "arithmetic",\n    "non-negative integer",\n    "range"\n  ],\n  "assumptions": [\n    "The input n is a non-negative natural number.",\n    "Built-in Lean operators for natural numbers, especially %, are used.",\n    "The module or theorem proving that n % 10 lies in [0,9] is either built-in or available."\n  ],\n  "retry_guidance": "If you encounter errors related to type mismatches or proofs not being discharged, verify that the function signature correctly uses Nat and that all cases in any proof (if provided) have been handled using tactics like \'by_cases\' or \'simp\' as necessary."\n}\n\nLean error:\nThe proof fails due to a tuple construction error. The constructor for the outer conjunction expects exactly two components: one for (0 ≤ n % 10 ∧ n % 10 < 10) and one for n % 10 = lastDigit n. The generated proof provided three separate arguments instead of nesting the first two into a pair.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 03:05:01,200 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:05:01,200 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:05:01,200 - DEBUG - send_request_headers.complete
2025-06-01 03:05:01,200 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:05:01,200 - DEBUG - send_request_body.complete
2025-06-01 03:05:01,200 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:05:09,645 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:05:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7810'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7813'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198872'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'338ms'), (b'x-request-id', b'req_41b27d229f30e54fe702cfdf06e6a257'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7ca6b97d8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:05:09,645 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:05:09,645 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:05:09,645 - DEBUG - receive_response_body.complete
2025-06-01 03:05:09,645 - DEBUG - response_closed.started
2025-06-01 03:05:09,646 - DEBUG - response_closed.complete
2025-06-01 03:05:09,646 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:05:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7810', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7813', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198872', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '338ms', 'x-request-id': 'req_41b27d229f30e54fe702cfdf06e6a257', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7ca6b97d8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:05:09,646 - DEBUG - request_id: req_41b27d229f30e54fe702cfdf06e6a257
2025-06-01 03:05:09,646 - INFO - Attempt 2/3
2025-06-01 03:05:09,646 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that computes the last digit of a non-negative integer using n % 10. In addition, if a proof is required to show that the output is in the range [0, 9] and equals n mod 10, ensure that the tuple used for the proof is constructed in a nested manner. That is, group the two range properties (0 ≤ n % 10 and n % 10 < 10) into a single component of the outer conjunction so that exactly two components are provided to the outer tuple.",
  "steps": [
    "Define the function signature, e.g., lastDigit : Nat → Nat, to accept a non-negative natural number.",
    "Compute the last digit by using the modulus operator, returning n % 10.",
    "If a proof is required to show that (n % 10) is in the range [0, 9] and that it equals the expected output, first prove that n % 10 satisfies 0 ≤ n % 10 and n % 10 < 10. Bundle these two proofs into a single pair or conjunction.",
    "Prove that n % 10 is equal to the output of the function by constructing a pair whose first element is the nested pair (range proofs) and whose second element is the equality proof.",
    "Use tactics like 'simp' and 'exact', and ensure that when handling Boolean conditions (if any), you use 'by_cases' or 'split_ifs'."
  ],
  "code_keywords": [
    "Nat",
    "mod",
    "n % 10",
    "function definition",
    "Lean 4"
  ],
  "proof_keywords": [
    "nat.mod_lt",
    "nested pairing",
    "and.intro",
    "simp",
    "range proof"
  ],
  "assumptions": [
    "Input n is a non-negative natural number that belongs to Nat.",
    "The modulus operation returns a number in the range [0, 9] for n % 10.",
    "The proof structure must use a nested pair for the conjunction to properly match the expected tuple format."
  ],
  "retry_guidance": "Ensure that the range property proofs (0 ≤ n % 10 ∧ n % 10 < 10) are bundled into one component of the tuple and that you do not attempt to provide three separate arguments to the outer pairing constructor. Verify that each nested pair is exactly in the structure required by the outer conjunction."
}
2025-06-01 03:05:09,646 - INFO - Updated plan: {
  "plan_summary": "Define a Lean 4 function that computes the last digit of a non-negative integer using n % 10. In addition, if a proof is required to show that the output is in the range [0, 9] and equals n mod 10, ensure that the tuple used for the proof is constructed in a nested manner. That is, group the two range properties (0 ≤ n % 10 and n % 10 < 10) into a single component of the outer conjunction so that exactly two components are provided to the outer tuple.",
  "steps": [
    "Define the function signature, e.g., lastDigit : Nat → Nat, to accept a non-negative natural number.",
    "Compute the last digit by using the modulus operator, returning n % 10.",
    "If a proof is required to show that (n % 10) is in the range [0, 9] and that it equals the expected output, first prove that n % 10 satisfies 0 ≤ n % 10 and n % 10 < 10. Bundle these two proofs into a single pair or conjunction.",
    "Prove that n % 10 is equal to the output of the function by constructing a pair whose first element is the nested pair (range proofs) and whose second element is the equality proof.",
    "Use tactics like 'simp' and 'exact', and ensure that when handling Boolean conditions (if any), you use 'by_cases' or 'split_ifs'."
  ],
  "code_keywords": [
    "Nat",
    "mod",
    "n % 10",
    "function definition",
    "Lean 4"
  ],
  "proof_keywords": [
    "nat.mod_lt",
    "nested pairing",
    "and.intro",
    "simp",
    "range proof"
  ],
  "assumptions": [
    "Input n is a non-negative natural number that belongs to Nat.",
    "The modulus operation returns a number in the range [0, 9] for n % 10.",
    "The proof structure must use a nested pair for the conjunction to properly match the expected tuple format."
  ],
  "retry_guidance": "Ensure that the range property proofs (0 ≤ n % 10 ∧ n % 10 < 10) are bundled into one component of the tuple and that you do not attempt to provide three separate arguments to the outer pairing constructor. Verify that each nested pair is exactly in the structure required by the outer conjunction."
}

Lean error summary:
The proof fails due to a tuple construction error. The constructor for the outer conjunction expects exactly two components: one for (0 ≤ n % 10 ∧ n % 10 < 10) and one for n % 10 = lastDigit n. The generated proof provided three separate arguments instead of nesting the first two into a pair.
Retry guidance (MUST FOLLOW):
Correct the tuple construction by grouping the proof of (0 ≤ n % 10 ∧ n % 10 < 10) into a single pair. Then verify the proof compiles and meets the specification.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 03:05:09,647 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that computes the last digit of a non-negative integer using n % 10. In addition, if a proof is required to show that the output is in the range [0, 9] and equals n mod 10, ensure that the tuple used for the proof is constructed in a nested manner. That is, group the two range properties (0 ≤ n % 10 and n % 10 < 10) into a single component of the outer conjunction so that exactly two components are provided to the outer tuple.",\n  "steps": [\n    "Define the function signature, e.g., lastDigit : Nat → Nat, to accept a non-negative natural number.",\n    "Compute the last digit by using the modulus operator, returning n % 10.",\n    "If a proof is required to show that (n % 10) is in the range [0, 9] and that it equals the expected output, first prove that n % 10 satisfies 0 ≤ n % 10 and n % 10 < 10. Bundle these two proofs into a single pair or conjunction.",\n    "Prove that n % 10 is equal to the output of the function by constructing a pair whose first element is the nested pair (range proofs) and whose second element is the equality proof.",\n    "Use tactics like \'simp\' and \'exact\', and ensure that when handling Boolean conditions (if any), you use \'by_cases\' or \'split_ifs\'."\n  ],\n  "code_keywords": [\n    "Nat",\n    "mod",\n    "n % 10",\n    "function definition",\n    "Lean 4"\n  ],\n  "proof_keywords": [\n    "nat.mod_lt",\n    "nested pairing",\n    "and.intro",\n    "simp",\n    "range proof"\n  ],\n  "assumptions": [\n    "Input n is a non-negative natural number that belongs to Nat.",\n    "The modulus operation returns a number in the range [0, 9] for n % 10.",\n    "The proof structure must use a nested pair for the conjunction to properly match the expected tuple format."\n  ],\n  "retry_guidance": "Ensure that the range property proofs (0 ≤ n % 10 ∧ n % 10 < 10) are bundled into one component of the tuple and that you do not attempt to provide three separate arguments to the outer pairing constructor. Verify that each nested pair is exactly in the structure required by the outer conjunction."\n}\n\nLean error summary:\nThe proof fails due to a tuple construction error. The constructor for the outer conjunction expects exactly two components: one for (0 ≤ n % 10 ∧ n % 10 < 10) and one for n % 10 = lastDigit n. The generated proof provided three separate arguments instead of nesting the first two into a pair.\nRetry guidance (MUST FOLLOW):\nCorrect the tuple construction by grouping the proof of (0 ≤ n % 10 ∧ n % 10 < 10) into a single pair. Then verify the proof compiles and meets the specification.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef lastDigit (n : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned digit d should be between 0 and 9; d should be the last digit of the input number n\ndef lastDigit_spec (n : Nat) (result : Nat) : Prop :=\n  -- << SPEC START >>\n  (0 ≤ result ∧ result < 10) ∧\n  (n % 10 = result)\n  -- << SPEC END >>\n\ntheorem lastDigit_spec_satisfied (n : Nat) :\n  lastDigit_spec n (lastDigit n) := by\n  -- << PROOF START >>\n  unfold lastDigit lastDigit_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 03:05:09,648 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:05:09,649 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:05:09,649 - DEBUG - send_request_headers.complete
2025-06-01 03:05:09,649 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:05:09,654 - DEBUG - send_request_body.complete
2025-06-01 03:05:09,654 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:05:17,298 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:05:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6795'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6803'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'6159'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'47.681s'), (b'x-request-id', b'req_e9f75613dc526ae2ab4d37554c42ffff'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7cdb8a618fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:05:17,298 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:05:17,298 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:05:17,301 - DEBUG - receive_response_body.complete
2025-06-01 03:05:17,301 - DEBUG - response_closed.started
2025-06-01 03:05:17,301 - DEBUG - response_closed.complete
2025-06-01 03:05:17,301 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:05:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6795', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6803', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '6159', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '47.681s', 'x-request-id': 'req_e9f75613dc526ae2ab4d37554c42ffff', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7cdb8a618fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:05:17,301 - DEBUG - request_id: req_e9f75613dc526ae2ab4d37554c42ffff
2025-06-01 03:05:17,301 - INFO - Raw solution received: ```json
{
  "code": "n % 10",
  "proof": "by_cases h: (n = 0)\n  simp [h]\n  trivial\n  \n  have hlt: n % 10 < 10 := Nat.mod_lt n (by decide)\n  have hge: 0 ≤ n % 10 := Nat.zero_le _\n  exact ⟨⟨hge, hlt⟩, rfl⟩"
}
```
2025-06-01 03:05:17,301 - INFO - <class 'str'>
2025-06-01 03:05:17,301 - INFO - Generated solution: {'code': 'n % 10', 'proof': 'by_cases h: (n = 0)\n  simp [h]\n  trivial\n  \n  have hlt: n % 10 < 10 := Nat.mod_lt n (by decide)\n  have hge: 0 ≤ n % 10 := Nat.zero_le _\n  exact ⟨⟨hge, hlt⟩, rfl⟩'}
2025-06-01 03:05:22,512 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:24:2: error: tactic 'assumption' failed
case neg
n : ℕ
h : ¬n = 0
⊢ (0 ≤ n % 10 ∧ n % 10 < 10) ∧ n % 10 = n % 10
2025-06-01 03:05:22,512 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef lastDigit (n : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned digit d should be between 0 and 9; d should be the last digit of the input number n\ndef lastDigit_spec (n : Nat) (result : Nat) : Prop :=\n  -- << SPEC START >>\n  (0 ≤ result ∧ result < 10) ∧\n  (n % 10 = result)\n  -- << SPEC END >>\n\ntheorem lastDigit_spec_satisfied (n : Nat) :\n  lastDigit_spec n (lastDigit n) := by\n  -- << PROOF START >>\n  unfold lastDigit lastDigit_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nn % 10\n\nGenerated Proof:\nby_cases h: (n = 0)\n  simp [h]\n  trivial\n  \n  have hlt: n % 10 < 10 := Nat.mod_lt n (by decide)\n  have hge: 0 ≤ n % 10 := Nat.zero_le _\n  exact ⟨⟨hge, hlt⟩, rfl⟩\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:24:2: error: tactic 'assumption' failed\ncase neg\nn : ℕ\nh : ¬n = 0\n⊢ (0 ≤ n % 10 ∧ n % 10 < 10) ∧ n % 10 = n % 10"}], 'model': 'o3-mini'}}
2025-06-01 03:05:22,513 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:05:22,513 - DEBUG - close.started
2025-06-01 03:05:22,513 - DEBUG - close.complete
2025-06-01 03:05:22,513 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:05:22,520 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fe53a0>
2025-06-01 03:05:22,520 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:05:22,529 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fe7350>
2025-06-01 03:05:22,529 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:05:22,530 - DEBUG - send_request_headers.complete
2025-06-01 03:05:22,530 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:05:22,530 - DEBUG - send_request_body.complete
2025-06-01 03:05:22,530 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:05:32,825 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:05:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'10014'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'10075'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199231'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'230ms'), (b'x-request-id', b'req_bdddee48dc9860bf2af2256d533f46c5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7d2c0ff447bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:05:32,825 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:05:32,825 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:05:32,825 - DEBUG - receive_response_body.complete
2025-06-01 03:05:32,826 - DEBUG - response_closed.started
2025-06-01 03:05:32,826 - DEBUG - response_closed.complete
2025-06-01 03:05:32,826 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:05:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '10014', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '10075', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199231', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '230ms', 'x-request-id': 'req_bdddee48dc9860bf2af2256d533f46c5', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7d2c0ff447bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:05:32,826 - DEBUG - request_id: req_bdddee48dc9860bf2af2256d533f46c5
2025-06-01 03:05:32,826 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails because in the branch where n ≠ 0 the tactic 'assumption' (invoked by 'trivial') does not close the goal. The case split using 'by_cases' does not properly handle the n = 0 case and the non-zero branch needs to provide a complete proof rather than relying on 'trivial'.", 'error_type': 'proof', 'suggested_fix': "Instead of using 'by_cases', consider using 'cases n with' to distinguish between the zero and nonzero cases. For example, you can rewrite the proof as follows:\n\n  theorem lastDigit_spec_satisfied (n : Nat) :\n    lastDigit_spec n (lastDigit n) := by\n    unfold lastDigit lastDigit_spec\n    cases n with\n    | zero =>\n        simp\n    | succ n' =>\n        have hlt: (Nat.succ n' % 10) < 10 := Nat.mod_lt (Nat.succ n') (by decide)\n        have hge: 0 ≤ (Nat.succ n' % 10) := Nat.zero_le (Nat.succ n' % 10)\n        exact ⟨⟨hge, hlt⟩, rfl⟩\n\nThis explicitly handles the base case and avoids relying on 'trivial' or 'assumption' in the nonzero case.", 'retry_strategy': "Rewrite the proof to use pattern matching on n with 'cases n' to handle both cases separately. This ensures that in each branch the required properties are directly established without relying on tactics that may fail."}
2025-06-01 03:05:32,827 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\nIf your function uses Boolean logic or `if...then...else`, always plan to:\n  - Use `by_cases` or `split_ifs` on the Boolean condition(s) in the proof.\n  - Use `simp` in each branch to reduce the goal to true ↔ true or false ↔ false.\n  - Close each goal with `trivial`, `exact`, or `exfalso` depending on context.\nDo not plan to use `case inl`/`case inr` (Lean 3-style); use `case pos`/`case neg` in Lean 4.\nNever rely on `sorry` or incomplete proofs; all goals must be discharged.\nIf the function's return type is `Bool` and the specification is a `↔` with a Prop, then include a plan to handle the `if` structure explicitly using `by_cases` or `split_ifs`.\nLean 4 requires `pos`/`neg` tags for `by_cases`. Do not mention `inl` or `inr`.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.\n\nPrevious plan:\n{\n  "plan_summary": "Define a Lean 4 function that computes the last digit of a non-negative integer using n % 10. In addition, if a proof is required to show that the output is in the range [0, 9] and equals n mod 10, ensure that the tuple used for the proof is constructed in a nested manner. That is, group the two range properties (0 ≤ n % 10 and n % 10 < 10) into a single component of the outer conjunction so that exactly two components are provided to the outer tuple.",\n  "steps": [\n    "Define the function signature, e.g., lastDigit : Nat → Nat, to accept a non-negative natural number.",\n    "Compute the last digit by using the modulus operator, returning n % 10.",\n    "If a proof is required to show that (n % 10) is in the range [0, 9] and that it equals the expected output, first prove that n % 10 satisfies 0 ≤ n % 10 and n % 10 < 10. Bundle these two proofs into a single pair or conjunction.",\n    "Prove that n % 10 is equal to the output of the function by constructing a pair whose first element is the nested pair (range proofs) and whose second element is the equality proof.",\n    "Use tactics like \'simp\' and \'exact\', and ensure that when handling Boolean conditions (if any), you use \'by_cases\' or \'split_ifs\'."\n  ],\n  "code_keywords": [\n    "Nat",\n    "mod",\n    "n % 10",\n    "function definition",\n    "Lean 4"\n  ],\n  "proof_keywords": [\n    "nat.mod_lt",\n    "nested pairing",\n    "and.intro",\n    "simp",\n    "range proof"\n  ],\n  "assumptions": [\n    "Input n is a non-negative natural number that belongs to Nat.",\n    "The modulus operation returns a number in the range [0, 9] for n % 10.",\n    "The proof structure must use a nested pair for the conjunction to properly match the expected tuple format."\n  ],\n  "retry_guidance": "Ensure that the range property proofs (0 ≤ n % 10 ∧ n % 10 < 10) are bundled into one component of the tuple and that you do not attempt to provide three separate arguments to the outer pairing constructor. Verify that each nested pair is exactly in the structure required by the outer conjunction."\n}\n\nLean error summary:\nThe proof fails due to a tuple construction error. The constructor for the outer conjunction expects exactly two components: one for (0 ≤ n % 10 ∧ n % 10 < 10) and one for n % 10 = lastDigit n. The generated proof provided three separate arguments instead of nesting the first two into a pair.\nRetry guidance (MUST FOLLOW):\nCorrect the tuple construction by grouping the proof of (0 ≤ n % 10 ∧ n % 10 < 10) into a single pair. Then verify the proof compiles and meets the specification.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThe proof fails because in the branch where n ≠ 0 the tactic \'assumption\' (invoked by \'trivial\') does not close the goal. The case split using \'by_cases\' does not properly handle the n = 0 case and the non-zero branch needs to provide a complete proof rather than relying on \'trivial\'.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 03:05:32,827 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:05:32,827 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:05:32,828 - DEBUG - send_request_headers.complete
2025-06-01 03:05:32,828 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:05:32,828 - DEBUG - send_request_body.complete
2025-06-01 03:05:32,828 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:05:42,529 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:05:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'9474'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'9480'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'197973'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'607ms'), (b'x-request-id', b'req_93830374a5afc456e9312be8a0d60a08'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7d6c591e47bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:05:42,529 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:05:42,529 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:05:42,529 - DEBUG - receive_response_body.complete
2025-06-01 03:05:42,530 - DEBUG - response_closed.started
2025-06-01 03:05:42,530 - DEBUG - response_closed.complete
2025-06-01 03:05:42,530 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:05:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '9474', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '9480', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '197973', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '607ms', 'x-request-id': 'req_93830374a5afc456e9312be8a0d60a08', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7d6c591e47bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:05:42,530 - DEBUG - request_id: req_93830374a5afc456e9312be8a0d60a08
2025-06-01 03:05:42,530 - INFO - Attempt 3/3
2025-06-01 03:05:42,530 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that computes the last digit of a non-negative integer using n % 10 and accompanies it with a proof that the result is in the range [0, 9] and equal to n % 10. The proof will use a case split on whether n is zero or non-zero, carefully grouping the range proofs into one nested pair and explicitly handling each case without relying on 'trivial' to close the non-zero branch.",
  "steps": [
    "Step 1: Define the function signature. For example, create a function lastDigit : Nat → Nat that returns n % 10.",
    "Step 2: In the function body, simply compute n % 10.",
    "Step 3: Attach a proof that the computed result meets the specification. Construct a tuple where the first component is the nested pair of proofs showing that 0 ≤ n % 10 ∧ n % 10 < 10, and the second component shows n % 10 = lastDigit n.",
    "Step 4: To handle any conditions on n, use 'by_cases' or 'split_ifs'. Explicitly consider the case where n = 0. In this branch, prove the properties easily (for example, 0 % 10 = 0, and the range conditions hold trivially).",
    "Step 5: In the non-zero branch, don't rely on 'trivial' or 'assumption'. Instead, invoke known lemmas such as nat.mod_lt to supply a complete proof that n % 10 < 10. Also provide a complete proof for 0 ≤ n % 10 (which is expected from the properties of the modulus).",
    "Step 6: Ensure that the tuple construction strictly groups the two range proofs into one nested pair so that the outer tuple has exactly two components.",
    "Step 7: Finalize by checking that both branches are fully discharged without any incomplete proof steps."
  ],
  "code_keywords": [
    "Nat",
    "mod",
    "n % 10",
    "function definition",
    "Lean 4",
    "by_cases",
    "split_ifs"
  ],
  "proof_keywords": [
    "nat.mod_lt",
    "nested pairing",
    "and.intro",
    "by_cases",
    "exact",
    "trivial",
    "range proof"
  ],
  "assumptions": [
    "Input n is a non-negative natural number (of type Nat).",
    "The modulus operation in Lean will ensure that n % 10 returns a value between 0 and 9.",
    "The proof structure requires a nested pair for the range proofs, and the case split must be complete for both n = 0 and n ≠ 0 cases."
  ],
  "retry_guidance": "Ensure that the 'by_cases' tactic explicitly differentiates the n = 0 branch and the n ≠ 0 branch. In the non-zero branch, do not rely on 'trivial' to close the goal; instead, apply lemmas like nat.mod_lt and provide explicit proofs for each part of the nested pair. Verify that the tuple constructor is used with exactly two arguments: one grouping the range proofs and the other proving the equality."
}
2025-06-01 03:05:42,530 - INFO - Updated plan: {
  "plan_summary": "Define a Lean 4 function that computes the last digit of a non-negative integer using n % 10 and accompanies it with a proof that the result is in the range [0, 9] and equal to n % 10. The proof will use a case split on whether n is zero or non-zero, carefully grouping the range proofs into one nested pair and explicitly handling each case without relying on 'trivial' to close the non-zero branch.",
  "steps": [
    "Step 1: Define the function signature. For example, create a function lastDigit : Nat → Nat that returns n % 10.",
    "Step 2: In the function body, simply compute n % 10.",
    "Step 3: Attach a proof that the computed result meets the specification. Construct a tuple where the first component is the nested pair of proofs showing that 0 ≤ n % 10 ∧ n % 10 < 10, and the second component shows n % 10 = lastDigit n.",
    "Step 4: To handle any conditions on n, use 'by_cases' or 'split_ifs'. Explicitly consider the case where n = 0. In this branch, prove the properties easily (for example, 0 % 10 = 0, and the range conditions hold trivially).",
    "Step 5: In the non-zero branch, don't rely on 'trivial' or 'assumption'. Instead, invoke known lemmas such as nat.mod_lt to supply a complete proof that n % 10 < 10. Also provide a complete proof for 0 ≤ n % 10 (which is expected from the properties of the modulus).",
    "Step 6: Ensure that the tuple construction strictly groups the two range proofs into one nested pair so that the outer tuple has exactly two components.",
    "Step 7: Finalize by checking that both branches are fully discharged without any incomplete proof steps."
  ],
  "code_keywords": [
    "Nat",
    "mod",
    "n % 10",
    "function definition",
    "Lean 4",
    "by_cases",
    "split_ifs"
  ],
  "proof_keywords": [
    "nat.mod_lt",
    "nested pairing",
    "and.intro",
    "by_cases",
    "exact",
    "trivial",
    "range proof"
  ],
  "assumptions": [
    "Input n is a non-negative natural number (of type Nat).",
    "The modulus operation in Lean will ensure that n % 10 returns a value between 0 and 9.",
    "The proof structure requires a nested pair for the range proofs, and the case split must be complete for both n = 0 and n ≠ 0 cases."
  ],
  "retry_guidance": "Ensure that the 'by_cases' tactic explicitly differentiates the n = 0 branch and the n ≠ 0 branch. In the non-zero branch, do not rely on 'trivial' to close the goal; instead, apply lemmas like nat.mod_lt and provide explicit proofs for each part of the nested pair. Verify that the tuple constructor is used with exactly two arguments: one grouping the range proofs and the other proving the equality."
}

Lean error summary:
The proof fails because in the branch where n ≠ 0 the tactic 'assumption' (invoked by 'trivial') does not close the goal. The case split using 'by_cases' does not properly handle the n = 0 case and the non-zero branch needs to provide a complete proof rather than relying on 'trivial'.
Retry guidance (MUST FOLLOW):
Rewrite the proof to use pattern matching on n with 'cases n' to handle both cases separately. This ensures that in each branch the required properties are directly established without relying on tactics that may fail.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 03:05:42,531 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that computes the last digit of a non-negative integer using n % 10 and accompanies it with a proof that the result is in the range [0, 9] and equal to n % 10. The proof will use a case split on whether n is zero or non-zero, carefully grouping the range proofs into one nested pair and explicitly handling each case without relying on \'trivial\' to close the non-zero branch.",\n  "steps": [\n    "Step 1: Define the function signature. For example, create a function lastDigit : Nat → Nat that returns n % 10.",\n    "Step 2: In the function body, simply compute n % 10.",\n    "Step 3: Attach a proof that the computed result meets the specification. Construct a tuple where the first component is the nested pair of proofs showing that 0 ≤ n % 10 ∧ n % 10 < 10, and the second component shows n % 10 = lastDigit n.",\n    "Step 4: To handle any conditions on n, use \'by_cases\' or \'split_ifs\'. Explicitly consider the case where n = 0. In this branch, prove the properties easily (for example, 0 % 10 = 0, and the range conditions hold trivially).",\n    "Step 5: In the non-zero branch, don\'t rely on \'trivial\' or \'assumption\'. Instead, invoke known lemmas such as nat.mod_lt to supply a complete proof that n % 10 < 10. Also provide a complete proof for 0 ≤ n % 10 (which is expected from the properties of the modulus).",\n    "Step 6: Ensure that the tuple construction strictly groups the two range proofs into one nested pair so that the outer tuple has exactly two components.",\n    "Step 7: Finalize by checking that both branches are fully discharged without any incomplete proof steps."\n  ],\n  "code_keywords": [\n    "Nat",\n    "mod",\n    "n % 10",\n    "function definition",\n    "Lean 4",\n    "by_cases",\n    "split_ifs"\n  ],\n  "proof_keywords": [\n    "nat.mod_lt",\n    "nested pairing",\n    "and.intro",\n    "by_cases",\n    "exact",\n    "trivial",\n    "range proof"\n  ],\n  "assumptions": [\n    "Input n is a non-negative natural number (of type Nat).",\n    "The modulus operation in Lean will ensure that n % 10 returns a value between 0 and 9.",\n    "The proof structure requires a nested pair for the range proofs, and the case split must be complete for both n = 0 and n ≠ 0 cases."\n  ],\n  "retry_guidance": "Ensure that the \'by_cases\' tactic explicitly differentiates the n = 0 branch and the n ≠ 0 branch. In the non-zero branch, do not rely on \'trivial\' to close the goal; instead, apply lemmas like nat.mod_lt and provide explicit proofs for each part of the nested pair. Verify that the tuple constructor is used with exactly two arguments: one grouping the range proofs and the other proving the equality."\n}\n\nLean error summary:\nThe proof fails because in the branch where n ≠ 0 the tactic \'assumption\' (invoked by \'trivial\') does not close the goal. The case split using \'by_cases\' does not properly handle the n = 0 case and the non-zero branch needs to provide a complete proof rather than relying on \'trivial\'.\nRetry guidance (MUST FOLLOW):\nRewrite the proof to use pattern matching on n with \'cases n\' to handle both cases separately. This ensures that in each branch the required properties are directly established without relying on tactics that may fail.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef lastDigit (n : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned digit d should be between 0 and 9; d should be the last digit of the input number n\ndef lastDigit_spec (n : Nat) (result : Nat) : Prop :=\n  -- << SPEC START >>\n  (0 ≤ result ∧ result < 10) ∧\n  (n % 10 = result)\n  -- << SPEC END >>\n\ntheorem lastDigit_spec_satisfied (n : Nat) :\n  lastDigit_spec n (lastDigit n) := by\n  -- << PROOF START >>\n  unfold lastDigit lastDigit_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 03:05:42,533 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:05:42,533 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:05:42,533 - DEBUG - send_request_headers.complete
2025-06-01 03:05:42,533 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:05:42,537 - DEBUG - send_request_body.complete
2025-06-01 03:05:42,537 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:05:45,422 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:05:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2641'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2645'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'2647'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'54.704s'), (b'x-request-id', b'req_0aedc133ca2b350f842b9590eb529486'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7da90be847bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:05:45,423 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:05:45,423 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:05:45,424 - DEBUG - receive_response_body.complete
2025-06-01 03:05:45,424 - DEBUG - response_closed.started
2025-06-01 03:05:45,424 - DEBUG - response_closed.complete
2025-06-01 03:05:45,424 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:05:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2641', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2645', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '2647', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '54.704s', 'x-request-id': 'req_0aedc133ca2b350f842b9590eb529486', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7da90be847bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:05:45,424 - DEBUG - request_id: req_0aedc133ca2b350f842b9590eb529486
2025-06-01 03:05:45,425 - INFO - Raw solution received: ```json
{
  "code": "n % 10",
  "proof": "cases n with\n  | zero =>\n    simp\n  | succ n =>\n    have : n % 10 < 10 := Nat.mod_lt _ (Nat.succ_pos _)\n    constructor\n    constructor\n    exact Nat.zero_le (n % 10)\n    exact this\n    rfl"
}
```
2025-06-01 03:05:45,425 - INFO - <class 'str'>
2025-06-01 03:05:45,425 - INFO - Generated solution: {'code': 'n % 10', 'proof': 'cases n with\n  | zero =>\n    simp\n  | succ n =>\n    have : n % 10 < 10 := Nat.mod_lt _ (Nat.succ_pos _)\n    constructor\n    constructor\n    exact Nat.zero_le (n % 10)\n    exact this\n    rfl'}
2025-06-01 03:05:50,779 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:29:4: error: type mismatch
  Nat.zero_le (n % 10)
has type
  0 ≤ n % 10 : Prop
but is expected to have type
  0 ≤ (n + 1) % 10 : Prop
2025-06-01 03:05:50,780 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef lastDigit (n : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned digit d should be between 0 and 9; d should be the last digit of the input number n\ndef lastDigit_spec (n : Nat) (result : Nat) : Prop :=\n  -- << SPEC START >>\n  (0 ≤ result ∧ result < 10) ∧\n  (n % 10 = result)\n  -- << SPEC END >>\n\ntheorem lastDigit_spec_satisfied (n : Nat) :\n  lastDigit_spec n (lastDigit n) := by\n  -- << PROOF START >>\n  unfold lastDigit lastDigit_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nn % 10\n\nGenerated Proof:\ncases n with\n  | zero =>\n    simp\n  | succ n =>\n    have : n % 10 < 10 := Nat.mod_lt _ (Nat.succ_pos _)\n    constructor\n    constructor\n    exact Nat.zero_le (n % 10)\n    exact this\n    rfl\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:29:4: error: type mismatch\n  Nat.zero_le (n % 10)\nhas type\n  0 ≤ n % 10 : Prop\nbut is expected to have type\n  0 ≤ (n + 1) % 10 : Prop'}], 'model': 'o3-mini'}}
2025-06-01 03:05:50,780 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:05:50,780 - DEBUG - close.started
2025-06-01 03:05:50,781 - DEBUG - close.complete
2025-06-01 03:05:50,781 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:05:50,788 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f91700>
2025-06-01 03:05:50,788 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:05:50,796 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737f860>
2025-06-01 03:05:50,796 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:05:50,797 - DEBUG - send_request_headers.complete
2025-06-01 03:05:50,797 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:05:50,797 - DEBUG - send_request_body.complete
2025-06-01 03:05:50,797 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:05:59,536 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:05:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8509'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8512'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199222'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'233ms'), (b'x-request-id', b'req_b0a73a9383c83f6c0d001ce13310ee6b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7ddcab664436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:05:59,537 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:05:59,537 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:05:59,537 - DEBUG - receive_response_body.complete
2025-06-01 03:05:59,537 - DEBUG - response_closed.started
2025-06-01 03:05:59,537 - DEBUG - response_closed.complete
2025-06-01 03:05:59,537 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:05:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8509', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8512', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199222', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '233ms', 'x-request-id': 'req_b0a73a9383c83f6c0d001ce13310ee6b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7ddcab664436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:05:59,537 - DEBUG - request_id: req_b0a73a9383c83f6c0d001ce13310ee6b
2025-06-01 03:05:59,538 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "In the 'succ' branch, the proof incorrectly uses 'n % 10' instead of '(succ n) % 10'. The theorem expects to show that 0 ≤ (succ n) % 10 and that (succ n) % 10 < 10, but the provided proof uses the wrong variable, causing a type mismatch.", 'error_type': 'type', 'suggested_fix': "In the 'succ' branch, replace 'n % 10' with '(succ n) % 10'. For example, change the 'have' statement to 'have : (succ n) % 10 < 10 := Nat.mod_lt (succ n) (Nat.succ_pos n)' and then use 'Nat.zero_le ((succ n) % 10)'. This change will align the proof with the definition of lastDigit when n is a successor.", 'retry_strategy': "Update the proof in the succ branch to properly refer to (succ n) % 10. Rerun the proof and check that the pattern match correctly handles both 'zero' and 'succ' cases without type mismatches."}
2025-06-01 03:05:59,539 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\nIf your function uses Boolean logic or `if...then...else`, always plan to:\n  - Use `by_cases` or `split_ifs` on the Boolean condition(s) in the proof.\n  - Use `simp` in each branch to reduce the goal to true ↔ true or false ↔ false.\n  - Close each goal with `trivial`, `exact`, or `exfalso` depending on context.\nDo not plan to use `case inl`/`case inr` (Lean 3-style); use `case pos`/`case neg` in Lean 4.\nNever rely on `sorry` or incomplete proofs; all goals must be discharged.\nIf the function's return type is `Bool` and the specification is a `↔` with a Prop, then include a plan to handle the `if` structure explicitly using `by_cases` or `split_ifs`.\nLean 4 requires `pos`/`neg` tags for `by_cases`. Do not mention `inl` or `inr`.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.\n\nPrevious plan:\n{\n  "plan_summary": "Define a Lean 4 function that computes the last digit of a non-negative integer using n % 10 and accompanies it with a proof that the result is in the range [0, 9] and equal to n % 10. The proof will use a case split on whether n is zero or non-zero, carefully grouping the range proofs into one nested pair and explicitly handling each case without relying on \'trivial\' to close the non-zero branch.",\n  "steps": [\n    "Step 1: Define the function signature. For example, create a function lastDigit : Nat → Nat that returns n % 10.",\n    "Step 2: In the function body, simply compute n % 10.",\n    "Step 3: Attach a proof that the computed result meets the specification. Construct a tuple where the first component is the nested pair of proofs showing that 0 ≤ n % 10 ∧ n % 10 < 10, and the second component shows n % 10 = lastDigit n.",\n    "Step 4: To handle any conditions on n, use \'by_cases\' or \'split_ifs\'. Explicitly consider the case where n = 0. In this branch, prove the properties easily (for example, 0 % 10 = 0, and the range conditions hold trivially).",\n    "Step 5: In the non-zero branch, don\'t rely on \'trivial\' or \'assumption\'. Instead, invoke known lemmas such as nat.mod_lt to supply a complete proof that n % 10 < 10. Also provide a complete proof for 0 ≤ n % 10 (which is expected from the properties of the modulus).",\n    "Step 6: Ensure that the tuple construction strictly groups the two range proofs into one nested pair so that the outer tuple has exactly two components.",\n    "Step 7: Finalize by checking that both branches are fully discharged without any incomplete proof steps."\n  ],\n  "code_keywords": [\n    "Nat",\n    "mod",\n    "n % 10",\n    "function definition",\n    "Lean 4",\n    "by_cases",\n    "split_ifs"\n  ],\n  "proof_keywords": [\n    "nat.mod_lt",\n    "nested pairing",\n    "and.intro",\n    "by_cases",\n    "exact",\n    "trivial",\n    "range proof"\n  ],\n  "assumptions": [\n    "Input n is a non-negative natural number (of type Nat).",\n    "The modulus operation in Lean will ensure that n % 10 returns a value between 0 and 9.",\n    "The proof structure requires a nested pair for the range proofs, and the case split must be complete for both n = 0 and n ≠ 0 cases."\n  ],\n  "retry_guidance": "Ensure that the \'by_cases\' tactic explicitly differentiates the n = 0 branch and the n ≠ 0 branch. In the non-zero branch, do not rely on \'trivial\' to close the goal; instead, apply lemmas like nat.mod_lt and provide explicit proofs for each part of the nested pair. Verify that the tuple constructor is used with exactly two arguments: one grouping the range proofs and the other proving the equality."\n}\n\nLean error summary:\nThe proof fails because in the branch where n ≠ 0 the tactic \'assumption\' (invoked by \'trivial\') does not close the goal. The case split using \'by_cases\' does not properly handle the n = 0 case and the non-zero branch needs to provide a complete proof rather than relying on \'trivial\'.\nRetry guidance (MUST FOLLOW):\nRewrite the proof to use pattern matching on n with \'cases n\' to handle both cases separately. This ensures that in each branch the required properties are directly established without relying on tactics that may fail.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nIn the \'succ\' branch, the proof incorrectly uses \'n % 10\' instead of \'(succ n) % 10\'. The theorem expects to show that 0 ≤ (succ n) % 10 and that (succ n) % 10 < 10, but the provided proof uses the wrong variable, causing a type mismatch.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 03:05:59,539 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:05:59,539 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:05:59,539 - DEBUG - send_request_headers.complete
2025-06-01 03:05:59,539 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:05:59,540 - DEBUG - send_request_body.complete
2025-06-01 03:05:59,540 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:06:08,620 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:06:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8845'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8854'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198085'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'574ms'), (b'x-request-id', b'req_a8a856faa06bda50d07ddc20ec128b60'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7e135cf24436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:06:08,621 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:06:08,621 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:06:08,621 - DEBUG - receive_response_body.complete
2025-06-01 03:06:08,621 - DEBUG - response_closed.started
2025-06-01 03:06:08,621 - DEBUG - response_closed.complete
2025-06-01 03:06:08,621 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:06:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8845', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8854', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198085', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '574ms', 'x-request-id': 'req_a8a856faa06bda50d07ddc20ec128b60', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7e135cf24436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:06:08,621 - DEBUG - request_id: req_a8a856faa06bda50d07ddc20ec128b60
2025-06-01 03:06:08,622 - INFO - Solution generated in 93.51 seconds
2025-06-01 03:06:08,622 - INFO - Generated code length: 6 characters
2025-06-01 03:06:08,622 - INFO - Generated proof length: 189 characters
2025-06-01 03:06:08,622 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 03:06:08,622 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 03:06:14,053 - INFO - Implementation test result: PASS
2025-06-01 03:06:14,054 - INFO - Executing Lean code with implementation and proof...
2025-06-01 03:06:19,313 - INFO - Full solution test result: FAIL
2025-06-01 03:06:19,313 - ERROR - Proof error: lean_playground/TempTest.lean:29:4: error: type mismatch
  Nat.zero_le (n % 10)
has type
  0 ≤ n % 10 : Prop
but is expected to have type
  0 ≤ (n + 1...
2025-06-01 03:06:19,313 - INFO - ✅ Implementation passes unit tests
2025-06-01 03:06:19,313 - ERROR - ❌ Proof has errors
2025-06-01 03:06:19,314 - INFO - 
==================================================
2025-06-01 03:06:19,314 - INFO - Processing task task_id_441...
2025-06-01 03:06:19,314 - INFO - Reading problem description and code template from tasks/task_id_441...
2025-06-01 03:06:19,314 - INFO - Problem description length: 489 characters
2025-06-01 03:06:19,314 - INFO - Reading unit tests from tasks/task_id_441...
2025-06-01 03:06:19,314 - INFO - Unit tests length: 171 characters
2025-06-01 03:06:19,314 - INFO - Running main workflow to generate solution...
2025-06-01 03:06:19,314 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.

-----Input-----
The input consists of:
size: An integer representing the length of an edge of the cube.

-----Output-----
The output is an integer:
Returns the surface area of the cube.

-----Note-----
The input edge length is assumed to be greater than 0.
2025-06-01 03:06:19,314 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def cubeSurfaceArea (size : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The surface area of the cube is calculated correctly
def cubeSurfaceArea_spec (size : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  result = 6 * size * size
  -- << SPEC END >>

theorem cubeSurfaceArea_spec_satisfied (size : Int):
  cubeSurfaceArea_spec size (cubeSurfaceArea size) := by
  -- << PROOF START >>
  unfold cubeSurfaceArea cubeSurfaceArea_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 03:06:19,344 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7f4e66ffa5c0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.\n\n-----Input-----\nThe input consists of:\nsize: An integer representing the length of an edge of the cube.\n\n-----Output-----\nThe output is an integer:\nReturns the surface area of the cube.\n\n-----Note-----\nThe input edge length is assumed to be greater than 0.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 03:06:19,344 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 03:06:19,344 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:06:19,351 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fdbaa0>
2025-06-01 03:06:19,351 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4e66ffe850> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:06:19,360 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fdb0b0>
2025-06-01 03:06:19,360 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:06:19,360 - DEBUG - send_request_headers.complete
2025-06-01 03:06:19,360 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:06:19,361 - DEBUG - send_request_body.complete
2025-06-01 03:06:19,361 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:06:20,050 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:06:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'60'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-58f7f7856-qpq7h'), (b'x-envoy-upstream-service-time', b'66'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999877'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_d1dd0a40399eb6eee5637f9ceacaa275'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1uNhWjk02H12rpGg7njVGPlB_kmfGqus_vpLr2ruQfw-1748747180-1.0.1.1-cOq5OyntcIXXm8_UlUn3NRNLTsWBO.xuRLGdIxT4Q.n8.KvfKCmdcdRnsTkkqnmTFTxqnVom5_EzgeN7BOa9HtiKwtkf2HApMWIUyQezHbk; path=/; expires=Sun, 01-Jun-25 03:36:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=sdkioIpiiSAcFepVf5GsA86A9gjq27zE7P2YcnES6Jw-1748747180076-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7e8f39344278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:06:20,050 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 03:06:20,050 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:06:20,051 - DEBUG - receive_response_body.complete
2025-06-01 03:06:20,051 - DEBUG - response_closed.started
2025-06-01 03:06:20,051 - DEBUG - response_closed.complete
2025-06-01 03:06:20,051 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 03:06:20 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '60'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-58f7f7856-qpq7h'), ('x-envoy-upstream-service-time', '66'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999877'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '7ms'), ('x-request-id', 'req_d1dd0a40399eb6eee5637f9ceacaa275'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=1uNhWjk02H12rpGg7njVGPlB_kmfGqus_vpLr2ruQfw-1748747180-1.0.1.1-cOq5OyntcIXXm8_UlUn3NRNLTsWBO.xuRLGdIxT4Q.n8.KvfKCmdcdRnsTkkqnmTFTxqnVom5_EzgeN7BOa9HtiKwtkf2HApMWIUyQezHbk; path=/; expires=Sun, 01-Jun-25 03:36:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=sdkioIpiiSAcFepVf5GsA86A9gjq27zE7P2YcnES6Jw-1748747180076-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b7e8f39344278-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 03:06:20,051 - DEBUG - request_id: req_d1dd0a40399eb6eee5637f9ceacaa275
2025-06-01 03:06:20,060 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
 modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
 m by rw [Nat.zero_add, Nat.add_zero])
       (fun (n : Nat) (ih : m + n = n + m) =>
        show m + succ n = succ n + m from
        calc m + succ n
          _ = succ (m + n) := rfl
          _ = succ (n + m) := by rw [ih]
          _ = succ n + m   := sorry)
    

At this point, we see that we need another supporting fact, namely, that `succ
(n + m) = succ n + m`. You can prove this by induction on `m`:

    
    
    open Nat
    
    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m
        (show succ n + 0 = succ (n + 0) from rfl)
        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>
         show succ n + succ m = succ (n + succ m) from
         calc succ n + succ m
           _ = succ (succ n + m)   := rfl
           _ = succ (succ (n + m)) := by rw [ih]
           _ = succ (n + succ m)   := rfl)
    

You can then replace the `sorry` in the previous proof with `succ_add`. Yet
again, the proofs can be compressed:

    
    
    namespace Hidden
    open Nat
    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m
        rfl
        (fun m ih => by simp only [add_succ, ih])
    
    theorem add_comm (m n : Nat) : m + n = n + m :=
      Nat.recOn (motive := fun x => m + x = x + m) n
        (by simp)
        (fun m ih => by simp [add_succ, succ_add, ih])
    end Hidden
    

## Other Recursive Data Types

Let us consider some more examples of inductively defined types. For any type,
`α`, the type `List α` of lists of elements of `α` is defined in the library.

    
    
    namespace Hidden
    inductive List (α : Type u) where
      | nil  : List α
      | cons : α → List α → List α
    
    namespace List
    
    def append (as bs : List α) : List α :=
      match as with
      | nil       => bs
      | cons a as => cons a (append as bs)
    
    theorem nil_append (as : List α) : append nil as = as :=
      rfl
    
    theorem cons_append (a : α) (as bs : List α)
                        : append (cons a as) bs = cons a (append as bs) :=
      rfl
    
    end List
    end Hidden
    

A list of elements of type `α` is either the empty list, `nil`, or an element
`h : α` followed by a list `t : List α`. The first element, `h`, is commonly
known as the "head" of the list, and the remainder, `t`, is known as the
"tail."

As an exercise, prove the following:

    
    
    namespace Hidden
    inductive List (α : Type u) where
    | nil  : List α
    | cons : α → List α → List α
    namespace List
    def append (as bs : List α) : List α :=
     match as with
     | nil       => bs
     | cons a as => cons a (append as bs)
    theorem nil_append (as : List α) : append nil as = as :=
     rfl
    theorem cons_append (a : α) (as bs : List α)
                        : append (cons a as) bs = cons a (append as bs) :=
     rfl
    theorem append_nil (as : List α) : append as nil = as :=
      sorry
    
    theorem append_assoc (as bs cs : List α)
            : append (append as bs) cs = append as (append bs cs) :=
      sorry
    end List
    end Hidden
    

Try also defining the function `length : {α : Type u} → List α → Nat` that
returns the length of a list, and prove that it behaves as expected (for
example, `length (append as bs) = length as + length bs`).

For another example, we can define the type of binary trees:

    
    
    inductive BinaryTree where
      | leaf : BinaryTree
      | node : BinaryTree → BinaryTree → BinaryTree
    

In fact, we can even define the type of countably branching trees:

    
    
    inductive CBTree where
      | leaf : CBTree
      | sup : (Nat → CBTree) → CBTree
    
    namespace CBTree
    
    def succ (t : CBTree) : CBTree :=
      sup (fun _ => t)
    
    def toCBTree : Nat → CBTree
      | 0 => leaf
      | n+1 => succ (toCBTree n)
    
    def omega : CBTree :=
      sup toCBTree
    
    end CBTree
    

## Tactics for Inductive Types

Given the fundamental importance of inductive types in Lean, it should not be
surprising that there are a number of tactics designed to work with them
effectively. We describe some of them here.

The `cases` tactic works on elements of an inductively defined type, and does
what the name suggests: it decomposes the element according to each of the
possible constructors. In its most basic form, it is applied to an element `x`
in the local context. It then reduces the goal to cases in which `x` is
replaced by each of the constructions.

    
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by
      intro n
      cases n
      . exact hz  -- goal is p 0
      . apply hs  -- goal is a : Nat ⊢ p (succ a)
    

There are extra bells and whistles. For one thing, `cases` allows you to
choose the names for each alternative using a `with` clause. In the next
example, for example, we choose the name `m` for the argument to `succ`, so
that the second case refers to `succ m`. More importantly, the cases tactic
will detect any items in the local context that depend on the target variable.
It reverts these elements, does the split, and reintroduces them. In the
example below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in
the first branch, and `h : succ m ≠ 0` in the second.

    
    
    open Nat
    
    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by
      cases n with
      | zero =>
        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0
        apply absurd rfl h
      | succ m =>
        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m
        rfl
    

Notice that `cases` can be used to produce data as well as prove propositions.

    
    
    def f (n : Nat) : Nat := by
      cases n; exact 3; exact 7
    
    example : f 0 = 3 := rfl
    example : f 5 = 7 := rfl
    

Once again, cases will revert, split, and then reintroduce dependencies in the
context.

    
    
    def Tuple (α : Type) (n : Nat) :=
      { as : List α // as.length = n }
    
    def f {n : Nat} (t : Tuple α n) : Nat := by
      cases n; exact 3; exact 7
    
    def myTuple : Tuple Nat 3 :=
      ⟨[0, 1, 2], rfl⟩
    
    example : f myTuple = 7 :=
      rfl
    

Here is an example of multiple constructors with arguments.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    
    def silly (x : Foo) : Nat := by
      cases x with
      | bar1 a b => exact b
      | bar2 c d e => exact e
    

The alternatives for each constructor don't need to be solved in the order the
constructors were declared.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x with
      | bar2 c d e => exact e
      | bar1 a b => exact b
    

The syntax of the `with` is convenient for writing structured proofs. Lean
also provides a complementary `case` tactic, which allows you to focus on goal
assign variable names.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x
      case bar1 a b => exact b
      case bar2 c d e => exact e
    

The `case` tactic is clever, in that it will match the constructor to the
appropriate goal. For example, we can fill the goals above in the opposite
order:

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x
      case bar2 c d e => exact e
      case bar1 a b => exact b
    

You can also use `cases` with an arbitrary expression. Assuming that
expression occurs in the goal, the cases tactic will generalize over the
expression, introduce the resulting universally quantified variable, and case
on that.

    
    
    open Nat
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
            : p (m + 3 * k) := by
      cases m + 3 * k
      exact hz   -- goal is p 0
      apply hs   -- goal is a : Nat ⊢ p (succ a)
    

Think of this as saying "split on cases as to whether `m + 3 * k` is zero or
the successor of some number." The result is functionally equivalent to the
following:

    
    
    open Nat
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
            : p (m + 3 * k) := by
      generalize m + 3 * k = n
      cases n
      exact hz   -- goal is p 0
      apply hs   -- goal is a : Nat ⊢ p (succ a)
    

Notice that the expression `m + 3 * k` is erased by `generalize`; all that
matters is whether it is of the form `0` or `succ a`. This form of `cases`
will _not_ revert any hypotheses that also mention the expression in the
equation (in this case, `m + 3 * k`). If such a term appears in a hypothesis
and you want to generalize over that as well, you need to `revert` it
explicitly.

If the expression you case on does not appear in the goal, the `cases` tactic
uses `have` to put the type of the expression into the context. Here is an
example:

    
    
    example (p : Prop) (m n : Nat)
            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by
      cases Nat.lt_or_ge m n
      case inl hlt => exact h₁ hlt
      case inr hge => exact h₂ hge
    

The theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to
think of the proof above as splitting on these two cases. In the first branch,
we have the hypothesis `hlt : m < n`, and in the second we have the hypothesis
`hge : m ≥ n`. The proof above is functionally equivalent to the following:

    
    
    example (p : Prop) (m n : Nat)
            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by
      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n
      cases h
      case inl hlt => exact h₁ hlt
      case inr hge => exact h₂ hge
    

After the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we
simply do cases on that.

Here is another example, where we use the decidability of equality on the
natural numbers to split on the cases `m = n` and `m ≠ n`.

    
    
    #check Nat.sub_self
    
    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by
      cases Decidable.em (m = n) with
      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n
      | inr hne => apply Or.inr; exact hne
    

Remember that if you `open Classical`, you can use the law of the excluded
middle for any proposition at all. But using type class inference (see
[Chapter Type Classes](./type_classes.html)), Lean can actually find the
relevant decision procedure, which means that you can use the case split in a
computable function.

Just as the `cases` tactic can be used to carry out proof by cases, the
`induction` tactic can be used to carry out proofs by induction. The syntax is
similar to that of `cases`, except that the argument can only be a term in the
local context. Here is an example:

    
    
    namespace Hidden
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n with
      | zero => rfl
      | succ n ih => rw [Nat.add_succ, ih]
    end Hidden
    

As with `cases`, we can use the `case` tactic instead of `with`.

    
    
    namespace Hidden
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n
      case zero => rfl
      case succ n ih => rw [Nat.add_succ, ih]
    end Hidden
    

Here are some additional examples:

    
    
    namespace Hidden
    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n
    open Nat
    
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n <;> simp [*, add_zero, add_succ]
    
    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by
      induction n <;> simp [*, add_zero, add_succ]
    
    theorem add_comm (m n : Nat) : m + n = n + m := by
      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]
    
    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by
      induction k <;> simp [*, add_zero, add_succ]
    end Hidden
    

The `induction` tactic also supports user-defined induction principles with
multiple targets (aka major premises).

    
    
    /-
    theorem Nat.mod.inductionOn
          {motive : Nat → Nat → Sort u}
          (x y  : Nat)
          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)
          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)
          : motive x y :=
    -/
    
    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by
      induction x, y using Nat.mod.inductionOn with
      | ind x y h₁ ih =>
        rw [Nat.mod_eq_sub_mod h₁.2]
        exact ih h
      | base x y h₁ =>
        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁
        match this with
        | Or.inl h₁ => exact absurd h h₁
        | Or.inr h₁ =>
          have hgt : y > x := Nat.gt_of_not_le h₁
          rw [← Nat.mod_eq_of_lt hgt] at hgt
          assumption
    

You can use the `match` notation in tactics too:

    
    
    example : p ∨ q → q ∨ p := by
      intro h
      match h with
      | Or.inl _  => apply Or.inr; assumption
      | Or.inr h2 => apply Or.inl; exact h2
    

As a convenience, pattern-matching has been integrated into tactics such as
`intro` and `funext`.

    
    
    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by
      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩
      exact ⟨hq, hp⟩
    
    example :
        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)
        =
        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by
      funext (a, b) (c, d)
      show a + d = d + a
      rw [Nat.add_comm]
    

We close this section with one last tactic that is designed to facilitate
working with inductive types, namely, the `injection` tactic. By design, the
elements of an inductive type are freely generated, which is to say, the
constructors are injective and have disjoint ranges. The `injection` tactic is
designed to make use of this fact:

    
    
    open Nat
    
    example (m n k : Nat) (h : succ (succ m) = succ (succ n))
            : n + k = m + k := by
      injection h with h'
      injection h' with h''
      rw [h'']
    

The first instance of the tactic adds `h' : succ m = succ n` to the context,
and the second adds `h'' : m = n`.

The `injection` tactic also detects contradictions that arise when different
constructors are set equal to one another, and uses them to close the goal.

    
    
    open Nat
    
    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
      injection h
    
    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
      contradiction
    
    example (h : 7 = 4) : False := by
      contradiction
    

As the second example shows, the `contradiction` tactic also detects
contradictions of this form.

## Inductive Families

We are almost done describing the full range of inductive definitions accepted
by Lean. So far, you have seen that Lean allows you to introduce inductive
types with any number of recursive constructors. In fact, a single inductive
definition can introduce an indexed _family_ of inductive types, in a manner
we now describe.

An inductive family is an indexed family of types defined by a simultaneous
induction of the following form:

    
    
    inductive foo : ... → Sort u where
      | constructor₁ : ... → foo ...
      | constructor₂ : ... → foo ...
      ...
      | constructorₙ : ... → foo ...
    

In contrast to an ordinary inductive definition, which constructs an element
of some `Sort u`, the more general version constructs a function `... → Sort
u`, where "`...`" denotes a sequence of argument types, also known as
_indices_. Each constructor then constructs an element of some member of the
family. One example is the definition of `Vector α n`, the type of vectors of
elements of `α` of length `n`:

    
    
    namespace Hidden
    inductive Vector (α : Type u) : Nat → Type u where
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    end Hidden
    

Notice that the `cons` constructor takes an element of `Vector α n` and
returns an element of `Vector α (n+1)`, thereby using an element of one member
of the family to build an element of another.

A more exotic example is given by the definition of the equality type in Lean:

    
    
    namespace Hidden
    inductive Eq {α : Sort u} (a : α) : α → Prop where
      | refl : Eq a a
    end Hidden
    

For each fixed `α : Sort u` and `a : α`, this definition constructs a family
of types `Eq a x`, indexed by `x : α`. Notably, however, there is only one
constructor, `refl`, which is an element of `Eq a a`. Intuitively, the only
way to construct a proof of `Eq a x` is to use reflexivity, in the case where
`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of
types `Eq a x`. The elimination principle generated by Lean is as follows:

    
    
    universe u v
    
    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}
                      → motive a rfl → {b : α} → (h : a = b) → motive b h)
    

It is a remarkable fact that all the basic axioms for equality follow from the
constructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality
is atypical, however; see the discussion in Section Axiomatic Details.

The recursor `Eq.rec` is also used to define substitution:

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      Eq.rec (motive := fun x _ => p x) h₂ h₁
    end Hidden
    

You can also define `subst` using `match`.

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      match h₁ with
      | rfl => h₂
    end Hidden
    

Actually, Lean compiles the `match` expressions using a definition based on
`Eq.rec`.

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      match h₁ with
      | rfl => h₂
    
    set_option pp.all true
    #print subst
      -- ... subst.match_1 ...
    #print subst.match_1
      -- ... Eq.casesOn ...
    #print Eq.casesOn
      -- ... Eq.rec ...
    end Hidden
    

Using the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are
the same, in which case, `p b` and `p a` are the same.

It is not hard to prove that `Eq` is symmetric and transitive. In the
following example, we prove `symm` and leave as exercises the theorems `trans`
and `congr` (congruence).

    
    
    namespace Hidden
    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=
      match h with
      | rfl => rfl
    
    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=
      sorry
    
    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=
      sorry
    end Hidden
    

In the type theory literature, there are further generalizations of inductive
definitions, for example, the principles of _induction-recursion_ and
_induction-induction_. These are not supported by Lean.

## Axiomatic Details

We have described inductive types and their syntax through examples. This
section provides additional information for those interested in the axiomatic
foundations.

We have seen that the constructor to an inductive type takes _parameters_ \---
intuitively, the arguments that remain fixed throughout the inductive
construction --- and _indices_ , the arguments parameterizing the family of
types that is simultaneously under construction. Each constructor should have
a type, where the argument types are built up from previously defined types,
the parameter and index types, and the inductive family currently being
defined. The requirement is that if the latter is present at all, it occurs
only _strictly positively_. This means simply that any argument to the
constructor in which it occurs is a dependent arrow type in which the
inductive type under definition occurs only as the resulting type, where the
indices are given in terms of constants and previous arguments.

Since an inductive type lives in `Sort u` for some `u`, it is reasonable to
ask _which_ universe levels `u` can be instantiated to. Each constructor `c`
in the definition of a family `C` of inductive types is of the form

    
    
      c : (a : α) → (b : β[a]) → C a p[a,b]
    

where `a` is a sequence of data type parameters, `b` is the sequence of
arguments to the constructors, and `p[a, b]` are the indices, which determine
which element of the inductive family the construction inhabits. (Note that
this description is somewhat misleading, in that the arguments to the
constructor can appear in any order as long as the dependencies make sense.)
The constraints on the universe level of `C` fall into two cases, depending on
whether or not the inductive type is specified to land in `Prop` (that is,
`Sort 0`).

Let us first consider the case where the inductive type is _not_ specified to
land in `Prop`. Then the universe level `u` is constrained to satisfy the
following:

> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,
> if `βk[a] : Sort v`, we have `u` ≥ `v`.

In other words, the universe level `u` is required to be at least as large as
the universe level of each type that represents an argument to a constructor.

When the inductive type is specified to land in `Prop`, there are no
constraints on the universe levels of the constructor arguments. But these
universe levels do have a bearing on the elimination rule. Generally speaking,
for an inductive type in `Prop`, the motive of the elimination rule is
required to be in `Prop`.

There is an exception to this last rule: we are allowed to eliminate from an
inductively defined `Prop` to an arbitrary `Sort` when there is only one
constructor and each constructor argument is either in `Prop` or an index. The
intuition is that in this case the elimination does not make use of any
information that is not already given by the mere fact that the type of
argument is inhabited. This special case is known as _singleton elimination_.

We have already seen singleton elimination at play in applications of
`Eq.rec`, the eliminator for the inductively defined equality type. We can use
an element `h : Eq a b` to cast an element `t' : p a` to `p b` even when `p a`
and `p b` are arbitrary types, because the cast does not produce new data; it
only reinterprets the data we already have. Singleton elimination is also used
with heterogeneous equality and well-founded recursion, which will be
discussed in a [Chapter Induction and
Recursion](./induction_and_recursion.html#well-founded-recursion-and-
induction).

## Mutual and Nested Inductive Types

We now consider two generalizations of inductive types that are often useful,
which Lean supports by "compiling" them down to the more primitive kinds of
inductive types described above. In other words, Lean parses the more general
definitions, defines auxiliary inductive types based on them, and then uses
the auxiliary types to define the ones we really want. Lean's equation
compiler, described in the next chapter, is needed to make use of these types
effectively. Nonetheless, it makes sense to describe the declarations here,
because they are straightforward variations on ordinary inductive definitions.

First, Lean supports _mutually defined_ inductive types. The idea is that we
can define two (or more) inductive types at the same time, where each one
refers to the other(s).

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : (n : Nat) → Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : (n : Nat) → Even n → Odd (n + 1)
    end
    

In this example, two types are defined simultaneously: a natural number `n` is
`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one
more than an `Even` number. In the exercises below, you are asked to spell out
the details.

A mutual inductive definition can also be used to define the notation of a
finite tree with nodes labelled by elements of `α`:

    
    
    mutual
        inductive Tree (α : Type u) where
          | node : α → TreeList α → Tree α
    
        inductive TreeList (α : Type u) where
          | nil  : TreeList α
          | cons : Tree α → TreeList α → TreeList α
    end
    

With this definition, one can construct an element of `Tree α` by giving an
element of `α` together with a list of subtrees, possibly empty. The list of
subtrees is represented by the type `TreeList α`, which is defined to be
either the empty list, `nil`, or the `cons` of a tree and an element of
`TreeList α`.

This definition is inconvenient to work with, however. It would be much nicer
if the list of subtrees were given by the type `List (Tree α)`, especially
since Lean's library contains a number of functions and theorems for working
with lists. One can show that the type `TreeList α` is _isomorphic_ to `List
(Tree α)`, but translating results back and forth along this isomorphism is
tedious.

In fact, Lean allows us to define the inductive type we really want:

    
    
    inductive Tree (α : Type u) where
      | mk : α → List (Tree α) → Tree α
    

This is known as a _nested_ inductive type. It falls outside the strict
specification of an inductive type given in the last section because `Tree`
does not occur strictly positively among the arguments to `mk`, but, rather,
nested inside the `List` type constructor. Lean then automatically builds the
isomorphism between `TreeList α` and `List (Tree α)` in its kernel, and
defines the constructors for `Tree` in terms of the isomorphism.

## Exercises

  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.

Since many of these are already defined in Lean's core library, you should
work within a namespace named `Hidden`, or something like that, in order to
avoid name clashes.

  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:

a. `length (s ++ t) = length s + length t`

b. `length (reverse t) = length t`

c. `reverse (reverse t) = t`

  3. Define an inductive data type consisting of terms built up from the following constructors:

     * `const n`, a constant denoting the natural number `n`
     * `var n`, a variable, numbered `n`
     * `plus s t`, denoting the sum of `s` and `t`
     * `times s t`, denoting the product of `s` and `t`

Recursively define a function that evaluates any such term with respect to an
assignment of values to the variables.

  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.

[ __](interacting_with_lean.html "Previous chapter") [
__](induction_and_recursion.html "Next chapter")

[ __](interacting_with_lean.html "Previous chapter") [
__](induction_and_recursion.html "Next chapter")
2025-06-01 03:06:20,064 - DEBUG - close.started
2025-06-01 03:06:20,064 - DEBUG - close.complete
2025-06-01 03:06:20,081 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\nIf your function uses Boolean logic or `if...then...else`, always plan to:\n  - Use `by_cases` or `split_ifs` on the Boolean condition(s) in the proof.\n  - Use `simp` in each branch to reduce the goal to true ↔ true or false ↔ false.\n  - Close each goal with `trivial`, `exact`, or `exfalso` depending on context.\nDo not plan to use `case inl`/`case inr` (Lean 3-style); use `case pos`/`case neg` in Lean 4.\nNever rely on `sorry` or incomplete proofs; all goals must be discharged.\nIf the function's return type is `Bool` and the specification is a `↔` with a Prop, then include a plan to handle the `if` structure explicitly using `by_cases` or `split_ifs`.\nLean 4 requires `pos`/`neg` tags for `by_cases`. Do not mention `inl` or `inr`.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.\n\n-----Input-----\nThe input consists of:\nsize: An integer representing the length of an edge of the cube.\n\n-----Output-----\nThe output is an integer:\nReturns the surface area of the cube.\n\n-----Note-----\nThe input edge length is assumed to be greater than 0.'}], 'model': 'o3-mini'}}
2025-06-01 03:06:20,082 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:06:20,082 - DEBUG - close.started
2025-06-01 03:06:20,083 - DEBUG - close.complete
2025-06-01 03:06:20,083 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:06:20,089 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fdbd10>
2025-06-01 03:06:20,089 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:06:20,097 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fd83e0>
2025-06-01 03:06:20,097 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:06:20,097 - DEBUG - send_request_headers.complete
2025-06-01 03:06:20,098 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:06:20,098 - DEBUG - send_request_body.complete
2025-06-01 03:06:20,098 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:06:26,149 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:06:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5791'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5799'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199391'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'182ms'), (b'x-request-id', b'req_ff8d0a72ff461c22d847e7f47b3836ab'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7e93ce7e3fe6-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:06:26,149 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:06:26,149 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:06:26,149 - DEBUG - receive_response_body.complete
2025-06-01 03:06:26,149 - DEBUG - response_closed.started
2025-06-01 03:06:26,149 - DEBUG - response_closed.complete
2025-06-01 03:06:26,149 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:06:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5791', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5799', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199391', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '182ms', 'x-request-id': 'req_ff8d0a72ff461c22d847e7f47b3836ab', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7e93ce7e3fe6-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:06:26,150 - DEBUG - request_id: req_ff8d0a72ff461c22d847e7f47b3836ab
2025-06-01 03:06:26,150 - INFO - Attempt 1/3
2025-06-01 03:06:26,150 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that computes the surface area of a cube by taking the input edge length and applying the formula: surface area = 6 * edge². The plan involves multiplying the edge length by itself and then by 6, with the assumption that the input is greater than zero.",
  "steps": [
    "Define the function with an appropriate signature (e.g., Int -> Int) since the input and output are integers.",
    "Multiply the input edge length by itself to compute the area of one face of the cube.",
    "Multiply the area of one face by 6 to obtain the total surface area of the cube.",
    "Return the computed surface area."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "multiplication",
    "edge length",
    "cube surface area"
  ],
  "proof_keywords": [
    "arithmetic",
    "multiplication properties",
    "associativity",
    "commutativity"
  ],
  "assumptions": [
    "The input edge length is assumed to be an integer and greater than 0."
  ],
  "retry_guidance": "If any errors occur related to type mismatches or arithmetic under/overflow, confirm the function signature and validate the arithmetic order of operations. Also, ensure Lean's arithmetic operations are correctly imported and used."
}
2025-06-01 03:06:26,151 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\nYou MUST:\n  - Use `split_ifs` or `by_cases` for Boolean if-expressions.\n  - In each case branch, simplify the goal using `simp`.\n  - Use `trivial`, `exact`, or `exfalso` to close simplified branches.\nYou MUST NOT:\n  - Use `case inl` / `case inr` → replace with `case pos` / `case neg`.\n  - Use `done`, `⟨..., by ...⟩`, `by assumption` in unclear contexts.\n  - Use `sorry`, or leave any goal open.\nFor Boolean-returning functions with specifications of the form:\n  `spec a b (hasOppositeSign a b) := ... ↔ ...`,\nalways:\n  - `unfold` the function and spec,\n  - `split_ifs with h` to analyze conditions,\n  - `simp` the goal under each condition,\n  - then `trivial`, `exact`, or `contradiction` to finish.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that computes the surface area of a cube by taking the input edge length and applying the formula: surface area = 6 * edge². The plan involves multiplying the edge length by itself and then by 6, with the assumption that the input is greater than zero.",\n  "steps": [\n    "Define the function with an appropriate signature (e.g., Int -> Int) since the input and output are integers.",\n    "Multiply the input edge length by itself to compute the area of one face of the cube.",\n    "Multiply the area of one face by 6 to obtain the total surface area of the cube.",\n    "Return the computed surface area."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "multiplication",\n    "edge length",\n    "cube surface area"\n  ],\n  "proof_keywords": [\n    "arithmetic",\n    "multiplication properties",\n    "associativity",\n    "commutativity"\n  ],\n  "assumptions": [\n    "The input edge length is assumed to be an integer and greater than 0."\n  ],\n  "retry_guidance": "If any errors occur related to type mismatches or arithmetic under/overflow, confirm the function signature and validate the arithmetic order of operations. Also, ensure Lean\'s arithmetic operations are correctly imported and used."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeSurfaceArea (size : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The surface area of the cube is calculated correctly\ndef cubeSurfaceArea_spec (size : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = 6 * size * size\n  -- << SPEC END >>\n\ntheorem cubeSurfaceArea_spec_satisfied (size : Int):\n  cubeSurfaceArea_spec size (cubeSurfaceArea size) := by\n  -- << PROOF START >>\n  unfold cubeSurfaceArea cubeSurfaceArea_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 03:06:26,152 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:06:26,152 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:06:26,153 - DEBUG - send_request_headers.complete
2025-06-01 03:06:26,153 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:06:26,157 - DEBUG - send_request_body.complete
2025-06-01 03:06:26,157 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:06:28,754 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:06:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2370'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2372'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'5785'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'48.428s'), (b'x-request-id', b'req_f727b8fffd2ac3d84f4072b2b23cc84c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7eb9a8673fe6-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:06:28,755 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:06:28,755 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:06:28,755 - DEBUG - receive_response_body.complete
2025-06-01 03:06:28,755 - DEBUG - response_closed.started
2025-06-01 03:06:28,755 - DEBUG - response_closed.complete
2025-06-01 03:06:28,755 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:06:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2370', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2372', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '5785', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '48.428s', 'x-request-id': 'req_f727b8fffd2ac3d84f4072b2b23cc84c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7eb9a8673fe6-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:06:28,755 - DEBUG - request_id: req_f727b8fffd2ac3d84f4072b2b23cc84c
2025-06-01 03:06:28,756 - INFO - Raw solution received: ```json
{
  "code": "6 * size * size",
  "proof": "rw [mul_assoc, mul_comm size] \ntrivial"
}
```
2025-06-01 03:06:28,756 - INFO - <class 'str'>
2025-06-01 03:06:28,756 - INFO - Generated solution: {'code': '6 * size * size', 'proof': 'rw [mul_assoc, mul_comm size] \ntrivial'}
2025-06-01 03:06:33,998 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:22:0: error: unexpected identifier; expected command
2025-06-01 03:06:33,999 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.\n\n-----Input-----\nThe input consists of:\nsize: An integer representing the length of an edge of the cube.\n\n-----Output-----\nThe output is an integer:\nReturns the surface area of the cube.\n\n-----Note-----\nThe input edge length is assumed to be greater than 0.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeSurfaceArea (size : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The surface area of the cube is calculated correctly\ndef cubeSurfaceArea_spec (size : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = 6 * size * size\n  -- << SPEC END >>\n\ntheorem cubeSurfaceArea_spec_satisfied (size : Int):\n  cubeSurfaceArea_spec size (cubeSurfaceArea size) := by\n  -- << PROOF START >>\n  unfold cubeSurfaceArea cubeSurfaceArea_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\n6 * size * size\n\nGenerated Proof:\nrw [mul_assoc, mul_comm size] \ntrivial\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:22:0: error: unexpected identifier; expected command'}], 'model': 'o3-mini'}}
2025-06-01 03:06:33,999 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:06:34,000 - DEBUG - close.started
2025-06-01 03:06:34,000 - DEBUG - close.complete
2025-06-01 03:06:34,000 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:06:34,008 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f91e20>
2025-06-01 03:06:34,009 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:06:34,017 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f936b0>
2025-06-01 03:06:34,017 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:06:34,017 - DEBUG - send_request_headers.complete
2025-06-01 03:06:34,017 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:06:34,017 - DEBUG - send_request_body.complete
2025-06-01 03:06:34,017 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:06:42,794 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:06:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8557'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8561'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199311'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'206ms'), (b'x-request-id', b'req_091f4f32867821b60f43a270c83224f9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dC4N1R0wC0I4xeKO4Zk0WpzgSuSPIBgsNJcgdhdvzj8-1748747202-1.0.1.1-OVoDqy0sbVOuzLucbD9iy9AFtpOPei6q7pbCcs8h2q1khd69jz.V8EJuyk4BlNs9v4yLa1BeJ_rmsXBtKVPl.yeV3LKO9cfNpVAnyux5Xrw; path=/; expires=Sun, 01-Jun-25 03:36:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7eeac9604436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:06:42,795 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:06:42,795 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:06:42,795 - DEBUG - receive_response_body.complete
2025-06-01 03:06:42,795 - DEBUG - response_closed.started
2025-06-01 03:06:42,795 - DEBUG - response_closed.complete
2025-06-01 03:06:42,795 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:06:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8557', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8561', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199311', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '206ms', 'x-request-id': 'req_091f4f32867821b60f43a270c83224f9', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=dC4N1R0wC0I4xeKO4Zk0WpzgSuSPIBgsNJcgdhdvzj8-1748747202-1.0.1.1-OVoDqy0sbVOuzLucbD9iy9AFtpOPei6q7pbCcs8h2q1khd69jz.V8EJuyk4BlNs9v4yLa1BeJ_rmsXBtKVPl.yeV3LKO9cfNpVAnyux5Xrw; path=/; expires=Sun, 01-Jun-25 03:36:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7eeac9604436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:06:42,795 - DEBUG - request_id: req_091f4f32867821b60f43a270c83224f9
2025-06-01 03:06:42,796 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof failed to parse due to an unexpected identifier error, likely because the generated proof tactics (using 'rw [mul_assoc, mul_comm size]' followed by 'trivial') are not valid as written. In Lean 4, using 'mul_comm size' is not recognized correctly, and the overall sequence of tactics after 'unfold' is misformatted.", 'error_type': 'syntax', 'suggested_fix': "Simplify the proof by replacing the generated tactics with a straightforward tactic such as 'rfl'. For example, after 'unfold cubeSurfaceArea cubeSurfaceArea_spec', simply add 'rfl'. Alternatively, if you wish to use rewrite tactics, ensure that they are valid; for instance, you might need to remove the parameter from 'mul_comm' (i.e., use 'rw [mul_assoc, mul_comm]') if the lemmas are applicable. In this case, the simplest fix is to change the proof to:\n\ntheorem cubeSurfaceArea_spec_satisfied (size : Int):\n  cubeSurfaceArea_spec size (cubeSurfaceArea size) := by\n  unfold cubeSurfaceArea cubeSurfaceArea_spec\n  rfl\n\nThis should resolve the syntax error.", 'retry_strategy': "Revise the proof tactics by replacing the rewrite and trivial steps with 'rfl' after the unfold, then re-run the code."}
2025-06-01 03:06:42,797 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\nIf your function uses Boolean logic or `if...then...else`, always plan to:\n  - Use `by_cases` or `split_ifs` on the Boolean condition(s) in the proof.\n  - Use `simp` in each branch to reduce the goal to true ↔ true or false ↔ false.\n  - Close each goal with `trivial`, `exact`, or `exfalso` depending on context.\nDo not plan to use `case inl`/`case inr` (Lean 3-style); use `case pos`/`case neg` in Lean 4.\nNever rely on `sorry` or incomplete proofs; all goals must be discharged.\nIf the function's return type is `Bool` and the specification is a `↔` with a Prop, then include a plan to handle the `if` structure explicitly using `by_cases` or `split_ifs`.\nLean 4 requires `pos`/`neg` tags for `by_cases`. Do not mention `inl` or `inr`.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.\n\n-----Input-----\nThe input consists of:\nsize: An integer representing the length of an edge of the cube.\n\n-----Output-----\nThe output is an integer:\nReturns the surface area of the cube.\n\n-----Note-----\nThe input edge length is assumed to be greater than 0.\n\nPrevious plan:\n{\n  "plan_summary": "Define a Lean 4 function that computes the surface area of a cube by taking the input edge length and applying the formula: surface area = 6 * edge². The plan involves multiplying the edge length by itself and then by 6, with the assumption that the input is greater than zero.",\n  "steps": [\n    "Define the function with an appropriate signature (e.g., Int -> Int) since the input and output are integers.",\n    "Multiply the input edge length by itself to compute the area of one face of the cube.",\n    "Multiply the area of one face by 6 to obtain the total surface area of the cube.",\n    "Return the computed surface area."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "multiplication",\n    "edge length",\n    "cube surface area"\n  ],\n  "proof_keywords": [\n    "arithmetic",\n    "multiplication properties",\n    "associativity",\n    "commutativity"\n  ],\n  "assumptions": [\n    "The input edge length is assumed to be an integer and greater than 0."\n  ],\n  "retry_guidance": "If any errors occur related to type mismatches or arithmetic under/overflow, confirm the function signature and validate the arithmetic order of operations. Also, ensure Lean\'s arithmetic operations are correctly imported and used."\n}\n\nLean error:\nThe proof failed to parse due to an unexpected identifier error, likely because the generated proof tactics (using \'rw [mul_assoc, mul_comm size]\' followed by \'trivial\') are not valid as written. In Lean 4, using \'mul_comm size\' is not recognized correctly, and the overall sequence of tactics after \'unfold\' is misformatted.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 03:06:42,797 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:06:42,797 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:06:42,797 - DEBUG - send_request_headers.complete
2025-06-01 03:06:42,798 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:06:42,798 - DEBUG - send_request_body.complete
2025-06-01 03:06:42,798 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:06:49,328 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:06:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6293'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6296'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198592'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'422ms'), (b'x-request-id', b'req_f4cbac0c4b19fdfe15772bb6cb12d0ed'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7f21aa904436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:06:49,328 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:06:49,328 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:06:49,328 - DEBUG - receive_response_body.complete
2025-06-01 03:06:49,329 - DEBUG - response_closed.started
2025-06-01 03:06:49,329 - DEBUG - response_closed.complete
2025-06-01 03:06:49,329 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:06:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6293', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6296', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198592', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '422ms', 'x-request-id': 'req_f4cbac0c4b19fdfe15772bb6cb12d0ed', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7f21aa904436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:06:49,329 - DEBUG - request_id: req_f4cbac0c4b19fdfe15772bb6cb12d0ed
2025-06-01 03:06:49,329 - INFO - Attempt 2/3
2025-06-01 03:06:49,329 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that computes the cube's surface area by applying the formula 6 * edge^2, and refine the proof strategy to use tactics that correctly rewrite arithmetic expressions in Lean 4. Instead of using 'rw' with 'mul_comm' or 'mul_assoc', we can rely on tactics such as 'simp' or 'ring' to handle the arithmetic normalization, ensuring the proof is formulated in a valid Lean 4 syntax.",
  "steps": [
    "Define the function with the appropriate signature, e.g. taking an integer input and returning an integer output.",
    "Compute the area of one face by multiplying the edge length by itself.",
    "Multiply the face area by 6 to get the total surface area.",
    "In the proof (if proving correctness), replace the previous 'rw' tactics with a tactic like 'simp' or 'ring' that correctly handles the arithmetic properties in Lean 4.",
    "Unfold necessary definitions if required, then simplify the goal and ensure that each branch (if any) in conditional constructs is handled with tactics like 'by_cases' and proper usage of 'simp'.",
    "Close the goal with 'trivial', 'exact', or 'exfalso', as appropriate."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "cube surface area",
    "multiplication",
    "arithmetic simplification"
  ],
  "proof_keywords": [
    "simp",
    "ring",
    "arithmetic normalization",
    "by_cases",
    "split_ifs"
  ],
  "assumptions": [
    "The input edge length is an integer and is greater than 0.",
    "Arithmetic operations in Lean 4 behave as expected and necessary tactics like 'simp' and 'ring' are available."
  ],
  "retry_guidance": "Ensure that when rewriting or simplifying arithmetic expressions, use Lean 4-appropriate tactics like 'simp' or 'ring' instead of manual 'rw' sequences. Check that the proof is free of syntactic issues by avoiding misformatted tactic sequences and ensuring the correct usage of pattern matching in 'by_cases' with 'pos' and 'neg' tags."
}
2025-06-01 03:06:49,329 - INFO - Updated plan: {
  "plan_summary": "Define a Lean 4 function that computes the cube's surface area by applying the formula 6 * edge^2, and refine the proof strategy to use tactics that correctly rewrite arithmetic expressions in Lean 4. Instead of using 'rw' with 'mul_comm' or 'mul_assoc', we can rely on tactics such as 'simp' or 'ring' to handle the arithmetic normalization, ensuring the proof is formulated in a valid Lean 4 syntax.",
  "steps": [
    "Define the function with the appropriate signature, e.g. taking an integer input and returning an integer output.",
    "Compute the area of one face by multiplying the edge length by itself.",
    "Multiply the face area by 6 to get the total surface area.",
    "In the proof (if proving correctness), replace the previous 'rw' tactics with a tactic like 'simp' or 'ring' that correctly handles the arithmetic properties in Lean 4.",
    "Unfold necessary definitions if required, then simplify the goal and ensure that each branch (if any) in conditional constructs is handled with tactics like 'by_cases' and proper usage of 'simp'.",
    "Close the goal with 'trivial', 'exact', or 'exfalso', as appropriate."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "cube surface area",
    "multiplication",
    "arithmetic simplification"
  ],
  "proof_keywords": [
    "simp",
    "ring",
    "arithmetic normalization",
    "by_cases",
    "split_ifs"
  ],
  "assumptions": [
    "The input edge length is an integer and is greater than 0.",
    "Arithmetic operations in Lean 4 behave as expected and necessary tactics like 'simp' and 'ring' are available."
  ],
  "retry_guidance": "Ensure that when rewriting or simplifying arithmetic expressions, use Lean 4-appropriate tactics like 'simp' or 'ring' instead of manual 'rw' sequences. Check that the proof is free of syntactic issues by avoiding misformatted tactic sequences and ensuring the correct usage of pattern matching in 'by_cases' with 'pos' and 'neg' tags."
}

Lean error summary:
The proof failed to parse due to an unexpected identifier error, likely because the generated proof tactics (using 'rw [mul_assoc, mul_comm size]' followed by 'trivial') are not valid as written. In Lean 4, using 'mul_comm size' is not recognized correctly, and the overall sequence of tactics after 'unfold' is misformatted.
Retry guidance (MUST FOLLOW):
Revise the proof tactics by replacing the rewrite and trivial steps with 'rfl' after the unfold, then re-run the code.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 03:06:49,330 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\nYou MUST:\n  - Use `split_ifs` or `by_cases` for Boolean if-expressions.\n  - In each case branch, simplify the goal using `simp`.\n  - Use `trivial`, `exact`, or `exfalso` to close simplified branches.\nYou MUST NOT:\n  - Use `case inl` / `case inr` → replace with `case pos` / `case neg`.\n  - Use `done`, `⟨..., by ...⟩`, `by assumption` in unclear contexts.\n  - Use `sorry`, or leave any goal open.\nFor Boolean-returning functions with specifications of the form:\n  `spec a b (hasOppositeSign a b) := ... ↔ ...`,\nalways:\n  - `unfold` the function and spec,\n  - `split_ifs with h` to analyze conditions,\n  - `simp` the goal under each condition,\n  - then `trivial`, `exact`, or `contradiction` to finish.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that computes the cube\'s surface area by applying the formula 6 * edge^2, and refine the proof strategy to use tactics that correctly rewrite arithmetic expressions in Lean 4. Instead of using \'rw\' with \'mul_comm\' or \'mul_assoc\', we can rely on tactics such as \'simp\' or \'ring\' to handle the arithmetic normalization, ensuring the proof is formulated in a valid Lean 4 syntax.",\n  "steps": [\n    "Define the function with the appropriate signature, e.g. taking an integer input and returning an integer output.",\n    "Compute the area of one face by multiplying the edge length by itself.",\n    "Multiply the face area by 6 to get the total surface area.",\n    "In the proof (if proving correctness), replace the previous \'rw\' tactics with a tactic like \'simp\' or \'ring\' that correctly handles the arithmetic properties in Lean 4.",\n    "Unfold necessary definitions if required, then simplify the goal and ensure that each branch (if any) in conditional constructs is handled with tactics like \'by_cases\' and proper usage of \'simp\'.",\n    "Close the goal with \'trivial\', \'exact\', or \'exfalso\', as appropriate."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "cube surface area",\n    "multiplication",\n    "arithmetic simplification"\n  ],\n  "proof_keywords": [\n    "simp",\n    "ring",\n    "arithmetic normalization",\n    "by_cases",\n    "split_ifs"\n  ],\n  "assumptions": [\n    "The input edge length is an integer and is greater than 0.",\n    "Arithmetic operations in Lean 4 behave as expected and necessary tactics like \'simp\' and \'ring\' are available."\n  ],\n  "retry_guidance": "Ensure that when rewriting or simplifying arithmetic expressions, use Lean 4-appropriate tactics like \'simp\' or \'ring\' instead of manual \'rw\' sequences. Check that the proof is free of syntactic issues by avoiding misformatted tactic sequences and ensuring the correct usage of pattern matching in \'by_cases\' with \'pos\' and \'neg\' tags."\n}\n\nLean error summary:\nThe proof failed to parse due to an unexpected identifier error, likely because the generated proof tactics (using \'rw [mul_assoc, mul_comm size]\' followed by \'trivial\') are not valid as written. In Lean 4, using \'mul_comm size\' is not recognized correctly, and the overall sequence of tactics after \'unfold\' is misformatted.\nRetry guidance (MUST FOLLOW):\nRevise the proof tactics by replacing the rewrite and trivial steps with \'rfl\' after the unfold, then re-run the code.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeSurfaceArea (size : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The surface area of the cube is calculated correctly\ndef cubeSurfaceArea_spec (size : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = 6 * size * size\n  -- << SPEC END >>\n\ntheorem cubeSurfaceArea_spec_satisfied (size : Int):\n  cubeSurfaceArea_spec size (cubeSurfaceArea size) := by\n  -- << PROOF START >>\n  unfold cubeSurfaceArea cubeSurfaceArea_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 03:06:49,331 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:06:49,332 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:06:49,332 - DEBUG - send_request_headers.complete
2025-06-01 03:06:49,332 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:06:49,337 - DEBUG - send_request_body.complete
2025-06-01 03:06:49,337 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:06:49,577 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sun, 01 Jun 2025 03:06:49 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'372'), (b'Connection', b'keep-alive'), (b'retry-after', b'3'), (b'retry-after-ms', b'2950'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'16234'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'27.53s'), (b'x-request-id', b'req_0de00b4ff5a4f89c3665c13e1626b187'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7f4a8e664436-BOM'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:06:49,577 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 03:06:49,577 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:06:49,577 - DEBUG - receive_response_body.complete
2025-06-01 03:06:49,577 - DEBUG - response_closed.started
2025-06-01 03:06:49,577 - DEBUG - response_closed.complete
2025-06-01 03:06:49,578 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sun, 01 Jun 2025 03:06:49 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '372', 'connection': 'keep-alive', 'retry-after': '3', 'retry-after-ms': '2950', 'vary': 'Origin', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '16234', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '27.53s', 'x-request-id': 'req_0de00b4ff5a4f89c3665c13e1626b187', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7f4a8e664436-BOM', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:06:49,578 - DEBUG - request_id: req_0de00b4ff5a4f89c3665c13e1626b187
2025-06-01 03:06:49,578 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/openai/_base_client.py", line 1007, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.12/dist-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-06-01 03:06:49,578 - DEBUG - Retrying due to status code 429
2025-06-01 03:06:49,578 - DEBUG - 2 retries left
2025-06-01 03:06:49,578 - INFO - Retrying request to /chat/completions in 2.950000 seconds
2025-06-01 03:06:52,528 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\nYou MUST:\n  - Use `split_ifs` or `by_cases` for Boolean if-expressions.\n  - In each case branch, simplify the goal using `simp`.\n  - Use `trivial`, `exact`, or `exfalso` to close simplified branches.\nYou MUST NOT:\n  - Use `case inl` / `case inr` → replace with `case pos` / `case neg`.\n  - Use `done`, `⟨..., by ...⟩`, `by assumption` in unclear contexts.\n  - Use `sorry`, or leave any goal open.\nFor Boolean-returning functions with specifications of the form:\n  `spec a b (hasOppositeSign a b) := ... ↔ ...`,\nalways:\n  - `unfold` the function and spec,\n  - `split_ifs with h` to analyze conditions,\n  - `simp` the goal under each condition,\n  - then `trivial`, `exact`, or `contradiction` to finish.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that computes the cube\'s surface area by applying the formula 6 * edge^2, and refine the proof strategy to use tactics that correctly rewrite arithmetic expressions in Lean 4. Instead of using \'rw\' with \'mul_comm\' or \'mul_assoc\', we can rely on tactics such as \'simp\' or \'ring\' to handle the arithmetic normalization, ensuring the proof is formulated in a valid Lean 4 syntax.",\n  "steps": [\n    "Define the function with the appropriate signature, e.g. taking an integer input and returning an integer output.",\n    "Compute the area of one face by multiplying the edge length by itself.",\n    "Multiply the face area by 6 to get the total surface area.",\n    "In the proof (if proving correctness), replace the previous \'rw\' tactics with a tactic like \'simp\' or \'ring\' that correctly handles the arithmetic properties in Lean 4.",\n    "Unfold necessary definitions if required, then simplify the goal and ensure that each branch (if any) in conditional constructs is handled with tactics like \'by_cases\' and proper usage of \'simp\'.",\n    "Close the goal with \'trivial\', \'exact\', or \'exfalso\', as appropriate."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "cube surface area",\n    "multiplication",\n    "arithmetic simplification"\n  ],\n  "proof_keywords": [\n    "simp",\n    "ring",\n    "arithmetic normalization",\n    "by_cases",\n    "split_ifs"\n  ],\n  "assumptions": [\n    "The input edge length is an integer and is greater than 0.",\n    "Arithmetic operations in Lean 4 behave as expected and necessary tactics like \'simp\' and \'ring\' are available."\n  ],\n  "retry_guidance": "Ensure that when rewriting or simplifying arithmetic expressions, use Lean 4-appropriate tactics like \'simp\' or \'ring\' instead of manual \'rw\' sequences. Check that the proof is free of syntactic issues by avoiding misformatted tactic sequences and ensuring the correct usage of pattern matching in \'by_cases\' with \'pos\' and \'neg\' tags."\n}\n\nLean error summary:\nThe proof failed to parse due to an unexpected identifier error, likely because the generated proof tactics (using \'rw [mul_assoc, mul_comm size]\' followed by \'trivial\') are not valid as written. In Lean 4, using \'mul_comm size\' is not recognized correctly, and the overall sequence of tactics after \'unfold\' is misformatted.\nRetry guidance (MUST FOLLOW):\nRevise the proof tactics by replacing the rewrite and trivial steps with \'rfl\' after the unfold, then re-run the code.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeSurfaceArea (size : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The surface area of the cube is calculated correctly\ndef cubeSurfaceArea_spec (size : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = 6 * size * size\n  -- << SPEC END >>\n\ntheorem cubeSurfaceArea_spec_satisfied (size : Int):\n  cubeSurfaceArea_spec size (cubeSurfaceArea size) := by\n  -- << PROOF START >>\n  unfold cubeSurfaceArea cubeSurfaceArea_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 03:06:52,530 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:06:52,530 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:06:52,531 - DEBUG - send_request_headers.complete
2025-06-01 03:06:52,531 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:06:52,531 - DEBUG - send_request_body.complete
2025-06-01 03:06:52,531 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:06:54,173 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:06:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'1405'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1410'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'117'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'59.764s'), (b'x-request-id', b'req_f2a889888b2f6145d650d4dc89ba643d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7f5e8e654436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:06:54,174 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:06:54,174 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:06:54,175 - DEBUG - receive_response_body.complete
2025-06-01 03:06:54,175 - DEBUG - response_closed.started
2025-06-01 03:06:54,175 - DEBUG - response_closed.complete
2025-06-01 03:06:54,175 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:06:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '1405', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1410', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '117', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '59.764s', 'x-request-id': 'req_f2a889888b2f6145d650d4dc89ba643d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7f5e8e654436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:06:54,176 - DEBUG - request_id: req_f2a889888b2f6145d650d4dc89ba643d
2025-06-01 03:06:54,176 - INFO - Raw solution received: ```json
{
  "code": "6 * size * size",
  "proof": "rfl"
}
```
2025-06-01 03:06:54,176 - INFO - <class 'str'>
2025-06-01 03:06:54,176 - INFO - Generated solution: {'code': '6 * size * size', 'proof': 'rfl'}
2025-06-01 03:06:59,513 - INFO - Lean execution result: Lean code executed successfully.
2025-06-01 03:06:59,514 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.\n\n-----Input-----\nThe input consists of:\nsize: An integer representing the length of an edge of the cube.\n\n-----Output-----\nThe output is an integer:\nReturns the surface area of the cube.\n\n-----Note-----\nThe input edge length is assumed to be greater than 0.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeSurfaceArea (size : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The surface area of the cube is calculated correctly\ndef cubeSurfaceArea_spec (size : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = 6 * size * size\n  -- << SPEC END >>\n\ntheorem cubeSurfaceArea_spec_satisfied (size : Int):\n  cubeSurfaceArea_spec size (cubeSurfaceArea size) := by\n  -- << PROOF START >>\n  unfold cubeSurfaceArea cubeSurfaceArea_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\n6 * size * size\n\nGenerated Proof:\nrfl\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean code executed successfully.'}], 'model': 'o3-mini'}}
2025-06-01 03:06:59,514 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:06:59,514 - DEBUG - close.started
2025-06-01 03:06:59,514 - DEBUG - close.complete
2025-06-01 03:06:59,514 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:06:59,522 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e670084a0>
2025-06-01 03:06:59,522 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:06:59,531 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e67009cd0>
2025-06-01 03:06:59,531 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:06:59,531 - DEBUG - send_request_headers.complete
2025-06-01 03:06:59,531 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:06:59,531 - DEBUG - send_request_body.complete
2025-06-01 03:06:59,531 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:07:02,060 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:07:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'1919'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1923'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199336'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'199ms'), (b'x-request-id', b'req_4d425cd10ec4b09f9fb42122ed98a68e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7f8a4b0b8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:07:02,060 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:07:02,060 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:07:02,060 - DEBUG - receive_response_body.complete
2025-06-01 03:07:02,061 - DEBUG - response_closed.started
2025-06-01 03:07:02,061 - DEBUG - response_closed.complete
2025-06-01 03:07:02,061 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:07:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '1919', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1923', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199336', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '199ms', 'x-request-id': 'req_4d425cd10ec4b09f9fb42122ed98a68e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7f8a4b0b8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:07:02,061 - DEBUG - request_id: req_4d425cd10ec4b09f9fb42122ed98a68e
2025-06-01 03:07:02,061 - INFO - Feedback received: {'verdict': 'pass', 'error_summary': 'The code and proof execute successfully without any errors.', 'error_type': 'unknown', 'suggested_fix': "No changes needed. The implementation using '6 * size * size' correctly calculates the cube's surface area, and the proof 'rfl' is sufficient since both sides of the equation are definitionally equal.", 'retry_strategy': 'None needed'}
2025-06-01 03:07:02,061 - INFO - Solution generated in 42.75 seconds
2025-06-01 03:07:02,061 - INFO - Generated code length: 15 characters
2025-06-01 03:07:02,061 - INFO - Generated proof length: 3 characters
2025-06-01 03:07:02,061 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 03:07:02,062 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 03:07:07,329 - INFO - Implementation test result: PASS
2025-06-01 03:07:07,329 - INFO - Executing Lean code with implementation and proof...
2025-06-01 03:07:12,732 - INFO - Full solution test result: PASS
2025-06-01 03:07:12,732 - INFO - ✅ Implementation passes unit tests
2025-06-01 03:07:12,732 - INFO - ✅ Proof is correct
2025-06-01 03:07:12,732 - INFO - 
==================================================
2025-06-01 03:07:12,732 - INFO - Processing task task_id_447...
2025-06-01 03:07:12,732 - INFO - Reading problem description and code template from tasks/task_id_447...
2025-06-01 03:07:12,732 - INFO - Problem description length: 691 characters
2025-06-01 03:07:12,733 - INFO - Reading unit tests from tasks/task_id_447...
2025-06-01 03:07:12,733 - INFO - Unit tests length: 234 characters
2025-06-01 03:07:12,733 - INFO - Running main workflow to generate solution...
2025-06-01 03:07:12,733 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.

-----Input-----
The input consists of:
a: An array of integers (which may be empty or non-empty).

-----Output-----
The output is an array of integers:
Returns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.

-----Note-----
There are no additional preconditions; the method should work correctly for any array of integers.
2025-06-01 03:07:12,733 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def cubeElements (a : Array Int) : Array Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array
def cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=
  -- << SPEC START >>
  (result.size = a.size) ∧
  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)
  -- << SPEC END >>

theorem cubeElements_spec_satisfied (a : Array Int) :
  cubeElements_spec a (cubeElements a) := by
  -- << PROOF START >>
  unfold cubeElements cubeElements_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 03:07:12,763 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7f4e67012700>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 03:07:12,763 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 03:07:12,764 - DEBUG - close.started
2025-06-01 03:07:12,764 - DEBUG - close.complete
2025-06-01 03:07:12,764 - DEBUG - close.started
2025-06-01 03:07:12,764 - DEBUG - close.complete
2025-06-01 03:07:12,764 - DEBUG - close.started
2025-06-01 03:07:12,764 - DEBUG - close.complete
2025-06-01 03:07:12,764 - DEBUG - close.started
2025-06-01 03:07:12,764 - DEBUG - close.complete
2025-06-01 03:07:12,769 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:07:12,775 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fe73b0>
2025-06-01 03:07:12,775 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4e66fffc50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:07:12,786 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e710fce60>
2025-06-01 03:07:12,786 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:07:12,786 - DEBUG - send_request_headers.complete
2025-06-01 03:07:12,786 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:07:12,786 - DEBUG - send_request_body.complete
2025-06-01 03:07:12,786 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:07:13,090 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:07:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'71'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-6b84dbcf9f-8vk6h'), (b'x-envoy-upstream-service-time', b'75'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999827'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_960dfa97f3cf70e3277903c86a5a811c'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=g6io.XojMWiu6.e0rEhCfPLIS.W_nLpT3UcJVH3VW6M-1748747233-1.0.1.1-vAZQdyCm0lq9kZBMsRfVUVSV2n.NUzTrSyxavVAHJdRGU3TeVvpBeTSZeR7UAubma4l11w2JmhMe.wO_b6ePvEWRXRXkYLemZvOdrAUHtz8; path=/; expires=Sun, 01-Jun-25 03:37:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=acMb8sXnGEVectrhqJ7caBTWTX.jaeuIqc6YMddk2nU-1748747233117-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7fdd18b247bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:07:13,091 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 03:07:13,091 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:07:13,091 - DEBUG - receive_response_body.complete
2025-06-01 03:07:13,092 - DEBUG - response_closed.started
2025-06-01 03:07:13,092 - DEBUG - response_closed.complete
2025-06-01 03:07:13,092 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 03:07:13 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '71'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-6b84dbcf9f-8vk6h'), ('x-envoy-upstream-service-time', '75'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999827'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '10ms'), ('x-request-id', 'req_960dfa97f3cf70e3277903c86a5a811c'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=g6io.XojMWiu6.e0rEhCfPLIS.W_nLpT3UcJVH3VW6M-1748747233-1.0.1.1-vAZQdyCm0lq9kZBMsRfVUVSV2n.NUzTrSyxavVAHJdRGU3TeVvpBeTSZeR7UAubma4l11w2JmhMe.wO_b6ePvEWRXRXkYLemZvOdrAUHtz8; path=/; expires=Sun, 01-Jun-25 03:37:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=acMb8sXnGEVectrhqJ7caBTWTX.jaeuIqc6YMddk2nU-1748747233117-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b7fdd18b247bc-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 03:07:13,092 - DEBUG - request_id: req_960dfa97f3cf70e3277903c86a5a811c
2025-06-01 03:07:13,098 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
 m by rw [Nat.zero_add, Nat.add_zero])
       (fun (n : Nat) (ih : m + n = n + m) =>
        show m + succ n = succ n + m from
        calc m + succ n
          _ = succ (m + n) := rfl
          _ = succ (n + m) := by rw [ih]
          _ = succ n + m   := sorry)
    

At this point, we see that we need another supporting fact, namely, that `succ
(n + m) = succ n + m`. You can prove this by induction on `m`:

    
    
    open Nat
    
    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m
        (show succ n + 0 = succ (n + 0) from rfl)
        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>
         show succ n + succ m = succ (n + succ m) from
         calc succ n + succ m
           _ = succ (succ n + m)   := rfl
           _ = succ (succ (n + m)) := by rw [ih]
           _ = succ (n + succ m)   := rfl)
    

You can then replace the `sorry` in the previous proof with `succ_add`. Yet
again, the proofs can be compressed:

    
    
    namespace Hidden
    open Nat
    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m
        rfl
        (fun m ih => by simp only [add_succ, ih])
    
    theorem add_comm (m n : Nat) : m + n = n + m :=
      Nat.recOn (motive := fun x => m + x = x + m) n
        (by simp)
        (fun m ih => by simp [add_succ, succ_add, ih])
    end Hidden
    

## Other Recursive Data Types

Let us consider some more examples of inductively defined types. For any type,
`α`, the type `List α` of lists of elements of `α` is defined in the library.

    
    
    namespace Hidden
    inductive List (α : Type u) where
      | nil  : List α
      | cons : α → List α → List α
    
    namespace List
    
    def append (as bs : List α) : List α :=
      match as with
      | nil       => bs
      | cons a as => cons a (append as bs)
    
    theorem nil_append (as : List α) : append nil as = as :=
      rfl
    
    theorem cons_append (a : α) (as bs : List α)
                        : append (cons a as) bs = cons a (append as bs) :=
      rfl
    
    end List
    end Hidden
    

A list of elements of type `α` is either the empty list, `nil`, or an element
`h : α` followed by a list `t : List α`. The first element, `h`, is commonly
known as the "head" of the list, and the remainder, `t`, is known as the
"tail."

As an exercise, prove the following:

    
    
    namespace Hidden
    inductive List (α : Type u) where
    | nil  : List α
    | cons : α → List α → List α
    namespace List
    def append (as bs : List α) : List α :=
     match as with
     | nil       => bs
     | cons a as => cons a (append as bs)
    theorem nil_append (as : List α) : append nil as = as :=
     rfl
    theorem cons_append (a : α) (as bs : List α)
                        : append (cons a as) bs = cons a (append as bs) :=
     rfl
    theorem append_nil (as : List α) : append as nil = as :=
      sorry
    
    theorem append_assoc (as bs cs : List α)
            : append (append as bs) cs = append as (append bs cs) :=
      sorry
    end List
    end Hidden
    

Try also defining the function `length : {α : Type u} → List α → Nat` that
returns the length of a list, and prove that it behaves as expected (for
example, `length (append as bs) = length as + length bs`).

For another example, we can define the type of binary trees:

    
    
    inductive BinaryTree where
      | leaf : BinaryTree
      | node : BinaryTree → BinaryTree → BinaryTree
    

In fact, we can even define the type of countably branching trees:

    
    
    inductive CBTree where
      | leaf : CBTree
      | sup : (Nat → CBTree) → CBTree
    
    namespace CBTree
    
    def succ (t : CBTree) : CBTree :=
      sup (fun _ => t)
    
    def toCBTree : Nat → CBTree
      | 0 => leaf
      | n+1 => succ (toCBTree n)
    
    def omega : CBTree :=
      sup toCBTree
    
    end CBTree
    

## Tactics for Inductive Types

Given the fundamental importance of inductive types in Lean, it should not be
surprising that there are a number of tactics designed to work with them
effectively. We describe some of them here.

The `cases` tactic works on elements of an inductively defined type, and does
what the name suggests: it decomposes the element according to each of the
possible constructors. In its most basic form, it is applied to an element `x`
in the local context. It then reduces the goal to cases in which `x` is
replaced by each of the constructions.

    
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by
      intro n
      cases n
      . exact hz  -- goal is p 0
      . apply hs  -- goal is a : Nat ⊢ p (succ a)
    

There are extra bells and whistles. For one thing, `cases` allows you to
choose the names for each alternative using a `with` clause. In the next
example, for example, we choose the name `m` for the argument to `succ`, so
that the second case refers to `succ m`. More importantly, the cases tactic
will detect any items in the local context that depend on the target variable.
It reverts these elements, does the split, and reintroduces them. In the
example below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in
the first branch, and `h : succ m ≠ 0` in the second.

    
    
    open Nat
    
    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by
      cases n with
      | zero =>
        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0
        apply absurd rfl h
      | succ m =>
        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m
        rfl
    

Notice that `cases` can be used to produce data as well as prove propositions.

    
    
    def f (n : Nat) : Nat := by
      cases n; exact 3; exact 7
    
    example : f 0 = 3 := rfl
    example : f 5 = 7 := rfl
    

Once again, cases will revert, split, and then reintroduce dependencies in the
context.

    
    
    def Tuple (α : Type) (n : Nat) :=
      { as : List α // as.length = n }
    
    def f {n : Nat} (t : Tuple α n) : Nat := by
      cases n; exact 3; exact 7
    
    def myTuple : Tuple Nat 3 :=
      ⟨[0, 1, 2], rfl⟩
    
    example : f myTuple = 7 :=
      rfl
    

Here is an example of multiple constructors with arguments.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    
    def silly (x : Foo) : Nat := by
      cases x with
      | bar1 a b => exact b
      | bar2 c d e => exact e
    

The alternatives for each constructor don't need to be solved in the order the
constructors were declared.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x with
      | bar2 c d e => exact e
      | bar1 a b => exact b
    

The syntax of the `with` is convenient for writing structured proofs. Lean
also provides a complementary `case` tactic, which allows you to focus on goal
assign variable names.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x
      case bar1 a b => exact b
      case bar2 c d e => exact e
    

The `case` tactic is clever, in that it will match the constructor to the
appropriate goal. For example, we can fill the goals above in the opposite
order:

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x
      case bar2 c d e => exact e
      case bar1 a b => exact b
    

You can also use `cases` with an arbitrary expression. Assuming that
expression occurs in the goal, the cases tactic will generalize over the
expression, introduce the resulting universally quantified variable, and case
on that.

    
    
    open Nat
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
            : p (m + 3 * k) := by
      cases m + 3 * k
      exact hz   -- goal is p 0
      apply hs   -- goal is a : Nat ⊢ p (succ a)
    

Think of this as saying "split on cases as to whether `m + 3 * k` is zero or
the successor of some number." The result is functionally equivalent to the
following:

    
    
    open Nat
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
            : p (m + 3 * k) := by
      generalize m + 3 * k = n
      cases n
      exact hz   -- goal is p 0
      apply hs   -- goal is a : Nat ⊢ p (succ a)
    

Notice that the expression `m + 3 * k` is erased by `generalize`; all that
matters is whether it is of the form `0` or `succ a`. This form of `cases`
will _not_ revert any hypotheses that also mention the expression in the
equation (in this case, `m + 3 * k`). If such a term appears in a hypothesis
and you want to generalize over that as well, you need to `revert` it
explicitly.

If the expression you case on does not appear in the goal, the `cases` tactic
uses `have` to put the type of the expression into the context. Here is an
example:

    
    
    example (p : Prop) (m n : Nat)
            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by
      cases Nat.lt_or_ge m n
      case inl hlt => exact h₁ hlt
      case inr hge => exact h₂ hge
    

The theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to
think of the proof above as splitting on these two cases. In the first branch,
we have the hypothesis `hlt : m < n`, and in the second we have the hypothesis
`hge : m ≥ n`. The proof above is functionally equivalent to the following:

    
    
    example (p : Prop) (m n : Nat)
            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by
      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n
      cases h
      case inl hlt => exact h₁ hlt
      case inr hge => exact h₂ hge
    

After the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we
simply do cases on that.

Here is another example, where we use the decidability of equality on the
natural numbers to split on the cases `m = n` and `m ≠ n`.

    
    
    #check Nat.sub_self
    
    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by
      cases Decidable.em (m = n) with
      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n
      | inr hne => apply Or.inr; exact hne
    

Remember that if you `open Classical`, you can use the law of the excluded
middle for any proposition at all. But using type class inference (see
[Chapter Type Classes](./type_classes.html)), Lean can actually find the
relevant decision procedure, which means that you can use the case split in a
computable function.

Just as the `cases` tactic can be used to carry out proof by cases, the
`induction` tactic can be used to carry out proofs by induction. The syntax is
similar to that of `cases`, except that the argument can only be a term in the
local context. Here is an example:

    
    
    namespace Hidden
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n with
      | zero => rfl
      | succ n ih => rw [Nat.add_succ, ih]
    end Hidden
    

As with `cases`, we can use the `case` tactic instead of `with`.

    
    
    namespace Hidden
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n
      case zero => rfl
      case succ n ih => rw [Nat.add_succ, ih]
    end Hidden
    

Here are some additional examples:

    
    
    namespace Hidden
    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n
    open Nat
    
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n <;> simp [*, add_zero, add_succ]
    
    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by
      induction n <;> simp [*, add_zero, add_succ]
    
    theorem add_comm (m n : Nat) : m + n = n + m := by
      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]
    
    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by
      induction k <;> simp [*, add_zero, add_succ]
    end Hidden
    

The `induction` tactic also supports user-defined induction principles with
multiple targets (aka major premises).

    
    
    /-
    theorem Nat.mod.inductionOn
          {motive : Nat → Nat → Sort u}
          (x y  : Nat)
          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)
          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)
          : motive x y :=
    -/
    
    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by
      induction x, y using Nat.mod.inductionOn with
      | ind x y h₁ ih =>
        rw [Nat.mod_eq_sub_mod h₁.2]
        exact ih h
      | base x y h₁ =>
        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁
        match this with
        | Or.inl h₁ => exact absurd h h₁
        | Or.inr h₁ =>
          have hgt : y > x := Nat.gt_of_not_le h₁
          rw [← Nat.mod_eq_of_lt hgt] at hgt
          assumption
    

You can use the `match` notation in tactics too:

    
    
    example : p ∨ q → q ∨ p := by
      intro h
      match h with
      | Or.inl _  => apply Or.inr; assumption
      | Or.inr h2 => apply Or.inl; exact h2
    

As a convenience, pattern-matching has been integrated into tactics such as
`intro` and `funext`.

    
    
    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by
      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩
      exact ⟨hq, hp⟩
    
    example :
        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)
        =
        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by
      funext (a, b) (c, d)
      show a + d = d + a
      rw [Nat.add_comm]
    

We close this section with one last tactic that is designed to facilitate
working with inductive types, namely, the `injection` tactic. By design, the
elements of an inductive type are freely generated, which is to say, the
constructors are injective and have disjoint ranges. The `injection` tactic is
designed to make use of this fact:

    
    
    open Nat
    
    example (m n k : Nat) (h : succ (succ m) = succ (succ n))
            : n + k = m + k := by
      injection h with h'
      injection h' with h''
      rw [h'']
    

The first instance of the tactic adds `h' : succ m = succ n` to the context,
and the second adds `h'' : m = n`.

The `injection` tactic also detects contradictions that arise when different
constructors are set equal to one another, and uses them to close the goal.

    
    
    open Nat
    
    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
      injection h
    
    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
      contradiction
    
    example (h : 7 = 4) : False := by
      contradiction
    

As the second example shows, the `contradiction` tactic also detects
contradictions of this form.

## Inductive Families

We are almost done describing the full range of inductive definitions accepted
by Lean. So far, you have seen that Lean allows you to introduce inductive
types with any number of recursive constructors. In fact, a single inductive
definition can introduce an indexed _family_ of inductive types, in a manner
we now describe.

An inductive family is an indexed family of types defined by a simultaneous
induction of the following form:

    
    
    inductive foo : ... → Sort u where
      | constructor₁ : ... → foo ...
      | constructor₂ : ... → foo ...
      ...
      | constructorₙ : ... → foo ...
    

In contrast to an ordinary inductive definition, which constructs an element
of some `Sort u`, the more general version constructs a function `... → Sort
u`, where "`...`" denotes a sequence of argument types, also known as
_indices_. Each constructor then constructs an element of some member of the
family. One example is the definition of `Vector α n`, the type of vectors of
elements of `α` of length `n`:

    
    
    namespace Hidden
    inductive Vector (α : Type u) : Nat → Type u where
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    end Hidden
    

Notice that the `cons` constructor takes an element of `Vector α n` and
returns an element of `Vector α (n+1)`, thereby using an element of one member
of the family to build an element of another.

A more exotic example is given by the definition of the equality type in Lean:

    
    
    namespace Hidden
    inductive Eq {α : Sort u} (a : α) : α → Prop where
      | refl : Eq a a
    end Hidden
    

For each fixed `α : Sort u` and `a : α`, this definition constructs a family
of types `Eq a x`, indexed by `x : α`. Notably, however, there is only one
constructor, `refl`, which is an element of `Eq a a`. Intuitively, the only
way to construct a proof of `Eq a x` is to use reflexivity, in the case where
`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of
types `Eq a x`. The elimination principle generated by Lean is as follows:

    
    
    universe u v
    
    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}
                      → motive a rfl → {b : α} → (h : a = b) → motive b h)
    

It is a remarkable fact that all the basic axioms for equality follow from the
constructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality
is atypical, however; see the discussion in Section Axiomatic Details.

The recursor `Eq.rec` is also used to define substitution:

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      Eq.rec (motive := fun x _ => p x) h₂ h₁
    end Hidden
    

You can also define `subst` using `match`.

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      match h₁ with
      | rfl => h₂
    end Hidden
    

Actually, Lean compiles the `match` expressions using a definition based on
`Eq.rec`.

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      match h₁ with
      | rfl => h₂
    
    set_option pp.all true
    #print subst
      -- ... subst.match_1 ...
    #print subst.match_1
      -- ... Eq.casesOn ...
    #print Eq.casesOn
      -- ... Eq.rec ...
    end Hidden
    

Using the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are
the same, in which case, `p b` and `p a` are the same.

It is not hard to prove that `Eq` is symmetric and transitive. In the
following example, we prove `symm` and leave as exercises the theorems `trans`
and `congr` (congruence).

    
    
    namespace Hidden
    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=
      match h with
      | rfl => rfl
    
    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=
      sorry
    
    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=
      sorry
    end Hidden
    

In the type theory literature, there are further generalizations of inductive
definitions, for example, the principles of _induction-recursion_ and
_induction-induction_. These are not supported by Lean.

## Axiomatic Details

We have described inductive types and their syntax through examples. This
section provides additional information for those interested in the axiomatic
foundations.

We have seen that the constructor to an inductive type takes _parameters_ \---
intuitively, the arguments that remain fixed throughout the inductive
construction --- and _indices_ , the arguments parameterizing the family of
types that is simultaneously under construction. Each constructor should have
a type, where the argument types are built up from previously defined types,
the parameter and index types, and the inductive family currently being
defined. The requirement is that if the latter is present at all, it occurs
only _strictly positively_. This means simply that any argument to the
constructor in which it occurs is a dependent arrow type in which the
inductive type under definition occurs only as the resulting type, where the
indices are given in terms of constants and previous arguments.

Since an inductive type lives in `Sort u` for some `u`, it is reasonable to
ask _which_ universe levels `u` can be instantiated to. Each constructor `c`
in the definition of a family `C` of inductive types is of the form

    
    
      c : (a : α) → (b : β[a]) → C a p[a,b]
    

where `a` is a sequence of data type parameters, `b` is the sequence of
arguments to the constructors, and `p[a, b]` are the indices, which determine
which element of the inductive family the construction inhabits. (Note that
this description is somewhat misleading, in that the arguments to the
constructor can appear in any order as long as the dependencies make sense.)
The constraints on the universe level of `C` fall into two cases, depending on
whether or not the inductive type is specified to land in `Prop` (that is,
`Sort 0`).

Let us first consider the case where the inductive type is _not_ specified to
land in `Prop`. Then the universe level `u` is constrained to satisfy the
following:

> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,
> if `βk[a] : Sort v`, we have `u` ≥ `v`.

In other words, the universe level `u` is required to be at least as large as
the universe level of each type that represents an argument to a constructor.

When the inductive type is specified to land in `Prop`, there are no
constraints on the universe levels of the constructor arguments. But these
universe levels do have a bearing on the elimination rule. Generally speaking,
for an inductive type in `Prop`, the motive of the elimination rule is
required to be in `Prop`.

There is an exception to this last rule: we are allowed to eliminate from an
inductively defined `Prop` to an arbitrary `Sort` when there is only one
constructor and each constructor argument is either in `Prop` or an index. The
intuition is that in this case the elimination does not make use of any
information that is not already given by the mere fact that the type of
argument is inhabited. This special case is known as _singleton elimination_.

We have already seen singleton elimination at play in applications of
`Eq.rec`, the eliminator for the inductively defined equality type. We can use
an element `h : Eq a b` to cast an element `t' : p a` to `p b` even when `p a`
and `p b` are arbitrary types, because the cast does not produce new data; it
only reinterprets the data we already have. Singleton elimination is also used
with heterogeneous equality and well-founded recursion, which will be
discussed in a [Chapter Induction and
Recursion](./induction_and_recursion.html#well-founded-recursion-and-
induction).

## Mutual and Nested Inductive Types

We now consider two generalizations of inductive types that are often useful,
which Lean supports by "compiling" them down to the more primitive kinds of
inductive types described above. In other words, Lean parses the more general
definitions, defines auxiliary inductive types based on them, and then uses
the auxiliary types to define the ones we really want. Lean's equation
compiler, described in the next chapter, is needed to make use of these types
effectively. Nonetheless, it makes sense to describe the declarations here,
because they are straightforward variations on ordinary inductive definitions.

First, Lean supports _mutually defined_ inductive types. The idea is that we
can define two (or more) inductive types at the same time, where each one
refers to the other(s).

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : (n : Nat) → Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : (n : Nat) → Even n → Odd (n + 1)
    end
    

In this example, two types are defined simultaneously: a natural number `n` is
`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one
more than an `Even` number. In the exercises below, you are asked to spell out
the details.

A mutual inductive definition can also be used to define the notation of a
finite tree with nodes labelled by elements of `α`:

    
    
    mutual
        inductive Tree (α : Type u) where
          | node : α → TreeList α → Tree α
    
        inductive TreeList (α : Type u) where
          | nil  : TreeList α
          | cons : Tree α → TreeList α → TreeList α
    end
    

With this definition, one can construct an element of `Tree α` by giving an
element of `α` together with a list of subtrees, possibly empty. The list of
subtrees is represented by the type `TreeList α`, which is defined to be
either the empty list, `nil`, or the `cons` of a tree and an element of
`TreeList α`.

This definition is inconvenient to work with, however. It would be much nicer
if the list of subtrees were given by the type `List (Tree α)`, especially
since Lean's library contains a number of functions and theorems for working
with lists. One can show that the type `TreeList α` is _isomorphic_ to `List
(Tree α)`, but translating results back and forth along this isomorphism is
tedious.

In fact, Lean allows us to define the inductive type we really want:

    
    
    inductive Tree (α : Type u) where
      | mk : α → List (Tree α) → Tree α
    

This is known as a _nested_ inductive type. It falls outside the strict
specification of an inductive type given in the last section because `Tree`
does not occur strictly positively among the arguments to `mk`, but, rather,
nested inside the `List` type constructor. Lean then automatically builds the
isomorphism between `TreeList α` and `List (Tree α)` in its kernel, and
defines the constructors for `Tree` in terms of the isomorphism.

## Exercises

  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.

Since many of these are already defined in Lean's core library, you should
work within a namespace named `Hidden`, or something like that, in order to
avoid name clashes.

  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:

a. `length (s ++ t) = length s + length t`

b. `length (reverse t) = length t`

c. `reverse (reverse t) = t`

  3. Define an inductive data type consisting of terms built up from the following constructors:

     * `const n`, a constant denoting the natural number `n`
     * `var n`, a variable, numbered `n`
     * `plus s t`, denoting the sum of `s` and `t`
     * `times s t`, denoting the product of `s` and `t`

Recursively define a function that evaluates any such term with respect to an
assignment of values to the variables.

  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.

[ __](interacting_with_lean.html "Previous chapter") [
__](induction_and_recursion.html "Next chapter")

[ __](interacting_with_lean.html "Previous chapter") [
__](induction_and_recursion.html "Next chapter")
 modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
2025-06-01 03:07:13,113 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\nIf your function uses Boolean logic or `if...then...else`, always plan to:\n  - Use `by_cases` or `split_ifs` on the Boolean condition(s) in the proof.\n  - Use `simp` in each branch to reduce the goal to true ↔ true or false ↔ false.\n  - Close each goal with `trivial`, `exact`, or `exfalso` depending on context.\nDo not plan to use `case inl`/`case inr` (Lean 3-style); use `case pos`/`case neg` in Lean 4.\nNever rely on `sorry` or incomplete proofs; all goals must be discharged.\nIf the function's return type is `Bool` and the specification is a `↔` with a Prop, then include a plan to handle the `if` structure explicitly using `by_cases` or `split_ifs`.\nLean 4 requires `pos`/`neg` tags for `by_cases`. Do not mention `inl` or `inr`.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.'}], 'model': 'o3-mini'}}
2025-06-01 03:07:13,114 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:07:13,114 - DEBUG - close.started
2025-06-01 03:07:13,114 - DEBUG - close.complete
2025-06-01 03:07:13,114 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:07:13,121 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fe6420>
2025-06-01 03:07:13,121 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:07:13,130 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fe7050>
2025-06-01 03:07:13,130 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:07:13,130 - DEBUG - send_request_headers.complete
2025-06-01 03:07:13,130 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:07:13,130 - DEBUG - send_request_body.complete
2025-06-01 03:07:13,130 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:07:24,783 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:07:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'11429'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'11434'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199341'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'197ms'), (b'x-request-id', b'req_27fa14786716560e626adab735ce6f5f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b7fdf4c1e4436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:07:24,783 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:07:24,783 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:07:24,784 - DEBUG - receive_response_body.complete
2025-06-01 03:07:24,784 - DEBUG - response_closed.started
2025-06-01 03:07:24,784 - DEBUG - response_closed.complete
2025-06-01 03:07:24,784 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:07:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '11429', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '11434', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199341', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '197ms', 'x-request-id': 'req_27fa14786716560e626adab735ce6f5f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b7fdf4c1e4436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:07:24,784 - DEBUG - request_id: req_27fa14786716560e626adab735ce6f5f
2025-06-01 03:07:24,784 - INFO - Attempt 1/3
2025-06-01 03:07:24,784 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that takes an array of integers and returns a new array where each element is replaced by its cube. The implementation consists of mapping over the input array and, for each element, computing its cube (x * x * x).",
  "steps": [
    "Define the function with an appropriate signature, taking an array of integers as input and returning an array of integers.",
    "Implement a helper operation to compute the cube of an integer (i.e., x * x * x).",
    "Use the built-in array.map function to traverse the array and apply the cube operation to each element.",
    "Return the resulting array, ensuring that the output array maintains the same length as the input."
  ],
  "code_keywords": [
    "Lean 4",
    "array",
    "array.map",
    "integer arithmetic",
    "cube calculation"
  ],
  "proof_keywords": [
    "inductive reasoning",
    "base case",
    "recursive structure",
    "map consistency"
  ],
  "assumptions": [
    "The array.map function is available and works as expected in Lean 4.",
    "Integer multiplication is well-defined and associative, so computing x * x * x yields the correct cube.",
    "No side conditions or preconditions are necessary for the transformation."
  ],
  "retry_guidance": "If there are any issues related to array mapping or type inconsistencies in Lean 4, revise the function signature or the use of array.map. Ensure that each branch of any conditional logic uses 'by_cases' or 'split_ifs' with 'simp' and proper closures (trivial/exact) as needed."
}
2025-06-01 03:07:24,785 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\nYou MUST:\n  - Use `split_ifs` or `by_cases` for Boolean if-expressions.\n  - In each case branch, simplify the goal using `simp`.\n  - Use `trivial`, `exact`, or `exfalso` to close simplified branches.\nYou MUST NOT:\n  - Use `case inl` / `case inr` → replace with `case pos` / `case neg`.\n  - Use `done`, `⟨..., by ...⟩`, `by assumption` in unclear contexts.\n  - Use `sorry`, or leave any goal open.\nFor Boolean-returning functions with specifications of the form:\n  `spec a b (hasOppositeSign a b) := ... ↔ ...`,\nalways:\n  - `unfold` the function and spec,\n  - `split_ifs with h` to analyze conditions,\n  - `simp` the goal under each condition,\n  - then `trivial`, `exact`, or `contradiction` to finish.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that takes an array of integers and returns a new array where each element is replaced by its cube. The implementation consists of mapping over the input array and, for each element, computing its cube (x * x * x).",\n  "steps": [\n    "Define the function with an appropriate signature, taking an array of integers as input and returning an array of integers.",\n    "Implement a helper operation to compute the cube of an integer (i.e., x * x * x).",\n    "Use the built-in array.map function to traverse the array and apply the cube operation to each element.",\n    "Return the resulting array, ensuring that the output array maintains the same length as the input."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "array",\n    "array.map",\n    "integer arithmetic",\n    "cube calculation"\n  ],\n  "proof_keywords": [\n    "inductive reasoning",\n    "base case",\n    "recursive structure",\n    "map consistency"\n  ],\n  "assumptions": [\n    "The array.map function is available and works as expected in Lean 4.",\n    "Integer multiplication is well-defined and associative, so computing x * x * x yields the correct cube.",\n    "No side conditions or preconditions are necessary for the transformation."\n  ],\n  "retry_guidance": "If there are any issues related to array mapping or type inconsistencies in Lean 4, revise the function signature or the use of array.map. Ensure that each branch of any conditional logic uses \'by_cases\' or \'split_ifs\' with \'simp\' and proper closures (trivial/exact) as needed."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  -- << SPEC START >>\n  (result.size = a.size) ∧\n  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n  -- << SPEC END >>\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  -- << PROOF START >>\n  unfold cubeElements cubeElements_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 03:07:24,787 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:07:24,787 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:07:24,787 - DEBUG - send_request_headers.complete
2025-06-01 03:07:24,787 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:07:24,792 - DEBUG - send_request_body.complete
2025-06-01 03:07:24,792 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:07:25,019 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sun, 01 Jun 2025 03:07:25 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'373'), (b'Connection', b'keep-alive'), (b'retry-after', b'5'), (b'retry-after-ms', b'4706'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'15133'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'29.732s'), (b'x-request-id', b'req_6231e639c34d8e145ab5c8881d8a614d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b802819854436-BOM'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:07:25,019 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 03:07:25,019 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:07:25,019 - DEBUG - receive_response_body.complete
2025-06-01 03:07:25,019 - DEBUG - response_closed.started
2025-06-01 03:07:25,019 - DEBUG - response_closed.complete
2025-06-01 03:07:25,019 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sun, 01 Jun 2025 03:07:25 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '373', 'connection': 'keep-alive', 'retry-after': '5', 'retry-after-ms': '4706', 'vary': 'Origin', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '15133', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '29.732s', 'x-request-id': 'req_6231e639c34d8e145ab5c8881d8a614d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b802819854436-BOM', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:07:25,019 - DEBUG - request_id: req_6231e639c34d8e145ab5c8881d8a614d
2025-06-01 03:07:25,019 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/openai/_base_client.py", line 1007, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.12/dist-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-06-01 03:07:25,020 - DEBUG - Retrying due to status code 429
2025-06-01 03:07:25,020 - DEBUG - 2 retries left
2025-06-01 03:07:25,020 - INFO - Retrying request to /chat/completions in 4.706000 seconds
2025-06-01 03:07:29,726 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\nYou MUST:\n  - Use `split_ifs` or `by_cases` for Boolean if-expressions.\n  - In each case branch, simplify the goal using `simp`.\n  - Use `trivial`, `exact`, or `exfalso` to close simplified branches.\nYou MUST NOT:\n  - Use `case inl` / `case inr` → replace with `case pos` / `case neg`.\n  - Use `done`, `⟨..., by ...⟩`, `by assumption` in unclear contexts.\n  - Use `sorry`, or leave any goal open.\nFor Boolean-returning functions with specifications of the form:\n  `spec a b (hasOppositeSign a b) := ... ↔ ...`,\nalways:\n  - `unfold` the function and spec,\n  - `split_ifs with h` to analyze conditions,\n  - `simp` the goal under each condition,\n  - then `trivial`, `exact`, or `contradiction` to finish.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that takes an array of integers and returns a new array where each element is replaced by its cube. The implementation consists of mapping over the input array and, for each element, computing its cube (x * x * x).",\n  "steps": [\n    "Define the function with an appropriate signature, taking an array of integers as input and returning an array of integers.",\n    "Implement a helper operation to compute the cube of an integer (i.e., x * x * x).",\n    "Use the built-in array.map function to traverse the array and apply the cube operation to each element.",\n    "Return the resulting array, ensuring that the output array maintains the same length as the input."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "array",\n    "array.map",\n    "integer arithmetic",\n    "cube calculation"\n  ],\n  "proof_keywords": [\n    "inductive reasoning",\n    "base case",\n    "recursive structure",\n    "map consistency"\n  ],\n  "assumptions": [\n    "The array.map function is available and works as expected in Lean 4.",\n    "Integer multiplication is well-defined and associative, so computing x * x * x yields the correct cube.",\n    "No side conditions or preconditions are necessary for the transformation."\n  ],\n  "retry_guidance": "If there are any issues related to array mapping or type inconsistencies in Lean 4, revise the function signature or the use of array.map. Ensure that each branch of any conditional logic uses \'by_cases\' or \'split_ifs\' with \'simp\' and proper closures (trivial/exact) as needed."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  -- << SPEC START >>\n  (result.size = a.size) ∧\n  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n  -- << SPEC END >>\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  -- << PROOF START >>\n  unfold cubeElements cubeElements_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 03:07:29,728 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:07:29,728 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:07:29,728 - DEBUG - send_request_headers.complete
2025-06-01 03:07:29,728 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:07:29,729 - DEBUG - send_request_body.complete
2025-06-01 03:07:29,729 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:07:34,569 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:07:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4593'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4595'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'115'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'59.769s'), (b'x-request-id', b'req_4d8a3dc2be38159ba167a87e4f1fe0fb'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b804709004436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:07:34,569 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:07:34,570 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:07:34,570 - DEBUG - receive_response_body.complete
2025-06-01 03:07:34,570 - DEBUG - response_closed.started
2025-06-01 03:07:34,570 - DEBUG - response_closed.complete
2025-06-01 03:07:34,570 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:07:34 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4593', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4595', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '115', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '59.769s', 'x-request-id': 'req_4d8a3dc2be38159ba167a87e4f1fe0fb', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b804709004436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:07:34,570 - DEBUG - request_id: req_4d8a3dc2be38159ba167a87e4f1fe0fb
2025-06-01 03:07:34,571 - INFO - Raw solution received: ```json
{
  "code": "a.map (fun x => x * x * x)",
  "proof": "intro a\n  induction a using Array.inductionOn with\n  | empty => simp\n  | @push x xs ih => simp [cubeElements, cubeElements_spec, Array.map, ih]\n  apply Array.ext\n  intro i\n  simp\n  by_cases i < xs.size\n  · simp [Array.get?_eq_get, ih i h]\n  · simp [Array.get?_eq_get, Nat.not_lt_zero i, lt_of_lt_of_le (Nat.lt_of_lt_succ h), not_lt_of_le (Nat.le_of_lt_succ h)]\n  let h_eq := Nat.not_lt_of_le (Ge.add_eq_add_eq (Array.size_push x xs) xs.size)\n  simp [Array.get?_eq_get, ih i h_eq]\n  exact desc_map_iff.mpr ih\n  "
}
```
2025-06-01 03:07:34,571 - INFO - <class 'str'>
2025-06-01 03:07:34,571 - INFO - Generated solution: {'code': 'a.map (fun x => x * x * x)', 'proof': 'intro a\n  induction a using Array.inductionOn with\n  | empty => simp\n  | @push x xs ih => simp [cubeElements, cubeElements_spec, Array.map, ih]\n  apply Array.ext\n  intro i\n  simp\n  by_cases i < xs.size\n  · simp [Array.get?_eq_get, ih i h]\n  · simp [Array.get?_eq_get, Nat.not_lt_zero i, lt_of_lt_of_le (Nat.lt_of_lt_succ h), not_lt_of_le (Nat.le_of_lt_succ h)]\n  let h_eq := Nat.not_lt_of_le (Ge.add_eq_add_eq (Array.size_push x xs) xs.size)\n  simp [Array.get?_eq_get, ih i h_eq]\n  exact desc_map_iff.mpr ih\n  '}
2025-06-01 03:07:39,662 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:22:8: error: tactic 'introN' failed, insufficient number of binders
a : Array ℤ
⊢ (Array.map (fun x => x * x * x) a).size = a.size ∧
    ∀ i < a.size, (Array.map (fun x => x * x * x) a)[i]! = a[i]! * a[i]! * a[i]!
2025-06-01 03:07:39,663 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  -- << SPEC START >>\n  (result.size = a.size) ∧\n  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n  -- << SPEC END >>\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  -- << PROOF START >>\n  unfold cubeElements cubeElements_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na.map (fun x => x * x * x)\n\nGenerated Proof:\nintro a\n  induction a using Array.inductionOn with\n  | empty => simp\n  | @push x xs ih => simp [cubeElements, cubeElements_spec, Array.map, ih]\n  apply Array.ext\n  intro i\n  simp\n  by_cases i < xs.size\n  · simp [Array.get?_eq_get, ih i h]\n  · simp [Array.get?_eq_get, Nat.not_lt_zero i, lt_of_lt_of_le (Nat.lt_of_lt_succ h), not_lt_of_le (Nat.le_of_lt_succ h)]\n  let h_eq := Nat.not_lt_of_le (Ge.add_eq_add_eq (Array.size_push x xs) xs.size)\n  simp [Array.get?_eq_get, ih i h_eq]\n  exact desc_map_iff.mpr ih\n  \n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:22:8: error: tactic 'introN' failed, insufficient number of binders\na : Array ℤ\n⊢ (Array.map (fun x => x * x * x) a).size = a.size ∧\n    ∀ i < a.size, (Array.map (fun x => x * x * x) a)[i]! = a[i]! * a[i]! * a[i]!"}], 'model': 'o3-mini'}}
2025-06-01 03:07:39,663 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:07:39,664 - DEBUG - close.started
2025-06-01 03:07:39,664 - DEBUG - close.complete
2025-06-01 03:07:39,664 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:07:39,672 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a7140>
2025-06-01 03:07:39,672 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:07:39,683 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e673a79e0>
2025-06-01 03:07:39,683 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:07:39,683 - DEBUG - send_request_headers.complete
2025-06-01 03:07:39,683 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:07:39,683 - DEBUG - send_request_body.complete
2025-06-01 03:07:39,683 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:07:53,110 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:07:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'12813'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'12817'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199052'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'284ms'), (b'x-request-id', b'req_003c635b185d1077e71f264606a4e766'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b80853fe48fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:07:53,110 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:07:53,110 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:07:53,111 - DEBUG - receive_response_body.complete
2025-06-01 03:07:53,111 - DEBUG - response_closed.started
2025-06-01 03:07:53,111 - DEBUG - response_closed.complete
2025-06-01 03:07:53,111 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:07:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '12813', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '12817', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199052', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '284ms', 'x-request-id': 'req_003c635b185d1077e71f264606a4e766', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b80853fe48fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:07:53,111 - DEBUG - request_id: req_003c635b185d1077e71f264606a4e766
2025-06-01 03:07:53,111 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails because of an extra 'intro a' tactic. The theorem already takes 'a' as a parameter, so calling 'intro a' introduces an extra (non-existent) binder. This causes the 'tactic 'introN' failed, insufficient number of binders' error.", 'error_type': 'syntax', 'suggested_fix': "Remove the redundant 'intro a' from the proof. For example, you can rewrite the proof as follows:\n\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  a.map (fun x => x * x * x)\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output is the cube of the corresponding element in the input.\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  result.size = a.size ∧ (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  simp [cubeElements, cubeElements_spec, Array.map]\n  intros i h\n  rfl\n\nThis streamlined proof uses 'simp' to handle the equality on the array sizes and the pointwise definition, then simply applies 'rfl' for the element equality.", 'retry_strategy': "Remove the superfluous 'intro a' and simplify the proof using the known properties of Array.map. Then re-run the proof to ensure it compiles and meets the specification."}
2025-06-01 03:07:53,112 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\nIf your function uses Boolean logic or `if...then...else`, always plan to:\n  - Use `by_cases` or `split_ifs` on the Boolean condition(s) in the proof.\n  - Use `simp` in each branch to reduce the goal to true ↔ true or false ↔ false.\n  - Close each goal with `trivial`, `exact`, or `exfalso` depending on context.\nDo not plan to use `case inl`/`case inr` (Lean 3-style); use `case pos`/`case neg` in Lean 4.\nNever rely on `sorry` or incomplete proofs; all goals must be discharged.\nIf the function's return type is `Bool` and the specification is a `↔` with a Prop, then include a plan to handle the `if` structure explicitly using `by_cases` or `split_ifs`.\nLean 4 requires `pos`/`neg` tags for `by_cases`. Do not mention `inl` or `inr`.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.\n\nPrevious plan:\n{\n  "plan_summary": "Define a Lean 4 function that takes an array of integers and returns a new array where each element is replaced by its cube. The implementation consists of mapping over the input array and, for each element, computing its cube (x * x * x).",\n  "steps": [\n    "Define the function with an appropriate signature, taking an array of integers as input and returning an array of integers.",\n    "Implement a helper operation to compute the cube of an integer (i.e., x * x * x).",\n    "Use the built-in array.map function to traverse the array and apply the cube operation to each element.",\n    "Return the resulting array, ensuring that the output array maintains the same length as the input."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "array",\n    "array.map",\n    "integer arithmetic",\n    "cube calculation"\n  ],\n  "proof_keywords": [\n    "inductive reasoning",\n    "base case",\n    "recursive structure",\n    "map consistency"\n  ],\n  "assumptions": [\n    "The array.map function is available and works as expected in Lean 4.",\n    "Integer multiplication is well-defined and associative, so computing x * x * x yields the correct cube.",\n    "No side conditions or preconditions are necessary for the transformation."\n  ],\n  "retry_guidance": "If there are any issues related to array mapping or type inconsistencies in Lean 4, revise the function signature or the use of array.map. Ensure that each branch of any conditional logic uses \'by_cases\' or \'split_ifs\' with \'simp\' and proper closures (trivial/exact) as needed."\n}\n\nLean error:\nThe proof fails because of an extra \'intro a\' tactic. The theorem already takes \'a\' as a parameter, so calling \'intro a\' introduces an extra (non-existent) binder. This causes the \'tactic \'introN\' failed, insufficient number of binders\' error.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 03:07:53,112 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:07:53,113 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:07:53,113 - DEBUG - send_request_headers.complete
2025-06-01 03:07:53,113 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:07:53,113 - DEBUG - send_request_body.complete
2025-06-01 03:07:53,113 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:07:58,373 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:07:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4652'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4656'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198872'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'338ms'), (b'x-request-id', b'req_871f7c0f10d0868e1b061739f21cc322'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b80d92e9c8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:07:58,374 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:07:58,374 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:07:58,374 - DEBUG - receive_response_body.complete
2025-06-01 03:07:58,374 - DEBUG - response_closed.started
2025-06-01 03:07:58,374 - DEBUG - response_closed.complete
2025-06-01 03:07:58,374 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:07:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4652', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4656', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198872', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '338ms', 'x-request-id': 'req_871f7c0f10d0868e1b061739f21cc322', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b80d92e9c8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:07:58,374 - DEBUG - request_id: req_871f7c0f10d0868e1b061739f21cc322
2025-06-01 03:07:58,375 - INFO - Attempt 2/3
2025-06-01 03:07:58,375 - INFO - Current plan: {
  "plan_summary": "Revise the Lean 4 function for cubing each element of an array by mapping a cube operation over the array, with careful attention to the proof tactics. In particular, ensure that the function parameters are not redundantly reintroduced (i.e., do not use 'intro a' when 'a' is already present).",
  "steps": [
    "Define the function with the correct signature to take an array of integers and return an array of integers.",
    "Implement a helper function (or inline computation) that computes the cube of an integer using multiplication (x * x * x).",
    "Apply the built-in array.map function to transform the input array by replacing each element with its cube.",
    "In the proof, ensure that no extra binder is introduced. If the function already takes parameter 'a', do not add 'intro a' again; confirm that all introductions or assumptions are appropriately scoped.",
    "Test the function with various input arrays (empty and non-empty) to ensure correct behavior."
  ],
  "code_keywords": [
    "Lean 4",
    "array.map",
    "integer arithmetic",
    "cube",
    "function signature"
  ],
  "proof_keywords": [
    "avoiding extra intros",
    "parameter scoping",
    "simp tactics",
    "by_cases",
    "split_ifs"
  ],
  "assumptions": [
    "The Lean 4 array.map function works as expected without needing extra introductions.",
    "Integer multiplication is associative, so computing x * x * x yields the cubic value.",
    "No other side conditions affect the transformation."
  ],
  "retry_guidance": "If a similar error occurs due to extra parameter introductions, re-check the function's parameters list and remove any unused or redundant 'intro' calls. Verify that each tactic correctly corresponds to the current proof context."
}
2025-06-01 03:07:58,375 - INFO - Updated plan: {
  "plan_summary": "Revise the Lean 4 function for cubing each element of an array by mapping a cube operation over the array, with careful attention to the proof tactics. In particular, ensure that the function parameters are not redundantly reintroduced (i.e., do not use 'intro a' when 'a' is already present).",
  "steps": [
    "Define the function with the correct signature to take an array of integers and return an array of integers.",
    "Implement a helper function (or inline computation) that computes the cube of an integer using multiplication (x * x * x).",
    "Apply the built-in array.map function to transform the input array by replacing each element with its cube.",
    "In the proof, ensure that no extra binder is introduced. If the function already takes parameter 'a', do not add 'intro a' again; confirm that all introductions or assumptions are appropriately scoped.",
    "Test the function with various input arrays (empty and non-empty) to ensure correct behavior."
  ],
  "code_keywords": [
    "Lean 4",
    "array.map",
    "integer arithmetic",
    "cube",
    "function signature"
  ],
  "proof_keywords": [
    "avoiding extra intros",
    "parameter scoping",
    "simp tactics",
    "by_cases",
    "split_ifs"
  ],
  "assumptions": [
    "The Lean 4 array.map function works as expected without needing extra introductions.",
    "Integer multiplication is associative, so computing x * x * x yields the cubic value.",
    "No other side conditions affect the transformation."
  ],
  "retry_guidance": "If a similar error occurs due to extra parameter introductions, re-check the function's parameters list and remove any unused or redundant 'intro' calls. Verify that each tactic correctly corresponds to the current proof context."
}

Lean error summary:
The proof fails because of an extra 'intro a' tactic. The theorem already takes 'a' as a parameter, so calling 'intro a' introduces an extra (non-existent) binder. This causes the 'tactic 'introN' failed, insufficient number of binders' error.
Retry guidance (MUST FOLLOW):
Remove the superfluous 'intro a' and simplify the proof using the known properties of Array.map. Then re-run the proof to ensure it compiles and meets the specification.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 03:07:58,376 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\nYou MUST:\n  - Use `split_ifs` or `by_cases` for Boolean if-expressions.\n  - In each case branch, simplify the goal using `simp`.\n  - Use `trivial`, `exact`, or `exfalso` to close simplified branches.\nYou MUST NOT:\n  - Use `case inl` / `case inr` → replace with `case pos` / `case neg`.\n  - Use `done`, `⟨..., by ...⟩`, `by assumption` in unclear contexts.\n  - Use `sorry`, or leave any goal open.\nFor Boolean-returning functions with specifications of the form:\n  `spec a b (hasOppositeSign a b) := ... ↔ ...`,\nalways:\n  - `unfold` the function and spec,\n  - `split_ifs with h` to analyze conditions,\n  - `simp` the goal under each condition,\n  - then `trivial`, `exact`, or `contradiction` to finish.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the Lean 4 function for cubing each element of an array by mapping a cube operation over the array, with careful attention to the proof tactics. In particular, ensure that the function parameters are not redundantly reintroduced (i.e., do not use \'intro a\' when \'a\' is already present).",\n  "steps": [\n    "Define the function with the correct signature to take an array of integers and return an array of integers.",\n    "Implement a helper function (or inline computation) that computes the cube of an integer using multiplication (x * x * x).",\n    "Apply the built-in array.map function to transform the input array by replacing each element with its cube.",\n    "In the proof, ensure that no extra binder is introduced. If the function already takes parameter \'a\', do not add \'intro a\' again; confirm that all introductions or assumptions are appropriately scoped.",\n    "Test the function with various input arrays (empty and non-empty) to ensure correct behavior."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "array.map",\n    "integer arithmetic",\n    "cube",\n    "function signature"\n  ],\n  "proof_keywords": [\n    "avoiding extra intros",\n    "parameter scoping",\n    "simp tactics",\n    "by_cases",\n    "split_ifs"\n  ],\n  "assumptions": [\n    "The Lean 4 array.map function works as expected without needing extra introductions.",\n    "Integer multiplication is associative, so computing x * x * x yields the cubic value.",\n    "No other side conditions affect the transformation."\n  ],\n  "retry_guidance": "If a similar error occurs due to extra parameter introductions, re-check the function\'s parameters list and remove any unused or redundant \'intro\' calls. Verify that each tactic correctly corresponds to the current proof context."\n}\n\nLean error summary:\nThe proof fails because of an extra \'intro a\' tactic. The theorem already takes \'a\' as a parameter, so calling \'intro a\' introduces an extra (non-existent) binder. This causes the \'tactic \'introN\' failed, insufficient number of binders\' error.\nRetry guidance (MUST FOLLOW):\nRemove the superfluous \'intro a\' and simplify the proof using the known properties of Array.map. Then re-run the proof to ensure it compiles and meets the specification.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  -- << SPEC START >>\n  (result.size = a.size) ∧\n  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n  -- << SPEC END >>\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  -- << PROOF START >>\n  unfold cubeElements cubeElements_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 03:07:58,377 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:07:58,377 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:07:58,377 - DEBUG - send_request_headers.complete
2025-06-01 03:07:58,378 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:07:58,382 - DEBUG - send_request_body.complete
2025-06-01 03:07:58,383 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:07:58,828 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sun, 01 Jun 2025 03:07:58 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'372'), (b'Connection', b'keep-alive'), (b'retry-after', b'9'), (b'retry-after-ms', b'8920'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'13234'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'33.531s'), (b'x-request-id', b'req_fca0e1239a62ef6fdde1d759ff0d73bc'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b80fa1f608fcd-BOM'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:07:58,829 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 03:07:58,829 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:07:58,829 - DEBUG - receive_response_body.complete
2025-06-01 03:07:58,829 - DEBUG - response_closed.started
2025-06-01 03:07:58,829 - DEBUG - response_closed.complete
2025-06-01 03:07:58,829 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sun, 01 Jun 2025 03:07:58 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '372', 'connection': 'keep-alive', 'retry-after': '9', 'retry-after-ms': '8920', 'vary': 'Origin', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '13234', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '33.531s', 'x-request-id': 'req_fca0e1239a62ef6fdde1d759ff0d73bc', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b80fa1f608fcd-BOM', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:07:58,829 - DEBUG - request_id: req_fca0e1239a62ef6fdde1d759ff0d73bc
2025-06-01 03:07:58,829 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/openai/_base_client.py", line 1007, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.12/dist-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-06-01 03:07:58,830 - DEBUG - Retrying due to status code 429
2025-06-01 03:07:58,830 - DEBUG - 2 retries left
2025-06-01 03:07:58,830 - INFO - Retrying request to /chat/completions in 8.920000 seconds
2025-06-01 03:08:07,750 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\nYou MUST:\n  - Use `split_ifs` or `by_cases` for Boolean if-expressions.\n  - In each case branch, simplify the goal using `simp`.\n  - Use `trivial`, `exact`, or `exfalso` to close simplified branches.\nYou MUST NOT:\n  - Use `case inl` / `case inr` → replace with `case pos` / `case neg`.\n  - Use `done`, `⟨..., by ...⟩`, `by assumption` in unclear contexts.\n  - Use `sorry`, or leave any goal open.\nFor Boolean-returning functions with specifications of the form:\n  `spec a b (hasOppositeSign a b) := ... ↔ ...`,\nalways:\n  - `unfold` the function and spec,\n  - `split_ifs with h` to analyze conditions,\n  - `simp` the goal under each condition,\n  - then `trivial`, `exact`, or `contradiction` to finish.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Revise the Lean 4 function for cubing each element of an array by mapping a cube operation over the array, with careful attention to the proof tactics. In particular, ensure that the function parameters are not redundantly reintroduced (i.e., do not use \'intro a\' when \'a\' is already present).",\n  "steps": [\n    "Define the function with the correct signature to take an array of integers and return an array of integers.",\n    "Implement a helper function (or inline computation) that computes the cube of an integer using multiplication (x * x * x).",\n    "Apply the built-in array.map function to transform the input array by replacing each element with its cube.",\n    "In the proof, ensure that no extra binder is introduced. If the function already takes parameter \'a\', do not add \'intro a\' again; confirm that all introductions or assumptions are appropriately scoped.",\n    "Test the function with various input arrays (empty and non-empty) to ensure correct behavior."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "array.map",\n    "integer arithmetic",\n    "cube",\n    "function signature"\n  ],\n  "proof_keywords": [\n    "avoiding extra intros",\n    "parameter scoping",\n    "simp tactics",\n    "by_cases",\n    "split_ifs"\n  ],\n  "assumptions": [\n    "The Lean 4 array.map function works as expected without needing extra introductions.",\n    "Integer multiplication is associative, so computing x * x * x yields the cubic value.",\n    "No other side conditions affect the transformation."\n  ],\n  "retry_guidance": "If a similar error occurs due to extra parameter introductions, re-check the function\'s parameters list and remove any unused or redundant \'intro\' calls. Verify that each tactic correctly corresponds to the current proof context."\n}\n\nLean error summary:\nThe proof fails because of an extra \'intro a\' tactic. The theorem already takes \'a\' as a parameter, so calling \'intro a\' introduces an extra (non-existent) binder. This causes the \'tactic \'introN\' failed, insufficient number of binders\' error.\nRetry guidance (MUST FOLLOW):\nRemove the superfluous \'intro a\' and simplify the proof using the known properties of Array.map. Then re-run the proof to ensure it compiles and meets the specification.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  -- << SPEC START >>\n  (result.size = a.size) ∧\n  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n  -- << SPEC END >>\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  -- << PROOF START >>\n  unfold cubeElements cubeElements_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 03:08:07,752 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:08:07,752 - DEBUG - close.started
2025-06-01 03:08:07,752 - DEBUG - close.complete
2025-06-01 03:08:07,753 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:08:07,760 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e67c25910>
2025-06-01 03:08:07,760 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:08:07,770 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f7d700>
2025-06-01 03:08:07,770 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:08:07,770 - DEBUG - send_request_headers.complete
2025-06-01 03:08:07,770 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:08:07,778 - DEBUG - send_request_body.complete
2025-06-01 03:08:07,778 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:08:11,489 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:08:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'3456'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'3478'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'130'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'59.738s'), (b'x-request-id', b'req_2769f936825741a625265e721d9f52dd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b8134ce7a46f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:08:11,490 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:08:11,490 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:08:11,491 - DEBUG - receive_response_body.complete
2025-06-01 03:08:11,491 - DEBUG - response_closed.started
2025-06-01 03:08:11,491 - DEBUG - response_closed.complete
2025-06-01 03:08:11,491 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:08:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '3456', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '3478', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '130', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '59.738s', 'x-request-id': 'req_2769f936825741a625265e721d9f52dd', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b8134ce7a46f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:08:11,491 - DEBUG - request_id: req_2769f936825741a625265e721d9f52dd
2025-06-01 03:08:11,491 - INFO - Raw solution received: ```json
{
  "code": "a.map (fun x => x * x * x)",
  "proof": "apply And.intro\n  \n  -- Proving the size is unchanged\n  simp [Array.size_map]\n  \n  -- Proving each element is the cube of the corresponding input element\n  intro i h\n  simp [Array.getElem_map, Array.getElem_eq_get]\n  -- Since map applies the function to each element, each result is cube\n  rfl"
}
```
2025-06-01 03:08:11,491 - INFO - <class 'str'>
2025-06-01 03:08:11,491 - INFO - Generated solution: {'code': 'a.map (fun x => x * x * x)', 'proof': 'apply And.intro\n  \n  -- Proving the size is unchanged\n  simp [Array.size_map]\n  \n  -- Proving each element is the cube of the corresponding input element\n  intro i h\n  simp [Array.getElem_map, Array.getElem_eq_get]\n  -- Since map applies the function to each element, each result is cube\n  rfl'}
2025-06-01 03:08:17,088 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:29:27: error: unknown constant 'Array.getElem_eq_get'
lean_playground/TempTest.lean:29:2: error: simp made no progress
2025-06-01 03:08:17,088 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  -- << SPEC START >>\n  (result.size = a.size) ∧\n  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n  -- << SPEC END >>\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  -- << PROOF START >>\n  unfold cubeElements cubeElements_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na.map (fun x => x * x * x)\n\nGenerated Proof:\napply And.intro\n  \n  -- Proving the size is unchanged\n  simp [Array.size_map]\n  \n  -- Proving each element is the cube of the corresponding input element\n  intro i h\n  simp [Array.getElem_map, Array.getElem_eq_get]\n  -- Since map applies the function to each element, each result is cube\n  rfl\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:29:27: error: unknown constant 'Array.getElem_eq_get'\nlean_playground/TempTest.lean:29:2: error: simp made no progress"}], 'model': 'o3-mini'}}
2025-06-01 03:08:17,089 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:08:17,089 - DEBUG - close.started
2025-06-01 03:08:17,089 - DEBUG - close.complete
2025-06-01 03:08:17,089 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:08:17,096 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fd83b0>
2025-06-01 03:08:17,096 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:08:17,105 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66fd8890>
2025-06-01 03:08:17,105 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:08:17,105 - DEBUG - send_request_headers.complete
2025-06-01 03:08:17,105 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:08:17,106 - DEBUG - send_request_body.complete
2025-06-01 03:08:17,106 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:08:21,980 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:08:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4612'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4621'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199133'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'260ms'), (b'x-request-id', b'req_87fe3184b5993e7bdaf19e988d2f73fd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b816f1d6b8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:08:21,980 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:08:21,980 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:08:21,981 - DEBUG - receive_response_body.complete
2025-06-01 03:08:21,981 - DEBUG - response_closed.started
2025-06-01 03:08:21,981 - DEBUG - response_closed.complete
2025-06-01 03:08:21,981 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:08:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4612', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4621', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199133', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '260ms', 'x-request-id': 'req_87fe3184b5993e7bdaf19e988d2f73fd', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b816f1d6b8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:08:21,981 - DEBUG - request_id: req_87fe3184b5993e7bdaf19e988d2f73fd
2025-06-01 03:08:21,981 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails because it refers to an unknown constant 'Array.getElem_eq_get'. This constant is not defined and results in a simp tactic that makes no progress.", 'error_type': 'proof', 'suggested_fix': "Remove the reference to 'Array.getElem_eq_get' from the simp invocation. You can simply use 'simp [Array.size_map, Array.getElem_map]' and then conclude with 'rfl' for the element equality. For example, update the proof to:\n\n  theorem cubeElements_spec_satisfied (a : Array Int) :\n    cubeElements_spec a (cubeElements a) := by\n    unfold cubeElements cubeElements_spec\n    apply And.intro\n    · simp [Array.size_map]\n    · intro i h\n      simp [Array.getElem_map]\n      rfl\n\nThis adjustment avoids the undefined constant and should allow the proof to complete.", 'retry_strategy': "Remove the problematic lemma from the simp list and rerun the proof. If necessary, add intermediate rewrites using 'rw Array.getElem_map' to simplify the expression before applying 'rfl'."}
2025-06-01 03:08:21,982 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\nIf your function uses Boolean logic or `if...then...else`, always plan to:\n  - Use `by_cases` or `split_ifs` on the Boolean condition(s) in the proof.\n  - Use `simp` in each branch to reduce the goal to true ↔ true or false ↔ false.\n  - Close each goal with `trivial`, `exact`, or `exfalso` depending on context.\nDo not plan to use `case inl`/`case inr` (Lean 3-style); use `case pos`/`case neg` in Lean 4.\nNever rely on `sorry` or incomplete proofs; all goals must be discharged.\nIf the function's return type is `Bool` and the specification is a `↔` with a Prop, then include a plan to handle the `if` structure explicitly using `by_cases` or `split_ifs`.\nLean 4 requires `pos`/`neg` tags for `by_cases`. Do not mention `inl` or `inr`.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.\n\nPrevious plan:\n{\n  "plan_summary": "Revise the Lean 4 function for cubing each element of an array by mapping a cube operation over the array, with careful attention to the proof tactics. In particular, ensure that the function parameters are not redundantly reintroduced (i.e., do not use \'intro a\' when \'a\' is already present).",\n  "steps": [\n    "Define the function with the correct signature to take an array of integers and return an array of integers.",\n    "Implement a helper function (or inline computation) that computes the cube of an integer using multiplication (x * x * x).",\n    "Apply the built-in array.map function to transform the input array by replacing each element with its cube.",\n    "In the proof, ensure that no extra binder is introduced. If the function already takes parameter \'a\', do not add \'intro a\' again; confirm that all introductions or assumptions are appropriately scoped.",\n    "Test the function with various input arrays (empty and non-empty) to ensure correct behavior."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "array.map",\n    "integer arithmetic",\n    "cube",\n    "function signature"\n  ],\n  "proof_keywords": [\n    "avoiding extra intros",\n    "parameter scoping",\n    "simp tactics",\n    "by_cases",\n    "split_ifs"\n  ],\n  "assumptions": [\n    "The Lean 4 array.map function works as expected without needing extra introductions.",\n    "Integer multiplication is associative, so computing x * x * x yields the cubic value.",\n    "No other side conditions affect the transformation."\n  ],\n  "retry_guidance": "If a similar error occurs due to extra parameter introductions, re-check the function\'s parameters list and remove any unused or redundant \'intro\' calls. Verify that each tactic correctly corresponds to the current proof context."\n}\n\nLean error summary:\nThe proof fails because of an extra \'intro a\' tactic. The theorem already takes \'a\' as a parameter, so calling \'intro a\' introduces an extra (non-existent) binder. This causes the \'tactic \'introN\' failed, insufficient number of binders\' error.\nRetry guidance (MUST FOLLOW):\nRemove the superfluous \'intro a\' and simplify the proof using the known properties of Array.map. Then re-run the proof to ensure it compiles and meets the specification.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThe proof fails because it refers to an unknown constant \'Array.getElem_eq_get\'. This constant is not defined and results in a simp tactic that makes no progress.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 03:08:21,986 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:08:21,986 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:08:21,986 - DEBUG - send_request_headers.complete
2025-06-01 03:08:21,986 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:08:21,986 - DEBUG - send_request_body.complete
2025-06-01 03:08:21,987 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:08:28,286 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:08:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6063'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6066'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198685'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'394ms'), (b'x-request-id', b'req_393feb9b4d1decca624bbdf06511b5f0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b818d9d6d8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:08:28,287 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:08:28,287 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:08:28,287 - DEBUG - receive_response_body.complete
2025-06-01 03:08:28,287 - DEBUG - response_closed.started
2025-06-01 03:08:28,287 - DEBUG - response_closed.complete
2025-06-01 03:08:28,287 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:08:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6063', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6066', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198685', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '394ms', 'x-request-id': 'req_393feb9b4d1decca624bbdf06511b5f0', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b818d9d6d8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:08:28,288 - DEBUG - request_id: req_393feb9b4d1decca624bbdf06511b5f0
2025-06-01 03:08:28,288 - INFO - Attempt 3/3
2025-06-01 03:08:28,288 - INFO - Current plan: {
  "plan_summary": "Refine the function that cubes each element of an array by mapping a cube operation over the array. In the proof, remove the extra introduction of parameter 'a' and avoid referencing any non-existent constants (like Array.getElem_eq_get). Instead, rely on built-in properties of Array.map and basic arithmetic manipulations to show that each element is cubed correctly.",
  "steps": [
    "Define the function with the correct signature to accept an array of integers and return an array of integers.",
    "Write a helper or inline lambda to compute the cube of an integer (using x * x * x).",
    "Apply the built-in Array.map function to transform the given array.",
    "In the accompanying proof or verification, avoid using redundant 'intro' calls since the parameters are already introduced, removing any 'intro a' extra binder.",
    "Replace the unknown constant 'Array.getElem_eq_get' with either direct unfolding of Array.map definitions or use known lemmas related to Array.map (if available) to demonstrate that the result is as expected.",
    "Confirm that the function length remains unchanged and that for every index the value in the output array corresponds to the cube of the value in the input array.",
    "Test and verify the function for both empty and non-empty arrays."
  ],
  "code_keywords": [
    "Lean 4",
    "Array.map",
    "cube",
    "integer arithmetic",
    "functional transformation"
  ],
  "proof_keywords": [
    "parameter binding",
    "simp tactics",
    "by_cases",
    "split_ifs",
    "arithmetic simp"
  ],
  "assumptions": [
    "The built-in Array.map works as expected and preserves the length and order of the array.",
    "Integer multiplication is associative and commutative, so computing x * x * x gives the correct cubic value.",
    "No extra introductions (intro a) are needed since the function's parameters are initially bound.",
    "If a lemma is needed to relate Array.get, it should be available or the proof should use a direct case distinction on the array structure."
  ],
  "retry_guidance": "If the proof fails again, double-check that no extra parameters are introduced with 'intro'. Replace any occurrences of 'Array.getElem_eq_get' with direct unfolding of Array.map or with other known results about array mapping. Use 'simp' within each branch after a 'by_cases' or 'split_ifs' to reduce expressions, and confirm that each goal is concluded properly with simple tactics like 'trivial' or 'exact'."
}
2025-06-01 03:08:28,288 - INFO - Updated plan: {
  "plan_summary": "Refine the function that cubes each element of an array by mapping a cube operation over the array. In the proof, remove the extra introduction of parameter 'a' and avoid referencing any non-existent constants (like Array.getElem_eq_get). Instead, rely on built-in properties of Array.map and basic arithmetic manipulations to show that each element is cubed correctly.",
  "steps": [
    "Define the function with the correct signature to accept an array of integers and return an array of integers.",
    "Write a helper or inline lambda to compute the cube of an integer (using x * x * x).",
    "Apply the built-in Array.map function to transform the given array.",
    "In the accompanying proof or verification, avoid using redundant 'intro' calls since the parameters are already introduced, removing any 'intro a' extra binder.",
    "Replace the unknown constant 'Array.getElem_eq_get' with either direct unfolding of Array.map definitions or use known lemmas related to Array.map (if available) to demonstrate that the result is as expected.",
    "Confirm that the function length remains unchanged and that for every index the value in the output array corresponds to the cube of the value in the input array.",
    "Test and verify the function for both empty and non-empty arrays."
  ],
  "code_keywords": [
    "Lean 4",
    "Array.map",
    "cube",
    "integer arithmetic",
    "functional transformation"
  ],
  "proof_keywords": [
    "parameter binding",
    "simp tactics",
    "by_cases",
    "split_ifs",
    "arithmetic simp"
  ],
  "assumptions": [
    "The built-in Array.map works as expected and preserves the length and order of the array.",
    "Integer multiplication is associative and commutative, so computing x * x * x gives the correct cubic value.",
    "No extra introductions (intro a) are needed since the function's parameters are initially bound.",
    "If a lemma is needed to relate Array.get, it should be available or the proof should use a direct case distinction on the array structure."
  ],
  "retry_guidance": "If the proof fails again, double-check that no extra parameters are introduced with 'intro'. Replace any occurrences of 'Array.getElem_eq_get' with direct unfolding of Array.map or with other known results about array mapping. Use 'simp' within each branch after a 'by_cases' or 'split_ifs' to reduce expressions, and confirm that each goal is concluded properly with simple tactics like 'trivial' or 'exact'."
}

Lean error summary:
The proof fails because it refers to an unknown constant 'Array.getElem_eq_get'. This constant is not defined and results in a simp tactic that makes no progress.
Retry guidance (MUST FOLLOW):
Remove the problematic lemma from the simp list and rerun the proof. If necessary, add intermediate rewrites using 'rw Array.getElem_map' to simplify the expression before applying 'rfl'.
You MUST NOT use 'sorry' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.
2025-06-01 03:08:28,289 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\nYou MUST:\n  - Use `split_ifs` or `by_cases` for Boolean if-expressions.\n  - In each case branch, simplify the goal using `simp`.\n  - Use `trivial`, `exact`, or `exfalso` to close simplified branches.\nYou MUST NOT:\n  - Use `case inl` / `case inr` → replace with `case pos` / `case neg`.\n  - Use `done`, `⟨..., by ...⟩`, `by assumption` in unclear contexts.\n  - Use `sorry`, or leave any goal open.\nFor Boolean-returning functions with specifications of the form:\n  `spec a b (hasOppositeSign a b) := ... ↔ ...`,\nalways:\n  - `unfold` the function and spec,\n  - `split_ifs with h` to analyze conditions,\n  - `simp` the goal under each condition,\n  - then `trivial`, `exact`, or `contradiction` to finish.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Refine the function that cubes each element of an array by mapping a cube operation over the array. In the proof, remove the extra introduction of parameter \'a\' and avoid referencing any non-existent constants (like Array.getElem_eq_get). Instead, rely on built-in properties of Array.map and basic arithmetic manipulations to show that each element is cubed correctly.",\n  "steps": [\n    "Define the function with the correct signature to accept an array of integers and return an array of integers.",\n    "Write a helper or inline lambda to compute the cube of an integer (using x * x * x).",\n    "Apply the built-in Array.map function to transform the given array.",\n    "In the accompanying proof or verification, avoid using redundant \'intro\' calls since the parameters are already introduced, removing any \'intro a\' extra binder.",\n    "Replace the unknown constant \'Array.getElem_eq_get\' with either direct unfolding of Array.map definitions or use known lemmas related to Array.map (if available) to demonstrate that the result is as expected.",\n    "Confirm that the function length remains unchanged and that for every index the value in the output array corresponds to the cube of the value in the input array.",\n    "Test and verify the function for both empty and non-empty arrays."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array.map",\n    "cube",\n    "integer arithmetic",\n    "functional transformation"\n  ],\n  "proof_keywords": [\n    "parameter binding",\n    "simp tactics",\n    "by_cases",\n    "split_ifs",\n    "arithmetic simp"\n  ],\n  "assumptions": [\n    "The built-in Array.map works as expected and preserves the length and order of the array.",\n    "Integer multiplication is associative and commutative, so computing x * x * x gives the correct cubic value.",\n    "No extra introductions (intro a) are needed since the function\'s parameters are initially bound.",\n    "If a lemma is needed to relate Array.get, it should be available or the proof should use a direct case distinction on the array structure."\n  ],\n  "retry_guidance": "If the proof fails again, double-check that no extra parameters are introduced with \'intro\'. Replace any occurrences of \'Array.getElem_eq_get\' with direct unfolding of Array.map or with other known results about array mapping. Use \'simp\' within each branch after a \'by_cases\' or \'split_ifs\' to reduce expressions, and confirm that each goal is concluded properly with simple tactics like \'trivial\' or \'exact\'."\n}\n\nLean error summary:\nThe proof fails because it refers to an unknown constant \'Array.getElem_eq_get\'. This constant is not defined and results in a simp tactic that makes no progress.\nRetry guidance (MUST FOLLOW):\nRemove the problematic lemma from the simp list and rerun the proof. If necessary, add intermediate rewrites using \'rw Array.getElem_map\' to simplify the expression before applying \'rfl\'.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  -- << SPEC START >>\n  (result.size = a.size) ∧\n  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n  -- << SPEC END >>\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  -- << PROOF START >>\n  unfold cubeElements cubeElements_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 03:08:28,290 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:08:28,290 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:08:28,291 - DEBUG - send_request_headers.complete
2025-06-01 03:08:28,291 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:08:28,296 - DEBUG - send_request_body.complete
2025-06-01 03:08:28,296 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:08:29,124 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sun, 01 Jun 2025 03:08:29 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'374'), (b'Connection', b'keep-alive'), (b'retry-after', b'17'), (b'retry-after-ms', b'16706'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'9504'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'40.991s'), (b'x-request-id', b'req_efb5ae874b2b91c7e57f770e405b8410'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b81b50ef38fcd-BOM'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:08:29,125 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-01 03:08:29,125 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:08:29,125 - DEBUG - receive_response_body.complete
2025-06-01 03:08:29,125 - DEBUG - response_closed.started
2025-06-01 03:08:29,125 - DEBUG - response_closed.complete
2025-06-01 03:08:29,125 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sun, 01 Jun 2025 03:08:29 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '374', 'connection': 'keep-alive', 'retry-after': '17', 'retry-after-ms': '16706', 'vary': 'Origin', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '9504', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '40.991s', 'x-request-id': 'req_efb5ae874b2b91c7e57f770e405b8410', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b81b50ef38fcd-BOM', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:08:29,125 - DEBUG - request_id: req_efb5ae874b2b91c7e57f770e405b8410
2025-06-01 03:08:29,125 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/openai/_base_client.py", line 1007, in _request
    response.raise_for_status()
  File "/usr/local/lib/python3.12/dist-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-06-01 03:08:29,126 - DEBUG - Retrying due to status code 429
2025-06-01 03:08:29,126 - DEBUG - 2 retries left
2025-06-01 03:08:29,126 - INFO - Retrying request to /chat/completions in 16.706000 seconds
2025-06-01 03:08:45,832 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\nYou MUST:\n  - Use `split_ifs` or `by_cases` for Boolean if-expressions.\n  - In each case branch, simplify the goal using `simp`.\n  - Use `trivial`, `exact`, or `exfalso` to close simplified branches.\nYou MUST NOT:\n  - Use `case inl` / `case inr` → replace with `case pos` / `case neg`.\n  - Use `done`, `⟨..., by ...⟩`, `by assumption` in unclear contexts.\n  - Use `sorry`, or leave any goal open.\nFor Boolean-returning functions with specifications of the form:\n  `spec a b (hasOppositeSign a b) := ... ↔ ...`,\nalways:\n  - `unfold` the function and spec,\n  - `split_ifs with h` to analyze conditions,\n  - `simp` the goal under each condition,\n  - then `trivial`, `exact`, or `contradiction` to finish.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Refine the function that cubes each element of an array by mapping a cube operation over the array. In the proof, remove the extra introduction of parameter \'a\' and avoid referencing any non-existent constants (like Array.getElem_eq_get). Instead, rely on built-in properties of Array.map and basic arithmetic manipulations to show that each element is cubed correctly.",\n  "steps": [\n    "Define the function with the correct signature to accept an array of integers and return an array of integers.",\n    "Write a helper or inline lambda to compute the cube of an integer (using x * x * x).",\n    "Apply the built-in Array.map function to transform the given array.",\n    "In the accompanying proof or verification, avoid using redundant \'intro\' calls since the parameters are already introduced, removing any \'intro a\' extra binder.",\n    "Replace the unknown constant \'Array.getElem_eq_get\' with either direct unfolding of Array.map definitions or use known lemmas related to Array.map (if available) to demonstrate that the result is as expected.",\n    "Confirm that the function length remains unchanged and that for every index the value in the output array corresponds to the cube of the value in the input array.",\n    "Test and verify the function for both empty and non-empty arrays."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array.map",\n    "cube",\n    "integer arithmetic",\n    "functional transformation"\n  ],\n  "proof_keywords": [\n    "parameter binding",\n    "simp tactics",\n    "by_cases",\n    "split_ifs",\n    "arithmetic simp"\n  ],\n  "assumptions": [\n    "The built-in Array.map works as expected and preserves the length and order of the array.",\n    "Integer multiplication is associative and commutative, so computing x * x * x gives the correct cubic value.",\n    "No extra introductions (intro a) are needed since the function\'s parameters are initially bound.",\n    "If a lemma is needed to relate Array.get, it should be available or the proof should use a direct case distinction on the array structure."\n  ],\n  "retry_guidance": "If the proof fails again, double-check that no extra parameters are introduced with \'intro\'. Replace any occurrences of \'Array.getElem_eq_get\' with direct unfolding of Array.map or with other known results about array mapping. Use \'simp\' within each branch after a \'by_cases\' or \'split_ifs\' to reduce expressions, and confirm that each goal is concluded properly with simple tactics like \'trivial\' or \'exact\'."\n}\n\nLean error summary:\nThe proof fails because it refers to an unknown constant \'Array.getElem_eq_get\'. This constant is not defined and results in a simp tactic that makes no progress.\nRetry guidance (MUST FOLLOW):\nRemove the problematic lemma from the simp list and rerun the proof. If necessary, add intermediate rewrites using \'rw Array.getElem_map\' to simplify the expression before applying \'rfl\'.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  -- << SPEC START >>\n  (result.size = a.size) ∧\n  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n  -- << SPEC END >>\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  -- << PROOF START >>\n  unfold cubeElements cubeElements_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 03:08:45,834 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:08:45,834 - DEBUG - close.started
2025-06-01 03:08:45,834 - DEBUG - close.complete
2025-06-01 03:08:45,834 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:08:45,842 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737f680>
2025-06-01 03:08:45,842 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:08:45,850 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e6737fd40>
2025-06-01 03:08:45,850 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:08:45,850 - DEBUG - send_request_headers.complete
2025-06-01 03:08:45,850 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:08:45,854 - DEBUG - send_request_body.complete
2025-06-01 03:08:45,855 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:08:47,970 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:08:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'1873'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1877'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'127'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'59.745s'), (b'x-request-id', b'req_0b1bdc6990432f137f30455dad13bb31'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b8222bb923bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:08:47,970 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:08:47,970 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:08:47,970 - DEBUG - receive_response_body.complete
2025-06-01 03:08:47,971 - DEBUG - response_closed.started
2025-06-01 03:08:47,971 - DEBUG - response_closed.complete
2025-06-01 03:08:47,971 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:08:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '1873', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1877', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '127', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '59.745s', 'x-request-id': 'req_0b1bdc6990432f137f30455dad13bb31', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b8222bb923bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:08:47,971 - DEBUG - request_id: req_0b1bdc6990432f137f30455dad13bb31
2025-06-01 03:08:47,971 - INFO - Raw solution received: ```json
{
  "code": "a.map (fun x => x * x * x)",
  "proof": "simp only [Array.map]; apply And.intro; simp; intro i; intros; rw [Array.getElem_map]; simp"
}
```
2025-06-01 03:08:47,971 - INFO - <class 'str'>
2025-06-01 03:08:47,971 - INFO - Generated solution: {'code': 'a.map (fun x => x * x * x)', 'proof': 'simp only [Array.map]; apply And.intro; simp; intro i; intros; rw [Array.getElem_map]; simp'}
2025-06-01 03:08:53,240 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:22:54: error: tactic 'introN' failed, insufficient number of binders
case left
a : Array ℤ
⊢ (Id.run (Array.map (fun x => x * x * x) a)).size = a.size
2025-06-01 03:08:53,241 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  -- << SPEC START >>\n  (result.size = a.size) ∧\n  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n  -- << SPEC END >>\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  -- << PROOF START >>\n  unfold cubeElements cubeElements_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na.map (fun x => x * x * x)\n\nGenerated Proof:\nsimp only [Array.map]; apply And.intro; simp; intro i; intros; rw [Array.getElem_map]; simp\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:22:54: error: tactic 'introN' failed, insufficient number of binders\ncase left\na : Array ℤ\n⊢ (Id.run (Array.map (fun x => x * x * x) a)).size = a.size"}], 'model': 'o3-mini'}}
2025-06-01 03:08:53,242 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:08:53,242 - DEBUG - close.started
2025-06-01 03:08:53,242 - DEBUG - close.complete
2025-06-01 03:08:53,242 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:08:53,251 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f80f80>
2025-06-01 03:08:53,251 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4f4f5a7c50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:08:53,259 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4e66f82990>
2025-06-01 03:08:53,259 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:08:53,260 - DEBUG - send_request_headers.complete
2025-06-01 03:08:53,260 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:08:53,260 - DEBUG - send_request_body.complete
2025-06-01 03:08:53,260 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:09:00,971 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:09:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'7486'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'7491'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199173'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_2240a90c33f018676fe33a9e8e66d713'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b82511c0f4436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:09:00,972 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:09:00,972 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:09:00,972 - DEBUG - receive_response_body.complete
2025-06-01 03:09:00,972 - DEBUG - response_closed.started
2025-06-01 03:09:00,972 - DEBUG - response_closed.complete
2025-06-01 03:09:00,972 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:09:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '7486', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '7491', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199173', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '247ms', 'x-request-id': 'req_2240a90c33f018676fe33a9e8e66d713', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b82511c0f4436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:09:00,972 - DEBUG - request_id: req_2240a90c33f018676fe33a9e8e66d713
2025-06-01 03:09:00,973 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The Lean output complains that the tactic 'introN' (triggered by the use of 'intro i; intros;') failed because there are not enough binders in the goal. In other words, the proof script makes redundant introductions causing a mismatch in the expected number of variables.", 'error_type': 'proof', 'suggested_fix': "Rewrite the proof to avoid redundant introductions. For instance, after splitting the conjunction, use 'intros i hi' to introduce the index and its hypothesis in one step, and remove the extra 'intros'. A suggested revised proof is:\n\n  theorem cubeElements_spec_satisfied (a : Array Int) :\n    cubeElements_spec a (cubeElements a) := by\n    unfold cubeElements cubeElements_spec\n    apply And.intro\n    · -- Show that sizes are equal\n      simp [Array.map]\n    · -- For each index, the element is cubed\n      intros i hi\n      simp [Array.map]\n      rw [Array.getElem_map]\n      rfl\n\nThis approach splits the goal into the two required parts and uses the appropriate introductions for the second part.", 'retry_strategy': 'Revise the proof script as suggested to correctly handle the introductions and split the goals properly. Then re-run the proof to ensure it typechecks and passes.'}
2025-06-01 03:09:00,974 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\nIf your function uses Boolean logic or `if...then...else`, always plan to:\n  - Use `by_cases` or `split_ifs` on the Boolean condition(s) in the proof.\n  - Use `simp` in each branch to reduce the goal to true ↔ true or false ↔ false.\n  - Close each goal with `trivial`, `exact`, or `exfalso` depending on context.\nDo not plan to use `case inl`/`case inr` (Lean 3-style); use `case pos`/`case neg` in Lean 4.\nNever rely on `sorry` or incomplete proofs; all goals must be discharged.\nIf the function's return type is `Bool` and the specification is a `↔` with a Prop, then include a plan to handle the `if` structure explicitly using `by_cases` or `split_ifs`.\nLean 4 requires `pos`/`neg` tags for `by_cases`. Do not mention `inl` or `inr`.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.\n\nPrevious plan:\n{\n  "plan_summary": "Refine the function that cubes each element of an array by mapping a cube operation over the array. In the proof, remove the extra introduction of parameter \'a\' and avoid referencing any non-existent constants (like Array.getElem_eq_get). Instead, rely on built-in properties of Array.map and basic arithmetic manipulations to show that each element is cubed correctly.",\n  "steps": [\n    "Define the function with the correct signature to accept an array of integers and return an array of integers.",\n    "Write a helper or inline lambda to compute the cube of an integer (using x * x * x).",\n    "Apply the built-in Array.map function to transform the given array.",\n    "In the accompanying proof or verification, avoid using redundant \'intro\' calls since the parameters are already introduced, removing any \'intro a\' extra binder.",\n    "Replace the unknown constant \'Array.getElem_eq_get\' with either direct unfolding of Array.map definitions or use known lemmas related to Array.map (if available) to demonstrate that the result is as expected.",\n    "Confirm that the function length remains unchanged and that for every index the value in the output array corresponds to the cube of the value in the input array.",\n    "Test and verify the function for both empty and non-empty arrays."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array.map",\n    "cube",\n    "integer arithmetic",\n    "functional transformation"\n  ],\n  "proof_keywords": [\n    "parameter binding",\n    "simp tactics",\n    "by_cases",\n    "split_ifs",\n    "arithmetic simp"\n  ],\n  "assumptions": [\n    "The built-in Array.map works as expected and preserves the length and order of the array.",\n    "Integer multiplication is associative and commutative, so computing x * x * x gives the correct cubic value.",\n    "No extra introductions (intro a) are needed since the function\'s parameters are initially bound.",\n    "If a lemma is needed to relate Array.get, it should be available or the proof should use a direct case distinction on the array structure."\n  ],\n  "retry_guidance": "If the proof fails again, double-check that no extra parameters are introduced with \'intro\'. Replace any occurrences of \'Array.getElem_eq_get\' with direct unfolding of Array.map or with other known results about array mapping. Use \'simp\' within each branch after a \'by_cases\' or \'split_ifs\' to reduce expressions, and confirm that each goal is concluded properly with simple tactics like \'trivial\' or \'exact\'."\n}\n\nLean error summary:\nThe proof fails because it refers to an unknown constant \'Array.getElem_eq_get\'. This constant is not defined and results in a simp tactic that makes no progress.\nRetry guidance (MUST FOLLOW):\nRemove the problematic lemma from the simp list and rerun the proof. If necessary, add intermediate rewrites using \'rw Array.getElem_map\' to simplify the expression before applying \'rfl\'.\nYou MUST NOT use \'sorry\' in code or proof. If you do, your output will be rejected. Always provide a complete implementation and proof.\n\nLean error:\nThe Lean output complains that the tactic \'introN\' (triggered by the use of \'intro i; intros;\') failed because there are not enough binders in the goal. In other words, the proof script makes redundant introductions causing a mismatch in the expected number of variables.\n\nRevise your plan to address the above Lean error.'}], 'model': 'o3-mini'}}
2025-06-01 03:09:00,974 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:09:00,974 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:09:00,974 - DEBUG - send_request_headers.complete
2025-06-01 03:09:00,975 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:09:00,975 - DEBUG - send_request_body.complete
2025-06-01 03:09:00,975 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:09:06,574 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:09:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5295'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5303'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'198336'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'499ms'), (b'x-request-id', b'req_85e0bade4f6edb8b942aafb8973b1b86'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b82814ee34436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:09:06,574 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:09:06,574 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:09:06,574 - DEBUG - receive_response_body.complete
2025-06-01 03:09:06,575 - DEBUG - response_closed.started
2025-06-01 03:09:06,575 - DEBUG - response_closed.complete
2025-06-01 03:09:06,575 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:09:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5295', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5303', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '198336', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '499ms', 'x-request-id': 'req_85e0bade4f6edb8b942aafb8973b1b86', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b82814ee34436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:09:06,575 - DEBUG - request_id: req_85e0bade4f6edb8b942aafb8973b1b86
2025-06-01 03:09:06,575 - INFO - Solution generated in 113.84 seconds
2025-06-01 03:09:06,575 - INFO - Generated code length: 26 characters
2025-06-01 03:09:06,575 - INFO - Generated proof length: 91 characters
2025-06-01 03:09:06,575 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 03:09:06,576 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 03:09:11,940 - INFO - Implementation test result: PASS
2025-06-01 03:09:11,941 - INFO - Executing Lean code with implementation and proof...
2025-06-01 03:09:17,335 - INFO - Full solution test result: FAIL
2025-06-01 03:09:17,335 - ERROR - Proof error: lean_playground/TempTest.lean:22:54: error: tactic 'introN' failed, insufficient number of binders
case left
a : Array ℤ
⊢ (Id.run (Array.map (fun x =...
2025-06-01 03:09:17,335 - INFO - ✅ Implementation passes unit tests
2025-06-01 03:09:17,335 - ERROR - ❌ Proof has errors
2025-06-01 03:09:17,335 - INFO - Testing Summary:
2025-06-01 03:09:17,335 - INFO - Task task_id_0:
2025-06-01 03:09:17,336 - INFO -   Passes Unit Tests: True
2025-06-01 03:09:17,336 - INFO -   Proof is Correct: True
2025-06-01 03:09:17,336 - INFO -   Runtime: 17.21546459197998 seconds
2025-06-01 03:09:17,336 - INFO - Testing completed.
2025-06-01 03:09:17,336 - INFO - Task task_id_58:
2025-06-01 03:09:17,336 - INFO -   Passes Unit Tests: True
2025-06-01 03:09:17,336 - INFO -   Proof is Correct: False
2025-06-01 03:09:17,336 - INFO -   Runtime: 96.88220429420471 seconds
2025-06-01 03:09:17,336 - INFO - Testing completed.
2025-06-01 03:09:17,336 - INFO - Task task_id_77:
2025-06-01 03:09:17,336 - INFO -   Passes Unit Tests: True
2025-06-01 03:09:17,336 - INFO -   Proof is Correct: False
2025-06-01 03:09:17,336 - INFO -   Runtime: 115.33524107933044 seconds
2025-06-01 03:09:17,336 - INFO - Testing completed.
2025-06-01 03:09:17,336 - INFO - Task task_id_127:
2025-06-01 03:09:17,336 - INFO -   Passes Unit Tests: True
2025-06-01 03:09:17,336 - INFO -   Proof is Correct: True
2025-06-01 03:09:17,336 - INFO -   Runtime: 15.391207218170166 seconds
2025-06-01 03:09:17,336 - INFO - Testing completed.
2025-06-01 03:09:17,337 - INFO - Task task_id_227:
2025-06-01 03:09:17,337 - INFO -   Passes Unit Tests: False
2025-06-01 03:09:17,337 - INFO -   Proof is Correct: False
2025-06-01 03:09:17,337 - INFO -   Runtime: 107.71563935279846 seconds
2025-06-01 03:09:17,337 - INFO - Testing completed.
2025-06-01 03:09:17,337 - INFO - Task task_id_404:
2025-06-01 03:09:17,337 - INFO -   Passes Unit Tests: True
2025-06-01 03:09:17,337 - INFO -   Proof is Correct: False
2025-06-01 03:09:17,337 - INFO -   Runtime: 112.10517001152039 seconds
2025-06-01 03:09:17,337 - INFO - Testing completed.
2025-06-01 03:09:17,337 - INFO - Task task_id_431:
2025-06-01 03:09:17,337 - INFO -   Passes Unit Tests: False
2025-06-01 03:09:17,337 - INFO -   Proof is Correct: False
2025-06-01 03:09:17,337 - INFO -   Runtime: 126.77114701271057 seconds
2025-06-01 03:09:17,337 - INFO - Testing completed.
2025-06-01 03:09:17,337 - INFO - Task task_id_433:
2025-06-01 03:09:17,337 - INFO -   Passes Unit Tests: True
2025-06-01 03:09:17,337 - INFO -   Proof is Correct: False
2025-06-01 03:09:17,337 - INFO -   Runtime: 110.09908986091614 seconds
2025-06-01 03:09:17,337 - INFO - Testing completed.
2025-06-01 03:09:17,337 - INFO - Task task_id_435:
2025-06-01 03:09:17,338 - INFO -   Passes Unit Tests: True
2025-06-01 03:09:17,338 - INFO -   Proof is Correct: False
2025-06-01 03:09:17,338 - INFO -   Runtime: 93.50755262374878 seconds
2025-06-01 03:09:17,338 - INFO - Testing completed.
2025-06-01 03:09:17,338 - INFO - Task task_id_441:
2025-06-01 03:09:17,338 - INFO -   Passes Unit Tests: True
2025-06-01 03:09:17,338 - INFO -   Proof is Correct: True
2025-06-01 03:09:17,338 - INFO -   Runtime: 42.74713587760925 seconds
2025-06-01 03:09:17,338 - INFO - Testing completed.
2025-06-01 03:09:17,338 - INFO - Task task_id_447:
2025-06-01 03:09:17,338 - INFO -   Passes Unit Tests: True
2025-06-01 03:09:17,338 - INFO -   Proof is Correct: False
2025-06-01 03:09:17,338 - INFO -   Runtime: 113.84248518943787 seconds
2025-06-01 03:09:17,338 - INFO - Testing completed.
2025-06-01 03:09:17,460 - DEBUG - close.started
2025-06-01 03:09:17,460 - DEBUG - close.complete
2025-06-01 03:09:17,635 - DEBUG - close.started
2025-06-01 03:09:17,636 - DEBUG - close.complete
