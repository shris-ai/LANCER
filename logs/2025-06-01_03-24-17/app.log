2025-06-01 03:24:20,906 - INFO - Starting test of 11 tasks: task_id_0, task_id_58, task_id_77, task_id_127, task_id_227, task_id_404, task_id_431, task_id_433, task_id_435, task_id_441, task_id_447
2025-06-01 03:24:20,906 - INFO - 
==================================================
2025-06-01 03:24:20,906 - INFO - Processing task task_id_0...
2025-06-01 03:24:20,906 - INFO - Reading problem description and code template from tasks/task_id_0...
2025-06-01 03:24:20,906 - INFO - Problem description length: 310 characters
2025-06-01 03:24:20,906 - INFO - Reading unit tests from tasks/task_id_0...
2025-06-01 03:24:20,906 - INFO - Unit tests length: 69 characters
2025-06-01 03:24:20,906 - INFO - Running main workflow to generate solution...
2025-06-01 03:24:20,906 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.

-----Input-----
The input consists of one natural number:
x: An natural number.

-----Output-----
The output is a natural number which the value equals to x.
2025-06-01 03:24:20,907 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def ident (x : Nat) : Nat :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


def ident_spec (x : Nat) (result: Nat) : Prop :=
  -- << SPEC START >>
  result = x
  -- << SPEC END >>

theorem ident_spec_satisfied (x : Nat) :
  ident_spec x (ident x) := by
  -- << PROOF START >>
  unfold ident ident_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 03:24:20,935 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x70adcaa02700>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 03:24:20,937 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 03:24:20,938 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:24:20,946 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x70adca60a030>
2025-06-01 03:24:20,947 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x70adcaedb1d0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:24:20,958 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x70adca609d60>
2025-06-01 03:24:20,958 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:24:20,958 - DEBUG - send_request_headers.complete
2025-06-01 03:24:20,958 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:24:20,959 - DEBUG - send_request_body.complete
2025-06-01 03:24:20,959 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:24:22,099 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:24:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'167'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5c589d798-hh5qz'), (b'x-envoy-upstream-service-time', b'169'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999923'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'4ms'), (b'x-request-id', b'req_0114d056b74120a3891ab3e2d0602540'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xdZI178nCrntzD46LerZ50UyWFRu4touBXoiZ3NnXkU-1748748262-1.0.1.1-QUNcILLP2w2B67ZGbKT0Vt6RQIO5M_csYt6sjy1ehiqzhxl3FQmcNcOtzT099zewjfJfBFNgUpc7dSZz9awYOIQCtaeh0V31A_yiN7YOKic; path=/; expires=Sun, 01-Jun-25 03:54:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=UYck9nTwP2IWrcKgc2FAZpsV_ZvSi553ompsI8AQ_.8-1748748262131-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b98f73d3685a2-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:24:22,099 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 03:24:22,099 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:24:22,100 - DEBUG - receive_response_body.complete
2025-06-01 03:24:22,100 - DEBUG - response_closed.started
2025-06-01 03:24:22,100 - DEBUG - response_closed.complete
2025-06-01 03:24:22,100 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 03:24:22 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '167'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-5c589d798-hh5qz'), ('x-envoy-upstream-service-time', '169'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999923'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '4ms'), ('x-request-id', 'req_0114d056b74120a3891ab3e2d0602540'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=xdZI178nCrntzD46LerZ50UyWFRu4touBXoiZ3NnXkU-1748748262-1.0.1.1-QUNcILLP2w2B67ZGbKT0Vt6RQIO5M_csYt6sjy1ehiqzhxl3FQmcNcOtzT099zewjfJfBFNgUpc7dSZz9awYOIQCtaeh0V31A_yiN7YOKic; path=/; expires=Sun, 01-Jun-25 03:54:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=UYck9nTwP2IWrcKgc2FAZpsV_ZvSi553ompsI8AQ_.8-1748748262131-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b98f73d3685a2-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 03:24:22,100 - DEBUG - request_id: req_0114d056b74120a3891ab3e2d0602540
2025-06-01 03:24:22,107 - INFO - Retrieved context:  modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
 Lean failed to infer it. Named arguments also improve
the readability of your code by identifying what each argument represents.

    
    
    def sum (xs : List Nat) :=
      xs.foldl (init := 0) (·+·)
    
    #eval sum [1, 2, 3, 4]
    -- 10
    
    example {a b : Nat} {p : Nat → Nat → Nat → Prop} (h₁ : p a b b) (h₂ : b = a)
        : p a a b :=
      Eq.subst (motive := fun x => p a x b) h₂ h₁
    

In the following examples, we illustrate the interaction between named and
default arguments.

    
    
    def f (x : Nat) (y : Nat := 1) (w : Nat := 2) (z : Nat) :=
      x + y + w - z
    
    example (x z : Nat) : f (z := z) x = x + 1 + 2 - z := rfl
    
    example (x z : Nat) : f x (z := z) = x + 1 + 2 - z := rfl
    
    example (x y : Nat) : f x y = fun z => x + y + 2 - z := rfl
    
    example : f = (fun x z => x + 1 + 2 - z) := rfl
    
    example (x : Nat) : f x = fun z => x + 1 + 2 - z := rfl
    
    example (y : Nat) : f (y := 5) = fun x z => x + 5 + 2 - z := rfl
    
    def g {α} [Add α] (a : α) (b? : Option α := none) (c : α) : α :=
      match b? with
      | none   => a + c
      | some b => a + b + c
    
    variable {α} [Add α]
    
    example : g = fun (a c : α) => a + c := rfl
    
    example (x : α) : g (c := x) = fun (a : α) => a + x := rfl
    
    example (x : α) : g (b? := some x) = fun (a c : α) => a + x + c := rfl
    
    example (x : α) : g x = fun (c : α) => x + c := rfl
    
    example (x y : α) : g x y = fun (c : α) => x + y + c := rfl
    

You can use `..` to provide missing explicit arguments as `_`. This feature
combined with named arguments is useful for writing patterns. Here is an
example:

    
    
    inductive Term where
      | var    (name : String)
      | num    (val : Nat)
      | app    (fn : Term) (arg : Term)
      | lambda (name : String) (type : Term) (body : Term)
    
    def getBinderName : Term → Option String
      | Term.lambda (name := n) .. => some n
      | _ => none
    
    def getBinderType : Term → Option Term
      | Term.lambda (type := t) .. => some t
      | _ => none
    

Ellipses are also useful when explicit arguments can be automatically inferred
by Lean, and we want to avoid a sequence of `_`s.

    
    
    example (f : Nat → Nat) (a b c : Nat) : f (a + b + c) = f (a + (b + c)) :=
      congrArg f (Nat.add_assoc ..)
    

[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next
chapter")

[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next
chapter")
2025-06-01 03:24:22,120 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\nIf your function uses Boolean logic or `if...then...else`, always plan to:\n  - Use `by_cases` or `split_ifs` on the Boolean condition(s) in the proof.\n  - Use `simp` in each branch to reduce the goal to true ↔ true or false ↔ false.\n  - Close each goal with `trivial`, `exact`, or `exfalso` depending on context.\nDo not plan to use `case inl`/`case inr` (Lean 3-style); use `case pos`/`case neg` in Lean 4.\nNever rely on `sorry` or incomplete proofs; all goals must be discharged.\nIf the function's return type is `Bool` and the specification is a `↔` with a Prop, then include a plan to handle the `if` structure explicitly using `by_cases` or `split_ifs`.\nLean 4 requires `pos`/`neg` tags for `by_cases`. Do not mention `inl` or `inr`.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.'}], 'model': 'o3-mini'}}
2025-06-01 03:24:22,121 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:24:22,121 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:24:22,129 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x70adcaa0c680>
2025-06-01 03:24:22,129 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x70aeb2c2fbd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:24:22,137 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x70adcaa0c260>
2025-06-01 03:24:22,137 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:24:22,138 - DEBUG - send_request_headers.complete
2025-06-01 03:24:22,138 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:24:22,138 - DEBUG - send_request_body.complete
2025-06-01 03:24:22,138 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:24:26,686 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:24:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4093'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4098'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199436'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'169ms'), (b'x-request-id', b'req_7763b95b3cc1d1f05956e44b43f4fb2c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=RFBwEU5oLSQiFASdxHauaitxdZqrHapzqBodCErcQ_E-1748748266-1.0.1.1-nOVZ6iSVMIi62w0ErNJEnH.ZDp8zzbpjfK.I7Syb2xZGo04b4pnz4.T9dKz6WSe2trQ1abc05A4FShzPBg79M6dJCBPOHwzaoKh7ABCbTk8; path=/; expires=Sun, 01-Jun-25 03:54:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=UlNRBsqgt422ZAGu2CSrWei6qZNUuKD29W8dVA9pfqQ-1748748266719-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b98fe997e46f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:24:26,687 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:24:26,687 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:24:26,687 - DEBUG - receive_response_body.complete
2025-06-01 03:24:26,687 - DEBUG - response_closed.started
2025-06-01 03:24:26,687 - DEBUG - response_closed.complete
2025-06-01 03:24:26,687 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 01 Jun 2025 03:24:26 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '4093'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '4098'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '199436'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '169ms'), ('x-request-id', 'req_7763b95b3cc1d1f05956e44b43f4fb2c'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=RFBwEU5oLSQiFASdxHauaitxdZqrHapzqBodCErcQ_E-1748748266-1.0.1.1-nOVZ6iSVMIi62w0ErNJEnH.ZDp8zzbpjfK.I7Syb2xZGo04b4pnz4.T9dKz6WSe2trQ1abc05A4FShzPBg79M6dJCBPOHwzaoKh7ABCbTk8; path=/; expires=Sun, 01-Jun-25 03:54:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=UlNRBsqgt422ZAGu2CSrWei6qZNUuKD29W8dVA9pfqQ-1748748266719-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b98fe997e46f0-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 03:24:26,687 - DEBUG - request_id: req_7763b95b3cc1d1f05956e44b43f4fb2c
2025-06-01 03:24:26,691 - INFO - Attempt 1/3
2025-06-01 03:24:26,691 - INFO - Current plan: {
  "plan_summary": "Define a simple identity function that takes a natural number and returns it unchanged.",
  "steps": [
    "Define the function with a name (e.g., identity or id_nat) having the type Nat -> Nat.",
    "Implement the function by pattern matching or directly returning the input argument.",
    "Optionally, if a proof is required for properties, use tactics like refl or trivial to establish the identity."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "identity function",
    "pattern matching"
  ],
  "proof_keywords": [
    "reflexivity",
    "trivial"
  ],
  "assumptions": [
    "Nat is defined in Lean 4 and represents natural numbers.",
    "The function is expected to be total and simply return the same value as input."
  ],
  "retry_guidance": "Since the task is straightforward, no specific retry adjustments are needed unless there is a requirement to prove properties using case analysis."
}
2025-06-01 03:24:26,692 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\nIf you encounter a Lean error in feedback, always revise the proof/code to address the specific cause, not just rephrase.\nIf a tactic fails (e.g., introN), use a more basic tactic sequence or split the goal differently.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a simple identity function that takes a natural number and returns it unchanged.",\n  "steps": [\n    "Define the function with a name (e.g., identity or id_nat) having the type Nat -> Nat.",\n    "Implement the function by pattern matching or directly returning the input argument.",\n    "Optionally, if a proof is required for properties, use tactics like refl or trivial to establish the identity."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "identity function",\n    "pattern matching"\n  ],\n  "proof_keywords": [\n    "reflexivity",\n    "trivial"\n  ],\n  "assumptions": [\n    "Nat is defined in Lean 4 and represents natural numbers.",\n    "The function is expected to be total and simply return the same value as input."\n  ],\n  "retry_guidance": "Since the task is straightforward, no specific retry adjustments are needed unless there is a requirement to prove properties using case analysis."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef ident (x : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\ndef ident_spec (x : Nat) (result: Nat) : Prop :=\n  -- << SPEC START >>\n  result = x\n  -- << SPEC END >>\n\ntheorem ident_spec_satisfied (x : Nat) :\n  ident_spec x (ident x) := by\n  -- << PROOF START >>\n  unfold ident ident_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n Lean failed to infer it. Named arguments also improve\nthe readability of your code by identifying what each argument represents.\n\n    \n    \n    def sum (xs : List Nat) :=\n      xs.foldl (init := 0) (·+·)\n    \n    #eval sum [1, 2, 3, 4]\n    -- 10\n    \n    example {a b : Nat} {p : Nat → Nat → Nat → Prop} (h₁ : p a b b) (h₂ : b = a)\n        : p a a b :=\n      Eq.subst (motive := fun x => p a x b) h₂ h₁\n    \n\nIn the following examples, we illustrate the interaction between named and\ndefault arguments.\n\n    \n    \n    def f (x : Nat) (y : Nat := 1) (w : Nat := 2) (z : Nat) :=\n      x + y + w - z\n    \n    example (x z : Nat) : f (z := z) x = x + 1 + 2 - z := rfl\n    \n    example (x z : Nat) : f x (z := z) = x + 1 + 2 - z := rfl\n    \n    example (x y : Nat) : f x y = fun z => x + y + 2 - z := rfl\n    \n    example : f = (fun x z => x + 1 + 2 - z) := rfl\n    \n    example (x : Nat) : f x = fun z => x + 1 + 2 - z := rfl\n    \n    example (y : Nat) : f (y := 5) = fun x z => x + 5 + 2 - z := rfl\n    \n    def g {α} [Add α] (a : α) (b? : Option α := none) (c : α) : α :=\n      match b? with\n      | none   => a + c\n      | some b => a + b + c\n    \n    variable {α} [Add α]\n    \n    example : g = fun (a c : α) => a + c := rfl\n    \n    example (x : α) : g (c := x) = fun (a : α) => a + x := rfl\n    \n    example (x : α) : g (b? := some x) = fun (a c : α) => a + x + c := rfl\n    \n    example (x : α) : g x = fun (c : α) => x + c := rfl\n    \n    example (x y : α) : g x y = fun (c : α) => x + y + c := rfl\n    \n\nYou can use `..` to provide missing explicit arguments as `_`. This feature\ncombined with named arguments is useful for writing patterns. Here is an\nexample:\n\n    \n    \n    inductive Term where\n      | var    (name : String)\n      | num    (val : Nat)\n      | app    (fn : Term) (arg : Term)\n      | lambda (name : String) (type : Term) (body : Term)\n    \n    def getBinderName : Term → Option String\n      | Term.lambda (name := n) .. => some n\n      | _ => none\n    \n    def getBinderType : Term → Option Term\n      | Term.lambda (type := t) .. => some t\n      | _ => none\n    \n\nEllipses are also useful when explicit arguments can be automatically inferred\nby Lean, and we want to avoid a sequence of `_`s.\n\n    \n    \n    example (f : Nat → Nat) (a b c : Nat) : f (a + b + c) = f (a + (b + c)) :=\n      congrArg f (Nat.add_assoc ..)\n    \n\n[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next\nchapter")\n\n[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next\nchapter")'}], 'model': 'gpt-4o'}}
2025-06-01 03:24:26,693 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:24:26,693 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:24:26,693 - DEBUG - send_request_headers.complete
2025-06-01 03:24:26,693 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:24:26,699 - DEBUG - send_request_body.complete
2025-06-01 03:24:26,699 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:24:29,871 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:24:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2301'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2304'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'13934'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'32.131s'), (b'x-request-id', b'req_38f8f2025f28cdd42ab31cc8bffb574d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b991b1c8d46f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:24:29,871 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:24:29,871 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:24:29,871 - DEBUG - receive_response_body.complete
2025-06-01 03:24:29,872 - DEBUG - response_closed.started
2025-06-01 03:24:29,872 - DEBUG - response_closed.complete
2025-06-01 03:24:29,872 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:24:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2301', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2304', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '13934', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '32.131s', 'x-request-id': 'req_38f8f2025f28cdd42ab31cc8bffb574d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b991b1c8d46f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:24:29,872 - DEBUG - request_id: req_38f8f2025f28cdd42ab31cc8bffb574d
2025-06-01 03:24:29,872 - INFO - Raw solution received: ```json
{
  "code": "x",
  "proof": "trivial"
}
```
2025-06-01 03:24:29,872 - INFO - <class 'str'>
2025-06-01 03:24:29,872 - INFO - Generated solution: {'code': 'x', 'proof': 'trivial'}
2025-06-01 03:24:35,007 - INFO - Lean execution result: Lean code executed successfully.
2025-06-01 03:24:35,007 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\', \'retrieval_prompt\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\nWhen Lean reports an error, always:\n  - Summarize the error in your own words.\n  - Suggest a concrete, minimal fix.\n  - If the error is about a tactic (e.g., `introN`), explain what went wrong and how to rewrite the tactic sequence.\n  - If the error is about an unknown identifier, suggest a known alternative or a simpler approach.\n  - If the error is repeated, recommend a different proof strategy.\n  - Provide a Lean documentation link if possible.\nIn addition, for any error, generate a retrieval prompt in the output field "retrieval_prompt".\nThis prompt should be a concise query or instruction that can be used to retrieve relevant documentation, examples, or code snippets to help address the specific error and suggested improvement.\nFor example, if the error is about a tactic, the retrieval prompt might be "Lean 4 tactic introN usage and alternatives".\nIf the error is about a type mismatch, the retrieval prompt might be "Lean 4 type mismatch Nat Bool common causes and fixes".\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef ident (x : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\ndef ident_spec (x : Nat) (result: Nat) : Prop :=\n  -- << SPEC START >>\n  result = x\n  -- << SPEC END >>\n\ntheorem ident_spec_satisfied (x : Nat) :\n  ident_spec x (ident x) := by\n  -- << PROOF START >>\n  unfold ident ident_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nx\n\nGenerated Proof:\ntrivial\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean code executed successfully.'}], 'model': 'o3-mini'}}
2025-06-01 03:24:35,008 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:24:35,008 - DEBUG - close.started
2025-06-01 03:24:35,008 - DEBUG - close.complete
2025-06-01 03:24:35,008 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:24:35,016 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x70adcaa0fc50>
2025-06-01 03:24:35,016 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x70aeb2c2fbd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:24:35,027 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x70adcaa0f920>
2025-06-01 03:24:35,027 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:24:35,027 - DEBUG - send_request_headers.complete
2025-06-01 03:24:35,027 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:24:35,028 - DEBUG - send_request_body.complete
2025-06-01 03:24:35,028 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:24:37,605 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:24:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2143'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2148'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199168'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'249ms'), (b'x-request-id', b'req_bfff1f9d8187aae3bce54ba68096b000'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b994f282747bc-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:24:37,606 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:24:37,606 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:24:37,606 - DEBUG - receive_response_body.complete
2025-06-01 03:24:37,606 - DEBUG - response_closed.started
2025-06-01 03:24:37,606 - DEBUG - response_closed.complete
2025-06-01 03:24:37,606 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:24:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2143', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2148', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199168', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '249ms', 'x-request-id': 'req_bfff1f9d8187aae3bce54ba68096b000', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b994f282747bc-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:24:37,606 - DEBUG - request_id: req_bfff1f9d8187aae3bce54ba68096b000
2025-06-01 03:24:37,607 - INFO - Feedback received: {'verdict': 'pass', 'error_summary': '', 'error_type': 'unknown', 'suggested_fix': 'No changes needed, the implementation and proof meet the requirements.', 'retry_strategy': '', 'retrieval_prompt': ''}
2025-06-01 03:24:37,607 - INFO - Solution generated in 16.70 seconds
2025-06-01 03:24:37,607 - INFO - Generated code length: 1 characters
2025-06-01 03:24:37,607 - INFO - Generated proof length: 7 characters
2025-06-01 03:24:37,607 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 03:24:37,607 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 03:24:42,754 - INFO - Implementation test result: PASS
2025-06-01 03:24:42,754 - INFO - Executing Lean code with implementation and proof...
2025-06-01 03:24:48,026 - INFO - Full solution test result: PASS
2025-06-01 03:24:48,026 - INFO - ✅ Implementation passes unit tests
2025-06-01 03:24:48,026 - INFO - ✅ Proof is correct
2025-06-01 03:24:48,026 - INFO - 
==================================================
2025-06-01 03:24:48,026 - INFO - Processing task task_id_58...
2025-06-01 03:24:48,026 - INFO - Reading problem description and code template from tasks/task_id_58...
2025-06-01 03:24:48,026 - INFO - Problem description length: 700 characters
2025-06-01 03:24:48,026 - INFO - Reading unit tests from tasks/task_id_58...
2025-06-01 03:24:48,026 - INFO - Unit tests length: 462 characters
2025-06-01 03:24:48,026 - INFO - Running main workflow to generate solution...
2025-06-01 03:24:48,027 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.

-----Input-----
The input consists of two integers:
a: An integer.
b: An integer.

-----Output-----
The output is a Boolean value:
Returns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).
Returns false if both integers are either non-negative or non-positive, or if one (or both) is zero.
2025-06-01 03:24:48,027 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def hasOppositeSign (a : Int) (b : Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result is true if a and b have opposite signs
def hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=
  -- << SPEC START >>
  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result
  -- << SPEC END >>

theorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :
  hasOppositeSign_spec a b (hasOppositeSign a b) := by
  -- << PROOF START >>
  unfold hasOppositeSign hasOppositeSign_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 03:24:48,057 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x70adcaa02480>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 03:24:48,057 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 03:24:48,057 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:24:48,064 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x70adcaa0ee40>
2025-06-01 03:24:48,064 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x70adcac5fd50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:24:48,072 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x70adcaa0ed80>
2025-06-01 03:24:48,072 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:24:48,072 - DEBUG - send_request_headers.complete
2025-06-01 03:24:48,072 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:24:48,072 - DEBUG - send_request_body.complete
2025-06-01 03:24:48,072 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:24:48,615 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:24:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'63'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-78998c59cd-tc49c'), (b'x-envoy-upstream-service-time', b'66'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999825'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_cc38affa007bc4bfee011491a340cc4f'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=lLU.YG4xCshJl3XKUMtEROuNjHcM6hQCvOq25OBeWIc-1748748288-1.0.1.1-tvtfX_A.B6eEOm2CyWYPTr9JEow1iE3TCYA_YOtr3BOlvYQpN3K4RF3Be4pC_Lq4oY0jvQu6QCEJnxzYUjR3Ht5H4bubvHASyDdXTcaXJNs; path=/; expires=Sun, 01-Jun-25 03:54:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Jf2oT.vBsivao5jeXM8hNGWJ4VBedaTQnNBa33RZ..Y-1748748288643-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b99a0a9123bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:24:48,615 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 03:24:48,615 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:24:48,616 - DEBUG - receive_response_body.complete
2025-06-01 03:24:48,616 - DEBUG - response_closed.started
2025-06-01 03:24:48,616 - DEBUG - response_closed.complete
2025-06-01 03:24:48,616 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 03:24:48 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '63'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-78998c59cd-tc49c'), ('x-envoy-upstream-service-time', '66'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999825'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '10ms'), ('x-request-id', 'req_cc38affa007bc4bfee011491a340cc4f'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=lLU.YG4xCshJl3XKUMtEROuNjHcM6hQCvOq25OBeWIc-1748748288-1.0.1.1-tvtfX_A.B6eEOm2CyWYPTr9JEow1iE3TCYA_YOtr3BOlvYQpN3K4RF3Be4pC_Lq4oY0jvQu6QCEJnxzYUjR3Ht5H4bubvHASyDdXTcaXJNs; path=/; expires=Sun, 01-Jun-25 03:54:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Jf2oT.vBsivao5jeXM8hNGWJ4VBedaTQnNBa33RZ..Y-1748748288643-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b99a0a9123bfe-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 03:24:48,616 - DEBUG - request_id: req_cc38affa007bc4bfee011491a340cc4f
2025-06-01 03:24:48,623 - INFO - Retrieved context:  the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
� r)`

Distributivity:

  5. `p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)`
  6. `p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)`

Other properties:

  7. `(p → (q → r)) ↔ (p ∧ q → r)`
  8. `((p ∨ q) → r) ↔ (p → r) ∧ (q → r)`
  9. `¬(p ∨ q) ↔ ¬p ∧ ¬q`
  10. `¬p ∨ ¬q → ¬(p ∧ q)`
  11. `¬(p ∧ ¬p)`
  12. `p ∧ ¬q → ¬(p → q)`
  13. `¬p → (p → q)`
  14. `(¬p ∨ q) → (p → q)`
  15. `p ∨ False ↔ p`
  16. `p ∧ False ↔ False`
  17. `¬(p ↔ ¬p)`
  18. `(p → q) → (¬q → ¬p)`

These require classical reasoning:

  19. `(p → r ∨ s) → ((p → r) ∨ (p → s))`
  20. `¬(p ∧ q) → ¬p ∨ ¬q`
  21. `¬(p → q) → p ∧ ¬q`
  22. `(p → q) → (¬p ∨ q)`
  23. `(¬q → ¬p) → (p → q)`
  24. `p ∨ ¬p`
  25. `(((p → q) → p) → p)`

The `sorry` identifier magically produces a proof of anything, or provides an
object of any data type at all. Of course, it is unsound as a proof method --
for example, you can use it to prove `False` \-- and Lean produces severe
warnings when files use or import theorems which depend on it. But it is very
useful for building long proofs incrementally. Start writing the proof from
the top down, using `sorry` to fill in subproofs. Make sure Lean accepts the
term with all the `sorry`'s; if not, there are errors that you need to
correct. Then go back and replace each `sorry` with an actual proof, until no
more remain.

Here is another useful trick. Instead of using `sorry`, you can use an
underscore `_` as a placeholder. Recall this tells Lean that the argument is
implicit, and should be filled in automatically. If Lean tries to do so and
fails, it returns with an error message "don't know how to synthesize
placeholder," followed by the type of the term it is expecting, and all the
objects and hypotheses available in the context. In other words, for each
unresolved placeholder, Lean reports the subgoal that needs to be filled at
that point. You can then construct a proof by incrementally filling in these
placeholders.

For reference, here are two sample proofs of validities taken from the list
above.

    
    
    open Classical
    
    -- distributivity
    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
      Iff.intro
        (fun h : p ∧ (q ∨ r) =>
          have hp : p := h.left
          Or.elim (h.right)
            (fun hq : q =>
              show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)
            (fun hr : r =>
              show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))
        (fun h : (p ∧ q) ∨ (p ∧ r) =>
          Or.elim h
            (fun hpq : p ∧ q =>
              have hp : p := hpq.left
              have hq : q := hpq.right
              show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)
            (fun hpr : p ∧ r =>
              have hp : p := hpr.left
              have hr : r := hpr.right
              show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))
    
    -- an example that requires classical reasoning
    example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=
      fun h : ¬(p ∧ ¬q) =>
      fun hp : p =>
      show q from
        Or.elim (em q)
          (fun hq : q => hq)
          (fun hnq : ¬q => absurd (And.intro hp hnq) h)
    

## Exercises

Prove the following identities, replacing the "sorry" placeholders with actual
proofs.

    
    
    variable (p q r : Prop)
    
    -- commutativity of ∧ and ∨
    example : p ∧ q ↔ q ∧ p := sorry
    example : p ∨ q ↔ q ∨ p := sorry
    
    -- associativity of ∧ and ∨
    example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry
    example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry
    
    -- distributivity
    example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry
    example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry
    
    -- other properties
    example : (p → (q → r)) ↔ (p ∧ q → r) := sorry
    example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry
    example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry
    example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry
    example : ¬(p ∧ ¬p) := sorry
    example : p ∧ ¬q → ¬(p → q) := sorry
    example : ¬p → (p → q) := sorry
    example : (¬p ∨ q) → (p → q) := sorry
    example : p ∨ False ↔ p := sorry
    example : p ∧ False ↔ False := sorry
    example : (p → q) → (¬q → ¬p) := sorry
    

Prove the following identities, replacing the "sorry" placeholders with actual
proofs. These require classical reasoning.

    
    
    open Classical
    
    variable (p q r : Prop)
    
    example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry
    example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry
    example : ¬(p → q) → p ∧ ¬q := sorry
    example : (p → q) → (¬p ∨ q) := sorry
    example : (¬q → ¬p) → (p → q) := sorry
    example : p ∨ ¬p := sorry
    example : (((p → q) → p) → p) := sorry
    

Prove `¬(p ↔ ¬p)` without using classical logic.

[ __](dependent_type_theory.html "Previous chapter") [
__](quantifiers_and_equality.html "Next chapter")

[ __](dependent_type_theory.html "Previous chapter") [
__](quantifiers_and_equality.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Propositions and Proofs

By now, you have seen some ways of defining objects and functions in Lean. In
this chapter, we will begin to explain how to write mathematical assertions
and proofs in the language of dependent type theory as well.

## Propositions as Types

One strategy for proving assertions about objects defined in the language of
dependent type theory is to layer an assertion language and a proof language
on top of the definition language. But there is no reason to multiply
languages in this way: dependent type theory is flexible and expressive, and
there is no reason we cannot represent assertions and proofs in the same
general framework.

For example, we could introduce a new type, `Prop`, to represent propositions,
and introduce constructors to build new propositions from others.

    
    
    def Implies (p q : Prop) : Prop := p → q
    #check And     -- Prop → Prop → Prop
    #check Or      -- Prop → Prop → Prop
    #check Not     -- Prop → Prop
    #check Implies -- Prop → Prop → Prop
    
    variable (p q r : Prop)
    #check And p q                      -- Prop
    #check Or (And p q) r               -- Prop
    #check Implies (And p q) (And q p)  -- Prop
    

We could then introduce, for each element `p : Prop`, another type `Proof p`,
for the type of proofs of `p`. An "axiom" would be a constant of such a type.

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    #check Proof   -- Proof : Prop → Type
    
    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))
    
    variable (p q : Prop)
    #check and_comm p q     -- Proof (Implies (And p q) (And q p))
    

In addition to axioms, however, we would also need rules to build new proofs
from old ones. For example, in many proof systems for propositional logic, we
have the rule of _modus ponens_ :

> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.

We could represent this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q
    

Systems of natural deduction for propositional logic also typically rely on
the following rule:

> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we
> can "cancel" the hypothesis and obtain a proof of `Implies p q`.

We could render this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)
    

This approach would provide us with a reasonable way of building assertions
and proofs. Determining that an expression `t` is a correct proof of assertion
`p` would then simply be a matter of checking that `t` has type `Proof p`.

Some simplifications are possible, however. To start with, we can avoid
writing the term `Proof` repeatedly by conflating `Proof p` with `p` itself.
In other words, whenever we have `p : Prop`, we can interpret `p` as a type,
namely, the type of its proofs. We can then read `t : p` as the assertion that
`t` is a proof of `p`.

Moreover, once we make this identification, the rules for implication show
that we can pass back and forth between `Implies p q` and `p → q`. In other
words, implication between propositions `p` and `q` corresponds to having a
function that takes any element of `p` to an element of `q`. As a result, the
introduction of the connective `Implies` is entirely redundant: we can use the
usual function space constructor `p → q` from dependent type theory as our
notion of implication.

This is the approach followed in the Calculus of Constructions, and hence in
Lean as well. The fact that the rules for implication in a proof system for
natural deduction correspond exactly to the rules governing abstraction and
application for functions is an instance of the _Curry-Howard isomorphism_ ,
sometimes known as the _propositions-as-types_ paradigm. In fact, the type
`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy
described in the last chapter. Moreover, `Type u` is also just syntactic sugar
for `Sort (u+1)`. `Prop` has some special features, but like the other type
universes, it is closed under the arrow constructor: if we have `p q : Prop`,
then `p → q : Prop`.

There are at least two ways of thinking about propositions as types. To some
who take a constructive view of logic and mathematics, this is a faithful
rendering of what it means to be a proposition: a proposition `p` represents a
sort of data type, namely, a specification of the type of data that
constitutes a proof. A proof of `p` is then simply an object `t : p` of the
right type.

Those not inclined to this ideology can view it, rather, as a simple coding
trick. To each proposition `p` we associate a type that is empty if `p` is
false and has a single element, say `*`, if `p` is true. In the latter case,
let us say that (the type associated with) `p` is _inhabited_. It just so
happens that the rules for function application and abstraction can
conveniently help us keep track of which elements of `Prop` are inhabited. So
constructing an element `t : p` tells us that `p` is indeed true. You can
think of the inhabitant of `p` as being the "fact that `p` is true." A proof
of `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is
true."

Indeed, if `p : Prop` is any proposition, Lean's kernel treats any two
elements `t1 t2 : p` as being definitionally equal, much the same way as it
treats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as
_proof irrelevance,_ and is consistent with the interpretation in the last
paragraph. It means that even though we can treat proofs `t : p` as ordinary
objects in the language of dependent type theory, they carry no information
beyond the fact that `p` is true.

The two ways we have suggested thinking about the propositions-as-types
paradigm differ in a fundamental way. From the constructive point of view,
proofs are abstract mathematical objects that are _denoted_ by suitable
expressions in dependent type theory. In contrast, if we think in terms of the
coding trick described above, then the expressions themselves do not denote
anything interesting. Rather, it is the fact that we can write them down and
check that they are well-typed that ensures that the proposition in question
is true. In other words, the expressions _themselves_ are the proofs.

In the exposition below, we will slip back and forth between these two ways of
talking, at times saying that an expression "constructs" or "produces" or
"returns" a proof of a proposition, and at other times simply saying that it
"is" such a proof. This is similar to the way that computer scientists
occasionally blur the distinction between syntax and semantics by saying, at
times, that a program "computes" a certain function, and at other times
speaking as though the program "is" the function in question.

In any case, all that really matters is the bottom line. To formally express a
mathematical assertion in the language of dependent type theory, we need to
exhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a
term `t : p`. Lean's task, as a proof assistant, is to help us to construct
such a term, `t`, and to verify that it is well-formed and has the correct
type.

## Working with Propositions as Types

In the propositions-as-types paradigm, theorems involving only `→` can be
proved using lambda abstraction and application. In Lean, the `theorem`
command introduces a new theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    

Compare this proof to the expression `fun x : α => fun y : β => x` of type `α
→ β → α`, where `α` and `β` are data types. This describes the function that
takes arguments `x` and `y` of type `α` and `β`, respectively, and returns
`x`. The proof of `t1` has the same form, the only difference being that `p`
and `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of
`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis
(trivially) to establish that the conclusion, `p`, is true.

Note that the `theorem` command is really a version of the `def` command:
under the propositions and types correspondence, proving the theorem `p → q →
p` is really the same as defining an element of the associated type. To the
kernel type checker, there is no difference between the two.

There are a few pragmatic differences between definitions and theorems,
however. In normal circumstances, it is never necessary to unfold the
"definition" of a theorem; by proof irrelevance, any two proofs of that
theorem are definitionally equal. Once the proof of a theorem is complete,
typically we only need to know that the proof exists; it doesn't matter what
the proof is. In light of that fact, Lean tags proofs as _irreducible_ , which
serves as a hint to the parser (more precisely, the _elaborator_) that there
is generally no need to unfold them when processing a file. In fact, Lean is
generally able to process and check proofs in parallel, since assessing the
correctness of one proof does not require knowing the details of another.

As with definitions, the `#print` command will show you the proof of a
theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    
    #print t1
    

Notice that the lambda abstractions `hp : p` and `hq : q` can be viewed as
temporary assumptions in the proof of `t1`. Lean also allows us to specify the
type of the final term `hp`, explicitly, with a `show` statement:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p :=
      fun hp : p =>
      fun hq : q =>
      show p from hp
    

Adding such extra information can improve the clarity of a proof and help
detect errors when writing a proof. The `show` command does nothing more than
annotate the type, and, internally, all the presentations of `t1` that we have
seen produce the same term.

As with ordinary definitions, we can move the lambda-abstracted variables to
the left of the colon:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    #print t1    -- p → q → p
    

We can use the theorem `t1` just as a function application:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    axiom hp : p
    
    theorem t2 : q → p := t1 hp
    

The `axiom` declaration postulates the existence of an element of the given
type and may compromise logical consistency. For example, we can use it to
postulate that the empty type `False` has an element:

    
    
    axiom unsound : False
    -- Everything follows from false
    theorem ex : 1 = 0 :=
      False.elim unsound
    

Declaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as
witnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`
that `p` is true yields the theorem `t1 hp : q → p`.

Recall that we can also write theorem `t1` as follows:

    
    
    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp
    
    #print t1
    

The type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the
assertion "for every pair of propositions `p q`, we have `p → q → p`." For
example, we can move all parameters to the right of the colon:

    
    
    theorem t1 : ∀ {p q : Prop}, p → q → p :=
      fun {p q : Prop} (hp : p) (hq : q) => hp
    

If `p` and `q` have been declared as variables, Lean will generalize them for
us automatically:

    
    
    variable {p q : Prop}
    
    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp
    

In fact, by the propositions-as-types correspondence, we can declare the
assumption `hp` that `p` holds, as another variable:

    
    
    variable {p q : Prop}
    variable (hp : p)
    
    theorem t1 : q → p := fun (hq : q) => hp
    

Lean detects that the proof uses `hp` and automatically adds `hp : p` as a
premise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →
q → p`. Remember that this type can just as well be written `∀ (p q : Prop)
(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type
in which the target does not depend on the bound variable.

When we generalize `t1` in such a way, we can then apply it to different pairs
of propositions, to obtain different instances of the general theorem.

    
    
    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp
    
    variable (p q r s : Prop)
    
    #check t1 p q                -- p → q → p
    #check t1 r s                -- r → s → r
    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s
    
    variable (h : r → s)
    #check t1 (r → s) (s → r) h  -- (s → r) → r → s
    

Once again, using the propositions-as-types correspondence, the variable `h`
of type `r → s` can be viewed as the hypothesis, or premise, that `r → s`
holds.

As another example, let us consider the composition function discussed in the
last chapter, now with propositions instead of types.

    
    
    variable (p q r s : Prop)
    
    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=
      fun h₃ : p =>
      show r from h₁ (h₂ h₃)
    

As a theorem of propositional logic, what does `t2` say?

Note that it is often useful to use numeric unicode subscripts, entered as
`\0`, `\1`, `\2`, ..., for hypotheses, as we did in this example.

## Propositional Logic

Lean defines all the standard logical connectives and notation. The
propositional connectives come with the following notation:

Ascii| Unicode| Editor shortcut| Definition  
---|---|---|---  
True| | | True  
False| | | False  
Not| ¬| `\not`, `\neg`| Not  
/\| ∧| `\and`| And  
\/| ∨| `\or`| Or  
->| →| `\to`, `\r`, `\imp`|   
<->| ↔| `\iff`, `\lr`| Iff  
  
They all take values in `Prop`.

    
    
    variable (p q : Prop)
    
    #check p → q → p ∧ q
    #check ¬p → p ↔ False
    #check p ∨ q → q ∨ p
    

The order of operations is as follows: unary negation `¬` binds most strongly,
then `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧
e` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right
(nothing changes now that the arguments are elements of `Prop`, instead of
some other `Type`), as do the other binary connectives. So if we have `p q r :
Prop`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This
is just the "curried" form of `p ∧ q → r`.

In the last chapter we observed that lambda abstraction can be viewed as an
"introduction rule" for `→`. In the current setting, it shows how to
"introduce" or establish an implication. Application can be viewed as an
"elimination rule," showing how to "eliminate" or use an implication in a
proof. The other propositional connectives are defined in Lean's library in
the file `Prelude.core` (see [importing
files](./interacting_with_lean.html#importing-files) for more information on
the library hierarchy), and each connective comes with its canonical
introduction and elimination rules.

### Conjunction

The expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :
p` and `h2 : q`. It is common to describe `And.intro` as the _and-
introduction_ rule. In the next example we use `And.intro` to create a proof
of `p → q → p ∧ q`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq
    
    #check fun (hp : p) (hq : q) => And.intro hp hq
    

The `example` command states a theorem without naming it or storing it in the
permanent context. Essentially, it just checks that the given term has the
indicated type. It is convenient for illustration, and we will use it often.

The expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.
Similarly, `And.right h` is a proof of `q`. They are commonly known as the
left and right _and-elimination_ rules.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : p := And.left h
    example (h : p ∧ q) : q := And.right h
    

We can now prove `p ∧ q → q ∧ p` with the following proof term.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      And.intro (And.right h) (And.left h)
    

Notice that and-introduction and and-elimination are similar to the pairing
and projection operations for the Cartesian product. The difference is that
given `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while
`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is
another instance of the Curry-Howard isomorphism, but in contrast to
implication and the function space constructor, `∧` and `×` are treated
separately in Lean. With the analogy, however, the proof we have just
constructed is similar to a function that swaps the elements of a pair.

We will see in [Chapter Structures and Records](./structures_and_records.html)
that certain types in Lean are _structures_ , which is to say, the type is
defined with a single canonical _constructor_ which builds an element of the
type from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is
an example: the canonical way to construct an element is to apply `And.intro`
to suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous
constructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the
relevant type is an inductive type and can be inferred from the context. In
particular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:

    
    
    variable (p q : Prop)
    variable (hp : p) (hq : q)
    
    #check (⟨hp, hq⟩ : p ∧ q)
    

These angle brackets are obtained by typing `\<` and `\>`, respectively.

Lean provides another useful syntactic gadget. Given an expression `e` of an
inductive type `Foo` (possibly applied to some arguments), the notation
`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of
accessing functions without opening a namespace. For example, the following
two expressions mean the same thing:

    
    
    variable (xs : List Nat)
    
    #check List.length xs
    #check xs.length
    

As a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and
`h.right` for `And.right h`. We can therefore rewrite the sample proof above
conveniently as follows:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      ⟨h.right, h.left⟩
    

There is a fine line between brevity and obfuscation, and omitting information
in this way can sometimes make a proof harder to read. But for straightforward
constructions like the one above, when the type of `h` and the goal of the
construction are salient, the notation is clean and effective.

It is common to iterate constructions like "And." Lean also allows you to
flatten nested constructors that associate to the right, so that these two
proofs are equivalent:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, ⟨h.left, h.right⟩⟩
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, h.left, h.right⟩
    

This is often useful as well.

### Disjunction

The expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof
`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a
proof `hq : q`. These are the left and right _or-introduction_ rules.

    
    
    variable (p q : Prop)
    example (hp : p) : p ∨ q := Or.intro_left q hp
    example (hq : q) : p ∨ q := Or.intro_right p hq
    

The _or-elimination_ rule is slightly more complicated. The idea is that we
can prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`
follows from `q`. In other words, it is a proof by cases. In the expression
`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :
p → r` and `hqr : q → r`, and produces a proof of `r`. In the following
example, we use `Or.elim` to prove `p ∨ q → q ∨ p`.

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h
        (fun hp : p =>
          show q ∨ p from Or.intro_right q hp)
        (fun hq : q =>
          show q ∨ p from Or.intro_left p hq)
    

In most cases, the first argument of `Or.intro_right` and `Or.intro_left` can
be inferred automatically by Lean. Lean therefore provides `Or.inr` and
`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and
`Or.intro_left _`. Thus the proof term above could be written more concisely:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Notice that there is enough information in the full expression for Lean to
infer the types of `hp` and `hq` as well. But using the type annotations in
the longer version makes the proof more readable, and can help catch and debug
errors.

Because `Or` has two constructors, we cannot use anonymous constructor
notation. But we can still write `h.elim` instead of `Or.elim h`:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Once again, you should exercise judgment as to whether such abbreviations
enhance or diminish readability.

### Negation and Falsity

Negation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by
deriving a contradiction from `p`. Similarly, the expression `hnp hp` produces
a proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both
these rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is
produced by typing `\not` or `\neg`.)

    
    
    variable (p q : Prop)
    
    example (hpq : p → q) (hnq : ¬q) : ¬p :=
      fun hp : p =>
      show False from hnq (hpq hp)
    

The connective `False` has a single elimination rule, `False.elim`, which
expresses the fact that anything follows from a contradiction. This rule is
sometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the
_principle of explosion_.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)
    

The arbitrary fact, `q`, that follows from falsity is an implicit argument in
`False.elim` and is inferred automatically. This pattern, deriving an
arbitrary fact from contradictory hypotheses, is quite common, and is
represented by `absurd`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := absurd hp hnp
    

Here, for example, is a proof of `¬p → q → (q → p) → r`:

    
    
    variable (p q r : Prop)
    
    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=
      absurd (hqp hq) hnp
    

Incidentally, just as `False` has only an elimination rule, `True` has only an
introduction rule, `True.intro : true`. In other words, `True` is simply true,
and has a canonical proof, `True.intro`.

### Logical Equivalence

The expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`
and `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from
`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔
q`. Here is a proof of `p ∧ q ↔ q ∧ p`:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      Iff.intro
        (fun h : p ∧ q =>
         show q ∧ p from And.intro (And.right h) (And.left h))
        (fun h : q ∧ p =>
         show p ∧ q from And.intro (And.right h) (And.left h))
    
    #check and_swap p q    -- p ∧ q ↔ q ∧ p
    
    variable (h : p ∧ q)
    example : q ∧ p := Iff.mp (and_swap p q) h
    

We can use the anonymous constructor notation to construct a proof of `p ↔ q`
from proofs of the forward and backward directions, and we can also use `.`
notation with `mp` and `mpr`. The previous examples can therefore be written
concisely as follows:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩
    
    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h
    

## Introducing Auxiliary Subgoals

This is a good place to introduce another device Lean offers to help structure
long proofs, namely, the `have` construct, which introduces an auxiliary
subgoal in a proof. Here is a small example, adapted from the last section:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      have hq : q := h.right
      show q ∧ p from And.intro hq hp
    

Internally, the expression `have h : p := s; t` produces the term `(fun (h :
p) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the
desired conclusion assuming `h : p`, and the two are combined by a lambda
abstraction and application. This simple device is extremely useful when it
comes to structuring long proofs, since we can use intermediate `have`'s as
stepping stones leading to the final goal.

Lean also supports a structured way of reasoning backwards from a goal, which
models the "suffices to show" construction in ordinary mathematics. The next
example simply permutes the last two lines in the previous proof.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      suffices hq : q from And.intro hq hp
      show q from And.right h
    

Writing `suffices hq : q` leaves us with two goals. First, we have to show
that it indeed suffices to show `q`, by proving the original goal of `q ∧ p`
with the additional hypothesis `hq : q`. Finally, we have to show `q`.

## Classical Logic

The introduction and elimination rules we have seen so far are all
constructive, which is to say, they reflect a computational understanding of
the logical connectives based on the propositions-as-types correspondence.
Ordinary classical logic adds to this the law of the excluded middle, `p ∨
¬p`. To use this principle, you have to open the classical namespace.

    
    
    open Classical
    
    variable (p : Prop)
    #check em p
    

Intuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts
to knowing which is the case. If `RH` represents the Riemann hypothesis, a
classical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot
yet assert either disjunct.

One consequence of the law of the excluded middle is the principle of double-
negation elimination:

    
    
    open Classical
    
    theorem dne {p : Prop} (h : ¬¬p) : p :=
      Or.elim (em p)
        (fun hp : p => hp)
        (fun hnp : ¬p => absurd hnp h)
    

Double-negation elimination allows one to prove any proposition, `p`, by
assuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In
other words, double-negation elimination allows one to carry out a proof by
contradiction, something which is not generally possible in constructive
logic. As an exercise, you might try proving the converse, that is, showing
that `em` can be proved from `dne`.

The classical axioms also give you access to additional patterns of proof that
can be justified by appeal to `em`. For example, one can carry out a proof by
cases:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byCases
        (fun h1 : p => h1)
        (fun h1 : ¬p => absurd h1 h)
    

Or you can carry out a proof by contradiction:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byContradiction
        (fun h1 : ¬p =>
         show False from h h1)
    

If you are not used to thinking constructively, it may take some time for you
to get a sense of where classical reasoning is used. It is needed in the
following example because, from a constructive standpoint, knowing that `p`
and `q` are not both true does not necessarily tell you which one is false:

    
    
    open Classical
    variable (p q : Prop)
    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=
      Or.elim (em p)
        (fun hp : p =>
          Or.inr
            (show ¬q from
              fun hq : q =>
              h ⟨hp, hq⟩))
        (fun hp : ¬p =>
          Or.inl hp)
    

We will see later that there _are_ situations in constructive logic where
principles like excluded middle and double-negation elimination are
permissible, and Lean supports the use of classical reasoning in such contexts
without relying on excluded middle.

The full list of axioms that are used in Lean to support classical reasoning
are discussed in [Axioms and Computation](./axioms_and_computation.html).

## Examples of Propositional Validities

Lean's standard library contains proofs of many valid statements of
propositional logic, all of which you are free to use in proofs of your own.
The following list includes a number of common identities.

Commutativity:

  1. `p ∧ q ↔ q ∧ p`
  2. `p ∨ q ↔ q ∨ p`

Associativity:

  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`
  4. `(p ∨ q) ∨ r ↔ p ∨ (q �
2025-06-01 03:24:48,638 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\nIf your function uses Boolean logic or `if...then...else`, always plan to:\n  - Use `by_cases` or `split_ifs` on the Boolean condition(s) in the proof.\n  - Use `simp` in each branch to reduce the goal to true ↔ true or false ↔ false.\n  - Close each goal with `trivial`, `exact`, or `exfalso` depending on context.\nDo not plan to use `case inl`/`case inr` (Lean 3-style); use `case pos`/`case neg` in Lean 4.\nNever rely on `sorry` or incomplete proofs; all goals must be discharged.\nIf the function's return type is `Bool` and the specification is a `↔` with a Prop, then include a plan to handle the `if` structure explicitly using `by_cases` or `split_ifs`.\nLean 4 requires `pos`/`neg` tags for `by_cases`. Do not mention `inl` or `inr`.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.'}], 'model': 'o3-mini'}}
2025-06-01 03:24:48,639 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:24:48,639 - DEBUG - close.started
2025-06-01 03:24:48,639 - DEBUG - close.complete
2025-06-01 03:24:48,639 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 03:24:48,646 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x70adcaa31fa0>
2025-06-01 03:24:48,646 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x70aeb2c2fbd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 03:24:48,654 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x70adcaa30500>
2025-06-01 03:24:48,654 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:24:48,654 - DEBUG - send_request_headers.complete
2025-06-01 03:24:48,654 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:24:48,654 - DEBUG - send_request_body.complete
2025-06-01 03:24:48,654 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:24:55,250 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 03:24:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6363'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6370'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199337'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'198ms'), (b'x-request-id', b'req_1c7cd7ef54298476fc4979d44eb7ea45'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b99a45e944436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 03:24:55,250 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 03:24:55,250 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 03:24:55,250 - DEBUG - receive_response_body.complete
2025-06-01 03:24:55,250 - DEBUG - response_closed.started
2025-06-01 03:24:55,250 - DEBUG - response_closed.complete
2025-06-01 03:24:55,251 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 03:24:55 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6363', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6370', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199337', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '198ms', 'x-request-id': 'req_1c7cd7ef54298476fc4979d44eb7ea45', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b99a45e944436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 03:24:55,251 - DEBUG - request_id: req_1c7cd7ef54298476fc4979d44eb7ea45
2025-06-01 03:24:55,251 - INFO - Attempt 1/3
2025-06-01 03:24:55,251 - INFO - Current plan: {
  "plan_summary": "The plan is to create a Lean 4 function that first checks whether either input integer is zero, returning false if so, and then uses an if-then-else (or by_cases) structure to determine if the integers have opposite signs. The function will branch into cases: one where a is positive and b is negative, and another where a is negative and b is positive, dispatching true only in those specific cases. Otherwise, it returns false.",
  "steps": [
    "Define the function with the correct type signature, taking two integers and returning a Bool.",
    "Check explicitly if either integer is zero. If so, return false since zero is neither positive nor negative.",
    "If neither integer is zero, use a by_cases (or split_ifs) structure on the comparison conditions: 'a > 0' and 'a < 0'.",
    "For each case, check the corresponding condition for b: if a > 0 then b must be < 0; if a < 0 then b must be > 0.",
    "Within each branch, use simp to simplify expressions and then close the branches with trivial or exact as required.",
    "Otherwise, return false when none of the conditions for opposite signs match."
  ],
  "code_keywords": [
    "if then else",
    "by_cases",
    "split_ifs",
    "zero check",
    "comparison operators"
  ],
  "proof_keywords": [
    "induction",
    "case analysis",
    "simp",
    "trivial",
    "exact",
    "logical disjunction"
  ],
  "assumptions": [
    "Zero is explicitly not positive or negative.",
    "The function strictly returns a Bool.",
    "The use of Lean 4's proof tactics like by_cases and simp is allowed and expected."
  ],
  "retry_guidance": "If errors are encountered regarding the use of case analysis or handling of the if-then-else structure, ensure that the conditions are explicitly checked using by_cases for non-zero and sign-based conditions. Revisit the ordering of conditions and simplify each branch using simp before closing the goals with trivial or exact."
}
2025-06-01 03:24:55,252 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\nIf you encounter a Lean error in feedback, always revise the proof/code to address the specific cause, not just rephrase.\nIf a tactic fails (e.g., introN), use a more basic tactic sequence or split the goal differently.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "The plan is to create a Lean 4 function that first checks whether either input integer is zero, returning false if so, and then uses an if-then-else (or by_cases) structure to determine if the integers have opposite signs. The function will branch into cases: one where a is positive and b is negative, and another where a is negative and b is positive, dispatching true only in those specific cases. Otherwise, it returns false.",\n  "steps": [\n    "Define the function with the correct type signature, taking two integers and returning a Bool.",\n    "Check explicitly if either integer is zero. If so, return false since zero is neither positive nor negative.",\n    "If neither integer is zero, use a by_cases (or split_ifs) structure on the comparison conditions: \'a > 0\' and \'a < 0\'.",\n    "For each case, check the corresponding condition for b: if a > 0 then b must be < 0; if a < 0 then b must be > 0.",\n    "Within each branch, use simp to simplify expressions and then close the branches with trivial or exact as required.",\n    "Otherwise, return false when none of the conditions for opposite signs match."\n  ],\n  "code_keywords": [\n    "if then else",\n    "by_cases",\n    "split_ifs",\n    "zero check",\n    "comparison operators"\n  ],\n  "proof_keywords": [\n    "induction",\n    "case analysis",\n    "simp",\n    "trivial",\n    "exact",\n    "logical disjunction"\n  ],\n  "assumptions": [\n    "Zero is explicitly not positive or negative.",\n    "The function strictly returns a Bool.",\n    "The use of Lean 4\'s proof tactics like by_cases and simp is allowed and expected."\n  ],\n  "retry_guidance": "If errors are encountered regarding the use of case analysis or handling of the if-then-else structure, ensure that the conditions are explicitly checked using by_cases for non-zero and sign-based conditions. Revisit the ordering of conditions and simplify each branch using simp before closing the goals with trivial or exact."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n� r)`\n\nDistributivity:\n\n  5. `p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)`\n  6. `p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)`\n\nOther properties:\n\n  7. `(p → (q → r)) ↔ (p ∧ q → r)`\n  8. `((p ∨ q) → r) ↔ (p → r) ∧ (q → r)`\n  9. `¬(p ∨ q) ↔ ¬p ∧ ¬q`\n  10. `¬p ∨ ¬q → ¬(p ∧ q)`\n  11. `¬(p ∧ ¬p)`\n  12. `p ∧ ¬q → ¬(p → q)`\n  13. `¬p → (p → q)`\n  14. `(¬p ∨ q) → (p → q)`\n  15. `p ∨ False ↔ p`\n  16. `p ∧ False ↔ False`\n  17. `¬(p ↔ ¬p)`\n  18. `(p → q) → (¬q → ¬p)`\n\nThese require classical reasoning:\n\n  19. `(p → r ∨ s) → ((p → r) ∨ (p → s))`\n  20. `¬(p ∧ q) → ¬p ∨ ¬q`\n  21. `¬(p → q) → p ∧ ¬q`\n  22. `(p → q) → (¬p ∨ q)`\n  23. `(¬q → ¬p) → (p → q)`\n  24. `p ∨ ¬p`\n  25. `(((p → q) → p) → p)`\n\nThe `sorry` identifier magically produces a proof of anything, or provides an\nobject of any data type at all. Of course, it is unsound as a proof method --\nfor example, you can use it to prove `False` \\-- and Lean produces severe\nwarnings when files use or import theorems which depend on it. But it is very\nuseful for building long proofs incrementally. Start writing the proof from\nthe top down, using `sorry` to fill in subproofs. Make sure Lean accepts the\nterm with all the `sorry`\'s; if not, there are errors that you need to\ncorrect. Then go back and replace each `sorry` with an actual proof, until no\nmore remain.\n\nHere is another useful trick. Instead of using `sorry`, you can use an\nunderscore `_` as a placeholder. Recall this tells Lean that the argument is\nimplicit, and should be filled in automatically. If Lean tries to do so and\nfails, it returns with an error message "don\'t know how to synthesize\nplaceholder," followed by the type of the term it is expecting, and all the\nobjects and hypotheses available in the context. In other words, for each\nunresolved placeholder, Lean reports the subgoal that needs to be filled at\nthat point. You can then construct a proof by incrementally filling in these\nplaceholders.\n\nFor reference, here are two sample proofs of validities taken from the list\nabove.\n\n    \n    \n    open Classical\n    \n    -- distributivity\n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=\n      Iff.intro\n        (fun h : p ∧ (q ∨ r) =>\n          have hp : p := h.left\n          Or.elim (h.right)\n            (fun hq : q =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)\n            (fun hr : r =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))\n        (fun h : (p ∧ q) ∨ (p ∧ r) =>\n          Or.elim h\n            (fun hpq : p ∧ q =>\n              have hp : p := hpq.left\n              have hq : q := hpq.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)\n            (fun hpr : p ∧ r =>\n              have hp : p := hpr.left\n              have hr : r := hpr.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))\n    \n    -- an example that requires classical reasoning\n    example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=\n      fun h : ¬(p ∧ ¬q) =>\n      fun hp : p =>\n      show q from\n        Or.elim (em q)\n          (fun hq : q => hq)\n          (fun hnq : ¬q => absurd (And.intro hp hnq) h)\n    \n\n## Exercises\n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs.\n\n    \n    \n    variable (p q r : Prop)\n    \n    -- commutativity of ∧ and ∨\n    example : p ∧ q ↔ q ∧ p := sorry\n    example : p ∨ q ↔ q ∨ p := sorry\n    \n    -- associativity of ∧ and ∨\n    example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry\n    example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry\n    \n    -- distributivity\n    example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry\n    example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry\n    \n    -- other properties\n    example : (p → (q → r)) ↔ (p ∧ q → r) := sorry\n    example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry\n    example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry\n    example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry\n    example : ¬(p ∧ ¬p) := sorry\n    example : p ∧ ¬q → ¬(p → q) := sorry\n    example : ¬p → (p → q) := sorry\n    example : (¬p ∨ q) → (p → q) := sorry\n    example : p ∨ False ↔ p := sorry\n    example : p ∧ False ↔ False := sorry\n    example : (p → q) → (¬q → ¬p) := sorry\n    \n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs. These require classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (p q r : Prop)\n    \n    example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry\n    example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry\n    example : ¬(p → q) → p ∧ ¬q := sorry\n    example : (p → q) → (¬p ∨ q) := sorry\n    example : (¬q → ¬p) → (p → q) := sorry\n    example : p ∨ ¬p := sorry\n    example : (((p → q) → p) → p) := sorry\n    \n\nProve `¬(p ↔ ¬p)` without using classical logic.\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Propositions and Proofs\n\nBy now, you have seen some ways of defining objects and functions in Lean. In\nthis chapter, we will begin to explain how to write mathematical assertions\nand proofs in the language of dependent type theory as well.\n\n## Propositions as Types\n\nOne strategy for proving assertions about objects defined in the language of\ndependent type theory is to layer an assertion language and a proof language\non top of the definition language. But there is no reason to multiply\nlanguages in this way: dependent type theory is flexible and expressive, and\nthere is no reason we cannot represent assertions and proofs in the same\ngeneral framework.\n\nFor example, we could introduce a new type, `Prop`, to represent propositions,\nand introduce constructors to build new propositions from others.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    #check And     -- Prop → Prop → Prop\n    #check Or      -- Prop → Prop → Prop\n    #check Not     -- Prop → Prop\n    #check Implies -- Prop → Prop → Prop\n    \n    variable (p q r : Prop)\n    #check And p q                      -- Prop\n    #check Or (And p q) r               -- Prop\n    #check Implies (And p q) (And q p)  -- Prop\n    \n\nWe could then introduce, for each element `p : Prop`, another type `Proof p`,\nfor the type of proofs of `p`. An "axiom" would be a constant of such a type.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    #check Proof   -- Proof : Prop → Type\n    \n    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))\n    \n    variable (p q : Prop)\n    #check and_comm p q     -- Proof (Implies (And p q) (And q p))\n    \n\nIn addition to axioms, however, we would also need rules to build new proofs\nfrom old ones. For example, in many proof systems for propositional logic, we\nhave the rule of _modus ponens_ :\n\n> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.\n\nWe could represent this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q\n    \n\nSystems of natural deduction for propositional logic also typically rely on\nthe following rule:\n\n> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we\n> can "cancel" the hypothesis and obtain a proof of `Implies p q`.\n\nWe could render this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)\n    \n\nThis approach would provide us with a reasonable way of building assertions\nand proofs. Determining that an expression `t` is a correct proof of assertion\n`p` would then simply be a matter of checking that `t` has type `Proof p`.\n\nSome simplifications are possible, however. To start with, we can avoid\nwriting the term `Proof` repeatedly by conflating `Proof p` with `p` itself.\nIn other words, whenever we have `p : Prop`, we can interpret `p` as a type,\nnamely, the type of its proofs. We can then read `t : p` as the assertion that\n`t` is a proof of `p`.\n\nMoreover, once we make this identification, the rules for implication show\nthat we can pass back and forth between `Implies p q` and `p → q`. In other\nwords, implication between propositions `p` and `q` corresponds to having a\nfunction that takes any element of `p` to an element of `q`. As a result, the\nintroduction of the connective `Implies` is entirely redundant: we can use the\nusual function space constructor `p → q` from dependent type theory as our\nnotion of implication.\n\nThis is the approach followed in the Calculus of Constructions, and hence in\nLean as well. The fact that the rules for implication in a proof system for\nnatural deduction correspond exactly to the rules governing abstraction and\napplication for functions is an instance of the _Curry-Howard isomorphism_ ,\nsometimes known as the _propositions-as-types_ paradigm. In fact, the type\n`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy\ndescribed in the last chapter. Moreover, `Type u` is also just syntactic sugar\nfor `Sort (u+1)`. `Prop` has some special features, but like the other type\nuniverses, it is closed under the arrow constructor: if we have `p q : Prop`,\nthen `p → q : Prop`.\n\nThere are at least two ways of thinking about propositions as types. To some\nwho take a constructive view of logic and mathematics, this is a faithful\nrendering of what it means to be a proposition: a proposition `p` represents a\nsort of data type, namely, a specification of the type of data that\nconstitutes a proof. A proof of `p` is then simply an object `t : p` of the\nright type.\n\nThose not inclined to this ideology can view it, rather, as a simple coding\ntrick. To each proposition `p` we associate a type that is empty if `p` is\nfalse and has a single element, say `*`, if `p` is true. In the latter case,\nlet us say that (the type associated with) `p` is _inhabited_. It just so\nhappens that the rules for function application and abstraction can\nconveniently help us keep track of which elements of `Prop` are inhabited. So\nconstructing an element `t : p` tells us that `p` is indeed true. You can\nthink of the inhabitant of `p` as being the "fact that `p` is true." A proof\nof `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is\ntrue."\n\nIndeed, if `p : Prop` is any proposition, Lean\'s kernel treats any two\nelements `t1 t2 : p` as being definitionally equal, much the same way as it\ntreats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as\n_proof irrelevance,_ and is consistent with the interpretation in the last\nparagraph. It means that even though we can treat proofs `t : p` as ordinary\nobjects in the language of dependent type theory, they carry no information\nbeyond the fact that `p` is true.\n\nThe two ways we have suggested thinking about the propositions-as-types\nparadigm differ in a fundamental way. From the constructive point of view,\nproofs are abstract mathematical objects that are _denoted_ by suitable\nexpressions in dependent type theory. In contrast, if we think in terms of the\ncoding trick described above, then the expressions themselves do not denote\nanything interesting. Rather, it is the fact that we can write them down and\ncheck that they are well-typed that ensures that the proposition in question\nis true. In other words, the expressions _themselves_ are the proofs.\n\nIn the exposition below, we will slip back and forth between these two ways of\ntalking, at times saying that an expression "constructs" or "produces" or\n"returns" a proof of a proposition, and at other times simply saying that it\n"is" such a proof. This is similar to the way that computer scientists\noccasionally blur the distinction between syntax and semantics by saying, at\ntimes, that a program "computes" a certain function, and at other times\nspeaking as though the program "is" the function in question.\n\nIn any case, all that really matters is the bottom line. To formally express a\nmathematical assertion in the language of dependent type theory, we need to\nexhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a\nterm `t : p`. Lean\'s task, as a proof assistant, is to help us to construct\nsuch a term, `t`, and to verify that it is well-formed and has the correct\ntype.\n\n## Working with Propositions as Types\n\nIn the propositions-as-types paradigm, theorems involving only `→` can be\nproved using lambda abstraction and application. In Lean, the `theorem`\ncommand introduces a new theorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    \n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n\nCompare this proof to the expression `fun x : α => fun y : β => x` of type `α\n→ β → α`, where `α` and `β` are data types. This describes the function that\ntakes arguments `x` and `y` of type `α` and `β`, respectively, and returns\n`x`. The proof of `t1` has the same form, the only difference being that `p`\nand `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of\n`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis\n(trivially) to establish that the conclusion, `p`, is true.\n\nNote that the `theorem` command is really a version of the `def` command:\nunder the propositions and types correspondence, proving the theorem `p → q →\np` is really the same as defining an element of the associated type. To the\nkernel type checker, there is no difference between the two.\n\nThere are a few pragmatic differences between definitions and theorems,\nhowever. In normal circumstances, it is never necessary to unfold the\n"definition" of a theorem; by proof irrelevance, any two proofs of that\ntheorem are definitionally equal. Once the proof of a theorem is complete,\ntypically we only need to know that the proof exists; it doesn\'t matter what\nthe proof is. In light of that fact, Lean tags proofs as _irreducible_ , which\nserves as a hint to the parser (more precisely, the _elaborator_) that there\nis generally no need to unfold them when processing a file. In fact, Lean is\ngenerally able to process and check proofs in parallel, since assessing the\ncorrectness of one proof does not require knowing the details of another.\n\nAs with definitions, the `#print` command will show you the proof of a\ntheorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n    #print t1\n    \n\nNotice that the lambda abstractions `hp : p` and `hq : q` can be viewed as\ntemporary assumptions in the proof of `t1`. Lean also allows us to specify the\ntype of the final term `hp`, explicitly, with a `show` statement:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p :=\n      fun hp : p =>\n      fun hq : q =>\n      show p from hp\n    \n\nAdding such extra information can improve the clarity of a proof and help\ndetect errors when writing a proof. The `show` command does nothing more than\nannotate the type, and, internally, all the presentations of `t1` that we have\nseen produce the same term.\n\nAs with ordinary definitions, we can move the lambda-abstracted variables to\nthe left of the colon:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    #print t1    -- p → q → p\n    \n\nWe can use the theorem `t1` just as a function application:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    axiom hp : p\n    \n    theorem t2 : q → p := t1 hp\n    \n\nThe `axiom` declaration postulates the existence of an element of the given\ntype and may compromise logical consistency. For example, we can use it to\npostulate that the empty type `False` has an element:\n\n    \n    \n    axiom unsound : False\n    -- Everything follows from false\n    theorem ex : 1 = 0 :=\n      False.elim unsound\n    \n\nDeclaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as\nwitnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`\nthat `p` is true yields the theorem `t1 hp : q → p`.\n\nRecall that we can also write theorem `t1` as follows:\n\n    \n    \n    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp\n    \n    #print t1\n    \n\nThe type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the\nassertion "for every pair of propositions `p q`, we have `p → q → p`." For\nexample, we can move all parameters to the right of the colon:\n\n    \n    \n    theorem t1 : ∀ {p q : Prop}, p → q → p :=\n      fun {p q : Prop} (hp : p) (hq : q) => hp\n    \n\nIf `p` and `q` have been declared as variables, Lean will generalize them for\nus automatically:\n\n    \n    \n    variable {p q : Prop}\n    \n    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp\n    \n\nIn fact, by the propositions-as-types correspondence, we can declare the\nassumption `hp` that `p` holds, as another variable:\n\n    \n    \n    variable {p q : Prop}\n    variable (hp : p)\n    \n    theorem t1 : q → p := fun (hq : q) => hp\n    \n\nLean detects that the proof uses `hp` and automatically adds `hp : p` as a\npremise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →\nq → p`. Remember that this type can just as well be written `∀ (p q : Prop)\n(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type\nin which the target does not depend on the bound variable.\n\nWhen we generalize `t1` in such a way, we can then apply it to different pairs\nof propositions, to obtain different instances of the general theorem.\n\n    \n    \n    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp\n    \n    variable (p q r s : Prop)\n    \n    #check t1 p q                -- p → q → p\n    #check t1 r s                -- r → s → r\n    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s\n    \n    variable (h : r → s)\n    #check t1 (r → s) (s → r) h  -- (s → r) → r → s\n    \n\nOnce again, using the propositions-as-types correspondence, the variable `h`\nof type `r → s` can be viewed as the hypothesis, or premise, that `r → s`\nholds.\n\nAs another example, let us consider the composition function discussed in the\nlast chapter, now with propositions instead of types.\n\n    \n    \n    variable (p q r s : Prop)\n    \n    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=\n      fun h₃ : p =>\n      show r from h₁ (h₂ h₃)\n    \n\nAs a theorem of propositional logic, what does `t2` say?\n\nNote that it is often useful to use numeric unicode subscripts, entered as\n`\\0`, `\\1`, `\\2`, ..., for hypotheses, as we did in this example.\n\n## Propositional Logic\n\nLean defines all the standard logical connectives and notation. The\npropositional connectives come with the following notation:\n\nAscii| Unicode| Editor shortcut| Definition  \n---|---|---|---  \nTrue| | | True  \nFalse| | | False  \nNot| ¬| `\\not`, `\\neg`| Not  \n/\\| ∧| `\\and`| And  \n\\/| ∨| `\\or`| Or  \n->| →| `\\to`, `\\r`, `\\imp`|   \n<->| ↔| `\\iff`, `\\lr`| Iff  \n  \nThey all take values in `Prop`.\n\n    \n    \n    variable (p q : Prop)\n    \n    #check p → q → p ∧ q\n    #check ¬p → p ↔ False\n    #check p ∨ q → q ∨ p\n    \n\nThe order of operations is as follows: unary negation `¬` binds most strongly,\nthen `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧\ne` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right\n(nothing changes now that the arguments are elements of `Prop`, instead of\nsome other `Type`), as do the other binary connectives. So if we have `p q r :\nProp`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This\nis just the "curried" form of `p ∧ q → r`.\n\nIn the last chapter we observed that lambda abstraction can be viewed as an\n"introduction rule" for `→`. In the current setting, it shows how to\n"introduce" or establish an implication. Application can be viewed as an\n"elimination rule," showing how to "eliminate" or use an implication in a\nproof. The other propositional connectives are defined in Lean\'s library in\nthe file `Prelude.core` (see [importing\nfiles](./interacting_with_lean.html#importing-files) for more information on\nthe library hierarchy), and each connective comes with its canonical\nintroduction and elimination rules.\n\n### Conjunction\n\nThe expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :\np` and `h2 : q`. It is common to describe `And.intro` as the _and-\nintroduction_ rule. In the next example we use `And.intro` to create a proof\nof `p → q → p ∧ q`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq\n    \n    #check fun (hp : p) (hq : q) => And.intro hp hq\n    \n\nThe `example` command states a theorem without naming it or storing it in the\npermanent context. Essentially, it just checks that the given term has the\nindicated type. It is convenient for illustration, and we will use it often.\n\nThe expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.\nSimilarly, `And.right h` is a proof of `q`. They are commonly known as the\nleft and right _and-elimination_ rules.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : p := And.left h\n    example (h : p ∧ q) : q := And.right h\n    \n\nWe can now prove `p ∧ q → q ∧ p` with the following proof term.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      And.intro (And.right h) (And.left h)\n    \n\nNotice that and-introduction and and-elimination are similar to the pairing\nand projection operations for the Cartesian product. The difference is that\ngiven `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while\n`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is\nanother instance of the Curry-Howard isomorphism, but in contrast to\nimplication and the function space constructor, `∧` and `×` are treated\nseparately in Lean. With the analogy, however, the proof we have just\nconstructed is similar to a function that swaps the elements of a pair.\n\nWe will see in [Chapter Structures and Records](./structures_and_records.html)\nthat certain types in Lean are _structures_ , which is to say, the type is\ndefined with a single canonical _constructor_ which builds an element of the\ntype from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is\nan example: the canonical way to construct an element is to apply `And.intro`\nto suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous\nconstructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the\nrelevant type is an inductive type and can be inferred from the context. In\nparticular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:\n\n    \n    \n    variable (p q : Prop)\n    variable (hp : p) (hq : q)\n    \n    #check (⟨hp, hq⟩ : p ∧ q)\n    \n\nThese angle brackets are obtained by typing `\\<` and `\\>`, respectively.\n\nLean provides another useful syntactic gadget. Given an expression `e` of an\ninductive type `Foo` (possibly applied to some arguments), the notation\n`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of\naccessing functions without opening a namespace. For example, the following\ntwo expressions mean the same thing:\n\n    \n    \n    variable (xs : List Nat)\n    \n    #check List.length xs\n    #check xs.length\n    \n\nAs a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and\n`h.right` for `And.right h`. We can therefore rewrite the sample proof above\nconveniently as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      ⟨h.right, h.left⟩\n    \n\nThere is a fine line between brevity and obfuscation, and omitting information\nin this way can sometimes make a proof harder to read. But for straightforward\nconstructions like the one above, when the type of `h` and the goal of the\nconstruction are salient, the notation is clean and effective.\n\nIt is common to iterate constructions like "And." Lean also allows you to\nflatten nested constructors that associate to the right, so that these two\nproofs are equivalent:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, ⟨h.left, h.right⟩⟩\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, h.left, h.right⟩\n    \n\nThis is often useful as well.\n\n### Disjunction\n\nThe expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof\n`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a\nproof `hq : q`. These are the left and right _or-introduction_ rules.\n\n    \n    \n    variable (p q : Prop)\n    example (hp : p) : p ∨ q := Or.intro_left q hp\n    example (hq : q) : p ∨ q := Or.intro_right p hq\n    \n\nThe _or-elimination_ rule is slightly more complicated. The idea is that we\ncan prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`\nfollows from `q`. In other words, it is a proof by cases. In the expression\n`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :\np → r` and `hqr : q → r`, and produces a proof of `r`. In the following\nexample, we use `Or.elim` to prove `p ∨ q → q ∨ p`.\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h\n        (fun hp : p =>\n          show q ∨ p from Or.intro_right q hp)\n        (fun hq : q =>\n          show q ∨ p from Or.intro_left p hq)\n    \n\nIn most cases, the first argument of `Or.intro_right` and `Or.intro_left` can\nbe inferred automatically by Lean. Lean therefore provides `Or.inr` and\n`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and\n`Or.intro_left _`. Thus the proof term above could be written more concisely:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nNotice that there is enough information in the full expression for Lean to\ninfer the types of `hp` and `hq` as well. But using the type annotations in\nthe longer version makes the proof more readable, and can help catch and debug\nerrors.\n\nBecause `Or` has two constructors, we cannot use anonymous constructor\nnotation. But we can still write `h.elim` instead of `Or.elim h`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nOnce again, you should exercise judgment as to whether such abbreviations\nenhance or diminish readability.\n\n### Negation and Falsity\n\nNegation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by\nderiving a contradiction from `p`. Similarly, the expression `hnp hp` produces\na proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both\nthese rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is\nproduced by typing `\\not` or `\\neg`.)\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hpq : p → q) (hnq : ¬q) : ¬p :=\n      fun hp : p =>\n      show False from hnq (hpq hp)\n    \n\nThe connective `False` has a single elimination rule, `False.elim`, which\nexpresses the fact that anything follows from a contradiction. This rule is\nsometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the\n_principle of explosion_.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)\n    \n\nThe arbitrary fact, `q`, that follows from falsity is an implicit argument in\n`False.elim` and is inferred automatically. This pattern, deriving an\narbitrary fact from contradictory hypotheses, is quite common, and is\nrepresented by `absurd`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := absurd hp hnp\n    \n\nHere, for example, is a proof of `¬p → q → (q → p) → r`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=\n      absurd (hqp hq) hnp\n    \n\nIncidentally, just as `False` has only an elimination rule, `True` has only an\nintroduction rule, `True.intro : true`. In other words, `True` is simply true,\nand has a canonical proof, `True.intro`.\n\n### Logical Equivalence\n\nThe expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`\nand `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from\n`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔\nq`. Here is a proof of `p ∧ q ↔ q ∧ p`:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      Iff.intro\n        (fun h : p ∧ q =>\n         show q ∧ p from And.intro (And.right h) (And.left h))\n        (fun h : q ∧ p =>\n         show p ∧ q from And.intro (And.right h) (And.left h))\n    \n    #check and_swap p q    -- p ∧ q ↔ q ∧ p\n    \n    variable (h : p ∧ q)\n    example : q ∧ p := Iff.mp (and_swap p q) h\n    \n\nWe can use the anonymous constructor notation to construct a proof of `p ↔ q`\nfrom proofs of the forward and backward directions, and we can also use `.`\nnotation with `mp` and `mpr`. The previous examples can therefore be written\nconcisely as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩\n    \n    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h\n    \n\n## Introducing Auxiliary Subgoals\n\nThis is a good place to introduce another device Lean offers to help structure\nlong proofs, namely, the `have` construct, which introduces an auxiliary\nsubgoal in a proof. Here is a small example, adapted from the last section:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      have hq : q := h.right\n      show q ∧ p from And.intro hq hp\n    \n\nInternally, the expression `have h : p := s; t` produces the term `(fun (h :\np) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the\ndesired conclusion assuming `h : p`, and the two are combined by a lambda\nabstraction and application. This simple device is extremely useful when it\ncomes to structuring long proofs, since we can use intermediate `have`\'s as\nstepping stones leading to the final goal.\n\nLean also supports a structured way of reasoning backwards from a goal, which\nmodels the "suffices to show" construction in ordinary mathematics. The next\nexample simply permutes the last two lines in the previous proof.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      suffices hq : q from And.intro hq hp\n      show q from And.right h\n    \n\nWriting `suffices hq : q` leaves us with two goals. First, we have to show\nthat it indeed suffices to show `q`, by proving the original goal of `q ∧ p`\nwith the additional hypothesis `hq : q`. Finally, we have to show `q`.\n\n## Classical Logic\n\nThe introduction and elimination rules we have seen so far are all\nconstructive, which is to say, they reflect a computational understanding of\nthe logical connectives based on the propositions-as-types correspondence.\nOrdinary classical logic adds to this the law of the excluded middle, `p ∨\n¬p`. To use this principle, you have to open the classical namespace.\n\n    \n    \n    open Classical\n    \n    variable (p : Prop)\n    #check em p\n    \n\nIntuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts\nto knowing which is the case. If `RH` represents the Riemann hypothesis, a\nclassical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot\nyet assert either disjunct.\n\nOne consequence of the law of the excluded middle is the principle of double-\nnegation elimination:\n\n    \n    \n    open Classical\n    \n    theorem dne {p : Prop} (h : ¬¬p) : p :=\n      Or.elim (em p)\n        (fun hp : p => hp)\n        (fun hnp : ¬p => absurd hnp h)\n    \n\nDouble-negation elimination allows one to prove any proposition, `p`, by\nassuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In\nother words, double-negation elimination allows one to carry out a proof by\ncontradiction, something which is not generally possible in constructive\nlogic. As an exercise, you might try proving the converse, that is, showing\nthat `em` can be proved from `dne`.\n\nThe classical axioms also give you access to additional patterns of proof that\ncan be justified by appeal to `em`. For example, one can carry out a proof by\ncases:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byCases\n        (fun h1 : p => h1)\n        (fun h1 : ¬p => absurd h1 h)\n    \n\nOr you can carry out a proof by contradiction:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byContradiction\n        (fun h1 : ¬p =>\n         show False from h h1)\n    \n\nIf you are not used to thinking constructively, it may take some time for you\nto get a sense of where classical reasoning is used. It is needed in the\nfollowing example because, from a constructive standpoint, knowing that `p`\nand `q` are not both true does not necessarily tell you which one is false:\n\n    \n    \n    open Classical\n    variable (p q : Prop)\n    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=\n      Or.elim (em p)\n        (fun hp : p =>\n          Or.inr\n            (show ¬q from\n              fun hq : q =>\n              h ⟨hp, hq⟩))\n        (fun hp : ¬p =>\n          Or.inl hp)\n    \n\nWe will see later that there _are_ situations in constructive logic where\nprinciples like excluded middle and double-negation elimination are\npermissible, and Lean supports the use of classical reasoning in such contexts\nwithout relying on excluded middle.\n\nThe full list of axioms that are used in Lean to support classical reasoning\nare discussed in [Axioms and Computation](./axioms_and_computation.html).\n\n## Examples of Propositional Validities\n\nLean\'s standard library contains proofs of many valid statements of\npropositional logic, all of which you are free to use in proofs of your own.\nThe following list includes a number of common identities.\n\nCommutativity:\n\n  1. `p ∧ q ↔ q ∧ p`\n  2. `p ∨ q ↔ q ∨ p`\n\nAssociativity:\n\n  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`\n  4. `(p ∨ q) ∨ r ↔ p ∨ (q �'}], 'model': 'gpt-4o'}}
2025-06-01 03:24:55,253 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 03:24:55,253 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 03:24:55,253 - DEBUG - send_request_headers.complete
2025-06-01 03:24:55,253 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 03:24:55,258 - DEBUG - send_request_body.complete
2025-06-01 03:24:55,258 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 03:24:57,269 - DEBUG - receive_response_headers.failed exception=KeyboardInterrupt()
2025-06-01 03:24:57,269 - DEBUG - response_closed.started
2025-06-01 03:24:57,269 - DEBUG - response_closed.complete
2025-06-01 03:24:57,416 - DEBUG - close.started
2025-06-01 03:24:57,417 - DEBUG - close.complete
2025-06-01 03:24:57,417 - DEBUG - close.started
2025-06-01 03:24:57,417 - DEBUG - close.complete
