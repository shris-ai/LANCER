2025-06-01 01:58:23,101 - INFO - Starting test of 11 tasks: task_id_0, task_id_58, task_id_77, task_id_127, task_id_227, task_id_404, task_id_431, task_id_433, task_id_435, task_id_441, task_id_447
2025-06-01 01:58:23,101 - INFO - 
==================================================
2025-06-01 01:58:23,101 - INFO - Processing task task_id_0...
2025-06-01 01:58:23,101 - INFO - Reading problem description and code template from tasks/task_id_0...
2025-06-01 01:58:23,103 - INFO - Problem description length: 310 characters
2025-06-01 01:58:23,103 - INFO - Reading unit tests from tasks/task_id_0...
2025-06-01 01:58:23,103 - INFO - Unit tests length: 69 characters
2025-06-01 01:58:23,103 - INFO - Running main workflow to generate solution...
2025-06-01 01:58:23,103 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.

-----Input-----
The input consists of one natural number:
x: An natural number.

-----Output-----
The output is a natural number which the value equals to x.
2025-06-01 01:58:23,103 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def ident (x : Nat) : Nat :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


def ident_spec (x : Nat) (result: Nat) : Prop :=
  -- << SPEC START >>
  result = x
  -- << SPEC END >>

theorem ident_spec_satisfied (x : Nat) :
  ident_spec x (ident x) := by
  -- << PROOF START >>
  unfold ident ident_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 01:58:23,142 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7159b62a2700>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:58:23,152 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:58:23,153 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:58:23,163 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eadc10>
2025-06-01 01:58:23,163 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7159b677f1d0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:58:23,171 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159c01bc770>
2025-06-01 01:58:23,171 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:58:23,171 - DEBUG - send_request_headers.complete
2025-06-01 01:58:23,172 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:58:23,172 - DEBUG - send_request_body.complete
2025-06-01 01:58:23,172 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:58:23,476 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:58:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'61'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-678485f6b9-d5sdz'), (b'x-envoy-upstream-service-time', b'63'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999923'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'4ms'), (b'x-request-id', b'req_2810738068898cde364452437e29c73c'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=iMVeTnp0dVa2UG6WnzmSJ2_f_Yk9DEva2PhgoNrclX4-1748743103-1.0.1.1-S.scS_H.zp46ACBYvPck.X4v6cMsbhFR8PyxzVBuoNjZ21dpdXZz3lWGo.g0XUZHh5gCIYQxO_wY.9qMs4llC7IIAZaWuZ7x289EAdldXJc; path=/; expires=Sun, 01-Jun-25 02:28:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=TS5ezvKvx9vEIWWK5f2eZ3UbJeK1orV_Jt_0EAUxkos-1748743103479-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1b0ae99e8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:58:23,476 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:58:23,476 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:58:23,477 - DEBUG - receive_response_body.complete
2025-06-01 01:58:23,477 - DEBUG - response_closed.started
2025-06-01 01:58:23,477 - DEBUG - response_closed.complete
2025-06-01 01:58:23,477 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 01:58:23 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '61'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-678485f6b9-d5sdz'), ('x-envoy-upstream-service-time', '63'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999923'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '4ms'), ('x-request-id', 'req_2810738068898cde364452437e29c73c'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=iMVeTnp0dVa2UG6WnzmSJ2_f_Yk9DEva2PhgoNrclX4-1748743103-1.0.1.1-S.scS_H.zp46ACBYvPck.X4v6cMsbhFR8PyxzVBuoNjZ21dpdXZz3lWGo.g0XUZHh5gCIYQxO_wY.9qMs4llC7IIAZaWuZ7x289EAdldXJc; path=/; expires=Sun, 01-Jun-25 02:28:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=TS5ezvKvx9vEIWWK5f2eZ3UbJeK1orV_Jt_0EAUxkos-1748743103479-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b1b0ae99e8fcd-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 01:58:23,477 - DEBUG - request_id: req_2810738068898cde364452437e29c73c
2025-06-01 01:58:23,484 - INFO - Retrieved context:  modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
 Lean failed to infer it. Named arguments also improve
the readability of your code by identifying what each argument represents.

    
    
    def sum (xs : List Nat) :=
      xs.foldl (init := 0) (·+·)
    
    #eval sum [1, 2, 3, 4]
    -- 10
    
    example {a b : Nat} {p : Nat → Nat → Nat → Prop} (h₁ : p a b b) (h₂ : b = a)
        : p a a b :=
      Eq.subst (motive := fun x => p a x b) h₂ h₁
    

In the following examples, we illustrate the interaction between named and
default arguments.

    
    
    def f (x : Nat) (y : Nat := 1) (w : Nat := 2) (z : Nat) :=
      x + y + w - z
    
    example (x z : Nat) : f (z := z) x = x + 1 + 2 - z := rfl
    
    example (x z : Nat) : f x (z := z) = x + 1 + 2 - z := rfl
    
    example (x y : Nat) : f x y = fun z => x + y + 2 - z := rfl
    
    example : f = (fun x z => x + 1 + 2 - z) := rfl
    
    example (x : Nat) : f x = fun z => x + 1 + 2 - z := rfl
    
    example (y : Nat) : f (y := 5) = fun x z => x + 5 + 2 - z := rfl
    
    def g {α} [Add α] (a : α) (b? : Option α := none) (c : α) : α :=
      match b? with
      | none   => a + c
      | some b => a + b + c
    
    variable {α} [Add α]
    
    example : g = fun (a c : α) => a + c := rfl
    
    example (x : α) : g (c := x) = fun (a : α) => a + x := rfl
    
    example (x : α) : g (b? := some x) = fun (a c : α) => a + x + c := rfl
    
    example (x : α) : g x = fun (c : α) => x + c := rfl
    
    example (x y : α) : g x y = fun (c : α) => x + y + c := rfl
    

You can use `..` to provide missing explicit arguments as `_`. This feature
combined with named arguments is useful for writing patterns. Here is an
example:

    
    
    inductive Term where
      | var    (name : String)
      | num    (val : Nat)
      | app    (fn : Term) (arg : Term)
      | lambda (name : String) (type : Term) (body : Term)
    
    def getBinderName : Term → Option String
      | Term.lambda (name := n) .. => some n
      | _ => none
    
    def getBinderType : Term → Option Term
      | Term.lambda (type := t) .. => some t
      | _ => none
    

Ellipses are also useful when explicit arguments can be automatically inferred
by Lean, and we want to avoid a sequence of `_`s.

    
    
    example (f : Nat → Nat) (a b c : Nat) : f (a + b + c) = f (a + (b + c)) :=
      congrArg f (Nat.add_assoc ..)
    

[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next
chapter")

[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next
chapter")
2025-06-01 01:58:23,504 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.'}], 'model': 'o3-mini'}}
2025-06-01 01:58:23,504 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:58:23,504 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:58:23,530 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b48c0>
2025-06-01 01:58:23,530 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:58:23,558 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b4560>
2025-06-01 01:58:23,558 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:58:23,558 - DEBUG - send_request_headers.complete
2025-06-01 01:58:23,558 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:58:23,559 - DEBUG - send_request_body.complete
2025-06-01 01:58:23,559 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:58:28,822 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:58:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5009'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5017'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199622'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'113ms'), (b'x-request-id', b'req_55a741f5fd70cab91fce8f0398639fc3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cVIlFU2QD5HTn6yXhWqjg3GXnf_u_tPLHW79SNS2jVw-1748743108-1.0.1.1-ThX.3ipIoBJnmLKl5vRESi.F01fK1WzOy_frKbZ5jSeMiuHnkYsPInjVCOuOezeCB5QM4NlwJ3.3QC.Gdk1A6pBUBxHd_Ur8WwM4UjQ_c7w; path=/; expires=Sun, 01-Jun-25 02:28:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=PkUNtRHJ78fT01x8S.8vn8yB4UVGw1z1Lb_Si0k8Z0w-1748743108824-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1b0d6a0746f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:58:28,822 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:58:28,822 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:58:28,823 - DEBUG - receive_response_body.complete
2025-06-01 01:58:28,823 - DEBUG - response_closed.started
2025-06-01 01:58:28,823 - DEBUG - response_closed.complete
2025-06-01 01:58:28,823 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 01 Jun 2025 01:58:28 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '5009'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '5017'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '199622'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '113ms'), ('x-request-id', 'req_55a741f5fd70cab91fce8f0398639fc3'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=cVIlFU2QD5HTn6yXhWqjg3GXnf_u_tPLHW79SNS2jVw-1748743108-1.0.1.1-ThX.3ipIoBJnmLKl5vRESi.F01fK1WzOy_frKbZ5jSeMiuHnkYsPInjVCOuOezeCB5QM4NlwJ3.3QC.Gdk1A6pBUBxHd_Ur8WwM4UjQ_c7w; path=/; expires=Sun, 01-Jun-25 02:28:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=PkUNtRHJ78fT01x8S.8vn8yB4UVGw1z1Lb_Si0k8Z0w-1748743108824-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b1b0d6a0746f0-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 01:58:28,823 - DEBUG - request_id: req_55a741f5fd70cab91fce8f0398639fc3
2025-06-01 01:58:28,827 - INFO - Attempt 1/3
2025-06-01 01:58:28,827 - INFO - Current plan: {
  "plan_summary": "The goal is to implement an identity function in Lean 4 that takes a natural number as input and returns the same natural number. The plan involves defining a function with the correct type signature and returning the input value directly.",
  "steps": [
    "Define a function of type Nat -> Nat (Nat representing natural numbers in Lean).",
    "Accept a natural number parameter, for example, x, as the input.",
    "Return the parameter x as the output, effectively implementing the identity function.",
    "Ensure that the function type-checks correctly in Lean 4."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "Nat",
    "identity function",
    "pattern matching"
  ],
  "proof_keywords": [
    "direct return",
    "reflexivity",
    "definition unfolding"
  ],
  "assumptions": [
    "The natural number type is represented by Nat in Lean 4.",
    "The function definition follows the standard Lean syntax for functions."
  ],
  "retry_guidance": "This is a straightforward problem. If any issues arise, double-check the syntax for function definitions in Lean 4 and confirm the use of the natural number type."
}
2025-06-01 01:58:28,827 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "The goal is to implement an identity function in Lean 4 that takes a natural number as input and returns the same natural number. The plan involves defining a function with the correct type signature and returning the input value directly.",\n  "steps": [\n    "Define a function of type Nat -> Nat (Nat representing natural numbers in Lean).",\n    "Accept a natural number parameter, for example, x, as the input.",\n    "Return the parameter x as the output, effectively implementing the identity function.",\n    "Ensure that the function type-checks correctly in Lean 4."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "Nat",\n    "identity function",\n    "pattern matching"\n  ],\n  "proof_keywords": [\n    "direct return",\n    "reflexivity",\n    "definition unfolding"\n  ],\n  "assumptions": [\n    "The natural number type is represented by Nat in Lean 4.",\n    "The function definition follows the standard Lean syntax for functions."\n  ],\n  "retry_guidance": "This is a straightforward problem. If any issues arise, double-check the syntax for function definitions in Lean 4 and confirm the use of the natural number type."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef ident (x : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\ndef ident_spec (x : Nat) (result: Nat) : Prop :=\n  -- << SPEC START >>\n  result = x\n  -- << SPEC END >>\n\ntheorem ident_spec_satisfied (x : Nat) :\n  ident_spec x (ident x) := by\n  -- << PROOF START >>\n  unfold ident ident_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n Lean failed to infer it. Named arguments also improve\nthe readability of your code by identifying what each argument represents.\n\n    \n    \n    def sum (xs : List Nat) :=\n      xs.foldl (init := 0) (·+·)\n    \n    #eval sum [1, 2, 3, 4]\n    -- 10\n    \n    example {a b : Nat} {p : Nat → Nat → Nat → Prop} (h₁ : p a b b) (h₂ : b = a)\n        : p a a b :=\n      Eq.subst (motive := fun x => p a x b) h₂ h₁\n    \n\nIn the following examples, we illustrate the interaction between named and\ndefault arguments.\n\n    \n    \n    def f (x : Nat) (y : Nat := 1) (w : Nat := 2) (z : Nat) :=\n      x + y + w - z\n    \n    example (x z : Nat) : f (z := z) x = x + 1 + 2 - z := rfl\n    \n    example (x z : Nat) : f x (z := z) = x + 1 + 2 - z := rfl\n    \n    example (x y : Nat) : f x y = fun z => x + y + 2 - z := rfl\n    \n    example : f = (fun x z => x + 1 + 2 - z) := rfl\n    \n    example (x : Nat) : f x = fun z => x + 1 + 2 - z := rfl\n    \n    example (y : Nat) : f (y := 5) = fun x z => x + 5 + 2 - z := rfl\n    \n    def g {α} [Add α] (a : α) (b? : Option α := none) (c : α) : α :=\n      match b? with\n      | none   => a + c\n      | some b => a + b + c\n    \n    variable {α} [Add α]\n    \n    example : g = fun (a c : α) => a + c := rfl\n    \n    example (x : α) : g (c := x) = fun (a : α) => a + x := rfl\n    \n    example (x : α) : g (b? := some x) = fun (a c : α) => a + x + c := rfl\n    \n    example (x : α) : g x = fun (c : α) => x + c := rfl\n    \n    example (x y : α) : g x y = fun (c : α) => x + y + c := rfl\n    \n\nYou can use `..` to provide missing explicit arguments as `_`. This feature\ncombined with named arguments is useful for writing patterns. Here is an\nexample:\n\n    \n    \n    inductive Term where\n      | var    (name : String)\n      | num    (val : Nat)\n      | app    (fn : Term) (arg : Term)\n      | lambda (name : String) (type : Term) (body : Term)\n    \n    def getBinderName : Term → Option String\n      | Term.lambda (name := n) .. => some n\n      | _ => none\n    \n    def getBinderType : Term → Option Term\n      | Term.lambda (type := t) .. => some t\n      | _ => none\n    \n\nEllipses are also useful when explicit arguments can be automatically inferred\nby Lean, and we want to avoid a sequence of `_`s.\n\n    \n    \n    example (f : Nat → Nat) (a b c : Nat) : f (a + b + c) = f (a + (b + c)) :=\n      congrArg f (Nat.add_assoc ..)\n    \n\n[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next\nchapter")\n\n[ __](tactics.html "Previous chapter") [ __](inductive_types.html "Next\nchapter")'}], 'model': 'gpt-4o'}}
2025-06-01 01:58:28,829 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:58:28,829 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:58:28,829 - DEBUG - send_request_headers.complete
2025-06-01 01:58:28,829 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:58:28,852 - DEBUG - send_request_body.complete
2025-06-01 01:58:28,852 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:58:30,911 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:58:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'1700'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1705'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'13935'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'32.13s'), (b'x-request-id', b'req_fd390697ca6e9e65dc667edae7c7c34e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1b2e58c646f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:58:30,912 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:58:30,912 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:58:30,913 - DEBUG - receive_response_body.complete
2025-06-01 01:58:30,913 - DEBUG - response_closed.started
2025-06-01 01:58:30,913 - DEBUG - response_closed.complete
2025-06-01 01:58:30,913 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:58:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '1700', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1705', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '13935', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '32.13s', 'x-request-id': 'req_fd390697ca6e9e65dc667edae7c7c34e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1b2e58c646f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:58:30,913 - DEBUG - request_id: req_fd390697ca6e9e65dc667edae7c7c34e
2025-06-01 01:58:30,914 - INFO - Raw solution received: ```json
{
  "code": "x",
  "proof": "rfl"
}
```
2025-06-01 01:58:30,914 - INFO - <class 'str'>
2025-06-01 01:58:30,914 - INFO - Generated solution: {'code': 'x', 'proof': 'rfl'}
2025-06-01 01:58:39,881 - INFO - Lean execution result: Lean code executed successfully.
2025-06-01 01:58:39,882 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 function that takes a natural number as input and returns the same natural number as output.\n\n-----Input-----\nThe input consists of one natural number:\nx: An natural number.\n\n-----Output-----\nThe output is a natural number which the value equals to x.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef ident (x : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\ndef ident_spec (x : Nat) (result: Nat) : Prop :=\n  -- << SPEC START >>\n  result = x\n  -- << SPEC END >>\n\ntheorem ident_spec_satisfied (x : Nat) :\n  ident_spec x (ident x) := by\n  -- << PROOF START >>\n  unfold ident ident_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nx\n\nGenerated Proof:\nrfl\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean code executed successfully.'}], 'model': 'o3-mini'}}
2025-06-01 01:58:39,882 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:58:39,882 - DEBUG - close.started
2025-06-01 01:58:39,883 - DEBUG - close.complete
2025-06-01 01:58:39,883 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:58:39,889 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b7d70>
2025-06-01 01:58:39,889 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:58:39,896 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b7c20>
2025-06-01 01:58:39,896 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:58:39,897 - DEBUG - send_request_headers.complete
2025-06-01 01:58:39,897 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:58:39,897 - DEBUG - send_request_body.complete
2025-06-01 01:58:39,897 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:58:42,527 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:58:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2393'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2407'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199425'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'172ms'), (b'x-request-id', b'req_3638fccf779564bf08fb377009eead7d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1b73582f3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:58:42,527 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:58:42,527 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:58:42,528 - DEBUG - receive_response_body.complete
2025-06-01 01:58:42,528 - DEBUG - response_closed.started
2025-06-01 01:58:42,528 - DEBUG - response_closed.complete
2025-06-01 01:58:42,528 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:58:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2393', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2407', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199425', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '172ms', 'x-request-id': 'req_3638fccf779564bf08fb377009eead7d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1b73582f3bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:58:42,528 - DEBUG - request_id: req_3638fccf779564bf08fb377009eead7d
2025-06-01 01:58:42,528 - INFO - Feedback received: {'verdict': 'pass', 'error_summary': '', 'error_type': 'unknown', 'suggested_fix': '', 'retry_strategy': ''}
2025-06-01 01:58:42,528 - INFO - Solution generated in 19.43 seconds
2025-06-01 01:58:42,528 - INFO - Generated code length: 1 characters
2025-06-01 01:58:42,529 - INFO - Generated proof length: 3 characters
2025-06-01 01:58:42,529 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 01:58:42,529 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 01:58:47,798 - INFO - Implementation test result: PASS
2025-06-01 01:58:47,798 - INFO - Executing Lean code with implementation and proof...
2025-06-01 01:58:52,909 - INFO - Full solution test result: PASS
2025-06-01 01:58:52,909 - INFO - ✅ Implementation passes unit tests
2025-06-01 01:58:52,909 - INFO - ✅ Proof is correct
2025-06-01 01:58:52,909 - INFO - 
==================================================
2025-06-01 01:58:52,909 - INFO - Processing task task_id_58...
2025-06-01 01:58:52,909 - INFO - Reading problem description and code template from tasks/task_id_58...
2025-06-01 01:58:52,912 - INFO - Problem description length: 700 characters
2025-06-01 01:58:52,912 - INFO - Reading unit tests from tasks/task_id_58...
2025-06-01 01:58:52,912 - INFO - Unit tests length: 462 characters
2025-06-01 01:58:52,912 - INFO - Running main workflow to generate solution...
2025-06-01 01:58:52,912 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.

-----Input-----
The input consists of two integers:
a: An integer.
b: An integer.

-----Output-----
The output is a Boolean value:
Returns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).
Returns false if both integers are either non-negative or non-positive, or if one (or both) is zero.
2025-06-01 01:58:52,912 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def hasOppositeSign (a : Int) (b : Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result is true if a and b have opposite signs
def hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=
  -- << SPEC START >>
  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result
  -- << SPEC END >>

theorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :
  hasOppositeSign_spec a b (hasOppositeSign a b) := by
  -- << PROOF START >>
  unfold hasOppositeSign hasOppositeSign_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 01:58:52,941 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7159b62a2480>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:58:52,942 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:58:52,942 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:58:52,967 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b7230>
2025-06-01 01:58:52,967 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7159b6503d50> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:58:52,994 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b7140>
2025-06-01 01:58:52,994 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:58:52,994 - DEBUG - send_request_headers.complete
2025-06-01 01:58:52,994 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:58:52,994 - DEBUG - send_request_body.complete
2025-06-01 01:58:52,994 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:58:53,385 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:58:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'74'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-78998c59cd-7ql8t'), (b'x-envoy-upstream-service-time', b'77'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999825'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_c16459cfd2a53330806a555d27edd3af'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=iiDNV59x_IUXstaN8Dl18GKtGL7ecIW5EOjjl9_K.9Q-1748743133-1.0.1.1-FvggVOI4kjabwkfN98roxZVreK.M_I8z8zOCkiCU.iY12BjE_U9b0VZ5D3hWri6g_dC7fkdC0U3wqgY83WmGBYqVGXXE6fTL6aKAvI2n9k8; path=/; expires=Sun, 01-Jun-25 02:28:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=aZrdi.e46iWw3OFfJKbEdQ7ad2nyX1jU_krZg5eCEto-1748743133388-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1bc56eeb46f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:58:53,386 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:58:53,386 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:58:53,386 - DEBUG - receive_response_body.complete
2025-06-01 01:58:53,386 - DEBUG - response_closed.started
2025-06-01 01:58:53,387 - DEBUG - response_closed.complete
2025-06-01 01:58:53,387 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 01:58:53 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '74'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-78998c59cd-7ql8t'), ('x-envoy-upstream-service-time', '77'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999825'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '10ms'), ('x-request-id', 'req_c16459cfd2a53330806a555d27edd3af'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=iiDNV59x_IUXstaN8Dl18GKtGL7ecIW5EOjjl9_K.9Q-1748743133-1.0.1.1-FvggVOI4kjabwkfN98roxZVreK.M_I8z8zOCkiCU.iY12BjE_U9b0VZ5D3hWri6g_dC7fkdC0U3wqgY83WmGBYqVGXXE6fTL6aKAvI2n9k8; path=/; expires=Sun, 01-Jun-25 02:28:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=aZrdi.e46iWw3OFfJKbEdQ7ad2nyX1jU_krZg5eCEto-1748743133388-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b1bc56eeb46f0-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 01:58:53,387 - DEBUG - request_id: req_c16459cfd2a53330806a555d27edd3af
2025-06-01 01:58:53,392 - INFO - Retrieved context:  the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
� r)`

Distributivity:

  5. `p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)`
  6. `p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)`

Other properties:

  7. `(p → (q → r)) ↔ (p ∧ q → r)`
  8. `((p ∨ q) → r) ↔ (p → r) ∧ (q → r)`
  9. `¬(p ∨ q) ↔ ¬p ∧ ¬q`
  10. `¬p ∨ ¬q → ¬(p ∧ q)`
  11. `¬(p ∧ ¬p)`
  12. `p ∧ ¬q → ¬(p → q)`
  13. `¬p → (p → q)`
  14. `(¬p ∨ q) → (p → q)`
  15. `p ∨ False ↔ p`
  16. `p ∧ False ↔ False`
  17. `¬(p ↔ ¬p)`
  18. `(p → q) → (¬q → ¬p)`

These require classical reasoning:

  19. `(p → r ∨ s) → ((p → r) ∨ (p → s))`
  20. `¬(p ∧ q) → ¬p ∨ ¬q`
  21. `¬(p → q) → p ∧ ¬q`
  22. `(p → q) → (¬p ∨ q)`
  23. `(¬q → ¬p) → (p → q)`
  24. `p ∨ ¬p`
  25. `(((p → q) → p) → p)`

The `sorry` identifier magically produces a proof of anything, or provides an
object of any data type at all. Of course, it is unsound as a proof method --
for example, you can use it to prove `False` \-- and Lean produces severe
warnings when files use or import theorems which depend on it. But it is very
useful for building long proofs incrementally. Start writing the proof from
the top down, using `sorry` to fill in subproofs. Make sure Lean accepts the
term with all the `sorry`'s; if not, there are errors that you need to
correct. Then go back and replace each `sorry` with an actual proof, until no
more remain.

Here is another useful trick. Instead of using `sorry`, you can use an
underscore `_` as a placeholder. Recall this tells Lean that the argument is
implicit, and should be filled in automatically. If Lean tries to do so and
fails, it returns with an error message "don't know how to synthesize
placeholder," followed by the type of the term it is expecting, and all the
objects and hypotheses available in the context. In other words, for each
unresolved placeholder, Lean reports the subgoal that needs to be filled at
that point. You can then construct a proof by incrementally filling in these
placeholders.

For reference, here are two sample proofs of validities taken from the list
above.

    
    
    open Classical
    
    -- distributivity
    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
      Iff.intro
        (fun h : p ∧ (q ∨ r) =>
          have hp : p := h.left
          Or.elim (h.right)
            (fun hq : q =>
              show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)
            (fun hr : r =>
              show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))
        (fun h : (p ∧ q) ∨ (p ∧ r) =>
          Or.elim h
            (fun hpq : p ∧ q =>
              have hp : p := hpq.left
              have hq : q := hpq.right
              show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)
            (fun hpr : p ∧ r =>
              have hp : p := hpr.left
              have hr : r := hpr.right
              show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))
    
    -- an example that requires classical reasoning
    example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=
      fun h : ¬(p ∧ ¬q) =>
      fun hp : p =>
      show q from
        Or.elim (em q)
          (fun hq : q => hq)
          (fun hnq : ¬q => absurd (And.intro hp hnq) h)
    

## Exercises

Prove the following identities, replacing the "sorry" placeholders with actual
proofs.

    
    
    variable (p q r : Prop)
    
    -- commutativity of ∧ and ∨
    example : p ∧ q ↔ q ∧ p := sorry
    example : p ∨ q ↔ q ∨ p := sorry
    
    -- associativity of ∧ and ∨
    example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry
    example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry
    
    -- distributivity
    example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry
    example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry
    
    -- other properties
    example : (p → (q → r)) ↔ (p ∧ q → r) := sorry
    example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry
    example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry
    example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry
    example : ¬(p ∧ ¬p) := sorry
    example : p ∧ ¬q → ¬(p → q) := sorry
    example : ¬p → (p → q) := sorry
    example : (¬p ∨ q) → (p → q) := sorry
    example : p ∨ False ↔ p := sorry
    example : p ∧ False ↔ False := sorry
    example : (p → q) → (¬q → ¬p) := sorry
    

Prove the following identities, replacing the "sorry" placeholders with actual
proofs. These require classical reasoning.

    
    
    open Classical
    
    variable (p q r : Prop)
    
    example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry
    example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry
    example : ¬(p → q) → p ∧ ¬q := sorry
    example : (p → q) → (¬p ∨ q) := sorry
    example : (¬q → ¬p) → (p → q) := sorry
    example : p ∨ ¬p := sorry
    example : (((p → q) → p) → p) := sorry
    

Prove `¬(p ↔ ¬p)` without using classical logic.

[ __](dependent_type_theory.html "Previous chapter") [
__](quantifiers_and_equality.html "Next chapter")

[ __](dependent_type_theory.html "Previous chapter") [
__](quantifiers_and_equality.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Propositions and Proofs

By now, you have seen some ways of defining objects and functions in Lean. In
this chapter, we will begin to explain how to write mathematical assertions
and proofs in the language of dependent type theory as well.

## Propositions as Types

One strategy for proving assertions about objects defined in the language of
dependent type theory is to layer an assertion language and a proof language
on top of the definition language. But there is no reason to multiply
languages in this way: dependent type theory is flexible and expressive, and
there is no reason we cannot represent assertions and proofs in the same
general framework.

For example, we could introduce a new type, `Prop`, to represent propositions,
and introduce constructors to build new propositions from others.

    
    
    def Implies (p q : Prop) : Prop := p → q
    #check And     -- Prop → Prop → Prop
    #check Or      -- Prop → Prop → Prop
    #check Not     -- Prop → Prop
    #check Implies -- Prop → Prop → Prop
    
    variable (p q r : Prop)
    #check And p q                      -- Prop
    #check Or (And p q) r               -- Prop
    #check Implies (And p q) (And q p)  -- Prop
    

We could then introduce, for each element `p : Prop`, another type `Proof p`,
for the type of proofs of `p`. An "axiom" would be a constant of such a type.

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    #check Proof   -- Proof : Prop → Type
    
    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))
    
    variable (p q : Prop)
    #check and_comm p q     -- Proof (Implies (And p q) (And q p))
    

In addition to axioms, however, we would also need rules to build new proofs
from old ones. For example, in many proof systems for propositional logic, we
have the rule of _modus ponens_ :

> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.

We could represent this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q
    

Systems of natural deduction for propositional logic also typically rely on
the following rule:

> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we
> can "cancel" the hypothesis and obtain a proof of `Implies p q`.

We could render this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)
    

This approach would provide us with a reasonable way of building assertions
and proofs. Determining that an expression `t` is a correct proof of assertion
`p` would then simply be a matter of checking that `t` has type `Proof p`.

Some simplifications are possible, however. To start with, we can avoid
writing the term `Proof` repeatedly by conflating `Proof p` with `p` itself.
In other words, whenever we have `p : Prop`, we can interpret `p` as a type,
namely, the type of its proofs. We can then read `t : p` as the assertion that
`t` is a proof of `p`.

Moreover, once we make this identification, the rules for implication show
that we can pass back and forth between `Implies p q` and `p → q`. In other
words, implication between propositions `p` and `q` corresponds to having a
function that takes any element of `p` to an element of `q`. As a result, the
introduction of the connective `Implies` is entirely redundant: we can use the
usual function space constructor `p → q` from dependent type theory as our
notion of implication.

This is the approach followed in the Calculus of Constructions, and hence in
Lean as well. The fact that the rules for implication in a proof system for
natural deduction correspond exactly to the rules governing abstraction and
application for functions is an instance of the _Curry-Howard isomorphism_ ,
sometimes known as the _propositions-as-types_ paradigm. In fact, the type
`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy
described in the last chapter. Moreover, `Type u` is also just syntactic sugar
for `Sort (u+1)`. `Prop` has some special features, but like the other type
universes, it is closed under the arrow constructor: if we have `p q : Prop`,
then `p → q : Prop`.

There are at least two ways of thinking about propositions as types. To some
who take a constructive view of logic and mathematics, this is a faithful
rendering of what it means to be a proposition: a proposition `p` represents a
sort of data type, namely, a specification of the type of data that
constitutes a proof. A proof of `p` is then simply an object `t : p` of the
right type.

Those not inclined to this ideology can view it, rather, as a simple coding
trick. To each proposition `p` we associate a type that is empty if `p` is
false and has a single element, say `*`, if `p` is true. In the latter case,
let us say that (the type associated with) `p` is _inhabited_. It just so
happens that the rules for function application and abstraction can
conveniently help us keep track of which elements of `Prop` are inhabited. So
constructing an element `t : p` tells us that `p` is indeed true. You can
think of the inhabitant of `p` as being the "fact that `p` is true." A proof
of `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is
true."

Indeed, if `p : Prop` is any proposition, Lean's kernel treats any two
elements `t1 t2 : p` as being definitionally equal, much the same way as it
treats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as
_proof irrelevance,_ and is consistent with the interpretation in the last
paragraph. It means that even though we can treat proofs `t : p` as ordinary
objects in the language of dependent type theory, they carry no information
beyond the fact that `p` is true.

The two ways we have suggested thinking about the propositions-as-types
paradigm differ in a fundamental way. From the constructive point of view,
proofs are abstract mathematical objects that are _denoted_ by suitable
expressions in dependent type theory. In contrast, if we think in terms of the
coding trick described above, then the expressions themselves do not denote
anything interesting. Rather, it is the fact that we can write them down and
check that they are well-typed that ensures that the proposition in question
is true. In other words, the expressions _themselves_ are the proofs.

In the exposition below, we will slip back and forth between these two ways of
talking, at times saying that an expression "constructs" or "produces" or
"returns" a proof of a proposition, and at other times simply saying that it
"is" such a proof. This is similar to the way that computer scientists
occasionally blur the distinction between syntax and semantics by saying, at
times, that a program "computes" a certain function, and at other times
speaking as though the program "is" the function in question.

In any case, all that really matters is the bottom line. To formally express a
mathematical assertion in the language of dependent type theory, we need to
exhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a
term `t : p`. Lean's task, as a proof assistant, is to help us to construct
such a term, `t`, and to verify that it is well-formed and has the correct
type.

## Working with Propositions as Types

In the propositions-as-types paradigm, theorems involving only `→` can be
proved using lambda abstraction and application. In Lean, the `theorem`
command introduces a new theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    

Compare this proof to the expression `fun x : α => fun y : β => x` of type `α
→ β → α`, where `α` and `β` are data types. This describes the function that
takes arguments `x` and `y` of type `α` and `β`, respectively, and returns
`x`. The proof of `t1` has the same form, the only difference being that `p`
and `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of
`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis
(trivially) to establish that the conclusion, `p`, is true.

Note that the `theorem` command is really a version of the `def` command:
under the propositions and types correspondence, proving the theorem `p → q →
p` is really the same as defining an element of the associated type. To the
kernel type checker, there is no difference between the two.

There are a few pragmatic differences between definitions and theorems,
however. In normal circumstances, it is never necessary to unfold the
"definition" of a theorem; by proof irrelevance, any two proofs of that
theorem are definitionally equal. Once the proof of a theorem is complete,
typically we only need to know that the proof exists; it doesn't matter what
the proof is. In light of that fact, Lean tags proofs as _irreducible_ , which
serves as a hint to the parser (more precisely, the _elaborator_) that there
is generally no need to unfold them when processing a file. In fact, Lean is
generally able to process and check proofs in parallel, since assessing the
correctness of one proof does not require knowing the details of another.

As with definitions, the `#print` command will show you the proof of a
theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    
    #print t1
    

Notice that the lambda abstractions `hp : p` and `hq : q` can be viewed as
temporary assumptions in the proof of `t1`. Lean also allows us to specify the
type of the final term `hp`, explicitly, with a `show` statement:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p :=
      fun hp : p =>
      fun hq : q =>
      show p from hp
    

Adding such extra information can improve the clarity of a proof and help
detect errors when writing a proof. The `show` command does nothing more than
annotate the type, and, internally, all the presentations of `t1` that we have
seen produce the same term.

As with ordinary definitions, we can move the lambda-abstracted variables to
the left of the colon:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    #print t1    -- p → q → p
    

We can use the theorem `t1` just as a function application:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    axiom hp : p
    
    theorem t2 : q → p := t1 hp
    

The `axiom` declaration postulates the existence of an element of the given
type and may compromise logical consistency. For example, we can use it to
postulate that the empty type `False` has an element:

    
    
    axiom unsound : False
    -- Everything follows from false
    theorem ex : 1 = 0 :=
      False.elim unsound
    

Declaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as
witnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`
that `p` is true yields the theorem `t1 hp : q → p`.

Recall that we can also write theorem `t1` as follows:

    
    
    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp
    
    #print t1
    

The type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the
assertion "for every pair of propositions `p q`, we have `p → q → p`." For
example, we can move all parameters to the right of the colon:

    
    
    theorem t1 : ∀ {p q : Prop}, p → q → p :=
      fun {p q : Prop} (hp : p) (hq : q) => hp
    

If `p` and `q` have been declared as variables, Lean will generalize them for
us automatically:

    
    
    variable {p q : Prop}
    
    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp
    

In fact, by the propositions-as-types correspondence, we can declare the
assumption `hp` that `p` holds, as another variable:

    
    
    variable {p q : Prop}
    variable (hp : p)
    
    theorem t1 : q → p := fun (hq : q) => hp
    

Lean detects that the proof uses `hp` and automatically adds `hp : p` as a
premise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →
q → p`. Remember that this type can just as well be written `∀ (p q : Prop)
(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type
in which the target does not depend on the bound variable.

When we generalize `t1` in such a way, we can then apply it to different pairs
of propositions, to obtain different instances of the general theorem.

    
    
    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp
    
    variable (p q r s : Prop)
    
    #check t1 p q                -- p → q → p
    #check t1 r s                -- r → s → r
    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s
    
    variable (h : r → s)
    #check t1 (r → s) (s → r) h  -- (s → r) → r → s
    

Once again, using the propositions-as-types correspondence, the variable `h`
of type `r → s` can be viewed as the hypothesis, or premise, that `r → s`
holds.

As another example, let us consider the composition function discussed in the
last chapter, now with propositions instead of types.

    
    
    variable (p q r s : Prop)
    
    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=
      fun h₃ : p =>
      show r from h₁ (h₂ h₃)
    

As a theorem of propositional logic, what does `t2` say?

Note that it is often useful to use numeric unicode subscripts, entered as
`\0`, `\1`, `\2`, ..., for hypotheses, as we did in this example.

## Propositional Logic

Lean defines all the standard logical connectives and notation. The
propositional connectives come with the following notation:

Ascii| Unicode| Editor shortcut| Definition  
---|---|---|---  
True| | | True  
False| | | False  
Not| ¬| `\not`, `\neg`| Not  
/\| ∧| `\and`| And  
\/| ∨| `\or`| Or  
->| →| `\to`, `\r`, `\imp`|   
<->| ↔| `\iff`, `\lr`| Iff  
  
They all take values in `Prop`.

    
    
    variable (p q : Prop)
    
    #check p → q → p ∧ q
    #check ¬p → p ↔ False
    #check p ∨ q → q ∨ p
    

The order of operations is as follows: unary negation `¬` binds most strongly,
then `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧
e` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right
(nothing changes now that the arguments are elements of `Prop`, instead of
some other `Type`), as do the other binary connectives. So if we have `p q r :
Prop`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This
is just the "curried" form of `p ∧ q → r`.

In the last chapter we observed that lambda abstraction can be viewed as an
"introduction rule" for `→`. In the current setting, it shows how to
"introduce" or establish an implication. Application can be viewed as an
"elimination rule," showing how to "eliminate" or use an implication in a
proof. The other propositional connectives are defined in Lean's library in
the file `Prelude.core` (see [importing
files](./interacting_with_lean.html#importing-files) for more information on
the library hierarchy), and each connective comes with its canonical
introduction and elimination rules.

### Conjunction

The expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :
p` and `h2 : q`. It is common to describe `And.intro` as the _and-
introduction_ rule. In the next example we use `And.intro` to create a proof
of `p → q → p ∧ q`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq
    
    #check fun (hp : p) (hq : q) => And.intro hp hq
    

The `example` command states a theorem without naming it or storing it in the
permanent context. Essentially, it just checks that the given term has the
indicated type. It is convenient for illustration, and we will use it often.

The expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.
Similarly, `And.right h` is a proof of `q`. They are commonly known as the
left and right _and-elimination_ rules.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : p := And.left h
    example (h : p ∧ q) : q := And.right h
    

We can now prove `p ∧ q → q ∧ p` with the following proof term.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      And.intro (And.right h) (And.left h)
    

Notice that and-introduction and and-elimination are similar to the pairing
and projection operations for the Cartesian product. The difference is that
given `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while
`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is
another instance of the Curry-Howard isomorphism, but in contrast to
implication and the function space constructor, `∧` and `×` are treated
separately in Lean. With the analogy, however, the proof we have just
constructed is similar to a function that swaps the elements of a pair.

We will see in [Chapter Structures and Records](./structures_and_records.html)
that certain types in Lean are _structures_ , which is to say, the type is
defined with a single canonical _constructor_ which builds an element of the
type from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is
an example: the canonical way to construct an element is to apply `And.intro`
to suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous
constructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the
relevant type is an inductive type and can be inferred from the context. In
particular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:

    
    
    variable (p q : Prop)
    variable (hp : p) (hq : q)
    
    #check (⟨hp, hq⟩ : p ∧ q)
    

These angle brackets are obtained by typing `\<` and `\>`, respectively.

Lean provides another useful syntactic gadget. Given an expression `e` of an
inductive type `Foo` (possibly applied to some arguments), the notation
`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of
accessing functions without opening a namespace. For example, the following
two expressions mean the same thing:

    
    
    variable (xs : List Nat)
    
    #check List.length xs
    #check xs.length
    

As a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and
`h.right` for `And.right h`. We can therefore rewrite the sample proof above
conveniently as follows:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      ⟨h.right, h.left⟩
    

There is a fine line between brevity and obfuscation, and omitting information
in this way can sometimes make a proof harder to read. But for straightforward
constructions like the one above, when the type of `h` and the goal of the
construction are salient, the notation is clean and effective.

It is common to iterate constructions like "And." Lean also allows you to
flatten nested constructors that associate to the right, so that these two
proofs are equivalent:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, ⟨h.left, h.right⟩⟩
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, h.left, h.right⟩
    

This is often useful as well.

### Disjunction

The expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof
`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a
proof `hq : q`. These are the left and right _or-introduction_ rules.

    
    
    variable (p q : Prop)
    example (hp : p) : p ∨ q := Or.intro_left q hp
    example (hq : q) : p ∨ q := Or.intro_right p hq
    

The _or-elimination_ rule is slightly more complicated. The idea is that we
can prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`
follows from `q`. In other words, it is a proof by cases. In the expression
`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :
p → r` and `hqr : q → r`, and produces a proof of `r`. In the following
example, we use `Or.elim` to prove `p ∨ q → q ∨ p`.

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h
        (fun hp : p =>
          show q ∨ p from Or.intro_right q hp)
        (fun hq : q =>
          show q ∨ p from Or.intro_left p hq)
    

In most cases, the first argument of `Or.intro_right` and `Or.intro_left` can
be inferred automatically by Lean. Lean therefore provides `Or.inr` and
`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and
`Or.intro_left _`. Thus the proof term above could be written more concisely:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Notice that there is enough information in the full expression for Lean to
infer the types of `hp` and `hq` as well. But using the type annotations in
the longer version makes the proof more readable, and can help catch and debug
errors.

Because `Or` has two constructors, we cannot use anonymous constructor
notation. But we can still write `h.elim` instead of `Or.elim h`:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Once again, you should exercise judgment as to whether such abbreviations
enhance or diminish readability.

### Negation and Falsity

Negation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by
deriving a contradiction from `p`. Similarly, the expression `hnp hp` produces
a proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both
these rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is
produced by typing `\not` or `\neg`.)

    
    
    variable (p q : Prop)
    
    example (hpq : p → q) (hnq : ¬q) : ¬p :=
      fun hp : p =>
      show False from hnq (hpq hp)
    

The connective `False` has a single elimination rule, `False.elim`, which
expresses the fact that anything follows from a contradiction. This rule is
sometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the
_principle of explosion_.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)
    

The arbitrary fact, `q`, that follows from falsity is an implicit argument in
`False.elim` and is inferred automatically. This pattern, deriving an
arbitrary fact from contradictory hypotheses, is quite common, and is
represented by `absurd`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := absurd hp hnp
    

Here, for example, is a proof of `¬p → q → (q → p) → r`:

    
    
    variable (p q r : Prop)
    
    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=
      absurd (hqp hq) hnp
    

Incidentally, just as `False` has only an elimination rule, `True` has only an
introduction rule, `True.intro : true`. In other words, `True` is simply true,
and has a canonical proof, `True.intro`.

### Logical Equivalence

The expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`
and `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from
`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔
q`. Here is a proof of `p ∧ q ↔ q ∧ p`:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      Iff.intro
        (fun h : p ∧ q =>
         show q ∧ p from And.intro (And.right h) (And.left h))
        (fun h : q ∧ p =>
         show p ∧ q from And.intro (And.right h) (And.left h))
    
    #check and_swap p q    -- p ∧ q ↔ q ∧ p
    
    variable (h : p ∧ q)
    example : q ∧ p := Iff.mp (and_swap p q) h
    

We can use the anonymous constructor notation to construct a proof of `p ↔ q`
from proofs of the forward and backward directions, and we can also use `.`
notation with `mp` and `mpr`. The previous examples can therefore be written
concisely as follows:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩
    
    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h
    

## Introducing Auxiliary Subgoals

This is a good place to introduce another device Lean offers to help structure
long proofs, namely, the `have` construct, which introduces an auxiliary
subgoal in a proof. Here is a small example, adapted from the last section:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      have hq : q := h.right
      show q ∧ p from And.intro hq hp
    

Internally, the expression `have h : p := s; t` produces the term `(fun (h :
p) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the
desired conclusion assuming `h : p`, and the two are combined by a lambda
abstraction and application. This simple device is extremely useful when it
comes to structuring long proofs, since we can use intermediate `have`'s as
stepping stones leading to the final goal.

Lean also supports a structured way of reasoning backwards from a goal, which
models the "suffices to show" construction in ordinary mathematics. The next
example simply permutes the last two lines in the previous proof.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      suffices hq : q from And.intro hq hp
      show q from And.right h
    

Writing `suffices hq : q` leaves us with two goals. First, we have to show
that it indeed suffices to show `q`, by proving the original goal of `q ∧ p`
with the additional hypothesis `hq : q`. Finally, we have to show `q`.

## Classical Logic

The introduction and elimination rules we have seen so far are all
constructive, which is to say, they reflect a computational understanding of
the logical connectives based on the propositions-as-types correspondence.
Ordinary classical logic adds to this the law of the excluded middle, `p ∨
¬p`. To use this principle, you have to open the classical namespace.

    
    
    open Classical
    
    variable (p : Prop)
    #check em p
    

Intuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts
to knowing which is the case. If `RH` represents the Riemann hypothesis, a
classical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot
yet assert either disjunct.

One consequence of the law of the excluded middle is the principle of double-
negation elimination:

    
    
    open Classical
    
    theorem dne {p : Prop} (h : ¬¬p) : p :=
      Or.elim (em p)
        (fun hp : p => hp)
        (fun hnp : ¬p => absurd hnp h)
    

Double-negation elimination allows one to prove any proposition, `p`, by
assuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In
other words, double-negation elimination allows one to carry out a proof by
contradiction, something which is not generally possible in constructive
logic. As an exercise, you might try proving the converse, that is, showing
that `em` can be proved from `dne`.

The classical axioms also give you access to additional patterns of proof that
can be justified by appeal to `em`. For example, one can carry out a proof by
cases:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byCases
        (fun h1 : p => h1)
        (fun h1 : ¬p => absurd h1 h)
    

Or you can carry out a proof by contradiction:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byContradiction
        (fun h1 : ¬p =>
         show False from h h1)
    

If you are not used to thinking constructively, it may take some time for you
to get a sense of where classical reasoning is used. It is needed in the
following example because, from a constructive standpoint, knowing that `p`
and `q` are not both true does not necessarily tell you which one is false:

    
    
    open Classical
    variable (p q : Prop)
    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=
      Or.elim (em p)
        (fun hp : p =>
          Or.inr
            (show ¬q from
              fun hq : q =>
              h ⟨hp, hq⟩))
        (fun hp : ¬p =>
          Or.inl hp)
    

We will see later that there _are_ situations in constructive logic where
principles like excluded middle and double-negation elimination are
permissible, and Lean supports the use of classical reasoning in such contexts
without relying on excluded middle.

The full list of axioms that are used in Lean to support classical reasoning
are discussed in [Axioms and Computation](./axioms_and_computation.html).

## Examples of Propositional Validities

Lean's standard library contains proofs of many valid statements of
propositional logic, all of which you are free to use in proofs of your own.
The following list includes a number of common identities.

Commutativity:

  1. `p ∧ q ↔ q ∧ p`
  2. `p ∨ q ↔ q ∨ p`

Associativity:

  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`
  4. `(p ∨ q) ∨ r ↔ p ∨ (q �
2025-06-01 01:58:53,404 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.'}], 'model': 'o3-mini'}}
2025-06-01 01:58:53,405 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:58:53,405 - DEBUG - close.started
2025-06-01 01:58:53,405 - DEBUG - close.complete
2025-06-01 01:58:53,405 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:58:53,430 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62ddfa0>
2025-06-01 01:58:53,430 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:58:53,457 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b7590>
2025-06-01 01:58:53,457 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:58:53,457 - DEBUG - send_request_headers.complete
2025-06-01 01:58:53,457 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:58:53,457 - DEBUG - send_request_body.complete
2025-06-01 01:58:53,457 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:58:59,360 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:58:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5650'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5657'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199523'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'142ms'), (b'x-request-id', b'req_318e6d1fb32cb340bf016dfed7b2895e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1bc84d2e4436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:58:59,361 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:58:59,361 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:58:59,361 - DEBUG - receive_response_body.complete
2025-06-01 01:58:59,361 - DEBUG - response_closed.started
2025-06-01 01:58:59,361 - DEBUG - response_closed.complete
2025-06-01 01:58:59,361 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:58:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5650', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5657', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199523', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '142ms', 'x-request-id': 'req_318e6d1fb32cb340bf016dfed7b2895e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1bc84d2e4436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:58:59,361 - DEBUG - request_id: req_318e6d1fb32cb340bf016dfed7b2895e
2025-06-01 01:58:59,362 - INFO - Attempt 1/3
2025-06-01 01:58:59,362 - INFO - Current plan: {
  "plan_summary": "The method will first check if either integer is zero and return false if so, since zero is neither positive nor negative. If both integers are nonzero, it will check if their product is negative. A negative product indicates that one integer is positive and the other is negative, hence the integers have opposite signs.",
  "steps": [
    "Step 1: Check if either a or b is equal to zero. If yes, return false.",
    "Step 2: If both integers are nonzero, calculate the product a * b.",
    "Step 3: Return true if the product is less than zero (indicating opposite signs) and false otherwise."
  ],
  "code_keywords": [
    "Lean 4",
    "if-else",
    "boolean",
    "integer multiplication",
    "zero check"
  ],
  "proof_keywords": [
    "case analysis",
    "edge cases",
    "constructive proof",
    "zero exclusion",
    "sign properties"
  ],
  "assumptions": [
    "Integer zero is treated as neither positive nor negative.",
    "A negative product is a sufficient condition to infer opposite signs when both numbers are nonzero."
  ],
  "retry_guidance": "If encountering type-checking or logical errors, ensure that zero is explicitly excluded from being considered positive or negative. Also, confirm that the arithmetic operations on integers are correctly applied. Consider using pattern matching or if-else expressions to handle the different cases."
}
2025-06-01 01:58:59,363 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "The method will first check if either integer is zero and return false if so, since zero is neither positive nor negative. If both integers are nonzero, it will check if their product is negative. A negative product indicates that one integer is positive and the other is negative, hence the integers have opposite signs.",\n  "steps": [\n    "Step 1: Check if either a or b is equal to zero. If yes, return false.",\n    "Step 2: If both integers are nonzero, calculate the product a * b.",\n    "Step 3: Return true if the product is less than zero (indicating opposite signs) and false otherwise."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "if-else",\n    "boolean",\n    "integer multiplication",\n    "zero check"\n  ],\n  "proof_keywords": [\n    "case analysis",\n    "edge cases",\n    "constructive proof",\n    "zero exclusion",\n    "sign properties"\n  ],\n  "assumptions": [\n    "Integer zero is treated as neither positive nor negative.",\n    "A negative product is a sufficient condition to infer opposite signs when both numbers are nonzero."\n  ],\n  "retry_guidance": "If encountering type-checking or logical errors, ensure that zero is explicitly excluded from being considered positive or negative. Also, confirm that the arithmetic operations on integers are correctly applied. Consider using pattern matching or if-else expressions to handle the different cases."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n� r)`\n\nDistributivity:\n\n  5. `p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)`\n  6. `p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)`\n\nOther properties:\n\n  7. `(p → (q → r)) ↔ (p ∧ q → r)`\n  8. `((p ∨ q) → r) ↔ (p → r) ∧ (q → r)`\n  9. `¬(p ∨ q) ↔ ¬p ∧ ¬q`\n  10. `¬p ∨ ¬q → ¬(p ∧ q)`\n  11. `¬(p ∧ ¬p)`\n  12. `p ∧ ¬q → ¬(p → q)`\n  13. `¬p → (p → q)`\n  14. `(¬p ∨ q) → (p → q)`\n  15. `p ∨ False ↔ p`\n  16. `p ∧ False ↔ False`\n  17. `¬(p ↔ ¬p)`\n  18. `(p → q) → (¬q → ¬p)`\n\nThese require classical reasoning:\n\n  19. `(p → r ∨ s) → ((p → r) ∨ (p → s))`\n  20. `¬(p ∧ q) → ¬p ∨ ¬q`\n  21. `¬(p → q) → p ∧ ¬q`\n  22. `(p → q) → (¬p ∨ q)`\n  23. `(¬q → ¬p) → (p → q)`\n  24. `p ∨ ¬p`\n  25. `(((p → q) → p) → p)`\n\nThe `sorry` identifier magically produces a proof of anything, or provides an\nobject of any data type at all. Of course, it is unsound as a proof method --\nfor example, you can use it to prove `False` \\-- and Lean produces severe\nwarnings when files use or import theorems which depend on it. But it is very\nuseful for building long proofs incrementally. Start writing the proof from\nthe top down, using `sorry` to fill in subproofs. Make sure Lean accepts the\nterm with all the `sorry`\'s; if not, there are errors that you need to\ncorrect. Then go back and replace each `sorry` with an actual proof, until no\nmore remain.\n\nHere is another useful trick. Instead of using `sorry`, you can use an\nunderscore `_` as a placeholder. Recall this tells Lean that the argument is\nimplicit, and should be filled in automatically. If Lean tries to do so and\nfails, it returns with an error message "don\'t know how to synthesize\nplaceholder," followed by the type of the term it is expecting, and all the\nobjects and hypotheses available in the context. In other words, for each\nunresolved placeholder, Lean reports the subgoal that needs to be filled at\nthat point. You can then construct a proof by incrementally filling in these\nplaceholders.\n\nFor reference, here are two sample proofs of validities taken from the list\nabove.\n\n    \n    \n    open Classical\n    \n    -- distributivity\n    example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=\n      Iff.intro\n        (fun h : p ∧ (q ∨ r) =>\n          have hp : p := h.left\n          Or.elim (h.right)\n            (fun hq : q =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)\n            (fun hr : r =>\n              show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))\n        (fun h : (p ∧ q) ∨ (p ∧ r) =>\n          Or.elim h\n            (fun hpq : p ∧ q =>\n              have hp : p := hpq.left\n              have hq : q := hpq.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)\n            (fun hpr : p ∧ r =>\n              have hp : p := hpr.left\n              have hr : r := hpr.right\n              show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))\n    \n    -- an example that requires classical reasoning\n    example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=\n      fun h : ¬(p ∧ ¬q) =>\n      fun hp : p =>\n      show q from\n        Or.elim (em q)\n          (fun hq : q => hq)\n          (fun hnq : ¬q => absurd (And.intro hp hnq) h)\n    \n\n## Exercises\n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs.\n\n    \n    \n    variable (p q r : Prop)\n    \n    -- commutativity of ∧ and ∨\n    example : p ∧ q ↔ q ∧ p := sorry\n    example : p ∨ q ↔ q ∨ p := sorry\n    \n    -- associativity of ∧ and ∨\n    example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry\n    example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry\n    \n    -- distributivity\n    example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry\n    example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry\n    \n    -- other properties\n    example : (p → (q → r)) ↔ (p ∧ q → r) := sorry\n    example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry\n    example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry\n    example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry\n    example : ¬(p ∧ ¬p) := sorry\n    example : p ∧ ¬q → ¬(p → q) := sorry\n    example : ¬p → (p → q) := sorry\n    example : (¬p ∨ q) → (p → q) := sorry\n    example : p ∨ False ↔ p := sorry\n    example : p ∧ False ↔ False := sorry\n    example : (p → q) → (¬q → ¬p) := sorry\n    \n\nProve the following identities, replacing the "sorry" placeholders with actual\nproofs. These require classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (p q r : Prop)\n    \n    example : (p → q ∨ r) → ((p → q) ∨ (p → r)) := sorry\n    example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry\n    example : ¬(p → q) → p ∧ ¬q := sorry\n    example : (p → q) → (¬p ∨ q) := sorry\n    example : (¬q → ¬p) → (p → q) := sorry\n    example : p ∨ ¬p := sorry\n    example : (((p → q) → p) → p) := sorry\n    \n\nProve `¬(p ↔ ¬p)` without using classical logic.\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n\n[ __](dependent_type_theory.html "Previous chapter") [\n__](quantifiers_and_equality.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Propositions and Proofs\n\nBy now, you have seen some ways of defining objects and functions in Lean. In\nthis chapter, we will begin to explain how to write mathematical assertions\nand proofs in the language of dependent type theory as well.\n\n## Propositions as Types\n\nOne strategy for proving assertions about objects defined in the language of\ndependent type theory is to layer an assertion language and a proof language\non top of the definition language. But there is no reason to multiply\nlanguages in this way: dependent type theory is flexible and expressive, and\nthere is no reason we cannot represent assertions and proofs in the same\ngeneral framework.\n\nFor example, we could introduce a new type, `Prop`, to represent propositions,\nand introduce constructors to build new propositions from others.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    #check And     -- Prop → Prop → Prop\n    #check Or      -- Prop → Prop → Prop\n    #check Not     -- Prop → Prop\n    #check Implies -- Prop → Prop → Prop\n    \n    variable (p q r : Prop)\n    #check And p q                      -- Prop\n    #check Or (And p q) r               -- Prop\n    #check Implies (And p q) (And q p)  -- Prop\n    \n\nWe could then introduce, for each element `p : Prop`, another type `Proof p`,\nfor the type of proofs of `p`. An "axiom" would be a constant of such a type.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    #check Proof   -- Proof : Prop → Type\n    \n    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))\n    \n    variable (p q : Prop)\n    #check and_comm p q     -- Proof (Implies (And p q) (And q p))\n    \n\nIn addition to axioms, however, we would also need rules to build new proofs\nfrom old ones. For example, in many proof systems for propositional logic, we\nhave the rule of _modus ponens_ :\n\n> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.\n\nWe could represent this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q\n    \n\nSystems of natural deduction for propositional logic also typically rely on\nthe following rule:\n\n> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we\n> can "cancel" the hypothesis and obtain a proof of `Implies p q`.\n\nWe could render this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)\n    \n\nThis approach would provide us with a reasonable way of building assertions\nand proofs. Determining that an expression `t` is a correct proof of assertion\n`p` would then simply be a matter of checking that `t` has type `Proof p`.\n\nSome simplifications are possible, however. To start with, we can avoid\nwriting the term `Proof` repeatedly by conflating `Proof p` with `p` itself.\nIn other words, whenever we have `p : Prop`, we can interpret `p` as a type,\nnamely, the type of its proofs. We can then read `t : p` as the assertion that\n`t` is a proof of `p`.\n\nMoreover, once we make this identification, the rules for implication show\nthat we can pass back and forth between `Implies p q` and `p → q`. In other\nwords, implication between propositions `p` and `q` corresponds to having a\nfunction that takes any element of `p` to an element of `q`. As a result, the\nintroduction of the connective `Implies` is entirely redundant: we can use the\nusual function space constructor `p → q` from dependent type theory as our\nnotion of implication.\n\nThis is the approach followed in the Calculus of Constructions, and hence in\nLean as well. The fact that the rules for implication in a proof system for\nnatural deduction correspond exactly to the rules governing abstraction and\napplication for functions is an instance of the _Curry-Howard isomorphism_ ,\nsometimes known as the _propositions-as-types_ paradigm. In fact, the type\n`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy\ndescribed in the last chapter. Moreover, `Type u` is also just syntactic sugar\nfor `Sort (u+1)`. `Prop` has some special features, but like the other type\nuniverses, it is closed under the arrow constructor: if we have `p q : Prop`,\nthen `p → q : Prop`.\n\nThere are at least two ways of thinking about propositions as types. To some\nwho take a constructive view of logic and mathematics, this is a faithful\nrendering of what it means to be a proposition: a proposition `p` represents a\nsort of data type, namely, a specification of the type of data that\nconstitutes a proof. A proof of `p` is then simply an object `t : p` of the\nright type.\n\nThose not inclined to this ideology can view it, rather, as a simple coding\ntrick. To each proposition `p` we associate a type that is empty if `p` is\nfalse and has a single element, say `*`, if `p` is true. In the latter case,\nlet us say that (the type associated with) `p` is _inhabited_. It just so\nhappens that the rules for function application and abstraction can\nconveniently help us keep track of which elements of `Prop` are inhabited. So\nconstructing an element `t : p` tells us that `p` is indeed true. You can\nthink of the inhabitant of `p` as being the "fact that `p` is true." A proof\nof `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is\ntrue."\n\nIndeed, if `p : Prop` is any proposition, Lean\'s kernel treats any two\nelements `t1 t2 : p` as being definitionally equal, much the same way as it\ntreats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as\n_proof irrelevance,_ and is consistent with the interpretation in the last\nparagraph. It means that even though we can treat proofs `t : p` as ordinary\nobjects in the language of dependent type theory, they carry no information\nbeyond the fact that `p` is true.\n\nThe two ways we have suggested thinking about the propositions-as-types\nparadigm differ in a fundamental way. From the constructive point of view,\nproofs are abstract mathematical objects that are _denoted_ by suitable\nexpressions in dependent type theory. In contrast, if we think in terms of the\ncoding trick described above, then the expressions themselves do not denote\nanything interesting. Rather, it is the fact that we can write them down and\ncheck that they are well-typed that ensures that the proposition in question\nis true. In other words, the expressions _themselves_ are the proofs.\n\nIn the exposition below, we will slip back and forth between these two ways of\ntalking, at times saying that an expression "constructs" or "produces" or\n"returns" a proof of a proposition, and at other times simply saying that it\n"is" such a proof. This is similar to the way that computer scientists\noccasionally blur the distinction between syntax and semantics by saying, at\ntimes, that a program "computes" a certain function, and at other times\nspeaking as though the program "is" the function in question.\n\nIn any case, all that really matters is the bottom line. To formally express a\nmathematical assertion in the language of dependent type theory, we need to\nexhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a\nterm `t : p`. Lean\'s task, as a proof assistant, is to help us to construct\nsuch a term, `t`, and to verify that it is well-formed and has the correct\ntype.\n\n## Working with Propositions as Types\n\nIn the propositions-as-types paradigm, theorems involving only `→` can be\nproved using lambda abstraction and application. In Lean, the `theorem`\ncommand introduces a new theorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    \n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n\nCompare this proof to the expression `fun x : α => fun y : β => x` of type `α\n→ β → α`, where `α` and `β` are data types. This describes the function that\ntakes arguments `x` and `y` of type `α` and `β`, respectively, and returns\n`x`. The proof of `t1` has the same form, the only difference being that `p`\nand `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of\n`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis\n(trivially) to establish that the conclusion, `p`, is true.\n\nNote that the `theorem` command is really a version of the `def` command:\nunder the propositions and types correspondence, proving the theorem `p → q →\np` is really the same as defining an element of the associated type. To the\nkernel type checker, there is no difference between the two.\n\nThere are a few pragmatic differences between definitions and theorems,\nhowever. In normal circumstances, it is never necessary to unfold the\n"definition" of a theorem; by proof irrelevance, any two proofs of that\ntheorem are definitionally equal. Once the proof of a theorem is complete,\ntypically we only need to know that the proof exists; it doesn\'t matter what\nthe proof is. In light of that fact, Lean tags proofs as _irreducible_ , which\nserves as a hint to the parser (more precisely, the _elaborator_) that there\nis generally no need to unfold them when processing a file. In fact, Lean is\ngenerally able to process and check proofs in parallel, since assessing the\ncorrectness of one proof does not require knowing the details of another.\n\nAs with definitions, the `#print` command will show you the proof of a\ntheorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n    #print t1\n    \n\nNotice that the lambda abstractions `hp : p` and `hq : q` can be viewed as\ntemporary assumptions in the proof of `t1`. Lean also allows us to specify the\ntype of the final term `hp`, explicitly, with a `show` statement:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p :=\n      fun hp : p =>\n      fun hq : q =>\n      show p from hp\n    \n\nAdding such extra information can improve the clarity of a proof and help\ndetect errors when writing a proof. The `show` command does nothing more than\nannotate the type, and, internally, all the presentations of `t1` that we have\nseen produce the same term.\n\nAs with ordinary definitions, we can move the lambda-abstracted variables to\nthe left of the colon:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    #print t1    -- p → q → p\n    \n\nWe can use the theorem `t1` just as a function application:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    axiom hp : p\n    \n    theorem t2 : q → p := t1 hp\n    \n\nThe `axiom` declaration postulates the existence of an element of the given\ntype and may compromise logical consistency. For example, we can use it to\npostulate that the empty type `False` has an element:\n\n    \n    \n    axiom unsound : False\n    -- Everything follows from false\n    theorem ex : 1 = 0 :=\n      False.elim unsound\n    \n\nDeclaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as\nwitnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`\nthat `p` is true yields the theorem `t1 hp : q → p`.\n\nRecall that we can also write theorem `t1` as follows:\n\n    \n    \n    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp\n    \n    #print t1\n    \n\nThe type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the\nassertion "for every pair of propositions `p q`, we have `p → q → p`." For\nexample, we can move all parameters to the right of the colon:\n\n    \n    \n    theorem t1 : ∀ {p q : Prop}, p → q → p :=\n      fun {p q : Prop} (hp : p) (hq : q) => hp\n    \n\nIf `p` and `q` have been declared as variables, Lean will generalize them for\nus automatically:\n\n    \n    \n    variable {p q : Prop}\n    \n    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp\n    \n\nIn fact, by the propositions-as-types correspondence, we can declare the\nassumption `hp` that `p` holds, as another variable:\n\n    \n    \n    variable {p q : Prop}\n    variable (hp : p)\n    \n    theorem t1 : q → p := fun (hq : q) => hp\n    \n\nLean detects that the proof uses `hp` and automatically adds `hp : p` as a\npremise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →\nq → p`. Remember that this type can just as well be written `∀ (p q : Prop)\n(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type\nin which the target does not depend on the bound variable.\n\nWhen we generalize `t1` in such a way, we can then apply it to different pairs\nof propositions, to obtain different instances of the general theorem.\n\n    \n    \n    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp\n    \n    variable (p q r s : Prop)\n    \n    #check t1 p q                -- p → q → p\n    #check t1 r s                -- r → s → r\n    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s\n    \n    variable (h : r → s)\n    #check t1 (r → s) (s → r) h  -- (s → r) → r → s\n    \n\nOnce again, using the propositions-as-types correspondence, the variable `h`\nof type `r → s` can be viewed as the hypothesis, or premise, that `r → s`\nholds.\n\nAs another example, let us consider the composition function discussed in the\nlast chapter, now with propositions instead of types.\n\n    \n    \n    variable (p q r s : Prop)\n    \n    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=\n      fun h₃ : p =>\n      show r from h₁ (h₂ h₃)\n    \n\nAs a theorem of propositional logic, what does `t2` say?\n\nNote that it is often useful to use numeric unicode subscripts, entered as\n`\\0`, `\\1`, `\\2`, ..., for hypotheses, as we did in this example.\n\n## Propositional Logic\n\nLean defines all the standard logical connectives and notation. The\npropositional connectives come with the following notation:\n\nAscii| Unicode| Editor shortcut| Definition  \n---|---|---|---  \nTrue| | | True  \nFalse| | | False  \nNot| ¬| `\\not`, `\\neg`| Not  \n/\\| ∧| `\\and`| And  \n\\/| ∨| `\\or`| Or  \n->| →| `\\to`, `\\r`, `\\imp`|   \n<->| ↔| `\\iff`, `\\lr`| Iff  \n  \nThey all take values in `Prop`.\n\n    \n    \n    variable (p q : Prop)\n    \n    #check p → q → p ∧ q\n    #check ¬p → p ↔ False\n    #check p ∨ q → q ∨ p\n    \n\nThe order of operations is as follows: unary negation `¬` binds most strongly,\nthen `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧\ne` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right\n(nothing changes now that the arguments are elements of `Prop`, instead of\nsome other `Type`), as do the other binary connectives. So if we have `p q r :\nProp`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This\nis just the "curried" form of `p ∧ q → r`.\n\nIn the last chapter we observed that lambda abstraction can be viewed as an\n"introduction rule" for `→`. In the current setting, it shows how to\n"introduce" or establish an implication. Application can be viewed as an\n"elimination rule," showing how to "eliminate" or use an implication in a\nproof. The other propositional connectives are defined in Lean\'s library in\nthe file `Prelude.core` (see [importing\nfiles](./interacting_with_lean.html#importing-files) for more information on\nthe library hierarchy), and each connective comes with its canonical\nintroduction and elimination rules.\n\n### Conjunction\n\nThe expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :\np` and `h2 : q`. It is common to describe `And.intro` as the _and-\nintroduction_ rule. In the next example we use `And.intro` to create a proof\nof `p → q → p ∧ q`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq\n    \n    #check fun (hp : p) (hq : q) => And.intro hp hq\n    \n\nThe `example` command states a theorem without naming it or storing it in the\npermanent context. Essentially, it just checks that the given term has the\nindicated type. It is convenient for illustration, and we will use it often.\n\nThe expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.\nSimilarly, `And.right h` is a proof of `q`. They are commonly known as the\nleft and right _and-elimination_ rules.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : p := And.left h\n    example (h : p ∧ q) : q := And.right h\n    \n\nWe can now prove `p ∧ q → q ∧ p` with the following proof term.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      And.intro (And.right h) (And.left h)\n    \n\nNotice that and-introduction and and-elimination are similar to the pairing\nand projection operations for the Cartesian product. The difference is that\ngiven `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while\n`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is\nanother instance of the Curry-Howard isomorphism, but in contrast to\nimplication and the function space constructor, `∧` and `×` are treated\nseparately in Lean. With the analogy, however, the proof we have just\nconstructed is similar to a function that swaps the elements of a pair.\n\nWe will see in [Chapter Structures and Records](./structures_and_records.html)\nthat certain types in Lean are _structures_ , which is to say, the type is\ndefined with a single canonical _constructor_ which builds an element of the\ntype from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is\nan example: the canonical way to construct an element is to apply `And.intro`\nto suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous\nconstructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the\nrelevant type is an inductive type and can be inferred from the context. In\nparticular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:\n\n    \n    \n    variable (p q : Prop)\n    variable (hp : p) (hq : q)\n    \n    #check (⟨hp, hq⟩ : p ∧ q)\n    \n\nThese angle brackets are obtained by typing `\\<` and `\\>`, respectively.\n\nLean provides another useful syntactic gadget. Given an expression `e` of an\ninductive type `Foo` (possibly applied to some arguments), the notation\n`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of\naccessing functions without opening a namespace. For example, the following\ntwo expressions mean the same thing:\n\n    \n    \n    variable (xs : List Nat)\n    \n    #check List.length xs\n    #check xs.length\n    \n\nAs a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and\n`h.right` for `And.right h`. We can therefore rewrite the sample proof above\nconveniently as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      ⟨h.right, h.left⟩\n    \n\nThere is a fine line between brevity and obfuscation, and omitting information\nin this way can sometimes make a proof harder to read. But for straightforward\nconstructions like the one above, when the type of `h` and the goal of the\nconstruction are salient, the notation is clean and effective.\n\nIt is common to iterate constructions like "And." Lean also allows you to\nflatten nested constructors that associate to the right, so that these two\nproofs are equivalent:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, ⟨h.left, h.right⟩⟩\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, h.left, h.right⟩\n    \n\nThis is often useful as well.\n\n### Disjunction\n\nThe expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof\n`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a\nproof `hq : q`. These are the left and right _or-introduction_ rules.\n\n    \n    \n    variable (p q : Prop)\n    example (hp : p) : p ∨ q := Or.intro_left q hp\n    example (hq : q) : p ∨ q := Or.intro_right p hq\n    \n\nThe _or-elimination_ rule is slightly more complicated. The idea is that we\ncan prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`\nfollows from `q`. In other words, it is a proof by cases. In the expression\n`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :\np → r` and `hqr : q → r`, and produces a proof of `r`. In the following\nexample, we use `Or.elim` to prove `p ∨ q → q ∨ p`.\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h\n        (fun hp : p =>\n          show q ∨ p from Or.intro_right q hp)\n        (fun hq : q =>\n          show q ∨ p from Or.intro_left p hq)\n    \n\nIn most cases, the first argument of `Or.intro_right` and `Or.intro_left` can\nbe inferred automatically by Lean. Lean therefore provides `Or.inr` and\n`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and\n`Or.intro_left _`. Thus the proof term above could be written more concisely:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nNotice that there is enough information in the full expression for Lean to\ninfer the types of `hp` and `hq` as well. But using the type annotations in\nthe longer version makes the proof more readable, and can help catch and debug\nerrors.\n\nBecause `Or` has two constructors, we cannot use anonymous constructor\nnotation. But we can still write `h.elim` instead of `Or.elim h`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nOnce again, you should exercise judgment as to whether such abbreviations\nenhance or diminish readability.\n\n### Negation and Falsity\n\nNegation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by\nderiving a contradiction from `p`. Similarly, the expression `hnp hp` produces\na proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both\nthese rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is\nproduced by typing `\\not` or `\\neg`.)\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hpq : p → q) (hnq : ¬q) : ¬p :=\n      fun hp : p =>\n      show False from hnq (hpq hp)\n    \n\nThe connective `False` has a single elimination rule, `False.elim`, which\nexpresses the fact that anything follows from a contradiction. This rule is\nsometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the\n_principle of explosion_.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)\n    \n\nThe arbitrary fact, `q`, that follows from falsity is an implicit argument in\n`False.elim` and is inferred automatically. This pattern, deriving an\narbitrary fact from contradictory hypotheses, is quite common, and is\nrepresented by `absurd`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := absurd hp hnp\n    \n\nHere, for example, is a proof of `¬p → q → (q → p) → r`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=\n      absurd (hqp hq) hnp\n    \n\nIncidentally, just as `False` has only an elimination rule, `True` has only an\nintroduction rule, `True.intro : true`. In other words, `True` is simply true,\nand has a canonical proof, `True.intro`.\n\n### Logical Equivalence\n\nThe expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`\nand `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from\n`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔\nq`. Here is a proof of `p ∧ q ↔ q ∧ p`:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      Iff.intro\n        (fun h : p ∧ q =>\n         show q ∧ p from And.intro (And.right h) (And.left h))\n        (fun h : q ∧ p =>\n         show p ∧ q from And.intro (And.right h) (And.left h))\n    \n    #check and_swap p q    -- p ∧ q ↔ q ∧ p\n    \n    variable (h : p ∧ q)\n    example : q ∧ p := Iff.mp (and_swap p q) h\n    \n\nWe can use the anonymous constructor notation to construct a proof of `p ↔ q`\nfrom proofs of the forward and backward directions, and we can also use `.`\nnotation with `mp` and `mpr`. The previous examples can therefore be written\nconcisely as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩\n    \n    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h\n    \n\n## Introducing Auxiliary Subgoals\n\nThis is a good place to introduce another device Lean offers to help structure\nlong proofs, namely, the `have` construct, which introduces an auxiliary\nsubgoal in a proof. Here is a small example, adapted from the last section:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      have hq : q := h.right\n      show q ∧ p from And.intro hq hp\n    \n\nInternally, the expression `have h : p := s; t` produces the term `(fun (h :\np) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the\ndesired conclusion assuming `h : p`, and the two are combined by a lambda\nabstraction and application. This simple device is extremely useful when it\ncomes to structuring long proofs, since we can use intermediate `have`\'s as\nstepping stones leading to the final goal.\n\nLean also supports a structured way of reasoning backwards from a goal, which\nmodels the "suffices to show" construction in ordinary mathematics. The next\nexample simply permutes the last two lines in the previous proof.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      suffices hq : q from And.intro hq hp\n      show q from And.right h\n    \n\nWriting `suffices hq : q` leaves us with two goals. First, we have to show\nthat it indeed suffices to show `q`, by proving the original goal of `q ∧ p`\nwith the additional hypothesis `hq : q`. Finally, we have to show `q`.\n\n## Classical Logic\n\nThe introduction and elimination rules we have seen so far are all\nconstructive, which is to say, they reflect a computational understanding of\nthe logical connectives based on the propositions-as-types correspondence.\nOrdinary classical logic adds to this the law of the excluded middle, `p ∨\n¬p`. To use this principle, you have to open the classical namespace.\n\n    \n    \n    open Classical\n    \n    variable (p : Prop)\n    #check em p\n    \n\nIntuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts\nto knowing which is the case. If `RH` represents the Riemann hypothesis, a\nclassical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot\nyet assert either disjunct.\n\nOne consequence of the law of the excluded middle is the principle of double-\nnegation elimination:\n\n    \n    \n    open Classical\n    \n    theorem dne {p : Prop} (h : ¬¬p) : p :=\n      Or.elim (em p)\n        (fun hp : p => hp)\n        (fun hnp : ¬p => absurd hnp h)\n    \n\nDouble-negation elimination allows one to prove any proposition, `p`, by\nassuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In\nother words, double-negation elimination allows one to carry out a proof by\ncontradiction, something which is not generally possible in constructive\nlogic. As an exercise, you might try proving the converse, that is, showing\nthat `em` can be proved from `dne`.\n\nThe classical axioms also give you access to additional patterns of proof that\ncan be justified by appeal to `em`. For example, one can carry out a proof by\ncases:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byCases\n        (fun h1 : p => h1)\n        (fun h1 : ¬p => absurd h1 h)\n    \n\nOr you can carry out a proof by contradiction:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byContradiction\n        (fun h1 : ¬p =>\n         show False from h h1)\n    \n\nIf you are not used to thinking constructively, it may take some time for you\nto get a sense of where classical reasoning is used. It is needed in the\nfollowing example because, from a constructive standpoint, knowing that `p`\nand `q` are not both true does not necessarily tell you which one is false:\n\n    \n    \n    open Classical\n    variable (p q : Prop)\n    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=\n      Or.elim (em p)\n        (fun hp : p =>\n          Or.inr\n            (show ¬q from\n              fun hq : q =>\n              h ⟨hp, hq⟩))\n        (fun hp : ¬p =>\n          Or.inl hp)\n    \n\nWe will see later that there _are_ situations in constructive logic where\nprinciples like excluded middle and double-negation elimination are\npermissible, and Lean supports the use of classical reasoning in such contexts\nwithout relying on excluded middle.\n\nThe full list of axioms that are used in Lean to support classical reasoning\nare discussed in [Axioms and Computation](./axioms_and_computation.html).\n\n## Examples of Propositional Validities\n\nLean\'s standard library contains proofs of many valid statements of\npropositional logic, all of which you are free to use in proofs of your own.\nThe following list includes a number of common identities.\n\nCommutativity:\n\n  1. `p ∧ q ↔ q ∧ p`\n  2. `p ∨ q ↔ q ∨ p`\n\nAssociativity:\n\n  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`\n  4. `(p ∨ q) ∨ r ↔ p ∨ (q �'}], 'model': 'gpt-4o'}}
2025-06-01 01:58:59,364 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:58:59,364 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:58:59,364 - DEBUG - send_request_headers.complete
2025-06-01 01:58:59,364 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:58:59,387 - DEBUG - send_request_body.complete
2025-06-01 01:58:59,387 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:59:08,228 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:59:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8548'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8552'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'14645'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'30.708s'), (b'x-request-id', b'req_43b596f09dc02a932beb6f2f7e504f19'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1bed392f4436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:59:08,229 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:59:08,229 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:59:08,229 - DEBUG - receive_response_body.complete
2025-06-01 01:59:08,229 - DEBUG - response_closed.started
2025-06-01 01:59:08,229 - DEBUG - response_closed.complete
2025-06-01 01:59:08,229 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:59:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8548', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8552', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '14645', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '30.708s', 'x-request-id': 'req_43b596f09dc02a932beb6f2f7e504f19', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1bed392f4436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:59:08,229 - DEBUG - request_id: req_43b596f09dc02a932beb6f2f7e504f19
2025-06-01 01:59:08,230 - INFO - Raw solution received: ```json
{
  "code": "if a = 0 ∨ b = 0 then false else a * b < 0",
  "proof": "by_cases h₁ : a = 0 ∨ b = 0\n  case inl =>\n    simp [h₁]\n  case inr h₂ =>\n    push_neg at h₂\n    cases h₂ with\n    | intro ha hb =>\n      by_cases h₃ : a * b < 0\n      case inl =>\n        simp [h₃]\n      case inr h₄ =>\n        simp [h₄]\n        cases (Int.sign_cases_on a) with\n        | inl ha_pos =>\n          cases (Int.sign_cases_on b) with\n          | inl hb_pos =>\n            exfalso\n            exact Int.not_lt_of_le (Int.mul_nonneg ha_pos hb_pos) h₄\n          | inr hb_neg =>\n            trivial\n        | inr ha_neg =>\n          cases (Int.sign_cases_on b) with\n          | inl hb_pos =>\n            trivial\n          | inr hb_neg =>\n            exfalso\n            exact Int.not_lt_of_le (Int.mul_nonneg ha_neg hb_neg) h₄\n"
}
```
2025-06-01 01:59:08,230 - INFO - <class 'str'>
2025-06-01 01:59:08,230 - INFO - Generated solution: {'code': 'if a = 0 ∨ b = 0 then false else a * b < 0', 'proof': 'by_cases h₁ : a = 0 ∨ b = 0\n  case inl =>\n    simp [h₁]\n  case inr h₂ =>\n    push_neg at h₂\n    cases h₂ with\n    | intro ha hb =>\n      by_cases h₃ : a * b < 0\n      case inl =>\n        simp [h₃]\n      case inr h₄ =>\n        simp [h₄]\n        cases (Int.sign_cases_on a) with\n        | inl ha_pos =>\n          cases (Int.sign_cases_on b) with\n          | inl hb_pos =>\n            exfalso\n            exact Int.not_lt_of_le (Int.mul_nonneg ha_pos hb_pos) h₄\n          | inr hb_neg =>\n            trivial\n        | inr ha_neg =>\n          cases (Int.sign_cases_on b) with\n          | inl hb_pos =>\n            trivial\n          | inr hb_neg =>\n            exfalso\n            exact Int.not_lt_of_le (Int.mul_nonneg ha_neg hb_neg) h₄\n'}
2025-06-01 01:59:13,420 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:22:2: error: Case tag 'inl' not found.

Available tags: 'pos._@.lean_playground.TempTest._hyg.93', 'neg._@.lean_playground.TempTest._hyg.93'
2025-06-01 01:59:13,421 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether two given integers have opposite signs. In other words, the method should return true if one integer is positive and the other is negative. Note that zero is considered neither positive nor negative; therefore, if either integer is zero, the method should return false.\n\n-----Input-----\nThe input consists of two integers:\na: An integer.\nb: An integer.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if one of the integers is positive and the other is negative (i.e., they have opposite signs).\nReturns false if both integers are either non-negative or non-positive, or if one (or both) is zero.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasOppositeSign (a : Int) (b : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if a and b have opposite signs\ndef hasOppositeSign_spec (a : Int) (b : Int) (result: Bool) : Prop :=\n  -- << SPEC START >>\n  (a < 0 ∧ b > 0) ∨ (a > 0 ∧ b < 0) ↔ result\n  -- << SPEC END >>\n\ntheorem hasOppositeSign_spec_satisfied (a : Int) (b : Int) :\n  hasOppositeSign_spec a b (hasOppositeSign a b) := by\n  -- << PROOF START >>\n  unfold hasOppositeSign hasOppositeSign_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a = 0 ∨ b = 0 then false else a * b < 0\n\nGenerated Proof:\nby_cases h₁ : a = 0 ∨ b = 0\n  case inl =>\n    simp [h₁]\n  case inr h₂ =>\n    push_neg at h₂\n    cases h₂ with\n    | intro ha hb =>\n      by_cases h₃ : a * b < 0\n      case inl =>\n        simp [h₃]\n      case inr h₄ =>\n        simp [h₄]\n        cases (Int.sign_cases_on a) with\n        | inl ha_pos =>\n          cases (Int.sign_cases_on b) with\n          | inl hb_pos =>\n            exfalso\n            exact Int.not_lt_of_le (Int.mul_nonneg ha_pos hb_pos) h₄\n          | inr hb_neg =>\n            trivial\n        | inr ha_neg =>\n          cases (Int.sign_cases_on b) with\n          | inl hb_pos =>\n            trivial\n          | inr hb_neg =>\n            exfalso\n            exact Int.not_lt_of_le (Int.mul_nonneg ha_neg hb_neg) h₄\n\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:22:2: error: Case tag 'inl' not found.\n\nAvailable tags: 'pos._@.lean_playground.TempTest._hyg.93', 'neg._@.lean_playground.TempTest._hyg.93'"}], 'model': 'o3-mini'}}
2025-06-01 01:59:13,421 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:59:13,421 - DEBUG - close.started
2025-06-01 01:59:13,421 - DEBUG - close.complete
2025-06-01 01:59:13,422 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:59:13,428 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eb4860>
2025-06-01 01:59:13,428 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:59:13,435 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eb46b0>
2025-06-01 01:59:13,435 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:59:13,436 - DEBUG - send_request_headers.complete
2025-06-01 01:59:13,436 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:59:13,436 - DEBUG - send_request_body.complete
2025-06-01 01:59:13,436 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:59:19,019 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:59:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5348'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5350'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199038'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'288ms'), (b'x-request-id', b'req_0e973ad9d11926e51f00beda0e429b9b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1c44fe393bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:59:19,019 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:59:19,019 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:59:19,020 - DEBUG - receive_response_body.complete
2025-06-01 01:59:19,020 - DEBUG - response_closed.started
2025-06-01 01:59:19,020 - DEBUG - response_closed.complete
2025-06-01 01:59:19,020 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:59:19 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5348', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5350', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199038', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '288ms', 'x-request-id': 'req_0e973ad9d11926e51f00beda0e429b9b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1c44fe393bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:59:19,020 - DEBUG - request_id: req_0e973ad9d11926e51f00beda0e429b9b
2025-06-01 01:59:19,020 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails due to incorrect case tags in the by_cases tactic. The generated proof uses 'inl' and 'inr' as case tags, but Lean 4 provides different tags (e.g., 'pos' and 'neg' for booleans) for the cases. You need to replace 'inl' with 'pos' and 'inr' with 'neg' (or use the appropriate case tags provided by Lean) in your case analysis.", 'error_type': 'syntax', 'suggested_fix': "Update the proof to use the correct case tags. For example, change 'case inl =>' to 'case pos =>' and 'case inr h₂ =>' to 'case neg h₂ =>'. Similarly, adjust all subsequent pattern matches that use 'inl' or 'inr' for boolean cases. This will align your proof with Lean 4's expected naming conventions for by_cases on booleans.", 'retry_strategy': "Modify the proof by replacing the incorrect case tags ('inl'/'inr') with the proper tags ('pos'/'neg'). Then re-run the Lean code to verify if the proof now compiles without errors. If further issues arise, re-examine the structure of the proof and ensure that each branch handles the cases as intended."}
2025-06-01 01:59:19,020 - INFO - Solution generated in 26.11 seconds
2025-06-01 01:59:19,021 - INFO - Generated code length: 5 characters
2025-06-01 01:59:19,021 - INFO - Generated proof length: 5 characters
2025-06-01 01:59:19,021 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 01:59:19,021 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 01:59:24,280 - INFO - Implementation test result: FAIL
2025-06-01 01:59:24,280 - ERROR - Implementation error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:17:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 01:59:24,280 - INFO - Executing Lean code with implementation and proof...
2025-06-01 01:59:29,423 - INFO - Full solution test result: FAIL
2025-06-01 01:59:29,423 - ERROR - Proof error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:17:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 01:59:29,423 - ERROR - ❌ Implementation fails unit tests
2025-06-01 01:59:29,423 - ERROR - ❌ Proof has errors
2025-06-01 01:59:29,423 - INFO - 
==================================================
2025-06-01 01:59:29,423 - INFO - Processing task task_id_77...
2025-06-01 01:59:29,423 - INFO - Reading problem description and code template from tasks/task_id_77...
2025-06-01 01:59:29,424 - INFO - Problem description length: 456 characters
2025-06-01 01:59:29,424 - INFO - Reading unit tests from tasks/task_id_77...
2025-06-01 01:59:29,424 - INFO - Unit tests length: 449 characters
2025-06-01 01:59:29,424 - INFO - Running main workflow to generate solution...
2025-06-01 01:59:29,424 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.

-----Input-----
The input consists of:
n: An integer to check for divisibility by 11.

-----Output-----
The output is a Boolean value:
Returns true if the input number is divisible by 11.
Returns false if the input number is not divisible by 11.
2025-06-01 01:59:29,424 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def isDivisibleBy11 (n : Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result is true if n is divisible by 11
def isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=
  -- << SPEC START >>
  n % 11 = 0 ↔ result
  -- << SPEC END >>

theorem isDivisibleBy11_spec_satisfied (n : Int) :
  isDivisibleBy11_spec n (isDivisibleBy11 n) := by
  -- << PROOF START >>
  unfold isDivisibleBy11 isDivisibleBy11_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 01:59:29,452 - DEBUG - close.started
2025-06-01 01:59:29,452 - DEBUG - close.complete
2025-06-01 01:59:29,452 - DEBUG - close.started
2025-06-01 01:59:29,453 - DEBUG - close.complete
2025-06-01 01:59:29,456 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7159b62ce700>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 01:59:29,457 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 01:59:29,457 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:59:29,464 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eafe90>
2025-06-01 01:59:29,464 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7159b62a80d0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:59:29,472 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eafc50>
2025-06-01 01:59:29,472 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:59:29,472 - DEBUG - send_request_headers.complete
2025-06-01 01:59:29,472 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:59:29,473 - DEBUG - send_request_body.complete
2025-06-01 01:59:29,473 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:59:29,832 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:59:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'39'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7c4bf98c9f-9w5mr'), (b'x-envoy-upstream-service-time', b'42'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999886'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_84b09bd055463267d6c30aeb51f56c6a'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=c9ler6a5bDImrdSW0msyjw8OH1wV1AwnRbzci2T4vzk-1748743169-1.0.1.1-OtRzs74KqPi7fDIL7OwDS4q19fEaiykNd43AgxB6iXdhb7cqQ00SO530vVk5N_QIEdV.4yQS5BEue1W5Ygw2_s6f_ZiCIBGto8menyV4nro; path=/; expires=Sun, 01-Jun-25 02:29:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Gy_rLImfCiyqyHnjyJUR0Z_ykpmKvQFzbPNeTkDtWro-1748743169832-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1ca94894ffa1-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:59:29,832 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 01:59:29,833 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:59:29,833 - DEBUG - receive_response_body.complete
2025-06-01 01:59:29,833 - DEBUG - response_closed.started
2025-06-01 01:59:29,833 - DEBUG - response_closed.complete
2025-06-01 01:59:29,833 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 01:59:29 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '39'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-7c4bf98c9f-9w5mr'), ('x-envoy-upstream-service-time', '42'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999886'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '6ms'), ('x-request-id', 'req_84b09bd055463267d6c30aeb51f56c6a'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=c9ler6a5bDImrdSW0msyjw8OH1wV1AwnRbzci2T4vzk-1748743169-1.0.1.1-OtRzs74KqPi7fDIL7OwDS4q19fEaiykNd43AgxB6iXdhb7cqQ00SO530vVk5N_QIEdV.4yQS5BEue1W5Ygw2_s6f_ZiCIBGto8menyV4nro; path=/; expires=Sun, 01-Jun-25 02:29:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Gy_rLImfCiyqyHnjyJUR0Z_ykpmKvQFzbPNeTkDtWro-1748743169832-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b1ca94894ffa1-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 01:59:29,833 - DEBUG - request_id: req_84b09bd055463267d6c30aeb51f56c6a
2025-06-01 01:59:29,856 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
 the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
2025-06-01 01:59:29,904 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.'}], 'model': 'o3-mini'}}
2025-06-01 01:59:29,906 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:59:29,907 - DEBUG - close.started
2025-06-01 01:59:29,907 - DEBUG - close.complete
2025-06-01 01:59:29,907 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:59:29,934 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b677af60>
2025-06-01 01:59:29,934 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:59:29,963 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b677ab10>
2025-06-01 01:59:29,967 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:59:29,967 - DEBUG - send_request_headers.complete
2025-06-01 01:59:29,967 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:59:29,967 - DEBUG - send_request_body.complete
2025-06-01 01:59:29,967 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:59:35,180 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:59:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4951'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4955'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199585'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'124ms'), (b'x-request-id', b'req_3cb55635f5139e2b3bfcffb5b3b7f223'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1cac78894436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:59:35,180 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:59:35,180 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:59:35,181 - DEBUG - receive_response_body.complete
2025-06-01 01:59:35,181 - DEBUG - response_closed.started
2025-06-01 01:59:35,181 - DEBUG - response_closed.complete
2025-06-01 01:59:35,181 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:59:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4951', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4955', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199585', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '124ms', 'x-request-id': 'req_3cb55635f5139e2b3bfcffb5b3b7f223', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1cac78894436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:59:35,181 - DEBUG - request_id: req_3cb55635f5139e2b3bfcffb5b3b7f223
2025-06-01 01:59:35,182 - INFO - Attempt 1/3
2025-06-01 01:59:35,182 - INFO - Current plan: {
  "plan_summary": "Implement a Lean 4 function that checks if an integer is divisible by 11 by computing the remainder of dividing the integer by 11 and comparing it to zero.",
  "steps": [
    "Define the function signature accepting an integer 'n'.",
    "Use the modulo operator (%) to compute 'n % 11'.",
    "Compare the result of the modulo operation with 0.",
    "Return true if the remainder is 0 (indicating divisibility by 11), otherwise return false."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "integer modulus",
    "modulo operator",
    "if statement"
  ],
  "proof_keywords": [
    "divisibility",
    "modular arithmetic",
    "basic arithmetic property"
  ],
  "assumptions": [
    "The Lean 4 language handles integer arithmetic with the modulo operator.",
    "The basic syntax for defining functions and using conditionals in Lean 4 is known."
  ],
  "retry_guidance": "If previous errors arise related to type mismatches or use of the modulo operator, verify that the correct integer type and modulo function are being used in Lean 4."
}
2025-06-01 01:59:35,182 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Implement a Lean 4 function that checks if an integer is divisible by 11 by computing the remainder of dividing the integer by 11 and comparing it to zero.",\n  "steps": [\n    "Define the function signature accepting an integer \'n\'.",\n    "Use the modulo operator (%) to compute \'n % 11\'.",\n    "Compare the result of the modulo operation with 0.",\n    "Return true if the remainder is 0 (indicating divisibility by 11), otherwise return false."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "integer modulus",\n    "modulo operator",\n    "if statement"\n  ],\n  "proof_keywords": [\n    "divisibility",\n    "modular arithmetic",\n    "basic arithmetic property"\n  ],\n  "assumptions": [\n    "The Lean 4 language handles integer arithmetic with the modulo operator.",\n    "The basic syntax for defining functions and using conditionals in Lean 4 is known."\n  ],\n  "retry_guidance": "If previous errors arise related to type mismatches or use of the modulo operator, verify that the correct integer type and modulo function are being used in Lean 4."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  n % 11 = 0 ↔ result\n  -- << SPEC END >>\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- << PROOF START >>\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The'}], 'model': 'gpt-4o'}}
2025-06-01 01:59:35,184 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:59:35,184 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:59:35,184 - DEBUG - send_request_headers.complete
2025-06-01 01:59:35,184 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:59:35,207 - DEBUG - send_request_body.complete
2025-06-01 01:59:35,207 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:59:37,770 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:59:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2252'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2254'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'16312'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'27.376s'), (b'x-request-id', b'req_4a80fd6f2c18328f464505b203dd8b9f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1ccd18ba4436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:59:37,770 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:59:37,770 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:59:37,772 - DEBUG - receive_response_body.complete
2025-06-01 01:59:37,772 - DEBUG - response_closed.started
2025-06-01 01:59:37,772 - DEBUG - response_closed.complete
2025-06-01 01:59:37,772 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:59:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2252', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2254', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '16312', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '27.376s', 'x-request-id': 'req_4a80fd6f2c18328f464505b203dd8b9f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1ccd18ba4436-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:59:37,773 - DEBUG - request_id: req_4a80fd6f2c18328f464505b203dd8b9f
2025-06-01 01:59:37,773 - INFO - Raw solution received: ```json
{
  "code": "n % 11 == 0",
  "proof": "by_cases (n % 11 = 0)\n  simp [*]\n  case pos => trivial\n  case neg =>\n    simp [*] at *\n    exfalso\n    apply h\n    assumption"
}
```
2025-06-01 01:59:37,773 - INFO - <class 'str'>
2025-06-01 01:59:37,773 - INFO - Generated solution: {'code': 'n % 11 == 0', 'proof': 'by_cases (n % 11 = 0)\n  simp [*]\n  case pos => trivial\n  case neg =>\n    simp [*] at *\n    exfalso\n    apply h\n    assumption'}
2025-06-01 01:59:42,907 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:23:2: error: Case tag 'pos' not found.

The only available case tag is 'neg._@.lean_playground.TempTest._hyg.43'.
2025-06-01 01:59:42,908 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines whether a given integer is divisible by 11. The method should return true if the number is divisible by 11 and false otherwise.\n\n-----Input-----\nThe input consists of:\nn: An integer to check for divisibility by 11.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the input number is divisible by 11.\nReturns false if the input number is not divisible by 11.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  n % 11 = 0 ↔ result\n  -- << SPEC END >>\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  -- << PROOF START >>\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nn % 11 == 0\n\nGenerated Proof:\nby_cases (n % 11 = 0)\n  simp [*]\n  case pos => trivial\n  case neg =>\n    simp [*] at *\n    exfalso\n    apply h\n    assumption\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:23:2: error: Case tag 'pos' not found.\n\nThe only available case tag is 'neg._@.lean_playground.TempTest._hyg.43'."}], 'model': 'o3-mini'}}
2025-06-01 01:59:42,909 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 01:59:42,909 - DEBUG - close.started
2025-06-01 01:59:42,909 - DEBUG - close.complete
2025-06-01 01:59:42,909 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 01:59:42,915 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b40b0>
2025-06-01 01:59:42,915 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 01:59:42,924 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b7110>
2025-06-01 01:59:42,924 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 01:59:42,924 - DEBUG - send_request_headers.complete
2025-06-01 01:59:42,924 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 01:59:42,924 - DEBUG - send_request_body.complete
2025-06-01 01:59:42,924 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 01:59:52,668 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 01:59:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'9517'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'9522'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199290'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'213ms'), (b'x-request-id', b'req_c481b09c0236c04d30f01018ffb581b6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1cfd4c493bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 01:59:52,668 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 01:59:52,668 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 01:59:52,669 - DEBUG - receive_response_body.complete
2025-06-01 01:59:52,669 - DEBUG - response_closed.started
2025-06-01 01:59:52,669 - DEBUG - response_closed.complete
2025-06-01 01:59:52,669 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 01:59:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '9517', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '9522', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199290', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '213ms', 'x-request-id': 'req_c481b09c0236c04d30f01018ffb581b6', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1cfd4c493bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 01:59:52,669 - DEBUG - request_id: req_c481b09c0236c04d30f01018ffb581b6
2025-06-01 01:59:52,669 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof uses a by_cases tactic with case tags 'pos' and 'neg', but Lean does not provide a case tag 'pos'. Only one case tag (with a generated name starting with 'neg') is available. This error suggests that the pattern matching in the proof script is incorrect.", 'error_type': 'proof', 'suggested_fix': "Replace the by_cases block with a pattern that doesn't name cases using 'pos' and 'neg'. For example, you can write the proof using a by_cases on the hypothesis and then use separate blocks for each case. Here is a revised version:\n\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isDivisibleBy11 (n : Int) : Bool :=\n  n % 11 == 0\n\n-- Theorem: The result is true if n is divisible by 11\ndef isDivisibleBy11_spec (n : Int) (result : Bool) : Prop :=\n  n % 11 = 0 ↔ result\n\ntheorem isDivisibleBy11_spec_satisfied (n : Int) :\n  isDivisibleBy11_spec n (isDivisibleBy11 n) := by\n  unfold isDivisibleBy11 isDivisibleBy11_spec\n  by_cases h: n % 11 = 0\n  { simp [h] }\n  { simp [h] }", 'retry_strategy': 'Please update the proof script as suggested and re-run the Lean code to verify that the proof checks successfully.'}
2025-06-01 01:59:52,669 - INFO - Solution generated in 23.25 seconds
2025-06-01 01:59:52,669 - INFO - Generated code length: 5 characters
2025-06-01 01:59:52,670 - INFO - Generated proof length: 5 characters
2025-06-01 01:59:52,670 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 01:59:52,670 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 01:59:57,917 - INFO - Implementation test result: FAIL
2025-06-01 01:59:57,917 - ERROR - Implementation error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:17:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 01:59:57,917 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:00:03,211 - INFO - Full solution test result: FAIL
2025-06-01 02:00:03,211 - ERROR - Proof error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:17:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:00:03,211 - ERROR - ❌ Implementation fails unit tests
2025-06-01 02:00:03,211 - ERROR - ❌ Proof has errors
2025-06-01 02:00:03,212 - INFO - 
==================================================
2025-06-01 02:00:03,212 - INFO - Processing task task_id_127...
2025-06-01 02:00:03,212 - INFO - Reading problem description and code template from tasks/task_id_127...
2025-06-01 02:00:03,213 - INFO - Problem description length: 342 characters
2025-06-01 02:00:03,213 - INFO - Reading unit tests from tasks/task_id_127...
2025-06-01 02:00:03,214 - INFO - Unit tests length: 219 characters
2025-06-01 02:00:03,214 - INFO - Running main workflow to generate solution...
2025-06-01 02:00:03,214 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.

-----Input-----
The input consists of:
a: The first integer.
b: The second integer.

-----Output-----
The output is an integer:
Returns the product of the two input integers (a * b).
2025-06-01 02:00:03,214 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def multiply (a : Int) (b : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The result should be the product of the two input integers
def multiply_spec (a : Int) (b : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  result = a * b
  -- << SPEC END >>

theorem multiply_spec_satisfied (a : Int) (b : Int) :
  multiply_spec a b (multiply a b) := by
  -- << PROOF START >>
  unfold multiply multiply_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:00:03,250 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7159b62a1b20>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.\n\n-----Input-----\nThe input consists of:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the product of the two input integers (a * b).', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:00:03,250 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:00:03,250 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:00:03,258 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x715aa057cc20>
2025-06-01 02:00:03,258 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7159b62c8450> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:00:03,268 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b4800>
2025-06-01 02:00:03,268 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:00:03,268 - DEBUG - send_request_headers.complete
2025-06-01 02:00:03,268 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:00:03,268 - DEBUG - send_request_body.complete
2025-06-01 02:00:03,268 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:00:03,652 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:00:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'83'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-dc9d5f6f7-brktq'), (b'x-envoy-upstream-service-time', b'86'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999914'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'x-request-id', b'req_3b3c7b8ec7a3138127a89c28e24c96cd'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=w6rL3JQzRmE9N9oSq1Qve_qUnadZkWHVxh3K.rh7dMk-1748743203-1.0.1.1-lBmnibOzXEYvXGd4GrMHstCetiy2C1sHx4o47IzUbbsKSVurv0urbu6LrgxPPiQQLkME8dIVpYJk9tyOdp2NmkMwgejikhRX7TT2uK.RnGM; path=/; expires=Sun, 01-Jun-25 02:30:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=35BUy0VDmezMN3nvm9Nw01RUVaI4q73VfbJJwOiTU1c-1748743203654-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1d7c7fcd4436-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:00:03,653 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:00:03,653 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:00:03,653 - DEBUG - receive_response_body.complete
2025-06-01 02:00:03,653 - DEBUG - response_closed.started
2025-06-01 02:00:03,653 - DEBUG - response_closed.complete
2025-06-01 02:00:03,653 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:00:03 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '83'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-dc9d5f6f7-brktq'), ('x-envoy-upstream-service-time', '86'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999914'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '5ms'), ('x-request-id', 'req_3b3c7b8ec7a3138127a89c28e24c96cd'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=w6rL3JQzRmE9N9oSq1Qve_qUnadZkWHVxh3K.rh7dMk-1748743203-1.0.1.1-lBmnibOzXEYvXGd4GrMHstCetiy2C1sHx4o47IzUbbsKSVurv0urbu6LrgxPPiQQLkME8dIVpYJk9tyOdp2NmkMwgejikhRX7TT2uK.RnGM; path=/; expires=Sun, 01-Jun-25 02:30:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=35BUy0VDmezMN3nvm9Nw01RUVaI4q73VfbJJwOiTU1c-1748743203654-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b1d7c7fcd4436-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:00:03,654 - DEBUG - request_id: req_3b3c7b8ec7a3138127a89c28e24c96cd
2025-06-01 02:00:03,659 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Interacting with Lean

You are now familiar with the fundamentals of dependent type theory, both as a
language for defining mathematical objects and a language for constructing
proofs. The one thing you are missing is a mechanism for defining new data
types. We will fill this gap in the next chapter, which introduces the notion
of an _inductive data type_. But first, in this chapter, we take a break from
the mechanics of type theory to explore some pragmatic aspects of interacting
with Lean.

Not all of the information found here will be useful to you right away. We
recommend skimming this section to get a sense of Lean's features, and then
returning to it as necessary.

## Importing Files

The goal of Lean's front end is to interpret user input, construct formal
expressions, and check that they are well-formed and type-correct. Lean also
supports the use of various editors, which provide continuous checking and
feedback. More information can be found on the Lean [documentation
pages](https://lean-lang.org/documentation/).

The definitions and theorems in Lean's standard library are spread across
multiple files. Users may also wish to make use of additional libraries, or
develop their own projects across multiple files. When Lean starts, it
automatically imports the contents of the library `Init` folder, which
includes a number of fundamental definitions and constructions. As a result,
most of the examples we present here work "out of the box."

If you want to use additional files, however, they need to be imported
manually, via an `import` statement at the beginning of a file. The command

    
    
    import Bar.Baz.Blah
    

imports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted
relative to the Lean _search path_. Information as to how the search path is
determined can be found on the [documentation pages](https://lean-
lang.org/documentation/). By default, it includes the standard library
directory, and (in some contexts) the root of the user's local project.

Importing is transitive. In other words, if you import `Foo` and `Foo` imports
`Bar`, then you also have access to the contents of `Bar`, and do not need to
import it explicitly.

## More on Sections

Lean provides various sectioning mechanisms to help structure a theory. You
saw in [Variables and Sections](./dependent_type_theory.html#variables-and-
sections) that the `section` command makes it possible not only to group
together elements of a theory that go together, but also to declare variables
that are inserted as arguments to theorems and definitions, as necessary.
Remember that the point of the `variable` command is to declare variables for
use in theorems, as in the following example:

    
    
    section
    variable (x y : Nat)
    
    def double := x + x
    
    #check double y
    #check double (2 * x)
    
    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm
    
    theorem t1 : double (x + y) = double x + double y := by
      simp [double]
    
    #check t1 y
    #check t1 (2 * x)
    
    theorem t2 : double (x * y) = double x * y := by
      simp [double, Nat.add_mul]
    
    end
    

The definition of `double` does not have to declare `x` as an argument; Lean
detects the dependence and inserts it automatically. Similarly, Lean detects
the occurrence of `x` in `t1` and `t2`, and inserts it automatically there,
too. Note that `double` does _not_ have `y` as argument. Variables are only
included in declarations where they are actually used.

## More on Namespaces

In Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We
saw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean
provides mechanisms for working with hierarchical names. The command
`namespace foo` causes `foo` to be prepended to the name of each definition
and theorem until `end foo` is encountered. The command `open foo` then
creates temporary _aliases_ to definitions and theorems that begin with prefix
`foo`.

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    
    open Foo
    
    #check bar
    #check Foo.bar
    

The following definition

    
    
    def Foo.bar : Nat := 1
    

is treated as a macro, and expands to

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    

Although the names of theorems and definitions have to be unique, the aliases
that identify them do not. When we open a namespace, an identifier may be
ambiguous. Lean tries to use type information to disambiguate the meaning in
context, but you can always disambiguate by giving the full name. To that end,
the string `_root_` is an explicit description of the empty prefix.

    
    
    def String.add (a b : String) : String :=
      a ++ b
    
    def Bool.add (a b : Bool) : Bool :=
      a != b
    
    def add (α β : Type) : Type := Sum α β
    
    open Bool
    open String
    -- #check add -- ambiguous
    #check String.add           -- String → String → String
    #check Bool.add             -- Bool → Bool → Bool
    #check _root_.add           -- Type → Type → Type
    
    #check add "hello" "world"  -- String
    #check add true false       -- Bool
    #check add Nat Nat          -- Type
    

We can prevent the shorter alias from being created by using the `protected`
keyword:

    
    
    protected def Foo.bar : Nat := 1
    
    open Foo
    
    -- #check bar -- error
    #check Foo.bar
    

This is often used for names like `Nat.rec` and `Nat.recOn`, to prevent
overloading of common names.

The `open` command admits variations. The command

    
    
    open Nat (succ zero gcd)
    #check zero     -- Nat
    #eval gcd 15 6  -- 3
    

creates aliases for only the identifiers listed. The command

    
    
    open Nat hiding succ gcd
    #check zero     -- Nat
    -- #eval gcd 15 6  -- error
    #eval Nat.gcd 15 6  -- 3
    

creates aliases for everything in the `Nat` namespace _except_ the identifiers
listed.

    
    
    open Nat renaming mul → times, add → plus
    #eval plus (times 2 2) 3  -- 7
    

creates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.

It is sometimes useful to `export` aliases from one namespace to another, or
to the top level. The command

    
    
    export Nat (succ add sub)
    

creates aliases for `succ`, `add`, and `sub` in the current namespace, so that
whenever the namespace is open, these aliases are available. If this command
is used outside a namespace, the aliases are exported to the top level.

## Attributes

The main function of Lean is to translate user input to formal expressions
that are checked by the kernel for correctness and then stored in the
environment for later use. But some commands have other effects on the
environment, either assigning attributes to objects in the environment,
defining notation, or declaring instances of type classes, as described in
[Chapter Type Classes](./type_classes.html). Most of these commands have
global effects, which is to say, they remain in effect not only in the current
file, but also in any file that imports it. However, such commands often
support the `local` modifier, which indicates that they only have effect until
the current `section` or `namespace` is closed, or until the end of the
current file.

In [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw
that theorems can be annotated with the `[simp]` attribute, which makes them
available for use by the simplifier. The following example defines the prefix
relation on lists, proves that this relation is reflexive, and assigns the
`[simp]` attribute to that theorem.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    

The simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to
`True`.

One can also assign the attribute any time after the definition takes place:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [simp] List.isPrefix_self
    

In all these cases, the attribute remains in effect in any file that imports
the one in which the declaration occurs. Adding the `local` modifier restricts
the scope:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    section
    
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [local simp] List.isPrefix_self
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    
    end
    
    -- Error:
    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by
    --  simp
    

For another example, we can use the `instance` command to assign the notation
`≤` to the `isPrefix` relation. That command, which will be explained in
[Chapter Type Classes](./type_classes.html), works by assigning an
`[instance]` attribute to the associated definition.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    instance : LE (List α) where
      le := isPrefix
    
    theorem List.isPrefix_self (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    

That assignment can also be made local:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    def instLe : LE (List α) :=
      { le := isPrefix }
    
    section
    attribute [local instance] instLe
    
    example (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    
    end
    
    -- Error:
    -- example (as : List α) : as ≤ as :=
    --  ⟨[], by simp⟩
    

In Section Notation below, we will discuss Lean's mechanisms for defining
notation, and see that they also support the `local` modifier. However, in
Section Setting Options, we will discuss Lean's mechanisms for setting
options, which does _not_ follow this pattern: options can _only_ be set
locally, which is to say, their scope is always restricted to the current
section or current file.

## More on Implicit Arguments

In [Section Implicit Arguments](./dependent_type_theory.html#implicit-
arguments), we saw that if Lean displays the type of a term `t` as `{x : α} →
β x`, then the curly brackets indicate that `x` has been marked as an
_implicit argument_ to `t`. This means that whenever you write `t`, a
placeholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you
don't want that to happen, you have to write `@t` instead.

Notice that implicit arguments are inserted eagerly. Suppose we define a
function `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,
when we write the expression `f 7` without further arguments, it is parsed as
`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that
a placeholder should only be added _before_ a subsequent explicit argument.
This annotation can also be written using as `⦃y : Nat⦄`, where the unicode
brackets are entered as `\{{` and `\}}`, respectively. With this annotation,
the expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as
`f 7 _ 3`, just as it would be with the strong annotation.

To illustrate the difference, consider the following example, which shows that
a reflexive euclidean relation is both symmetric and transitive.

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b : α}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
     th2 (th1 reflr @euclr) @euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3
    

The results are broken down into small steps: `th1` shows that a relation that
is reflexive and euclidean is symmetric, and `th2` shows that a relation that
is symmetric and euclidean is transitive. Then `th3` combines the two results.
But notice that we have to manually disable the implicit arguments in `euclr`,
because otherwise too many implicit arguments are inserted. The problem goes
away if we use weak implicit arguments:

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b : α}}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
      th2 (th1 reflr euclr) euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- euclidean r
    

There is a third kind of implicit argument that is denoted with square
brackets, `[` and `]`. These are used for type classes, as explained in
[Chapter Type Classes](./type_classes.html).

## Notation

Identifiers in Lean can include any alphanumeric characters, including Greek
characters (other than ∀ , Σ , and λ , which, as we have seen, have a special
meaning in the dependent type theory). They can also include subscripts, which
can be entered by typing `\_` followed by the desired subscripted character.

Lean's parser is extensible, which is to say, we can define new notation.

Lean's syntax can be extended and customized by users at every level, ranging
from basic "mixfix" notations to custom elaborators. In fact, all builtin
syntax is parsed and processed using the same mechanisms and APIs open to
users. In this section, we will describe and explain the various extension
points.

While introducing new notations is a relatively rare feature in programming
languages and sometimes even frowned upon because of its potential to obscure
code, it is an invaluable tool in formalization for expressing established
conventions and notations of the respective field succinctly in code. Going
beyond basic notations, Lean's ability to factor out common boilerplate code
into (well-behaved) macros and to embed entire custom domain specific
languages (DSLs) to textually encode subproblems efficiently and readably can
be of great benefit to both programmers and proof engineers alike.

### Notations and Precedence

The most basic syntax extension commands allow introducing new (or overloading
existing) prefix, infix, and postfix operators.

    
    
    infixl:65   " + " => HAdd.hAdd  -- left-associative
    infix:50    " = " => Eq         -- non-associative
    infixr:80   " ^ " => HPow.hPow  -- right-associative
    prefix:100  "-"   => Neg.neg
    set_option quotPrecheck false
    postfix:max "⁻¹"  => Inv.inv
    

After the initial command name describing the operator kind (its "fixity"), we
give the _parsing precedence_ of the operator preceded by a colon `:`, then a
new or existing token surrounded by double quotes (the whitespace is used for
pretty printing), then the function this operator should be translated to
after the arrow `=>`.

The precedence is a natural number describing how "tightly" an operator binds
to its arguments, encoding the order of operations. We can make this more
precise by looking at the commands the above unfold to:

    
    
    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs
    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs
    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs
    notation:100 "-" arg:100 => Neg.neg arg
    set_option quotPrecheck false
    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024
    

It turns out that all commands from the first code block are in fact command
_macros_ translating to the more general `notation` command. We will learn
about writing such macros below. Instead of a single token, the `notation`
command accepts a mixed sequence of tokens and named term placeholders with
precedences, which can be referenced on the right-hand side of `=>` and will
be replaced by the respective term parsed at that position. A placeholder with
precedence `p` accepts only notations with precedence at least `p` in that
place. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +
(b + c)` because the right-hand side operand of an `infixl` notation has
precedence one greater than the notation itself. In contrast, `infixr` reuses
the notation's precedence for the right-hand side operand, so `a ^ b ^ c`
_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to
introduce an infix notation like

    
    
    set_option quotPrecheck false
    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs
    

where the precedences do not sufficiently determine associativity, Lean's
parser will default to right associativity. More precisely, Lean's parser
follows a local _longest parse_ rule in the presence of ambiguous grammars:
when parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue
parsing as long as possible (as the current precedence allows), not stopping
after `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~
c)`.

As mentioned above, the `notation` command allows us to define arbitrary
_mixfix_ syntax freely mixing tokens and placeholders.

    
    
    set_option quotPrecheck false
    notation:max "(" e ")" => e
    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ
    

Placeholders without precedence default to `0`, i.e. they accept notations of
any precedence in their place. If two notations overlap, we again apply the
longest parse rule:

    
    
    notation:65 a " + " b:66 " + " c:66 => a + b - c
    #eval 1 + 2 + 3  -- 0
    

The new notation is preferred to the binary notation since the latter, before
chaining, would stop parsing after `1 + 2`. If there are multiple notations
accepting the same longest parse, the choice will be delayed until
elaboration, which will fail unless exactly one overload is type-correct.

## Coercions

In Lean, the type of natural numbers, `Nat`, is different from the type of
integers, `Int`. But there is a function `Int.ofNat` that embeds the natural
numbers in the integers, meaning that we can view any natural number as an
integer, when needed. Lean has mechanisms to detect and insert _coercions_ of
this sort.

    
    
    variable (m n : Nat)
    variable (i j : Int)
    
    #check i + m      -- i + Int.ofNat m : Int
    #check i + m + j  -- i + Int.ofNat m + j : Int
    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int
    

## Displaying Information

There are a number of ways in which you can query Lean for information about
its current state and the objects and theorems that are available in the
current context. You have already seen two of the most common ones, `#check`
and `#eval`. Remember that `#check` is often used in conjunction with the `@`
operator, which makes all of the arguments to a theorem or definition
explicit. In addition, you can use the `#print` command to get information
about any identifier. If the identifier denotes a definition or theorem, Lean
prints the type of the symbol, and its definition. If it is a constant or an
axiom, Lean indicates that fact, and shows the type.

    
    
    -- examples with equality
    #check Eq
    #check @Eq
    #check Eq.symm
    #check @Eq.symm
    
    #print Eq.symm
    
    -- examples with And
    #check And
    #check And.intro
    #check @And.intro
    
    -- a user-defined function
    def foo {α : Type u} (x : α) : α := x
    
    #check foo
    #check @foo
    #print foo
    

## Setting Options

Lean maintains a number of internal variables that can be set by users to
control its behavior. The syntax for doing so is as follows:

    
    
    set_option <name> <value>
    

One very useful family of options controls the way Lean's _pretty- printer_
displays terms. The following options take an input of true or false:

    
    
    pp.explicit  : display implicit arguments
    pp.universes : display hidden universe parameters
    pp.notation  : display output using defined notations
    

As an example, the following settings yield much longer output:

    
    
    set_option pp.explicit true
    set_option pp.universes true
    set_option pp.notation false
    
    #check 2 + 2 = 4
    #reduce (fun x => x + 2) = (fun x => x + 3)
    #check (fun x => x + 1) 1
    

The command `set_option pp.all true` carries out these settings all at once,
whereas `set_option pp.all false` reverts to the previous values. Pretty
printing additional information is often very useful when you are debugging a
proof, or trying to understand a cryptic error message. Too much information
can be overwhelming, though, and Lean's defaults are generally sufficient for
ordinary interactions.

## Using the Library

To use Lean effectively you will inevitably need to make use of definitions
and theorems in the library. Recall that the `import` command at the beginning
of a file imports previously compiled results from other files, and that
importing is transitive; if you import `Foo` and `Foo` imports `Bar`, then the
definitions and theorems from `Bar` are available to you as well. But the act
of opening a namespace, which provides shorter names, does not carry over. In
each file, you need to open the namespaces you wish to use.

In general, it is important for you to be familiar with the library and its
contents, so you know what theorems, definitions, notations, and resources are
available to you. Below we will see that Lean's editor modes can also help you
find things you need, but studying the contents of the library directly is
often unavoidable. Lean's standard library can be found online, on GitHub:

  * <https://github.com/leanprover/lean4/tree/master/src/Init>

  * <https://github.com/leanprover/std4/tree/main/Std>

You can see the contents of these directories and files using GitHub's browser
interface. If you have installed Lean on your own computer, you can find the
library in the `lean` folder, and explore it with your file manager. Comment
headers at the top of each file provide additional information.

Lean's library developers follow general naming guidelines to make it easier
to guess the name of a theorem you need, or to find it using tab completion in
editors with a Lean mode that supports this, which is discussed in the next
section. Identifiers are generally `camelCase`, and types are `CamelCase`. For
theorem names, we rely on descriptive names where the different components are
separated by `_`s. Often the name of theorem simply describes the conclusion:

    
    
    #check Nat.succ_ne_zero
    #check Nat.zero_add
    #check Nat.mul_one
    #check Nat.le_of_succ_le_succ
    

Remember that identifiers in Lean can be organized into hierarchical
namespaces. For example, the theorem named `le_of_succ_le_succ` in the
namespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name
is made available by the command `open Nat` (for names not marked as
`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)
and [Chapter Structures and Records](./structures_and_records.html) that
defining structures and inductive data types in Lean generates associated
operations, and these are stored in a namespace with the same name as the type
under definition. For example, the product type comes with the following
operations:

    
    
    #check @Prod.mk
    #check @Prod.fst
    #check @Prod.snd
    #check @Prod.rec
    

The first is used to construct a pair, whereas the next two, `Prod.fst` and
`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another
mechanism for defining functions on a product in terms of a function on the
two components. Names like `Prod.rec` are _protected_ , which means that one
has to use the full name even when the `Prod` namespace is open.

With the propositions as types correspondence, logical connectives are also
instances of inductive types, and so we tend to use dot notation for them as
well:

    
    
    #check @And.intro
    #check @And.casesOn
    #check @And.left
    #check @And.right
    #check @Or.inl
    #check @Or.inr
    #check @Or.elim
    #check @Exists.intro
    #check @Exists.elim
    #check @Eq.refl
    #check @Eq.subst
    

## Auto Bound Implicit Arguments

In the previous section, we have shown how implicit arguments make functions
more convenient to use. However, functions such as `compose` are still quite
verbose to define. Note that the universe polymorphic `compose` is even more
verbose than the one previously defined.

    
    
    universe u v w
    def compose {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

You can avoid the `universe` command by providing the universe parameters when
defining `compose`.

    
    
    def compose.{u, v, w}
                {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

Lean 4 supports a new feature called _auto bound implicit arguments_. It makes
functions such as `compose` much more convenient to write. When Lean processes
the header of a declaration, any unbound identifier is automatically added as
an implicit argument _if_ it is a single lower case or greek letter. With this
feature we can write `compose` as

    
    
    def compose (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    
    #check @compose
    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ
    

Note that Lean inferred a more general type using `Sort` instead of `Type`.

Although we love this feature and use it extensively when implementing Lean,
we realize some users may feel uncomfortable with it. Thus, you can disable it
using the command `set_option autoImplicit false`.

    
    
    set_option autoImplicit false
    /- The following definition produces `unknown identifier` errors -/
    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=
    --   g (f x)
    

## Implicit Lambdas

In Lean 3 stdlib, we find many
[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)
of the dreadful `@`+`_` idiom. It is often used when the expected type is a
function type with implicit arguments, and we have a constant (`reader_t.pure`
in the example) which also takes implicit arguments. In Lean 4, the elaborator
automatically introduces lambdas for consuming implicit arguments. We are
still exploring this feature and analyzing its impact, but the experience so
far has been very positive. Here is the example from the link above using Lean
4 implicit lambdas.

    
    
    variable (ρ : Type) (m : Type → Type) [Monad m]
    instance : Monad (ReaderT ρ m) where
      pure := ReaderT.pure
      bind := ReaderT.bind
    

Users can disable the implicit lambda feature by using `@` or writing a lambda
expression with `{}` or `[]` binder annotations. Here are few examples

    
    
    namespace ex2
    def id1 : {α : Type} → α → α :=
      fun x => x
    
    def listId : List ({α : Type} → α → α) :=
      (fun x => x) :: []
    
    -- In this example, implicit lambda introduction has been disabled because
    -- we use `@` before `fun`
    def id2 : {α : Type} → α → α :=
      @fun α (x : α) => id1 x
    
    def id3 : {α : Type} → α → α :=
      @fun α x => id1 x
    
    def id4 : {α : Type} → α → α :=
      fun x => id1 x
    
    -- In this example, implicit lambda introduction has been disabled
    -- because we used the binder annotation `{...}`
    def id5 : {α : Type} → α → α :=
      fun {α} x => id1 x
    end ex2
    

## Sugar for Simple Functions

In Lean 3, we can create simple functions from infix operators by using
parentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we
generalize this notation using `·` as a placeholder. Here are a few examples:

    
    
    namespace ex3
    #check (· + 1)
    -- fun a => a + 1
    #check (2 - ·)
    -- fun a => 2 - a
    #eval [1, 2, 3, 4, 5].foldl (·*·) 1
    -- 120
    
    def f (x y z : Nat) :=
      x + y + z
    
    #check (f · 1 ·)
    -- fun a b => f a 1 b
    
    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)
    -- [1, 3, 5]
    end ex3
    

As in Lean 3, the notation is activated using parentheses, and the lambda
abstraction is created by collecting the nested `·`s. The collection is
interrupted by nested parentheses. In the following example, two different
lambda expressions are created.

    
    
    #check (Prod.mk · (· + 1))
    -- fun a => (a, fun b => b + 1)
    

## Named Arguments

Named arguments enable you to specify an argument for a parameter by matching
the argument with its name rather than with its position in the parameter
list. If you don't remember the order of the parameters but know their names,
you can send the arguments in any order. You may also provide the value for an
implicit parameter when
 modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
2025-06-01 02:00:03,673 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.\n\n-----Input-----\nThe input consists of:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the product of the two input integers (a * b).'}], 'model': 'o3-mini'}}
2025-06-01 02:00:03,674 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:00:03,674 - DEBUG - close.started
2025-06-01 02:00:03,674 - DEBUG - close.complete
2025-06-01 02:00:03,674 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:00:03,681 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b6cc0>
2025-06-01 02:00:03,681 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:00:03,691 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b4e00>
2025-06-01 02:00:03,691 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:00:03,691 - DEBUG - send_request_headers.complete
2025-06-01 02:00:03,691 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:00:03,691 - DEBUG - send_request_body.complete
2025-06-01 02:00:03,691 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:00:08,815 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:00:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4524'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4527'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199613'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'115ms'), (b'x-request-id', b'req_87dc7b8da7145d6ff21d14021ea05ed2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1d7f2fd88fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:00:08,816 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:00:08,816 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:00:08,816 - DEBUG - receive_response_body.complete
2025-06-01 02:00:08,816 - DEBUG - response_closed.started
2025-06-01 02:00:08,816 - DEBUG - response_closed.complete
2025-06-01 02:00:08,816 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:00:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4524', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4527', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199613', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '115ms', 'x-request-id': 'req_87dc7b8da7145d6ff21d14021ea05ed2', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1d7f2fd88fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:00:08,816 - DEBUG - request_id: req_87dc7b8da7145d6ff21d14021ea05ed2
2025-06-01 02:00:08,817 - INFO - Attempt 1/3
2025-06-01 02:00:08,817 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function that multiplies two integers by directly applying the multiplication operator. The function takes two integer parameters and returns their product.",
  "steps": [
    "Define the function with an appropriate signature that accepts two integers (a and b) and returns an integer.",
    "Inside the function body, use the multiplication operator * to compute the product of a and b.",
    "Return the computed product.",
    "Ensure that the implementation is straightforward without unnecessary complications since Lean's built-in integer multiplication is used."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "Int",
    "multiplication operator",
    "product"
  ],
  "proof_keywords": [
    "algebraic properties",
    "associativity",
    "commutativity",
    "identity element"
  ],
  "assumptions": [
    "The Lean 4 environment already supports integer arithmetic.",
    "The multiplication operator * is available for integers in the standard library."
  ],
  "retry_guidance": "If errors arise related to type mismatches or operator definitions, verify the function signature and ensure that the correct type (Int) is used. Also, check Leon's import statements to ensure that integer arithmetic is correctly imported."
}
2025-06-01 02:00:08,818 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function that multiplies two integers by directly applying the multiplication operator. The function takes two integer parameters and returns their product.",\n  "steps": [\n    "Define the function with an appropriate signature that accepts two integers (a and b) and returns an integer.",\n    "Inside the function body, use the multiplication operator * to compute the product of a and b.",\n    "Return the computed product.",\n    "Ensure that the implementation is straightforward without unnecessary complications since Lean\'s built-in integer multiplication is used."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "Int",\n    "multiplication operator",\n    "product"\n  ],\n  "proof_keywords": [\n    "algebraic properties",\n    "associativity",\n    "commutativity",\n    "identity element"\n  ],\n  "assumptions": [\n    "The Lean 4 environment already supports integer arithmetic.",\n    "The multiplication operator * is available for integers in the standard library."\n  ],\n  "retry_guidance": "If errors arise related to type mismatches or operator definitions, verify the function signature and ensure that the correct type (Int) is used. Also, check Leon\'s import statements to ensure that integer arithmetic is correctly imported."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef multiply (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result should be the product of the two input integers\ndef multiply_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = a * b\n  -- << SPEC END >>\n\ntheorem multiply_spec_satisfied (a : Int) (b : Int) :\n  multiply_spec a b (multiply a b) := by\n  -- << PROOF START >>\n  unfold multiply multiply_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 02:00:08,819 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:00:08,819 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:00:08,819 - DEBUG - send_request_headers.complete
2025-06-01 02:00:08,820 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:00:08,824 - DEBUG - send_request_body.complete
2025-06-01 02:00:08,824 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:00:10,843 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:00:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'1570'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1576'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'11796'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'36.408s'), (b'x-request-id', b'req_1303f37a9abdd8a98e15d9300ca688d6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1d9f2e0d8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:00:10,843 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:00:10,843 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:00:10,843 - DEBUG - receive_response_body.complete
2025-06-01 02:00:10,844 - DEBUG - response_closed.started
2025-06-01 02:00:10,844 - DEBUG - response_closed.complete
2025-06-01 02:00:10,844 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:00:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '1570', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1576', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '11796', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '36.408s', 'x-request-id': 'req_1303f37a9abdd8a98e15d9300ca688d6', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1d9f2e0d8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:00:10,844 - DEBUG - request_id: req_1303f37a9abdd8a98e15d9300ca688d6
2025-06-01 02:00:10,844 - INFO - Raw solution received: ```json
{
  "code": "a * b",
  "proof": "by simp"
}
```
2025-06-01 02:00:10,844 - INFO - <class 'str'>
2025-06-01 02:00:10,844 - INFO - Generated solution: {'code': 'a * b', 'proof': 'by simp'}
2025-06-01 02:00:16,095 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:18:38: error: unsolved goals
a b : ℤ
⊢ a * b = a * b
lean_playground/TempTest.lean:21:2: error: unexpected token 'by'; expected command
2025-06-01 02:00:16,096 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that multiplies two integers. The method should return the product of the two input numbers.\n\n-----Input-----\nThe input consists of:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the product of the two input integers (a * b).\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef multiply (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The result should be the product of the two input integers\ndef multiply_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = a * b\n  -- << SPEC END >>\n\ntheorem multiply_spec_satisfied (a : Int) (b : Int) :\n  multiply_spec a b (multiply a b) := by\n  -- << PROOF START >>\n  unfold multiply multiply_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na * b\n\nGenerated Proof:\nby simp\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:18:38: error: unsolved goals\na b : ℤ\n⊢ a * b = a * b\nlean_playground/TempTest.lean:21:2: error: unexpected token 'by'; expected command"}], 'model': 'o3-mini'}}
2025-06-01 02:00:16,096 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:00:16,097 - DEBUG - close.started
2025-06-01 02:00:16,097 - DEBUG - close.complete
2025-06-01 02:00:16,097 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:00:16,103 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62de210>
2025-06-01 02:00:16,103 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:00:16,110 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eaecf0>
2025-06-01 02:00:16,111 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:00:16,111 - DEBUG - send_request_headers.complete
2025-06-01 02:00:16,111 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:00:16,111 - DEBUG - send_request_body.complete
2025-06-01 02:00:16,111 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:00:28,192 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:00:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'11856'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'11860'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199345'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'196ms'), (b'x-request-id', b'req_587383c2aef2a295da5a0fba6f7c256f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1dccbbd73bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:00:28,192 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:00:28,192 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:00:28,193 - DEBUG - receive_response_body.complete
2025-06-01 02:00:28,193 - DEBUG - response_closed.started
2025-06-01 02:00:28,193 - DEBUG - response_closed.complete
2025-06-01 02:00:28,193 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:00:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '11856', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '11860', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199345', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '196ms', 'x-request-id': 'req_587383c2aef2a295da5a0fba6f7c256f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1dccbbd73bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:00:28,193 - DEBUG - request_id: req_587383c2aef2a295da5a0fba6f7c256f
2025-06-01 02:00:28,193 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The current proof fails in two respects. First, using 'by simp' after unfolding leads to an unsolved goal (a * b = a * b) that 'simp' does not automatically close. Second, the placement of 'by' appears to be syntactically incorrect or mis-indented, causing an unexpected token error.", 'error_type': 'proof', 'suggested_fix': "Replace the proof with the trivial proof 'rfl', which immediately closes the goal since a * b is equal to itself. In other words, update the theorem as follows:\n\n  theorem multiply_spec_satisfied (a : Int) (b : Int) :\n    multiply_spec a b (multiply a b) := rfl\n\nThis eliminates both the unsolved goal and the syntax error with 'by'.", 'retry_strategy': "Revise the proof block to remove the unnecessary tactics. Use a direct proof via reflexivity (rfl) to show that a * b = a * b. Also check that the formatting (indentation and placement of 'by' or end-of-proof markers) conforms to Lean 4 standards."}
2025-06-01 02:00:28,193 - INFO - Solution generated in 24.98 seconds
2025-06-01 02:00:28,193 - INFO - Generated code length: 5 characters
2025-06-01 02:00:28,194 - INFO - Generated proof length: 5 characters
2025-06-01 02:00:28,194 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:00:28,194 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:00:33,325 - INFO - Implementation test result: FAIL
2025-06-01 02:00:33,325 - ERROR - Implementation error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:17:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:00:33,325 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:00:38,596 - INFO - Full solution test result: FAIL
2025-06-01 02:00:38,596 - ERROR - Proof error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:17:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:00:38,596 - ERROR - ❌ Implementation fails unit tests
2025-06-01 02:00:38,596 - ERROR - ❌ Proof has errors
2025-06-01 02:00:38,596 - INFO - 
==================================================
2025-06-01 02:00:38,596 - INFO - Processing task task_id_227...
2025-06-01 02:00:38,596 - INFO - Reading problem description and code template from tasks/task_id_227...
2025-06-01 02:00:38,597 - INFO - Problem description length: 608 characters
2025-06-01 02:00:38,597 - INFO - Reading unit tests from tasks/task_id_227...
2025-06-01 02:00:38,597 - INFO - Unit tests length: 339 characters
2025-06-01 02:00:38,597 - INFO - Running main workflow to generate solution...
2025-06-01 02:00:38,597 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.

-----Input-----
The input consists of three integers:
a: The first integer.
b: The second integer.
c: The third integer.

-----Output-----
The output is an integer:
Returns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.
2025-06-01 02:00:38,597 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def minOfThree (a : Int) (b : Int) (c : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The returned value is the minimum of the three input numbers
def minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  (result <= a ∧ result <= b ∧ result <= c) ∧
  (result = a ∨ result = b ∨ result = c)
  -- << SPEC END >>

theorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :
  minOfThree_spec a b c (minOfThree a b c) := by
  -- << PROOF START >>
  unfold minOfThree minOfThree_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:00:38,629 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7159b5eca480>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:00:38,629 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:00:38,630 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:00:38,637 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eb4260>
2025-06-01 02:00:38,637 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7159b62aa650> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:00:38,647 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eb5310>
2025-06-01 02:00:38,647 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:00:38,647 - DEBUG - send_request_headers.complete
2025-06-01 02:00:38,647 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:00:38,647 - DEBUG - send_request_body.complete
2025-06-01 02:00:38,647 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:00:39,038 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:00:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'84'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-b5646b449-jrr6p'), (b'x-envoy-upstream-service-time', b'91'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999847'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_f53df1019d0728e9ad161b49201e7d4f'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QZmQa2C4o05s2xjiokFDRvf_kTQaKkVS71KvoNCoQEc-1748743239-1.0.1.1-1ha9R1CP1b8rm7GO9lKRi_ansEnpBq8Wv7CuzgE68oHNtqQNIJ2OmkJdqYaFUJuaJFhlEsbV0B.DpFscEnbvAH08FvpBsjYjuiUUlv3VZsA; path=/; expires=Sun, 01-Jun-25 02:30:39 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=iJCa.aWLU_Kq6XMxF3vxXUrZL0NGSoRGzjqUjQ4Akik-1748743239040-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1e599b874278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:00:39,038 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:00:39,038 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:00:39,039 - DEBUG - receive_response_body.complete
2025-06-01 02:00:39,039 - DEBUG - response_closed.started
2025-06-01 02:00:39,039 - DEBUG - response_closed.complete
2025-06-01 02:00:39,039 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:00:39 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '84'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-b5646b449-jrr6p'), ('x-envoy-upstream-service-time', '91'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999847'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '9ms'), ('x-request-id', 'req_f53df1019d0728e9ad161b49201e7d4f'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=QZmQa2C4o05s2xjiokFDRvf_kTQaKkVS71KvoNCoQEc-1748743239-1.0.1.1-1ha9R1CP1b8rm7GO9lKRi_ansEnpBq8Wv7CuzgE68oHNtqQNIJ2OmkJdqYaFUJuaJFhlEsbV0B.DpFscEnbvAH08FvpBsjYjuiUUlv3VZsA; path=/; expires=Sun, 01-Jun-25 02:30:39 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=iJCa.aWLU_Kq6XMxF3vxXUrZL0NGSoRGzjqUjQ4Akik-1748743239040-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b1e599b874278-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:00:39,039 - DEBUG - request_id: req_f53df1019d0728e9ad161b49201e7d4f
2025-06-01 02:00:39,044 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Interacting with Lean

You are now familiar with the fundamentals of dependent type theory, both as a
language for defining mathematical objects and a language for constructing
proofs. The one thing you are missing is a mechanism for defining new data
types. We will fill this gap in the next chapter, which introduces the notion
of an _inductive data type_. But first, in this chapter, we take a break from
the mechanics of type theory to explore some pragmatic aspects of interacting
with Lean.

Not all of the information found here will be useful to you right away. We
recommend skimming this section to get a sense of Lean's features, and then
returning to it as necessary.

## Importing Files

The goal of Lean's front end is to interpret user input, construct formal
expressions, and check that they are well-formed and type-correct. Lean also
supports the use of various editors, which provide continuous checking and
feedback. More information can be found on the Lean [documentation
pages](https://lean-lang.org/documentation/).

The definitions and theorems in Lean's standard library are spread across
multiple files. Users may also wish to make use of additional libraries, or
develop their own projects across multiple files. When Lean starts, it
automatically imports the contents of the library `Init` folder, which
includes a number of fundamental definitions and constructions. As a result,
most of the examples we present here work "out of the box."

If you want to use additional files, however, they need to be imported
manually, via an `import` statement at the beginning of a file. The command

    
    
    import Bar.Baz.Blah
    

imports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted
relative to the Lean _search path_. Information as to how the search path is
determined can be found on the [documentation pages](https://lean-
lang.org/documentation/). By default, it includes the standard library
directory, and (in some contexts) the root of the user's local project.

Importing is transitive. In other words, if you import `Foo` and `Foo` imports
`Bar`, then you also have access to the contents of `Bar`, and do not need to
import it explicitly.

## More on Sections

Lean provides various sectioning mechanisms to help structure a theory. You
saw in [Variables and Sections](./dependent_type_theory.html#variables-and-
sections) that the `section` command makes it possible not only to group
together elements of a theory that go together, but also to declare variables
that are inserted as arguments to theorems and definitions, as necessary.
Remember that the point of the `variable` command is to declare variables for
use in theorems, as in the following example:

    
    
    section
    variable (x y : Nat)
    
    def double := x + x
    
    #check double y
    #check double (2 * x)
    
    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm
    
    theorem t1 : double (x + y) = double x + double y := by
      simp [double]
    
    #check t1 y
    #check t1 (2 * x)
    
    theorem t2 : double (x * y) = double x * y := by
      simp [double, Nat.add_mul]
    
    end
    

The definition of `double` does not have to declare `x` as an argument; Lean
detects the dependence and inserts it automatically. Similarly, Lean detects
the occurrence of `x` in `t1` and `t2`, and inserts it automatically there,
too. Note that `double` does _not_ have `y` as argument. Variables are only
included in declarations where they are actually used.

## More on Namespaces

In Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We
saw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean
provides mechanisms for working with hierarchical names. The command
`namespace foo` causes `foo` to be prepended to the name of each definition
and theorem until `end foo` is encountered. The command `open foo` then
creates temporary _aliases_ to definitions and theorems that begin with prefix
`foo`.

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    
    open Foo
    
    #check bar
    #check Foo.bar
    

The following definition

    
    
    def Foo.bar : Nat := 1
    

is treated as a macro, and expands to

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    

Although the names of theorems and definitions have to be unique, the aliases
that identify them do not. When we open a namespace, an identifier may be
ambiguous. Lean tries to use type information to disambiguate the meaning in
context, but you can always disambiguate by giving the full name. To that end,
the string `_root_` is an explicit description of the empty prefix.

    
    
    def String.add (a b : String) : String :=
      a ++ b
    
    def Bool.add (a b : Bool) : Bool :=
      a != b
    
    def add (α β : Type) : Type := Sum α β
    
    open Bool
    open String
    -- #check add -- ambiguous
    #check String.add           -- String → String → String
    #check Bool.add             -- Bool → Bool → Bool
    #check _root_.add           -- Type → Type → Type
    
    #check add "hello" "world"  -- String
    #check add true false       -- Bool
    #check add Nat Nat          -- Type
    

We can prevent the shorter alias from being created by using the `protected`
keyword:

    
    
    protected def Foo.bar : Nat := 1
    
    open Foo
    
    -- #check bar -- error
    #check Foo.bar
    

This is often used for names like `Nat.rec` and `Nat.recOn`, to prevent
overloading of common names.

The `open` command admits variations. The command

    
    
    open Nat (succ zero gcd)
    #check zero     -- Nat
    #eval gcd 15 6  -- 3
    

creates aliases for only the identifiers listed. The command

    
    
    open Nat hiding succ gcd
    #check zero     -- Nat
    -- #eval gcd 15 6  -- error
    #eval Nat.gcd 15 6  -- 3
    

creates aliases for everything in the `Nat` namespace _except_ the identifiers
listed.

    
    
    open Nat renaming mul → times, add → plus
    #eval plus (times 2 2) 3  -- 7
    

creates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.

It is sometimes useful to `export` aliases from one namespace to another, or
to the top level. The command

    
    
    export Nat (succ add sub)
    

creates aliases for `succ`, `add`, and `sub` in the current namespace, so that
whenever the namespace is open, these aliases are available. If this command
is used outside a namespace, the aliases are exported to the top level.

## Attributes

The main function of Lean is to translate user input to formal expressions
that are checked by the kernel for correctness and then stored in the
environment for later use. But some commands have other effects on the
environment, either assigning attributes to objects in the environment,
defining notation, or declaring instances of type classes, as described in
[Chapter Type Classes](./type_classes.html). Most of these commands have
global effects, which is to say, they remain in effect not only in the current
file, but also in any file that imports it. However, such commands often
support the `local` modifier, which indicates that they only have effect until
the current `section` or `namespace` is closed, or until the end of the
current file.

In [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw
that theorems can be annotated with the `[simp]` attribute, which makes them
available for use by the simplifier. The following example defines the prefix
relation on lists, proves that this relation is reflexive, and assigns the
`[simp]` attribute to that theorem.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    

The simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to
`True`.

One can also assign the attribute any time after the definition takes place:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [simp] List.isPrefix_self
    

In all these cases, the attribute remains in effect in any file that imports
the one in which the declaration occurs. Adding the `local` modifier restricts
the scope:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    section
    
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [local simp] List.isPrefix_self
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    
    end
    
    -- Error:
    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by
    --  simp
    

For another example, we can use the `instance` command to assign the notation
`≤` to the `isPrefix` relation. That command, which will be explained in
[Chapter Type Classes](./type_classes.html), works by assigning an
`[instance]` attribute to the associated definition.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    instance : LE (List α) where
      le := isPrefix
    
    theorem List.isPrefix_self (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    

That assignment can also be made local:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    def instLe : LE (List α) :=
      { le := isPrefix }
    
    section
    attribute [local instance] instLe
    
    example (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    
    end
    
    -- Error:
    -- example (as : List α) : as ≤ as :=
    --  ⟨[], by simp⟩
    

In Section Notation below, we will discuss Lean's mechanisms for defining
notation, and see that they also support the `local` modifier. However, in
Section Setting Options, we will discuss Lean's mechanisms for setting
options, which does _not_ follow this pattern: options can _only_ be set
locally, which is to say, their scope is always restricted to the current
section or current file.

## More on Implicit Arguments

In [Section Implicit Arguments](./dependent_type_theory.html#implicit-
arguments), we saw that if Lean displays the type of a term `t` as `{x : α} →
β x`, then the curly brackets indicate that `x` has been marked as an
_implicit argument_ to `t`. This means that whenever you write `t`, a
placeholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you
don't want that to happen, you have to write `@t` instead.

Notice that implicit arguments are inserted eagerly. Suppose we define a
function `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,
when we write the expression `f 7` without further arguments, it is parsed as
`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that
a placeholder should only be added _before_ a subsequent explicit argument.
This annotation can also be written using as `⦃y : Nat⦄`, where the unicode
brackets are entered as `\{{` and `\}}`, respectively. With this annotation,
the expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as
`f 7 _ 3`, just as it would be with the strong annotation.

To illustrate the difference, consider the following example, which shows that
a reflexive euclidean relation is both symmetric and transitive.

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b : α}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
     th2 (th1 reflr @euclr) @euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3
    

The results are broken down into small steps: `th1` shows that a relation that
is reflexive and euclidean is symmetric, and `th2` shows that a relation that
is symmetric and euclidean is transitive. Then `th3` combines the two results.
But notice that we have to manually disable the implicit arguments in `euclr`,
because otherwise too many implicit arguments are inserted. The problem goes
away if we use weak implicit arguments:

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b : α}}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
      th2 (th1 reflr euclr) euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- euclidean r
    

There is a third kind of implicit argument that is denoted with square
brackets, `[` and `]`. These are used for type classes, as explained in
[Chapter Type Classes](./type_classes.html).

## Notation

Identifiers in Lean can include any alphanumeric characters, including Greek
characters (other than ∀ , Σ , and λ , which, as we have seen, have a special
meaning in the dependent type theory). They can also include subscripts, which
can be entered by typing `\_` followed by the desired subscripted character.

Lean's parser is extensible, which is to say, we can define new notation.

Lean's syntax can be extended and customized by users at every level, ranging
from basic "mixfix" notations to custom elaborators. In fact, all builtin
syntax is parsed and processed using the same mechanisms and APIs open to
users. In this section, we will describe and explain the various extension
points.

While introducing new notations is a relatively rare feature in programming
languages and sometimes even frowned upon because of its potential to obscure
code, it is an invaluable tool in formalization for expressing established
conventions and notations of the respective field succinctly in code. Going
beyond basic notations, Lean's ability to factor out common boilerplate code
into (well-behaved) macros and to embed entire custom domain specific
languages (DSLs) to textually encode subproblems efficiently and readably can
be of great benefit to both programmers and proof engineers alike.

### Notations and Precedence

The most basic syntax extension commands allow introducing new (or overloading
existing) prefix, infix, and postfix operators.

    
    
    infixl:65   " + " => HAdd.hAdd  -- left-associative
    infix:50    " = " => Eq         -- non-associative
    infixr:80   " ^ " => HPow.hPow  -- right-associative
    prefix:100  "-"   => Neg.neg
    set_option quotPrecheck false
    postfix:max "⁻¹"  => Inv.inv
    

After the initial command name describing the operator kind (its "fixity"), we
give the _parsing precedence_ of the operator preceded by a colon `:`, then a
new or existing token surrounded by double quotes (the whitespace is used for
pretty printing), then the function this operator should be translated to
after the arrow `=>`.

The precedence is a natural number describing how "tightly" an operator binds
to its arguments, encoding the order of operations. We can make this more
precise by looking at the commands the above unfold to:

    
    
    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs
    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs
    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs
    notation:100 "-" arg:100 => Neg.neg arg
    set_option quotPrecheck false
    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024
    

It turns out that all commands from the first code block are in fact command
_macros_ translating to the more general `notation` command. We will learn
about writing such macros below. Instead of a single token, the `notation`
command accepts a mixed sequence of tokens and named term placeholders with
precedences, which can be referenced on the right-hand side of `=>` and will
be replaced by the respective term parsed at that position. A placeholder with
precedence `p` accepts only notations with precedence at least `p` in that
place. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +
(b + c)` because the right-hand side operand of an `infixl` notation has
precedence one greater than the notation itself. In contrast, `infixr` reuses
the notation's precedence for the right-hand side operand, so `a ^ b ^ c`
_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to
introduce an infix notation like

    
    
    set_option quotPrecheck false
    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs
    

where the precedences do not sufficiently determine associativity, Lean's
parser will default to right associativity. More precisely, Lean's parser
follows a local _longest parse_ rule in the presence of ambiguous grammars:
when parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue
parsing as long as possible (as the current precedence allows), not stopping
after `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~
c)`.

As mentioned above, the `notation` command allows us to define arbitrary
_mixfix_ syntax freely mixing tokens and placeholders.

    
    
    set_option quotPrecheck false
    notation:max "(" e ")" => e
    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ
    

Placeholders without precedence default to `0`, i.e. they accept notations of
any precedence in their place. If two notations overlap, we again apply the
longest parse rule:

    
    
    notation:65 a " + " b:66 " + " c:66 => a + b - c
    #eval 1 + 2 + 3  -- 0
    

The new notation is preferred to the binary notation since the latter, before
chaining, would stop parsing after `1 + 2`. If there are multiple notations
accepting the same longest parse, the choice will be delayed until
elaboration, which will fail unless exactly one overload is type-correct.

## Coercions

In Lean, the type of natural numbers, `Nat`, is different from the type of
integers, `Int`. But there is a function `Int.ofNat` that embeds the natural
numbers in the integers, meaning that we can view any natural number as an
integer, when needed. Lean has mechanisms to detect and insert _coercions_ of
this sort.

    
    
    variable (m n : Nat)
    variable (i j : Int)
    
    #check i + m      -- i + Int.ofNat m : Int
    #check i + m + j  -- i + Int.ofNat m + j : Int
    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int
    

## Displaying Information

There are a number of ways in which you can query Lean for information about
its current state and the objects and theorems that are available in the
current context. You have already seen two of the most common ones, `#check`
and `#eval`. Remember that `#check` is often used in conjunction with the `@`
operator, which makes all of the arguments to a theorem or definition
explicit. In addition, you can use the `#print` command to get information
about any identifier. If the identifier denotes a definition or theorem, Lean
prints the type of the symbol, and its definition. If it is a constant or an
axiom, Lean indicates that fact, and shows the type.

    
    
    -- examples with equality
    #check Eq
    #check @Eq
    #check Eq.symm
    #check @Eq.symm
    
    #print Eq.symm
    
    -- examples with And
    #check And
    #check And.intro
    #check @And.intro
    
    -- a user-defined function
    def foo {α : Type u} (x : α) : α := x
    
    #check foo
    #check @foo
    #print foo
    

## Setting Options

Lean maintains a number of internal variables that can be set by users to
control its behavior. The syntax for doing so is as follows:

    
    
    set_option <name> <value>
    

One very useful family of options controls the way Lean's _pretty- printer_
displays terms. The following options take an input of true or false:

    
    
    pp.explicit  : display implicit arguments
    pp.universes : display hidden universe parameters
    pp.notation  : display output using defined notations
    

As an example, the following settings yield much longer output:

    
    
    set_option pp.explicit true
    set_option pp.universes true
    set_option pp.notation false
    
    #check 2 + 2 = 4
    #reduce (fun x => x + 2) = (fun x => x + 3)
    #check (fun x => x + 1) 1
    

The command `set_option pp.all true` carries out these settings all at once,
whereas `set_option pp.all false` reverts to the previous values. Pretty
printing additional information is often very useful when you are debugging a
proof, or trying to understand a cryptic error message. Too much information
can be overwhelming, though, and Lean's defaults are generally sufficient for
ordinary interactions.

## Using the Library

To use Lean effectively you will inevitably need to make use of definitions
and theorems in the library. Recall that the `import` command at the beginning
of a file imports previously compiled results from other files, and that
importing is transitive; if you import `Foo` and `Foo` imports `Bar`, then the
definitions and theorems from `Bar` are available to you as well. But the act
of opening a namespace, which provides shorter names, does not carry over. In
each file, you need to open the namespaces you wish to use.

In general, it is important for you to be familiar with the library and its
contents, so you know what theorems, definitions, notations, and resources are
available to you. Below we will see that Lean's editor modes can also help you
find things you need, but studying the contents of the library directly is
often unavoidable. Lean's standard library can be found online, on GitHub:

  * <https://github.com/leanprover/lean4/tree/master/src/Init>

  * <https://github.com/leanprover/std4/tree/main/Std>

You can see the contents of these directories and files using GitHub's browser
interface. If you have installed Lean on your own computer, you can find the
library in the `lean` folder, and explore it with your file manager. Comment
headers at the top of each file provide additional information.

Lean's library developers follow general naming guidelines to make it easier
to guess the name of a theorem you need, or to find it using tab completion in
editors with a Lean mode that supports this, which is discussed in the next
section. Identifiers are generally `camelCase`, and types are `CamelCase`. For
theorem names, we rely on descriptive names where the different components are
separated by `_`s. Often the name of theorem simply describes the conclusion:

    
    
    #check Nat.succ_ne_zero
    #check Nat.zero_add
    #check Nat.mul_one
    #check Nat.le_of_succ_le_succ
    

Remember that identifiers in Lean can be organized into hierarchical
namespaces. For example, the theorem named `le_of_succ_le_succ` in the
namespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name
is made available by the command `open Nat` (for names not marked as
`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)
and [Chapter Structures and Records](./structures_and_records.html) that
defining structures and inductive data types in Lean generates associated
operations, and these are stored in a namespace with the same name as the type
under definition. For example, the product type comes with the following
operations:

    
    
    #check @Prod.mk
    #check @Prod.fst
    #check @Prod.snd
    #check @Prod.rec
    

The first is used to construct a pair, whereas the next two, `Prod.fst` and
`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another
mechanism for defining functions on a product in terms of a function on the
two components. Names like `Prod.rec` are _protected_ , which means that one
has to use the full name even when the `Prod` namespace is open.

With the propositions as types correspondence, logical connectives are also
instances of inductive types, and so we tend to use dot notation for them as
well:

    
    
    #check @And.intro
    #check @And.casesOn
    #check @And.left
    #check @And.right
    #check @Or.inl
    #check @Or.inr
    #check @Or.elim
    #check @Exists.intro
    #check @Exists.elim
    #check @Eq.refl
    #check @Eq.subst
    

## Auto Bound Implicit Arguments

In the previous section, we have shown how implicit arguments make functions
more convenient to use. However, functions such as `compose` are still quite
verbose to define. Note that the universe polymorphic `compose` is even more
verbose than the one previously defined.

    
    
    universe u v w
    def compose {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

You can avoid the `universe` command by providing the universe parameters when
defining `compose`.

    
    
    def compose.{u, v, w}
                {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

Lean 4 supports a new feature called _auto bound implicit arguments_. It makes
functions such as `compose` much more convenient to write. When Lean processes
the header of a declaration, any unbound identifier is automatically added as
an implicit argument _if_ it is a single lower case or greek letter. With this
feature we can write `compose` as

    
    
    def compose (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    
    #check @compose
    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ
    

Note that Lean inferred a more general type using `Sort` instead of `Type`.

Although we love this feature and use it extensively when implementing Lean,
we realize some users may feel uncomfortable with it. Thus, you can disable it
using the command `set_option autoImplicit false`.

    
    
    set_option autoImplicit false
    /- The following definition produces `unknown identifier` errors -/
    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=
    --   g (f x)
    

## Implicit Lambdas

In Lean 3 stdlib, we find many
[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)
of the dreadful `@`+`_` idiom. It is often used when the expected type is a
function type with implicit arguments, and we have a constant (`reader_t.pure`
in the example) which also takes implicit arguments. In Lean 4, the elaborator
automatically introduces lambdas for consuming implicit arguments. We are
still exploring this feature and analyzing its impact, but the experience so
far has been very positive. Here is the example from the link above using Lean
4 implicit lambdas.

    
    
    variable (ρ : Type) (m : Type → Type) [Monad m]
    instance : Monad (ReaderT ρ m) where
      pure := ReaderT.pure
      bind := ReaderT.bind
    

Users can disable the implicit lambda feature by using `@` or writing a lambda
expression with `{}` or `[]` binder annotations. Here are few examples

    
    
    namespace ex2
    def id1 : {α : Type} → α → α :=
      fun x => x
    
    def listId : List ({α : Type} → α → α) :=
      (fun x => x) :: []
    
    -- In this example, implicit lambda introduction has been disabled because
    -- we use `@` before `fun`
    def id2 : {α : Type} → α → α :=
      @fun α (x : α) => id1 x
    
    def id3 : {α : Type} → α → α :=
      @fun α x => id1 x
    
    def id4 : {α : Type} → α → α :=
      fun x => id1 x
    
    -- In this example, implicit lambda introduction has been disabled
    -- because we used the binder annotation `{...}`
    def id5 : {α : Type} → α → α :=
      fun {α} x => id1 x
    end ex2
    

## Sugar for Simple Functions

In Lean 3, we can create simple functions from infix operators by using
parentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we
generalize this notation using `·` as a placeholder. Here are a few examples:

    
    
    namespace ex3
    #check (· + 1)
    -- fun a => a + 1
    #check (2 - ·)
    -- fun a => 2 - a
    #eval [1, 2, 3, 4, 5].foldl (·*·) 1
    -- 120
    
    def f (x y z : Nat) :=
      x + y + z
    
    #check (f · 1 ·)
    -- fun a b => f a 1 b
    
    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)
    -- [1, 3, 5]
    end ex3
    

As in Lean 3, the notation is activated using parentheses, and the lambda
abstraction is created by collecting the nested `·`s. The collection is
interrupted by nested parentheses. In the following example, two different
lambda expressions are created.

    
    
    #check (Prod.mk · (· + 1))
    -- fun a => (a, fun b => b + 1)
    

## Named Arguments

Named arguments enable you to specify an argument for a parameter by matching
the argument with its name rather than with its position in the parameter
list. If you don't remember the order of the parameters but know their names,
you can send the arguments in any order. You may also provide the value for an
implicit parameter when
2025-06-01 02:00:39,047 - DEBUG - close.started
2025-06-01 02:00:39,047 - DEBUG - close.complete
2025-06-01 02:00:39,057 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.'}], 'model': 'o3-mini'}}
2025-06-01 02:00:39,058 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:00:39,058 - DEBUG - close.started
2025-06-01 02:00:39,058 - DEBUG - close.complete
2025-06-01 02:00:39,058 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:00:39,064 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eaf680>
2025-06-01 02:00:39,064 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:00:39,073 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b677ad50>
2025-06-01 02:00:39,073 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:00:39,074 - DEBUG - send_request_headers.complete
2025-06-01 02:00:39,074 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:00:39,074 - DEBUG - send_request_body.complete
2025-06-01 02:00:39,074 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:00:47,450 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:00:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8153'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8155'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199547'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'135ms'), (b'x-request-id', b'req_41a312ee32967cbcb53ede030e03fc3f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1e5c4f3c3fe6-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:00:47,450 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:00:47,450 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:00:47,450 - DEBUG - receive_response_body.complete
2025-06-01 02:00:47,451 - DEBUG - response_closed.started
2025-06-01 02:00:47,451 - DEBUG - response_closed.complete
2025-06-01 02:00:47,451 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:00:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8153', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8155', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199547', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '135ms', 'x-request-id': 'req_41a312ee32967cbcb53ede030e03fc3f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1e5c4f3c3fe6-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:00:47,451 - DEBUG - request_id: req_41a312ee32967cbcb53ede030e03fc3f
2025-06-01 02:00:47,451 - INFO - Attempt 1/3
2025-06-01 02:00:47,451 - INFO - Current plan: {
  "plan_summary": "Implement a Lean 4 function that takes three integers and returns the smallest among them. The plan uses conditional checks (if-then-else) or the built-in min function to compare the values. Along with the function, correctness must be ensured by confirming that the result is less than or equal to each of the inputs and exactly matches one of them.",
  "steps": [
    "Define the function signature in Lean 4 (e.g., def min3 (a b c : Int) : Int).",
    "Determine the method of comparison: either use nested if-then-else statements or compute the minimum of a and b (using a built-in min function if available) and then compare that result with c.",
    "Implement the logic ensuring that the returned value is less than or equal to a, b, and c. For instance, check conditions with if-then-else statements such that if a is less than or equal to both b and c then a is returned, else check for others.",
    "Confirm (possibly in comments or via test cases) that the returned integer is one of the inputs and satisfies the minimality property (i.e., <= a, <= b, and <= c).",
    "Optionally, outline a short proof (using induction or direct reasoning) that the chosen implementation meets the specifications."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "min function",
    "if-then-else",
    "integer comparison"
  ],
  "proof_keywords": [
    "correctness",
    "inequalities",
    "minimal property",
    "case analysis"
  ],
  "assumptions": [
    "The integers are represented by Lean's built-in Int type.",
    "A built-in min function is available or can be simulated using if-then-else constructs.",
    "There are no constraints regarding performance or edge cases aside from correctness of the minimal value.",
    "The function will be used in contexts where typical integer behavior (including negatives) applies."
  ],
  "retry_guidance": "If errors occur, verify that the comparison operators and the if-then-else syntax are correctly used in Lean 4. Also ensure that type mismatches or logical mistakes (such as incorrect ordering of conditions) are addressed. Reassess the approach (e.g., comparing a with b before comparing with c) if the minimality condition is not met."
}
2025-06-01 02:00:47,452 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Implement a Lean 4 function that takes three integers and returns the smallest among them. The plan uses conditional checks (if-then-else) or the built-in min function to compare the values. Along with the function, correctness must be ensured by confirming that the result is less than or equal to each of the inputs and exactly matches one of them.",\n  "steps": [\n    "Define the function signature in Lean 4 (e.g., def min3 (a b c : Int) : Int).",\n    "Determine the method of comparison: either use nested if-then-else statements or compute the minimum of a and b (using a built-in min function if available) and then compare that result with c.",\n    "Implement the logic ensuring that the returned value is less than or equal to a, b, and c. For instance, check conditions with if-then-else statements such that if a is less than or equal to both b and c then a is returned, else check for others.",\n    "Confirm (possibly in comments or via test cases) that the returned integer is one of the inputs and satisfies the minimality property (i.e., <= a, <= b, and <= c).",\n    "Optionally, outline a short proof (using induction or direct reasoning) that the chosen implementation meets the specifications."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "min function",\n    "if-then-else",\n    "integer comparison"\n  ],\n  "proof_keywords": [\n    "correctness",\n    "inequalities",\n    "minimal property",\n    "case analysis"\n  ],\n  "assumptions": [\n    "The integers are represented by Lean\'s built-in Int type.",\n    "A built-in min function is available or can be simulated using if-then-else constructs.",\n    "There are no constraints regarding performance or edge cases aside from correctness of the minimal value.",\n    "The function will be used in contexts where typical integer behavior (including negatives) applies."\n  ],\n  "retry_guidance": "If errors occur, verify that the comparison operators and the if-then-else syntax are correctly used in Lean 4. Also ensure that type mismatches or logical mistakes (such as incorrect ordering of conditions) are addressed. Reassess the approach (e.g., comparing a with b before comparing with c) if the minimality condition is not met."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned value is the minimum of the three input numbers\ndef minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result <= a ∧ result <= b ∧ result <= c) ∧\n  (result = a ∨ result = b ∨ result = c)\n  -- << SPEC END >>\n\ntheorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :\n  minOfThree_spec a b c (minOfThree a b c) := by\n  -- << PROOF START >>\n  unfold minOfThree minOfThree_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:00:47,454 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:00:47,454 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:00:47,454 - DEBUG - send_request_headers.complete
2025-06-01 02:00:47,454 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:00:47,462 - DEBUG - send_request_body.complete
2025-06-01 02:00:47,462 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:00:54,058 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:00:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6341'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6377'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'10739'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'38.522s'), (b'x-request-id', b'req_26c733fae316c793d950e9d9270cce77'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1e90ab8d3fe6-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:00:54,058 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:00:54,058 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:00:54,061 - DEBUG - receive_response_body.complete
2025-06-01 02:00:54,061 - DEBUG - response_closed.started
2025-06-01 02:00:54,061 - DEBUG - response_closed.complete
2025-06-01 02:00:54,061 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:00:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6341', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6377', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '10739', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '38.522s', 'x-request-id': 'req_26c733fae316c793d950e9d9270cce77', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1e90ab8d3fe6-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:00:54,061 - DEBUG - request_id: req_26c733fae316c793d950e9d9270cce77
2025-06-01 02:00:54,062 - INFO - Raw solution received: ```json
{
  "code": "if a <= b then if a <= c then a else c else if b <= c then b else c",
  "proof": "by_cases h1 : a <= b\n  case pos => \n    by_cases h2 : a <= c\n    case pos =>\n      simp [h1, h2]\n      unfold minOfThree\n      exact And.intro (And.intro h1 h2) (Or.inl rfl)\n    case neg =>\n      simp [h1, h2]\n      unfold minOfThree\n      apply And.intro\n      exact And.intro h1 (le_of_not_le h2)\n      right; right; exact rfl\n  case neg =>\n    by_cases h3 : b <= c\n    case pos =>\n      simp [h1, h3]\n      unfold minOfThree\n      exact And.intro (And.intro (le_of_not_le h1) h3) (Or.inr (Or.inl rfl))\n    case neg =>\n      simp [h1, h3]\n      unfold minOfThree\n      apply And.intro\n      exact And.intro (le_of_not_le h1) (le_of_not_le h3)\n      exact Or.inr (Or.inr rfl)"
}
```
2025-06-01 02:00:54,062 - INFO - <class 'str'>
2025-06-01 02:00:54,062 - INFO - Generated solution: {'code': 'if a <= b then if a <= c then a else c else if b <= c then b else c', 'proof': 'by_cases h1 : a <= b\n  case pos => \n    by_cases h2 : a <= c\n    case pos =>\n      simp [h1, h2]\n      unfold minOfThree\n      exact And.intro (And.intro h1 h2) (Or.inl rfl)\n    case neg =>\n      simp [h1, h2]\n      unfold minOfThree\n      apply And.intro\n      exact And.intro h1 (le_of_not_le h2)\n      right; right; exact rfl\n  case neg =>\n    by_cases h3 : b <= c\n    case pos =>\n      simp [h1, h3]\n      unfold minOfThree\n      exact And.intro (And.intro (le_of_not_le h1) h3) (Or.inr (Or.inl rfl))\n    case neg =>\n      simp [h1, h3]\n      unfold minOfThree\n      apply And.intro\n      exact And.intro (le_of_not_le h1) (le_of_not_le h3)\n      exact Or.inr (Or.inr rfl)'}
2025-06-01 02:00:59,371 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:27:6: error: no goals to be solved
lean_playground/TempTest.lean:31:13: error: tactic 'unfold' failed to unfold 'minOfThree' at
  c ≤ a ∧ c ≤ b
lean_playground/TempTest.lean:39:13: error: tactic 'unfold' failed to unfold 'minOfThree' at
  b ≤ a
lean_playground/TempTest.lean:43:13: error: tactic 'unfold' failed to unfold 'minOfThree' at
  c ≤ a ∧ c ≤ b
2025-06-01 02:00:59,372 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that finds the minimum among three given integers. The method should return the smallest value, ensuring that the result is less than or equal to each of the input numbers and that it is one of the provided integers.\n\n-----Input-----\nThe input consists of three integers:\na: The first integer.\nb: The second integer.\nc: The third integer.\n\n-----Output-----\nThe output is an integer:\nReturns the minimum of the three input numbers, assuring that the returned value is less than or equal to a, b, and c, and that it matches one of these values.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef minOfThree (a : Int) (b : Int) (c : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned value is the minimum of the three input numbers\ndef minOfThree_spec (a : Int) (b : Int) (c : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result <= a ∧ result <= b ∧ result <= c) ∧\n  (result = a ∨ result = b ∨ result = c)\n  -- << SPEC END >>\n\ntheorem minOfThree_spec_satisfied (a : Int) (b : Int) (c : Int) :\n  minOfThree_spec a b c (minOfThree a b c) := by\n  -- << PROOF START >>\n  unfold minOfThree minOfThree_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a <= b then if a <= c then a else c else if b <= c then b else c\n\nGenerated Proof:\nby_cases h1 : a <= b\n  case pos => \n    by_cases h2 : a <= c\n    case pos =>\n      simp [h1, h2]\n      unfold minOfThree\n      exact And.intro (And.intro h1 h2) (Or.inl rfl)\n    case neg =>\n      simp [h1, h2]\n      unfold minOfThree\n      apply And.intro\n      exact And.intro h1 (le_of_not_le h2)\n      right; right; exact rfl\n  case neg =>\n    by_cases h3 : b <= c\n    case pos =>\n      simp [h1, h3]\n      unfold minOfThree\n      exact And.intro (And.intro (le_of_not_le h1) h3) (Or.inr (Or.inl rfl))\n    case neg =>\n      simp [h1, h3]\n      unfold minOfThree\n      apply And.intro\n      exact And.intro (le_of_not_le h1) (le_of_not_le h3)\n      exact Or.inr (Or.inr rfl)\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:27:6: error: no goals to be solved\nlean_playground/TempTest.lean:31:13: error: tactic 'unfold' failed to unfold 'minOfThree' at\n  c ≤ a ∧ c ≤ b\nlean_playground/TempTest.lean:39:13: error: tactic 'unfold' failed to unfold 'minOfThree' at\n  b ≤ a\nlean_playground/TempTest.lean:43:13: error: tactic 'unfold' failed to unfold 'minOfThree' at\n  c ≤ a ∧ c ≤ b"}], 'model': 'o3-mini'}}
2025-06-01 02:00:59,372 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:00:59,373 - DEBUG - close.started
2025-06-01 02:00:59,373 - DEBUG - close.complete
2025-06-01 02:00:59,373 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:00:59,379 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62dfc20>
2025-06-01 02:00:59,379 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:00:59,386 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62dc770>
2025-06-01 02:00:59,386 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:00:59,386 - DEBUG - send_request_headers.complete
2025-06-01 02:00:59,386 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:00:59,386 - DEBUG - send_request_body.complete
2025-06-01 02:00:59,386 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:01:05,886 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:01:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6259'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6271'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199006'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'298ms'), (b'x-request-id', b'req_0e7e7942a08eb7db5c5e42a97b8ba82e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1edb2b0b3bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:01:05,886 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:01:05,886 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:01:05,887 - DEBUG - receive_response_body.complete
2025-06-01 02:01:05,887 - DEBUG - response_closed.started
2025-06-01 02:01:05,887 - DEBUG - response_closed.complete
2025-06-01 02:01:05,887 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:01:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6259', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6271', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199006', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '298ms', 'x-request-id': 'req_0e7e7942a08eb7db5c5e42a97b8ba82e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1edb2b0b3bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:01:05,887 - DEBUG - request_id: req_0e7e7942a08eb7db5c5e42a97b8ba82e
2025-06-01 02:01:05,887 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails because of unnecessary or incorrect use of the 'unfold' tactic. In several cases, the tactic fails to unfold minOfThree, and in one instance it reports 'no goals to be solved'. This indicates that after applying other tactics (like simp), the proof state no longer contains the expected goals for unfolding.", 'error_type': 'proof', 'suggested_fix': "Remove the 'unfold minOfThree' steps and rely on computation/simplification (e.g., using 'dsimp' or 'simp') to reveal the definition of minOfThree. Structure the proof so that each case directly establishes the required properties by comparing the computed value with the inputs. In addition, ensure that you're applying tactics in the correct order so that goals exist when needed.", 'retry_strategy': "Refactor the proof by eliminating the redundant 'unfold' calls. Instead, use 'simp', 'dsimp', or 'rfl' in each case to show that the computed value satisfies the specification. Also, check that each branch of the case analysis properly matches a goal, so that tactics are applied only when goals are available."}
2025-06-01 02:01:05,887 - INFO - Solution generated in 27.29 seconds
2025-06-01 02:01:05,887 - INFO - Generated code length: 5 characters
2025-06-01 02:01:05,888 - INFO - Generated proof length: 5 characters
2025-06-01 02:01:05,888 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:01:05,888 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:01:11,168 - INFO - Implementation test result: FAIL
2025-06-01 02:01:11,168 - ERROR - Implementation error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:18:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:01:11,168 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:01:16,349 - INFO - Full solution test result: FAIL
2025-06-01 02:01:16,350 - ERROR - Proof error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:18:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:01:16,350 - ERROR - ❌ Implementation fails unit tests
2025-06-01 02:01:16,350 - ERROR - ❌ Proof has errors
2025-06-01 02:01:16,350 - INFO - 
==================================================
2025-06-01 02:01:16,350 - INFO - Processing task task_id_404...
2025-06-01 02:01:16,350 - INFO - Reading problem description and code template from tasks/task_id_404...
2025-06-01 02:01:16,350 - INFO - Problem description length: 483 characters
2025-06-01 02:01:16,350 - INFO - Reading unit tests from tasks/task_id_404...
2025-06-01 02:01:16,350 - INFO - Unit tests length: 228 characters
2025-06-01 02:01:16,351 - INFO - Running main workflow to generate solution...
2025-06-01 02:01:16,351 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.

-----Input-----
The input consists of two integers:
a: The first integer.
b: The second integer.

-----Output-----
The output is an integer:
Returns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.
2025-06-01 02:01:16,351 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def myMin (a : Int) (b : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b
def myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  (result ≤ a ∧ result ≤ b) ∧
  (result = a ∨ result = b)
  -- << SPEC END >>

theorem myMin_spec_satisfied (a : Int) (b : Int) :
  myMin_spec a b (myMin a b) := by
  -- << PROOF START >>
  unfold myMin myMin_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:01:16,379 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7159b5eca660>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:01:16,379 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:01:16,379 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:01:16,386 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eb4440>
2025-06-01 02:01:16,386 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7159b69508d0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:01:16,396 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b56a0>
2025-06-01 02:01:16,396 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:01:16,396 - DEBUG - send_request_headers.complete
2025-06-01 02:01:16,396 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:01:16,396 - DEBUG - send_request_body.complete
2025-06-01 02:01:16,396 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:01:17,540 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:01:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'45'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-58f7f7856-26f68'), (b'x-envoy-upstream-service-time', b'49'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999880'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_9963a9b2ec0bfcd105158bd9523e652a'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=eUC7JY_dwr9ikJAI89WhNIhY8QRcuvurB0lZ_pFHyFg-1748743277-1.0.1.1-apVd5hsVHTpmREHyWODV5oM7N1mFYWkOzSrx0z6LZaYqADbvSutoKMSArUF85Ni1thDaa3haWIzpMAca48y3.qQmMkvt01PJCGIwf9t.VaA; path=/; expires=Sun, 01-Jun-25 02:31:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=doPnDANQy3Cf8Cwsf.l9xEseXzF4He16mR_jHqeyjDs-1748743277544-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1f458cc28fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:01:17,540 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:01:17,540 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:01:17,540 - DEBUG - receive_response_body.complete
2025-06-01 02:01:17,541 - DEBUG - response_closed.started
2025-06-01 02:01:17,541 - DEBUG - response_closed.complete
2025-06-01 02:01:17,541 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:01:17 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '45'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-58f7f7856-26f68'), ('x-envoy-upstream-service-time', '49'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999880'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '7ms'), ('x-request-id', 'req_9963a9b2ec0bfcd105158bd9523e652a'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=eUC7JY_dwr9ikJAI89WhNIhY8QRcuvurB0lZ_pFHyFg-1748743277-1.0.1.1-apVd5hsVHTpmREHyWODV5oM7N1mFYWkOzSrx0z6LZaYqADbvSutoKMSArUF85Ni1thDaa3haWIzpMAca48y3.qQmMkvt01PJCGIwf9t.VaA; path=/; expires=Sun, 01-Jun-25 02:31:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=doPnDANQy3Cf8Cwsf.l9xEseXzF4He16mR_jHqeyjDs-1748743277544-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b1f458cc28fcd-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:01:17,541 - DEBUG - request_id: req_9963a9b2ec0bfcd105158bd9523e652a
2025-06-01 02:01:17,546 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Interacting with Lean

You are now familiar with the fundamentals of dependent type theory, both as a
language for defining mathematical objects and a language for constructing
proofs. The one thing you are missing is a mechanism for defining new data
types. We will fill this gap in the next chapter, which introduces the notion
of an _inductive data type_. But first, in this chapter, we take a break from
the mechanics of type theory to explore some pragmatic aspects of interacting
with Lean.

Not all of the information found here will be useful to you right away. We
recommend skimming this section to get a sense of Lean's features, and then
returning to it as necessary.

## Importing Files

The goal of Lean's front end is to interpret user input, construct formal
expressions, and check that they are well-formed and type-correct. Lean also
supports the use of various editors, which provide continuous checking and
feedback. More information can be found on the Lean [documentation
pages](https://lean-lang.org/documentation/).

The definitions and theorems in Lean's standard library are spread across
multiple files. Users may also wish to make use of additional libraries, or
develop their own projects across multiple files. When Lean starts, it
automatically imports the contents of the library `Init` folder, which
includes a number of fundamental definitions and constructions. As a result,
most of the examples we present here work "out of the box."

If you want to use additional files, however, they need to be imported
manually, via an `import` statement at the beginning of a file. The command

    
    
    import Bar.Baz.Blah
    

imports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted
relative to the Lean _search path_. Information as to how the search path is
determined can be found on the [documentation pages](https://lean-
lang.org/documentation/). By default, it includes the standard library
directory, and (in some contexts) the root of the user's local project.

Importing is transitive. In other words, if you import `Foo` and `Foo` imports
`Bar`, then you also have access to the contents of `Bar`, and do not need to
import it explicitly.

## More on Sections

Lean provides various sectioning mechanisms to help structure a theory. You
saw in [Variables and Sections](./dependent_type_theory.html#variables-and-
sections) that the `section` command makes it possible not only to group
together elements of a theory that go together, but also to declare variables
that are inserted as arguments to theorems and definitions, as necessary.
Remember that the point of the `variable` command is to declare variables for
use in theorems, as in the following example:

    
    
    section
    variable (x y : Nat)
    
    def double := x + x
    
    #check double y
    #check double (2 * x)
    
    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm
    
    theorem t1 : double (x + y) = double x + double y := by
      simp [double]
    
    #check t1 y
    #check t1 (2 * x)
    
    theorem t2 : double (x * y) = double x * y := by
      simp [double, Nat.add_mul]
    
    end
    

The definition of `double` does not have to declare `x` as an argument; Lean
detects the dependence and inserts it automatically. Similarly, Lean detects
the occurrence of `x` in `t1` and `t2`, and inserts it automatically there,
too. Note that `double` does _not_ have `y` as argument. Variables are only
included in declarations where they are actually used.

## More on Namespaces

In Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We
saw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean
provides mechanisms for working with hierarchical names. The command
`namespace foo` causes `foo` to be prepended to the name of each definition
and theorem until `end foo` is encountered. The command `open foo` then
creates temporary _aliases_ to definitions and theorems that begin with prefix
`foo`.

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    
    open Foo
    
    #check bar
    #check Foo.bar
    

The following definition

    
    
    def Foo.bar : Nat := 1
    

is treated as a macro, and expands to

    
    
    namespace Foo
    def bar : Nat := 1
    end Foo
    

Although the names of theorems and definitions have to be unique, the aliases
that identify them do not. When we open a namespace, an identifier may be
ambiguous. Lean tries to use type information to disambiguate the meaning in
context, but you can always disambiguate by giving the full name. To that end,
the string `_root_` is an explicit description of the empty prefix.

    
    
    def String.add (a b : String) : String :=
      a ++ b
    
    def Bool.add (a b : Bool) : Bool :=
      a != b
    
    def add (α β : Type) : Type := Sum α β
    
    open Bool
    open String
    -- #check add -- ambiguous
    #check String.add           -- String → String → String
    #check Bool.add             -- Bool → Bool → Bool
    #check _root_.add           -- Type → Type → Type
    
    #check add "hello" "world"  -- String
    #check add true false       -- Bool
    #check add Nat Nat          -- Type
    

We can prevent the shorter alias from being created by using the `protected`
keyword:

    
    
    protected def Foo.bar : Nat := 1
    
    open Foo
    
    -- #check bar -- error
    #check Foo.bar
    

This is often used for names like `Nat.rec` and `Nat.recOn`, to prevent
overloading of common names.

The `open` command admits variations. The command

    
    
    open Nat (succ zero gcd)
    #check zero     -- Nat
    #eval gcd 15 6  -- 3
    

creates aliases for only the identifiers listed. The command

    
    
    open Nat hiding succ gcd
    #check zero     -- Nat
    -- #eval gcd 15 6  -- error
    #eval Nat.gcd 15 6  -- 3
    

creates aliases for everything in the `Nat` namespace _except_ the identifiers
listed.

    
    
    open Nat renaming mul → times, add → plus
    #eval plus (times 2 2) 3  -- 7
    

creates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.

It is sometimes useful to `export` aliases from one namespace to another, or
to the top level. The command

    
    
    export Nat (succ add sub)
    

creates aliases for `succ`, `add`, and `sub` in the current namespace, so that
whenever the namespace is open, these aliases are available. If this command
is used outside a namespace, the aliases are exported to the top level.

## Attributes

The main function of Lean is to translate user input to formal expressions
that are checked by the kernel for correctness and then stored in the
environment for later use. But some commands have other effects on the
environment, either assigning attributes to objects in the environment,
defining notation, or declaring instances of type classes, as described in
[Chapter Type Classes](./type_classes.html). Most of these commands have
global effects, which is to say, they remain in effect not only in the current
file, but also in any file that imports it. However, such commands often
support the `local` modifier, which indicates that they only have effect until
the current `section` or `namespace` is closed, or until the end of the
current file.

In [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw
that theorems can be annotated with the `[simp]` attribute, which makes them
available for use by the simplifier. The following example defines the prefix
relation on lists, proves that this relation is reflexive, and assigns the
`[simp]` attribute to that theorem.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    

The simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to
`True`.

One can also assign the attribute any time after the definition takes place:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [simp] List.isPrefix_self
    

In all these cases, the attribute remains in effect in any file that imports
the one in which the declaration occurs. Adding the `local` modifier restricts
the scope:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
     ∃ t, l₁ ++ t = l₂
    section
    
    theorem List.isPrefix_self (as : List α) : isPrefix as as :=
      ⟨[], by simp⟩
    
    attribute [local simp] List.isPrefix_self
    
    example : isPrefix [1, 2, 3] [1, 2, 3] := by
      simp
    
    end
    
    -- Error:
    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by
    --  simp
    

For another example, we can use the `instance` command to assign the notation
`≤` to the `isPrefix` relation. That command, which will be explained in
[Chapter Type Classes](./type_classes.html), works by assigning an
`[instance]` attribute to the associated definition.

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    
    instance : LE (List α) where
      le := isPrefix
    
    theorem List.isPrefix_self (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    

That assignment can also be made local:

    
    
    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
      ∃ t, l₁ ++ t = l₂
    def instLe : LE (List α) :=
      { le := isPrefix }
    
    section
    attribute [local instance] instLe
    
    example (as : List α) : as ≤ as :=
      ⟨[], by simp⟩
    
    end
    
    -- Error:
    -- example (as : List α) : as ≤ as :=
    --  ⟨[], by simp⟩
    

In Section Notation below, we will discuss Lean's mechanisms for defining
notation, and see that they also support the `local` modifier. However, in
Section Setting Options, we will discuss Lean's mechanisms for setting
options, which does _not_ follow this pattern: options can _only_ be set
locally, which is to say, their scope is always restricted to the current
section or current file.

## More on Implicit Arguments

In [Section Implicit Arguments](./dependent_type_theory.html#implicit-
arguments), we saw that if Lean displays the type of a term `t` as `{x : α} →
β x`, then the curly brackets indicate that `x` has been marked as an
_implicit argument_ to `t`. This means that whenever you write `t`, a
placeholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you
don't want that to happen, you have to write `@t` instead.

Notice that implicit arguments are inserted eagerly. Suppose we define a
function `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,
when we write the expression `f 7` without further arguments, it is parsed as
`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that
a placeholder should only be added _before_ a subsequent explicit argument.
This annotation can also be written using as `⦃y : Nat⦄`, where the unicode
brackets are entered as `\{{` and `\}}`, respectively. With this annotation,
the expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as
`f 7 _ 3`, just as it would be with the strong annotation.

To illustrate the difference, consider the following example, which shows that
a reflexive euclidean relation is both symmetric and transitive.

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b : α}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {a b c : α}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
     th2 (th1 reflr @euclr) @euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3
    

The results are broken down into small steps: `th1` shows that a relation that
is reflexive and euclidean is symmetric, and `th2` shows that a relation that
is symmetric and euclidean is transitive. Then `th3` combines the two results.
But notice that we have to manually disable the implicit arguments in `euclr`,
because otherwise too many implicit arguments are inserted. The problem goes
away if we use weak implicit arguments:

    
    
    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ (a : α), r a a
    
    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b : α}}, r a b → r b a
    
    def transitive {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r b c → r a c
    
    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
      ∀ {{a b c : α}}, r a b → r a c → r b c
    
    theorem th1 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : symmetric r :=
      fun {a b : α} =>
      fun (h : r a b) =>
      show r b a from euclr h (reflr _)
    
    theorem th2 {α : Type u} {r : α → α → Prop}
                (symmr : symmetric r) (euclr : euclidean r)
                : transitive r :=
      fun {a b c : α} =>
      fun (rab : r a b) (rbc : r b c) =>
      euclr (symmr rab) rbc
    
    theorem th3 {α : Type u} {r : α → α → Prop}
                (reflr : reflexive r) (euclr : euclidean r)
                : transitive r :=
      th2 (th1 reflr euclr) euclr
    
    variable (r : α → α → Prop)
    variable (euclr : euclidean r)
    
    #check euclr  -- euclidean r
    

There is a third kind of implicit argument that is denoted with square
brackets, `[` and `]`. These are used for type classes, as explained in
[Chapter Type Classes](./type_classes.html).

## Notation

Identifiers in Lean can include any alphanumeric characters, including Greek
characters (other than ∀ , Σ , and λ , which, as we have seen, have a special
meaning in the dependent type theory). They can also include subscripts, which
can be entered by typing `\_` followed by the desired subscripted character.

Lean's parser is extensible, which is to say, we can define new notation.

Lean's syntax can be extended and customized by users at every level, ranging
from basic "mixfix" notations to custom elaborators. In fact, all builtin
syntax is parsed and processed using the same mechanisms and APIs open to
users. In this section, we will describe and explain the various extension
points.

While introducing new notations is a relatively rare feature in programming
languages and sometimes even frowned upon because of its potential to obscure
code, it is an invaluable tool in formalization for expressing established
conventions and notations of the respective field succinctly in code. Going
beyond basic notations, Lean's ability to factor out common boilerplate code
into (well-behaved) macros and to embed entire custom domain specific
languages (DSLs) to textually encode subproblems efficiently and readably can
be of great benefit to both programmers and proof engineers alike.

### Notations and Precedence

The most basic syntax extension commands allow introducing new (or overloading
existing) prefix, infix, and postfix operators.

    
    
    infixl:65   " + " => HAdd.hAdd  -- left-associative
    infix:50    " = " => Eq         -- non-associative
    infixr:80   " ^ " => HPow.hPow  -- right-associative
    prefix:100  "-"   => Neg.neg
    set_option quotPrecheck false
    postfix:max "⁻¹"  => Inv.inv
    

After the initial command name describing the operator kind (its "fixity"), we
give the _parsing precedence_ of the operator preceded by a colon `:`, then a
new or existing token surrounded by double quotes (the whitespace is used for
pretty printing), then the function this operator should be translated to
after the arrow `=>`.

The precedence is a natural number describing how "tightly" an operator binds
to its arguments, encoding the order of operations. We can make this more
precise by looking at the commands the above unfold to:

    
    
    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs
    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs
    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs
    notation:100 "-" arg:100 => Neg.neg arg
    set_option quotPrecheck false
    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024
    

It turns out that all commands from the first code block are in fact command
_macros_ translating to the more general `notation` command. We will learn
about writing such macros below. Instead of a single token, the `notation`
command accepts a mixed sequence of tokens and named term placeholders with
precedences, which can be referenced on the right-hand side of `=>` and will
be replaced by the respective term parsed at that position. A placeholder with
precedence `p` accepts only notations with precedence at least `p` in that
place. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +
(b + c)` because the right-hand side operand of an `infixl` notation has
precedence one greater than the notation itself. In contrast, `infixr` reuses
the notation's precedence for the right-hand side operand, so `a ^ b ^ c`
_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to
introduce an infix notation like

    
    
    set_option quotPrecheck false
    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs
    

where the precedences do not sufficiently determine associativity, Lean's
parser will default to right associativity. More precisely, Lean's parser
follows a local _longest parse_ rule in the presence of ambiguous grammars:
when parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue
parsing as long as possible (as the current precedence allows), not stopping
after `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~
c)`.

As mentioned above, the `notation` command allows us to define arbitrary
_mixfix_ syntax freely mixing tokens and placeholders.

    
    
    set_option quotPrecheck false
    notation:max "(" e ")" => e
    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ
    

Placeholders without precedence default to `0`, i.e. they accept notations of
any precedence in their place. If two notations overlap, we again apply the
longest parse rule:

    
    
    notation:65 a " + " b:66 " + " c:66 => a + b - c
    #eval 1 + 2 + 3  -- 0
    

The new notation is preferred to the binary notation since the latter, before
chaining, would stop parsing after `1 + 2`. If there are multiple notations
accepting the same longest parse, the choice will be delayed until
elaboration, which will fail unless exactly one overload is type-correct.

## Coercions

In Lean, the type of natural numbers, `Nat`, is different from the type of
integers, `Int`. But there is a function `Int.ofNat` that embeds the natural
numbers in the integers, meaning that we can view any natural number as an
integer, when needed. Lean has mechanisms to detect and insert _coercions_ of
this sort.

    
    
    variable (m n : Nat)
    variable (i j : Int)
    
    #check i + m      -- i + Int.ofNat m : Int
    #check i + m + j  -- i + Int.ofNat m + j : Int
    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int
    

## Displaying Information

There are a number of ways in which you can query Lean for information about
its current state and the objects and theorems that are available in the
current context. You have already seen two of the most common ones, `#check`
and `#eval`. Remember that `#check` is often used in conjunction with the `@`
operator, which makes all of the arguments to a theorem or definition
explicit. In addition, you can use the `#print` command to get information
about any identifier. If the identifier denotes a definition or theorem, Lean
prints the type of the symbol, and its definition. If it is a constant or an
axiom, Lean indicates that fact, and shows the type.

    
    
    -- examples with equality
    #check Eq
    #check @Eq
    #check Eq.symm
    #check @Eq.symm
    
    #print Eq.symm
    
    -- examples with And
    #check And
    #check And.intro
    #check @And.intro
    
    -- a user-defined function
    def foo {α : Type u} (x : α) : α := x
    
    #check foo
    #check @foo
    #print foo
    

## Setting Options

Lean maintains a number of internal variables that can be set by users to
control its behavior. The syntax for doing so is as follows:

    
    
    set_option <name> <value>
    

One very useful family of options controls the way Lean's _pretty- printer_
displays terms. The following options take an input of true or false:

    
    
    pp.explicit  : display implicit arguments
    pp.universes : display hidden universe parameters
    pp.notation  : display output using defined notations
    

As an example, the following settings yield much longer output:

    
    
    set_option pp.explicit true
    set_option pp.universes true
    set_option pp.notation false
    
    #check 2 + 2 = 4
    #reduce (fun x => x + 2) = (fun x => x + 3)
    #check (fun x => x + 1) 1
    

The command `set_option pp.all true` carries out these settings all at once,
whereas `set_option pp.all false` reverts to the previous values. Pretty
printing additional information is often very useful when you are debugging a
proof, or trying to understand a cryptic error message. Too much information
can be overwhelming, though, and Lean's defaults are generally sufficient for
ordinary interactions.

## Using the Library

To use Lean effectively you will inevitably need to make use of definitions
and theorems in the library. Recall that the `import` command at the beginning
of a file imports previously compiled results from other files, and that
importing is transitive; if you import `Foo` and `Foo` imports `Bar`, then the
definitions and theorems from `Bar` are available to you as well. But the act
of opening a namespace, which provides shorter names, does not carry over. In
each file, you need to open the namespaces you wish to use.

In general, it is important for you to be familiar with the library and its
contents, so you know what theorems, definitions, notations, and resources are
available to you. Below we will see that Lean's editor modes can also help you
find things you need, but studying the contents of the library directly is
often unavoidable. Lean's standard library can be found online, on GitHub:

  * <https://github.com/leanprover/lean4/tree/master/src/Init>

  * <https://github.com/leanprover/std4/tree/main/Std>

You can see the contents of these directories and files using GitHub's browser
interface. If you have installed Lean on your own computer, you can find the
library in the `lean` folder, and explore it with your file manager. Comment
headers at the top of each file provide additional information.

Lean's library developers follow general naming guidelines to make it easier
to guess the name of a theorem you need, or to find it using tab completion in
editors with a Lean mode that supports this, which is discussed in the next
section. Identifiers are generally `camelCase`, and types are `CamelCase`. For
theorem names, we rely on descriptive names where the different components are
separated by `_`s. Often the name of theorem simply describes the conclusion:

    
    
    #check Nat.succ_ne_zero
    #check Nat.zero_add
    #check Nat.mul_one
    #check Nat.le_of_succ_le_succ
    

Remember that identifiers in Lean can be organized into hierarchical
namespaces. For example, the theorem named `le_of_succ_le_succ` in the
namespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name
is made available by the command `open Nat` (for names not marked as
`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)
and [Chapter Structures and Records](./structures_and_records.html) that
defining structures and inductive data types in Lean generates associated
operations, and these are stored in a namespace with the same name as the type
under definition. For example, the product type comes with the following
operations:

    
    
    #check @Prod.mk
    #check @Prod.fst
    #check @Prod.snd
    #check @Prod.rec
    

The first is used to construct a pair, whereas the next two, `Prod.fst` and
`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another
mechanism for defining functions on a product in terms of a function on the
two components. Names like `Prod.rec` are _protected_ , which means that one
has to use the full name even when the `Prod` namespace is open.

With the propositions as types correspondence, logical connectives are also
instances of inductive types, and so we tend to use dot notation for them as
well:

    
    
    #check @And.intro
    #check @And.casesOn
    #check @And.left
    #check @And.right
    #check @Or.inl
    #check @Or.inr
    #check @Or.elim
    #check @Exists.intro
    #check @Exists.elim
    #check @Eq.refl
    #check @Eq.subst
    

## Auto Bound Implicit Arguments

In the previous section, we have shown how implicit arguments make functions
more convenient to use. However, functions such as `compose` are still quite
verbose to define. Note that the universe polymorphic `compose` is even more
verbose than the one previously defined.

    
    
    universe u v w
    def compose {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

You can avoid the `universe` command by providing the universe parameters when
defining `compose`.

    
    
    def compose.{u, v, w}
                {α : Type u} {β : Type v} {γ : Type w}
                (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    

Lean 4 supports a new feature called _auto bound implicit arguments_. It makes
functions such as `compose` much more convenient to write. When Lean processes
the header of a declaration, any unbound identifier is automatically added as
an implicit argument _if_ it is a single lower case or greek letter. With this
feature we can write `compose` as

    
    
    def compose (g : β → γ) (f : α → β) (x : α) : γ :=
      g (f x)
    
    #check @compose
    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ
    

Note that Lean inferred a more general type using `Sort` instead of `Type`.

Although we love this feature and use it extensively when implementing Lean,
we realize some users may feel uncomfortable with it. Thus, you can disable it
using the command `set_option autoImplicit false`.

    
    
    set_option autoImplicit false
    /- The following definition produces `unknown identifier` errors -/
    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=
    --   g (f x)
    

## Implicit Lambdas

In Lean 3 stdlib, we find many
[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)
of the dreadful `@`+`_` idiom. It is often used when the expected type is a
function type with implicit arguments, and we have a constant (`reader_t.pure`
in the example) which also takes implicit arguments. In Lean 4, the elaborator
automatically introduces lambdas for consuming implicit arguments. We are
still exploring this feature and analyzing its impact, but the experience so
far has been very positive. Here is the example from the link above using Lean
4 implicit lambdas.

    
    
    variable (ρ : Type) (m : Type → Type) [Monad m]
    instance : Monad (ReaderT ρ m) where
      pure := ReaderT.pure
      bind := ReaderT.bind
    

Users can disable the implicit lambda feature by using `@` or writing a lambda
expression with `{}` or `[]` binder annotations. Here are few examples

    
    
    namespace ex2
    def id1 : {α : Type} → α → α :=
      fun x => x
    
    def listId : List ({α : Type} → α → α) :=
      (fun x => x) :: []
    
    -- In this example, implicit lambda introduction has been disabled because
    -- we use `@` before `fun`
    def id2 : {α : Type} → α → α :=
      @fun α (x : α) => id1 x
    
    def id3 : {α : Type} → α → α :=
      @fun α x => id1 x
    
    def id4 : {α : Type} → α → α :=
      fun x => id1 x
    
    -- In this example, implicit lambda introduction has been disabled
    -- because we used the binder annotation `{...}`
    def id5 : {α : Type} → α → α :=
      fun {α} x => id1 x
    end ex2
    

## Sugar for Simple Functions

In Lean 3, we can create simple functions from infix operators by using
parentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we
generalize this notation using `·` as a placeholder. Here are a few examples:

    
    
    namespace ex3
    #check (· + 1)
    -- fun a => a + 1
    #check (2 - ·)
    -- fun a => 2 - a
    #eval [1, 2, 3, 4, 5].foldl (·*·) 1
    -- 120
    
    def f (x y z : Nat) :=
      x + y + z
    
    #check (f · 1 ·)
    -- fun a b => f a 1 b
    
    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)
    -- [1, 3, 5]
    end ex3
    

As in Lean 3, the notation is activated using parentheses, and the lambda
abstraction is created by collecting the nested `·`s. The collection is
interrupted by nested parentheses. In the following example, two different
lambda expressions are created.

    
    
    #check (Prod.mk · (· + 1))
    -- fun a => (a, fun b => b + 1)
    

## Named Arguments

Named arguments enable you to specify an argument for a parameter by matching
the argument with its name rather than with its position in the parameter
list. If you don't remember the order of the parameters but know their names,
you can send the arguments in any order. You may also provide the value for an
implicit parameter when
2025-06-01 02:01:17,549 - DEBUG - close.started
2025-06-01 02:01:17,549 - DEBUG - close.complete
2025-06-01 02:01:17,561 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.'}], 'model': 'o3-mini'}}
2025-06-01 02:01:17,562 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:01:17,562 - DEBUG - close.started
2025-06-01 02:01:17,562 - DEBUG - close.complete
2025-06-01 02:01:17,562 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:01:17,570 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b58b0>
2025-06-01 02:01:17,570 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:01:17,580 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b6c90>
2025-06-01 02:01:17,580 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:01:17,580 - DEBUG - send_request_headers.complete
2025-06-01 02:01:17,580 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:01:17,580 - DEBUG - send_request_body.complete
2025-06-01 02:01:17,580 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:01:23,126 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:01:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5314'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5318'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199578'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'126ms'), (b'x-request-id', b'req_086a368328b4586b9fa79770cd90c6e8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1f4cedc34278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:01:23,126 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:01:23,126 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:01:23,126 - DEBUG - receive_response_body.complete
2025-06-01 02:01:23,126 - DEBUG - response_closed.started
2025-06-01 02:01:23,126 - DEBUG - response_closed.complete
2025-06-01 02:01:23,127 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:01:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5314', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5318', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199578', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '126ms', 'x-request-id': 'req_086a368328b4586b9fa79770cd90c6e8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1f4cedc34278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:01:23,127 - DEBUG - request_id: req_086a368328b4586b9fa79770cd90c6e8
2025-06-01 02:01:23,127 - INFO - Attempt 1/3
2025-06-01 02:01:23,127 - INFO - Current plan: {
  "plan_summary": "Define a Lean 4 function to compute the minimum of two integers by comparing them using a simple if-then-else statement. The plan uses basic integer comparison and returns the value that is less than or equal to both inputs.",
  "steps": [
    "Define the function signature to accept two integer arguments and return an integer.",
    "Implement an if-then-else construct to compare the two integers.",
    "Return the first integer if it is less than or equal to the second; otherwise, return the second integer.",
    "Optionally, add a proof or comment that the returned value is less than or equal to both inputs."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "integer comparison",
    "if then else",
    "min function"
  ],
  "proof_keywords": [
    "basic arithmetic",
    "inequality",
    "reflexivity",
    "case analysis"
  ],
  "assumptions": [
    "Both inputs are integers and can be compared using standard comparison operators.",
    "Equality case is handled by either branch since returning either integer satisfies the requirement."
  ],
  "retry_guidance": "If the implementation does not compile or does not correctly compare the integers, re-check the conditional expression's syntax in Lean 4 and ensure that the integers are properly typed."
}
2025-06-01 02:01:23,128 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Define a Lean 4 function to compute the minimum of two integers by comparing them using a simple if-then-else statement. The plan uses basic integer comparison and returns the value that is less than or equal to both inputs.",\n  "steps": [\n    "Define the function signature to accept two integer arguments and return an integer.",\n    "Implement an if-then-else construct to compare the two integers.",\n    "Return the first integer if it is less than or equal to the second; otherwise, return the second integer.",\n    "Optionally, add a proof or comment that the returned value is less than or equal to both inputs."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "integer comparison",\n    "if then else",\n    "min function"\n  ],\n  "proof_keywords": [\n    "basic arithmetic",\n    "inequality",\n    "reflexivity",\n    "case analysis"\n  ],\n  "assumptions": [\n    "Both inputs are integers and can be compared using standard comparison operators.",\n    "Equality case is handled by either branch since returning either integer satisfies the requirement."\n  ],\n  "retry_guidance": "If the implementation does not compile or does not correctly compare the integers, re-check the conditional expression\'s syntax in Lean 4 and ensure that the integers are properly typed."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef myMin (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b\ndef myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result ≤ a ∧ result ≤ b) ∧\n  (result = a ∨ result = b)\n  -- << SPEC END >>\n\ntheorem myMin_spec_satisfied (a : Int) (b : Int) :\n  myMin_spec a b (myMin a b) := by\n  -- << PROOF START >>\n  unfold myMin myMin_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Interacting with Lean\n\nYou are now familiar with the fundamentals of dependent type theory, both as a\nlanguage for defining mathematical objects and a language for constructing\nproofs. The one thing you are missing is a mechanism for defining new data\ntypes. We will fill this gap in the next chapter, which introduces the notion\nof an _inductive data type_. But first, in this chapter, we take a break from\nthe mechanics of type theory to explore some pragmatic aspects of interacting\nwith Lean.\n\nNot all of the information found here will be useful to you right away. We\nrecommend skimming this section to get a sense of Lean\'s features, and then\nreturning to it as necessary.\n\n## Importing Files\n\nThe goal of Lean\'s front end is to interpret user input, construct formal\nexpressions, and check that they are well-formed and type-correct. Lean also\nsupports the use of various editors, which provide continuous checking and\nfeedback. More information can be found on the Lean [documentation\npages](https://lean-lang.org/documentation/).\n\nThe definitions and theorems in Lean\'s standard library are spread across\nmultiple files. Users may also wish to make use of additional libraries, or\ndevelop their own projects across multiple files. When Lean starts, it\nautomatically imports the contents of the library `Init` folder, which\nincludes a number of fundamental definitions and constructions. As a result,\nmost of the examples we present here work "out of the box."\n\nIf you want to use additional files, however, they need to be imported\nmanually, via an `import` statement at the beginning of a file. The command\n\n    \n    \n    import Bar.Baz.Blah\n    \n\nimports the file `Bar/Baz/Blah.olean`, where the descriptions are interpreted\nrelative to the Lean _search path_. Information as to how the search path is\ndetermined can be found on the [documentation pages](https://lean-\nlang.org/documentation/). By default, it includes the standard library\ndirectory, and (in some contexts) the root of the user\'s local project.\n\nImporting is transitive. In other words, if you import `Foo` and `Foo` imports\n`Bar`, then you also have access to the contents of `Bar`, and do not need to\nimport it explicitly.\n\n## More on Sections\n\nLean provides various sectioning mechanisms to help structure a theory. You\nsaw in [Variables and Sections](./dependent_type_theory.html#variables-and-\nsections) that the `section` command makes it possible not only to group\ntogether elements of a theory that go together, but also to declare variables\nthat are inserted as arguments to theorems and definitions, as necessary.\nRemember that the point of the `variable` command is to declare variables for\nuse in theorems, as in the following example:\n\n    \n    \n    section\n    variable (x y : Nat)\n    \n    def double := x + x\n    \n    #check double y\n    #check double (2 * x)\n    \n    attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm\n    \n    theorem t1 : double (x + y) = double x + double y := by\n      simp [double]\n    \n    #check t1 y\n    #check t1 (2 * x)\n    \n    theorem t2 : double (x * y) = double x * y := by\n      simp [double, Nat.add_mul]\n    \n    end\n    \n\nThe definition of `double` does not have to declare `x` as an argument; Lean\ndetects the dependence and inserts it automatically. Similarly, Lean detects\nthe occurrence of `x` in `t1` and `t2`, and inserts it automatically there,\ntoo. Note that `double` does _not_ have `y` as argument. Variables are only\nincluded in declarations where they are actually used.\n\n## More on Namespaces\n\nIn Lean, identifiers are given by hierarchical _names_ like `Foo.Bar.baz`. We\nsaw in [Namespaces](./dependent_type_theory.html#namespaces) that Lean\nprovides mechanisms for working with hierarchical names. The command\n`namespace foo` causes `foo` to be prepended to the name of each definition\nand theorem until `end foo` is encountered. The command `open foo` then\ncreates temporary _aliases_ to definitions and theorems that begin with prefix\n`foo`.\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n    open Foo\n    \n    #check bar\n    #check Foo.bar\n    \n\nThe following definition\n\n    \n    \n    def Foo.bar : Nat := 1\n    \n\nis treated as a macro, and expands to\n\n    \n    \n    namespace Foo\n    def bar : Nat := 1\n    end Foo\n    \n\nAlthough the names of theorems and definitions have to be unique, the aliases\nthat identify them do not. When we open a namespace, an identifier may be\nambiguous. Lean tries to use type information to disambiguate the meaning in\ncontext, but you can always disambiguate by giving the full name. To that end,\nthe string `_root_` is an explicit description of the empty prefix.\n\n    \n    \n    def String.add (a b : String) : String :=\n      a ++ b\n    \n    def Bool.add (a b : Bool) : Bool :=\n      a != b\n    \n    def add (α β : Type) : Type := Sum α β\n    \n    open Bool\n    open String\n    -- #check add -- ambiguous\n    #check String.add           -- String → String → String\n    #check Bool.add             -- Bool → Bool → Bool\n    #check _root_.add           -- Type → Type → Type\n    \n    #check add "hello" "world"  -- String\n    #check add true false       -- Bool\n    #check add Nat Nat          -- Type\n    \n\nWe can prevent the shorter alias from being created by using the `protected`\nkeyword:\n\n    \n    \n    protected def Foo.bar : Nat := 1\n    \n    open Foo\n    \n    -- #check bar -- error\n    #check Foo.bar\n    \n\nThis is often used for names like `Nat.rec` and `Nat.recOn`, to prevent\noverloading of common names.\n\nThe `open` command admits variations. The command\n\n    \n    \n    open Nat (succ zero gcd)\n    #check zero     -- Nat\n    #eval gcd 15 6  -- 3\n    \n\ncreates aliases for only the identifiers listed. The command\n\n    \n    \n    open Nat hiding succ gcd\n    #check zero     -- Nat\n    -- #eval gcd 15 6  -- error\n    #eval Nat.gcd 15 6  -- 3\n    \n\ncreates aliases for everything in the `Nat` namespace _except_ the identifiers\nlisted.\n\n    \n    \n    open Nat renaming mul → times, add → plus\n    #eval plus (times 2 2) 3  -- 7\n    \n\ncreates aliases renaming `Nat.mul` to `times` and `Nat.add` to `plus`.\n\nIt is sometimes useful to `export` aliases from one namespace to another, or\nto the top level. The command\n\n    \n    \n    export Nat (succ add sub)\n    \n\ncreates aliases for `succ`, `add`, and `sub` in the current namespace, so that\nwhenever the namespace is open, these aliases are available. If this command\nis used outside a namespace, the aliases are exported to the top level.\n\n## Attributes\n\nThe main function of Lean is to translate user input to formal expressions\nthat are checked by the kernel for correctness and then stored in the\nenvironment for later use. But some commands have other effects on the\nenvironment, either assigning attributes to objects in the environment,\ndefining notation, or declaring instances of type classes, as described in\n[Chapter Type Classes](./type_classes.html). Most of these commands have\nglobal effects, which is to say, they remain in effect not only in the current\nfile, but also in any file that imports it. However, such commands often\nsupport the `local` modifier, which indicates that they only have effect until\nthe current `section` or `namespace` is closed, or until the end of the\ncurrent file.\n\nIn [Section Using the Simplifier](./tactics.html#using-the-simplifier), we saw\nthat theorems can be annotated with the `[simp]` attribute, which makes them\navailable for use by the simplifier. The following example defines the prefix\nrelation on lists, proves that this relation is reflexive, and assigns the\n`[simp]` attribute to that theorem.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    @[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n\nThe simplifier then proves `isPrefix [1, 2, 3] [1, 2, 3]` by rewriting it to\n`True`.\n\nOne can also assign the attribute any time after the definition takes place:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [simp] List.isPrefix_self\n    \n\nIn all these cases, the attribute remains in effect in any file that imports\nthe one in which the declaration occurs. Adding the `local` modifier restricts\nthe scope:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n     ∃ t, l₁ ++ t = l₂\n    section\n    \n    theorem List.isPrefix_self (as : List α) : isPrefix as as :=\n      ⟨[], by simp⟩\n    \n    attribute [local simp] List.isPrefix_self\n    \n    example : isPrefix [1, 2, 3] [1, 2, 3] := by\n      simp\n    \n    end\n    \n    -- Error:\n    -- example : isPrefix [1, 2, 3] [1, 2, 3] := by\n    --  simp\n    \n\nFor another example, we can use the `instance` command to assign the notation\n`≤` to the `isPrefix` relation. That command, which will be explained in\n[Chapter Type Classes](./type_classes.html), works by assigning an\n`[instance]` attribute to the associated definition.\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    \n    instance : LE (List α) where\n      le := isPrefix\n    \n    theorem List.isPrefix_self (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n\nThat assignment can also be made local:\n\n    \n    \n    def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=\n      ∃ t, l₁ ++ t = l₂\n    def instLe : LE (List α) :=\n      { le := isPrefix }\n    \n    section\n    attribute [local instance] instLe\n    \n    example (as : List α) : as ≤ as :=\n      ⟨[], by simp⟩\n    \n    end\n    \n    -- Error:\n    -- example (as : List α) : as ≤ as :=\n    --  ⟨[], by simp⟩\n    \n\nIn Section Notation below, we will discuss Lean\'s mechanisms for defining\nnotation, and see that they also support the `local` modifier. However, in\nSection Setting Options, we will discuss Lean\'s mechanisms for setting\noptions, which does _not_ follow this pattern: options can _only_ be set\nlocally, which is to say, their scope is always restricted to the current\nsection or current file.\n\n## More on Implicit Arguments\n\nIn [Section Implicit Arguments](./dependent_type_theory.html#implicit-\narguments), we saw that if Lean displays the type of a term `t` as `{x : α} →\nβ x`, then the curly brackets indicate that `x` has been marked as an\n_implicit argument_ to `t`. This means that whenever you write `t`, a\nplaceholder, or "hole," is inserted, so that `t` is replaced by `@t _`. If you\ndon\'t want that to happen, you have to write `@t` instead.\n\nNotice that implicit arguments are inserted eagerly. Suppose we define a\nfunction `f (x : Nat) {y : Nat} (z : Nat)` with the arguments shown. Then,\nwhen we write the expression `f 7` without further arguments, it is parsed as\n`f 7 _`. Lean offers a weaker annotation, `{{y : Nat}}`, which specifies that\na placeholder should only be added _before_ a subsequent explicit argument.\nThis annotation can also be written using as `⦃y : Nat⦄`, where the unicode\nbrackets are entered as `\\{{` and `\\}}`, respectively. With this annotation,\nthe expression `f 7` would be parsed as is, whereas `f 7 3` would be parsed as\n`f 7 _ 3`, just as it would be with the strong annotation.\n\nTo illustrate the difference, consider the following example, which shows that\na reflexive euclidean relation is both symmetric and transitive.\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b : α}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {a b c : α}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n     th2 (th1 reflr @euclr) @euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3\n    \n\nThe results are broken down into small steps: `th1` shows that a relation that\nis reflexive and euclidean is symmetric, and `th2` shows that a relation that\nis symmetric and euclidean is transitive. Then `th3` combines the two results.\nBut notice that we have to manually disable the implicit arguments in `euclr`,\nbecause otherwise too many implicit arguments are inserted. The problem goes\naway if we use weak implicit arguments:\n\n    \n    \n    def reflexive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ (a : α), r a a\n    \n    def symmetric {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b : α}}, r a b → r b a\n    \n    def transitive {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r b c → r a c\n    \n    def euclidean {α : Type u} (r : α → α → Prop) : Prop :=\n      ∀ {{a b c : α}}, r a b → r a c → r b c\n    \n    theorem th1 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : symmetric r :=\n      fun {a b : α} =>\n      fun (h : r a b) =>\n      show r b a from euclr h (reflr _)\n    \n    theorem th2 {α : Type u} {r : α → α → Prop}\n                (symmr : symmetric r) (euclr : euclidean r)\n                : transitive r :=\n      fun {a b c : α} =>\n      fun (rab : r a b) (rbc : r b c) =>\n      euclr (symmr rab) rbc\n    \n    theorem th3 {α : Type u} {r : α → α → Prop}\n                (reflr : reflexive r) (euclr : euclidean r)\n                : transitive r :=\n      th2 (th1 reflr euclr) euclr\n    \n    variable (r : α → α → Prop)\n    variable (euclr : euclidean r)\n    \n    #check euclr  -- euclidean r\n    \n\nThere is a third kind of implicit argument that is denoted with square\nbrackets, `[` and `]`. These are used for type classes, as explained in\n[Chapter Type Classes](./type_classes.html).\n\n## Notation\n\nIdentifiers in Lean can include any alphanumeric characters, including Greek\ncharacters (other than ∀ , Σ , and λ , which, as we have seen, have a special\nmeaning in the dependent type theory). They can also include subscripts, which\ncan be entered by typing `\\_` followed by the desired subscripted character.\n\nLean\'s parser is extensible, which is to say, we can define new notation.\n\nLean\'s syntax can be extended and customized by users at every level, ranging\nfrom basic "mixfix" notations to custom elaborators. In fact, all builtin\nsyntax is parsed and processed using the same mechanisms and APIs open to\nusers. In this section, we will describe and explain the various extension\npoints.\n\nWhile introducing new notations is a relatively rare feature in programming\nlanguages and sometimes even frowned upon because of its potential to obscure\ncode, it is an invaluable tool in formalization for expressing established\nconventions and notations of the respective field succinctly in code. Going\nbeyond basic notations, Lean\'s ability to factor out common boilerplate code\ninto (well-behaved) macros and to embed entire custom domain specific\nlanguages (DSLs) to textually encode subproblems efficiently and readably can\nbe of great benefit to both programmers and proof engineers alike.\n\n### Notations and Precedence\n\nThe most basic syntax extension commands allow introducing new (or overloading\nexisting) prefix, infix, and postfix operators.\n\n    \n    \n    infixl:65   " + " => HAdd.hAdd  -- left-associative\n    infix:50    " = " => Eq         -- non-associative\n    infixr:80   " ^ " => HPow.hPow  -- right-associative\n    prefix:100  "-"   => Neg.neg\n    set_option quotPrecheck false\n    postfix:max "⁻¹"  => Inv.inv\n    \n\nAfter the initial command name describing the operator kind (its "fixity"), we\ngive the _parsing precedence_ of the operator preceded by a colon `:`, then a\nnew or existing token surrounded by double quotes (the whitespace is used for\npretty printing), then the function this operator should be translated to\nafter the arrow `=>`.\n\nThe precedence is a natural number describing how "tightly" an operator binds\nto its arguments, encoding the order of operations. We can make this more\nprecise by looking at the commands the above unfold to:\n\n    \n    \n    notation:65 lhs:65 " + " rhs:66 => HAdd.hAdd lhs rhs\n    notation:50 lhs:51 " = " rhs:51 => Eq lhs rhs\n    notation:80 lhs:81 " ^ " rhs:80 => HPow.hPow lhs rhs\n    notation:100 "-" arg:100 => Neg.neg arg\n    set_option quotPrecheck false\n    notation:1024 arg:1024 "⁻¹" => Inv.inv arg  -- `max` is a shorthand for precedence 1024\n    \n\nIt turns out that all commands from the first code block are in fact command\n_macros_ translating to the more general `notation` command. We will learn\nabout writing such macros below. Instead of a single token, the `notation`\ncommand accepts a mixed sequence of tokens and named term placeholders with\nprecedences, which can be referenced on the right-hand side of `=>` and will\nbe replaced by the respective term parsed at that position. A placeholder with\nprecedence `p` accepts only notations with precedence at least `p` in that\nplace. Thus the string `a + b + c` cannot be parsed as the equivalent of `a +\n(b + c)` because the right-hand side operand of an `infixl` notation has\nprecedence one greater than the notation itself. In contrast, `infixr` reuses\nthe notation\'s precedence for the right-hand side operand, so `a ^ b ^ c`\n_can_ be parsed as `a ^ (b ^ c)`. Note that if we used `notation` directly to\nintroduce an infix notation like\n\n    \n    \n    set_option quotPrecheck false\n    notation:65 lhs:65 " ~ " rhs:65 => wobble lhs rhs\n    \n\nwhere the precedences do not sufficiently determine associativity, Lean\'s\nparser will default to right associativity. More precisely, Lean\'s parser\nfollows a local _longest parse_ rule in the presence of ambiguous grammars:\nwhen parsing the right-hand side of `a ~` in `a ~ b ~ c`, it will continue\nparsing as long as possible (as the current precedence allows), not stopping\nafter `b` but parsing `~ c` as well. Thus the term is equivalent to `a ~ (b ~\nc)`.\n\nAs mentioned above, the `notation` command allows us to define arbitrary\n_mixfix_ syntax freely mixing tokens and placeholders.\n\n    \n    \n    set_option quotPrecheck false\n    notation:max "(" e ")" => e\n    notation:10 Γ " ⊢ " e " : " τ => Typing Γ e τ\n    \n\nPlaceholders without precedence default to `0`, i.e. they accept notations of\nany precedence in their place. If two notations overlap, we again apply the\nlongest parse rule:\n\n    \n    \n    notation:65 a " + " b:66 " + " c:66 => a + b - c\n    #eval 1 + 2 + 3  -- 0\n    \n\nThe new notation is preferred to the binary notation since the latter, before\nchaining, would stop parsing after `1 + 2`. If there are multiple notations\naccepting the same longest parse, the choice will be delayed until\nelaboration, which will fail unless exactly one overload is type-correct.\n\n## Coercions\n\nIn Lean, the type of natural numbers, `Nat`, is different from the type of\nintegers, `Int`. But there is a function `Int.ofNat` that embeds the natural\nnumbers in the integers, meaning that we can view any natural number as an\ninteger, when needed. Lean has mechanisms to detect and insert _coercions_ of\nthis sort.\n\n    \n    \n    variable (m n : Nat)\n    variable (i j : Int)\n    \n    #check i + m      -- i + Int.ofNat m : Int\n    #check i + m + j  -- i + Int.ofNat m + j : Int\n    #check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int\n    \n\n## Displaying Information\n\nThere are a number of ways in which you can query Lean for information about\nits current state and the objects and theorems that are available in the\ncurrent context. You have already seen two of the most common ones, `#check`\nand `#eval`. Remember that `#check` is often used in conjunction with the `@`\noperator, which makes all of the arguments to a theorem or definition\nexplicit. In addition, you can use the `#print` command to get information\nabout any identifier. If the identifier denotes a definition or theorem, Lean\nprints the type of the symbol, and its definition. If it is a constant or an\naxiom, Lean indicates that fact, and shows the type.\n\n    \n    \n    -- examples with equality\n    #check Eq\n    #check @Eq\n    #check Eq.symm\n    #check @Eq.symm\n    \n    #print Eq.symm\n    \n    -- examples with And\n    #check And\n    #check And.intro\n    #check @And.intro\n    \n    -- a user-defined function\n    def foo {α : Type u} (x : α) : α := x\n    \n    #check foo\n    #check @foo\n    #print foo\n    \n\n## Setting Options\n\nLean maintains a number of internal variables that can be set by users to\ncontrol its behavior. The syntax for doing so is as follows:\n\n    \n    \n    set_option <name> <value>\n    \n\nOne very useful family of options controls the way Lean\'s _pretty- printer_\ndisplays terms. The following options take an input of true or false:\n\n    \n    \n    pp.explicit  : display implicit arguments\n    pp.universes : display hidden universe parameters\n    pp.notation  : display output using defined notations\n    \n\nAs an example, the following settings yield much longer output:\n\n    \n    \n    set_option pp.explicit true\n    set_option pp.universes true\n    set_option pp.notation false\n    \n    #check 2 + 2 = 4\n    #reduce (fun x => x + 2) = (fun x => x + 3)\n    #check (fun x => x + 1) 1\n    \n\nThe command `set_option pp.all true` carries out these settings all at once,\nwhereas `set_option pp.all false` reverts to the previous values. Pretty\nprinting additional information is often very useful when you are debugging a\nproof, or trying to understand a cryptic error message. Too much information\ncan be overwhelming, though, and Lean\'s defaults are generally sufficient for\nordinary interactions.\n\n## Using the Library\n\nTo use Lean effectively you will inevitably need to make use of definitions\nand theorems in the library. Recall that the `import` command at the beginning\nof a file imports previously compiled results from other files, and that\nimporting is transitive; if you import `Foo` and `Foo` imports `Bar`, then the\ndefinitions and theorems from `Bar` are available to you as well. But the act\nof opening a namespace, which provides shorter names, does not carry over. In\neach file, you need to open the namespaces you wish to use.\n\nIn general, it is important for you to be familiar with the library and its\ncontents, so you know what theorems, definitions, notations, and resources are\navailable to you. Below we will see that Lean\'s editor modes can also help you\nfind things you need, but studying the contents of the library directly is\noften unavoidable. Lean\'s standard library can be found online, on GitHub:\n\n  * <https://github.com/leanprover/lean4/tree/master/src/Init>\n\n  * <https://github.com/leanprover/std4/tree/main/Std>\n\nYou can see the contents of these directories and files using GitHub\'s browser\ninterface. If you have installed Lean on your own computer, you can find the\nlibrary in the `lean` folder, and explore it with your file manager. Comment\nheaders at the top of each file provide additional information.\n\nLean\'s library developers follow general naming guidelines to make it easier\nto guess the name of a theorem you need, or to find it using tab completion in\neditors with a Lean mode that supports this, which is discussed in the next\nsection. Identifiers are generally `camelCase`, and types are `CamelCase`. For\ntheorem names, we rely on descriptive names where the different components are\nseparated by `_`s. Often the name of theorem simply describes the conclusion:\n\n    \n    \n    #check Nat.succ_ne_zero\n    #check Nat.zero_add\n    #check Nat.mul_one\n    #check Nat.le_of_succ_le_succ\n    \n\nRemember that identifiers in Lean can be organized into hierarchical\nnamespaces. For example, the theorem named `le_of_succ_le_succ` in the\nnamespace `Nat` has full name `Nat.le_of_succ_le_succ`, but the shorter name\nis made available by the command `open Nat` (for names not marked as\n`protected`). We will see in [Chapter Inductive Types](./inductive_types.html)\nand [Chapter Structures and Records](./structures_and_records.html) that\ndefining structures and inductive data types in Lean generates associated\noperations, and these are stored in a namespace with the same name as the type\nunder definition. For example, the product type comes with the following\noperations:\n\n    \n    \n    #check @Prod.mk\n    #check @Prod.fst\n    #check @Prod.snd\n    #check @Prod.rec\n    \n\nThe first is used to construct a pair, whereas the next two, `Prod.fst` and\n`Prod.snd`, project the two elements. The last, `Prod.rec`, provides another\nmechanism for defining functions on a product in terms of a function on the\ntwo components. Names like `Prod.rec` are _protected_ , which means that one\nhas to use the full name even when the `Prod` namespace is open.\n\nWith the propositions as types correspondence, logical connectives are also\ninstances of inductive types, and so we tend to use dot notation for them as\nwell:\n\n    \n    \n    #check @And.intro\n    #check @And.casesOn\n    #check @And.left\n    #check @And.right\n    #check @Or.inl\n    #check @Or.inr\n    #check @Or.elim\n    #check @Exists.intro\n    #check @Exists.elim\n    #check @Eq.refl\n    #check @Eq.subst\n    \n\n## Auto Bound Implicit Arguments\n\nIn the previous section, we have shown how implicit arguments make functions\nmore convenient to use. However, functions such as `compose` are still quite\nverbose to define. Note that the universe polymorphic `compose` is even more\nverbose than the one previously defined.\n\n    \n    \n    universe u v w\n    def compose {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nYou can avoid the `universe` command by providing the universe parameters when\ndefining `compose`.\n\n    \n    \n    def compose.{u, v, w}\n                {α : Type u} {β : Type v} {γ : Type w}\n                (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n\nLean 4 supports a new feature called _auto bound implicit arguments_. It makes\nfunctions such as `compose` much more convenient to write. When Lean processes\nthe header of a declaration, any unbound identifier is automatically added as\nan implicit argument _if_ it is a single lower case or greek letter. With this\nfeature we can write `compose` as\n\n    \n    \n    def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n      g (f x)\n    \n    #check @compose\n    -- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ\n    \n\nNote that Lean inferred a more general type using `Sort` instead of `Type`.\n\nAlthough we love this feature and use it extensively when implementing Lean,\nwe realize some users may feel uncomfortable with it. Thus, you can disable it\nusing the command `set_option autoImplicit false`.\n\n    \n    \n    set_option autoImplicit false\n    /- The following definition produces `unknown identifier` errors -/\n    -- def compose (g : β → γ) (f : α → β) (x : α) : γ :=\n    --   g (f x)\n    \n\n## Implicit Lambdas\n\nIn Lean 3 stdlib, we find many\n[instances](https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39)\nof the dreadful `@`+`_` idiom. It is often used when the expected type is a\nfunction type with implicit arguments, and we have a constant (`reader_t.pure`\nin the example) which also takes implicit arguments. In Lean 4, the elaborator\nautomatically introduces lambdas for consuming implicit arguments. We are\nstill exploring this feature and analyzing its impact, but the experience so\nfar has been very positive. Here is the example from the link above using Lean\n4 implicit lambdas.\n\n    \n    \n    variable (ρ : Type) (m : Type → Type) [Monad m]\n    instance : Monad (ReaderT ρ m) where\n      pure := ReaderT.pure\n      bind := ReaderT.bind\n    \n\nUsers can disable the implicit lambda feature by using `@` or writing a lambda\nexpression with `{}` or `[]` binder annotations. Here are few examples\n\n    \n    \n    namespace ex2\n    def id1 : {α : Type} → α → α :=\n      fun x => x\n    \n    def listId : List ({α : Type} → α → α) :=\n      (fun x => x) :: []\n    \n    -- In this example, implicit lambda introduction has been disabled because\n    -- we use `@` before `fun`\n    def id2 : {α : Type} → α → α :=\n      @fun α (x : α) => id1 x\n    \n    def id3 : {α : Type} → α → α :=\n      @fun α x => id1 x\n    \n    def id4 : {α : Type} → α → α :=\n      fun x => id1 x\n    \n    -- In this example, implicit lambda introduction has been disabled\n    -- because we used the binder annotation `{...}`\n    def id5 : {α : Type} → α → α :=\n      fun {α} x => id1 x\n    end ex2\n    \n\n## Sugar for Simple Functions\n\nIn Lean 3, we can create simple functions from infix operators by using\nparentheses. For example, `(+1)` is sugar for `fun x, x + 1`. In Lean 4, we\ngeneralize this notation using `·` as a placeholder. Here are a few examples:\n\n    \n    \n    namespace ex3\n    #check (· + 1)\n    -- fun a => a + 1\n    #check (2 - ·)\n    -- fun a => 2 - a\n    #eval [1, 2, 3, 4, 5].foldl (·*·) 1\n    -- 120\n    \n    def f (x y z : Nat) :=\n      x + y + z\n    \n    #check (f · 1 ·)\n    -- fun a b => f a 1 b\n    \n    #eval [(1, 2), (3, 4), (5, 6)].map (·.1)\n    -- [1, 3, 5]\n    end ex3\n    \n\nAs in Lean 3, the notation is activated using parentheses, and the lambda\nabstraction is created by collecting the nested `·`s. The collection is\ninterrupted by nested parentheses. In the following example, two different\nlambda expressions are created.\n\n    \n    \n    #check (Prod.mk · (· + 1))\n    -- fun a => (a, fun b => b + 1)\n    \n\n## Named Arguments\n\nNamed arguments enable you to specify an argument for a parameter by matching\nthe argument with its name rather than with its position in the parameter\nlist. If you don\'t remember the order of the parameters but know their names,\nyou can send the arguments in any order. You may also provide the value for an\nimplicit parameter when'}], 'model': 'gpt-4o'}}
2025-06-01 02:01:23,129 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:01:23,129 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:01:23,130 - DEBUG - send_request_headers.complete
2025-06-01 02:01:23,130 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:01:23,135 - DEBUG - send_request_body.complete
2025-06-01 02:01:23,135 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:01:26,445 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:01:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2860'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2863'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'8672'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'42.654s'), (b'x-request-id', b'req_cc958c98411730e389a68ed92c504c91'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1f6f9f674278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:01:26,445 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:01:26,445 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:01:26,447 - DEBUG - receive_response_body.complete
2025-06-01 02:01:26,447 - DEBUG - response_closed.started
2025-06-01 02:01:26,447 - DEBUG - response_closed.complete
2025-06-01 02:01:26,447 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:01:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2860', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2863', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '8672', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '42.654s', 'x-request-id': 'req_cc958c98411730e389a68ed92c504c91', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1f6f9f674278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:01:26,447 - DEBUG - request_id: req_cc958c98411730e389a68ed92c504c91
2025-06-01 02:01:26,447 - INFO - Raw solution received: ```json
{
  "code": "if a ≤ b then a else b",
  "proof": "by_cases h : a ≤ b\n  simp [h]  -- in this case, myMin a b = a\n  constructor\n  simp [h]\n  right\n  rfl\n  -- case h : ¬(a ≤ b)\n  simp [h]\n  constructor\n  apply le_of_not_le\n  exact h\n  left\n  rfl"
}
```
2025-06-01 02:01:26,447 - INFO - <class 'str'>
2025-06-01 02:01:26,448 - INFO - Generated solution: {'code': 'if a ≤ b then a else b', 'proof': 'by_cases h : a ≤ b\n  simp [h]  -- in this case, myMin a b = a\n  constructor\n  simp [h]\n  right\n  rfl\n  -- case h : ¬(a ≤ b)\n  simp [h]\n  constructor\n  apply le_of_not_le\n  exact h\n  left\n  rfl'}
2025-06-01 02:01:31,990 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:26:2: error: tactic 'right' failed, right tactic works for inductive types with exactly 2 constructors
case neg.left
a b : ℤ
h : ¬a ≤ b
⊢ b ≤ a
2025-06-01 02:01:31,991 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines the minimum of two integers. The method should return the smaller of the two numbers. When both numbers are equal, either one may be returned.\n\n-----Input-----\nThe input consists of two integers:\na: The first integer.\nb: The second integer.\n\n-----Output-----\nThe output is an integer:\nReturns the smaller value between the input integers, ensuring that the result is less than or equal to both inputs.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef myMin (a : Int) (b : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The minValue is either a or b; The minValue is less than or equal to both a and b\ndef myMin_spec (a : Int) (b : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  (result ≤ a ∧ result ≤ b) ∧\n  (result = a ∨ result = b)\n  -- << SPEC END >>\n\ntheorem myMin_spec_satisfied (a : Int) (b : Int) :\n  myMin_spec a b (myMin a b) := by\n  -- << PROOF START >>\n  unfold myMin myMin_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a ≤ b then a else b\n\nGenerated Proof:\nby_cases h : a ≤ b\n  simp [h]  -- in this case, myMin a b = a\n  constructor\n  simp [h]\n  right\n  rfl\n  -- case h : ¬(a ≤ b)\n  simp [h]\n  constructor\n  apply le_of_not_le\n  exact h\n  left\n  rfl\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:26:2: error: tactic 'right' failed, right tactic works for inductive types with exactly 2 constructors\ncase neg.left\na b : ℤ\nh : ¬a ≤ b\n⊢ b ≤ a"}], 'model': 'o3-mini'}}
2025-06-01 02:01:31,992 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:01:31,992 - DEBUG - close.started
2025-06-01 02:01:31,992 - DEBUG - close.complete
2025-06-01 02:01:31,992 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:01:31,999 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62dede0>
2025-06-01 02:01:32,000 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:01:32,009 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62dcec0>
2025-06-01 02:01:32,009 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:01:32,009 - DEBUG - send_request_headers.complete
2025-06-01 02:01:32,009 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:01:32,009 - DEBUG - send_request_body.complete
2025-06-01 02:01:32,009 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:01:51,041 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:01:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'18802'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'18805'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199241'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'227ms'), (b'x-request-id', b'req_9133e6814c48220b3c9675c0cbb59f6c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b1fa71f1c8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:01:51,041 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:01:51,041 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:01:51,042 - DEBUG - receive_response_body.complete
2025-06-01 02:01:51,042 - DEBUG - response_closed.started
2025-06-01 02:01:51,042 - DEBUG - response_closed.complete
2025-06-01 02:01:51,042 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:01:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '18802', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '18805', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199241', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '227ms', 'x-request-id': 'req_9133e6814c48220b3c9675c0cbb59f6c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b1fa71f1c8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:01:51,042 - DEBUG - request_id: req_9133e6814c48220b3c9675c0cbb59f6c
2025-06-01 02:01:51,043 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails in the second branch (when ¬(a ≤ b)) because the tactic 'right' is applied improperly. In this branch, the goal for the disjunction (result = a ∨ result = b) must choose the variant corresponding to 'result = b', but using 'right' failed since the disjunction type does not have exactly two constructors in this context. Also, the proof needs to justify that b ≤ a using the totality of the order on Ints.", 'error_type': 'proof', 'suggested_fix': "Revise the proof by first using 'by_cases a ≤ b' and in the second branch, prove that b ≤ a by appealing to the total order on integers. For example, you can use the fact that Int.le_total a b gives either a ≤ b or b ≤ a. In the branch for ¬(a ≤ b), you may write something like:\n\n  by_cases h : a ≤ b\n  · simp [myMin, h]\n    split\n    · exact le_refl a\n    · left; rfl\n  · simp [myMin, h]\n    have hb : b ≤ a :=\n      by { cases Int.le_total a b with h' h'; [contradiction, exact h'] } \n    split\n    · exact hb\n    · right; rfl\n\nThis revised proof explicitly obtains b ≤ a in the second branch and then uses 'right' to show (result = b) for the disjunction. Adjust your tactics accordingly.", 'retry_strategy': "Revise the proof structure for the ¬(a ≤ b) case to obtain and use b ≤ a from the totality of Int order. Make sure the disjunction is correctly resolved by selecting the proper branch (using 'left' or 'right') that aligns with the equalities a = a or b = b. Then, re-run the proof."}
2025-06-01 02:01:51,043 - INFO - Solution generated in 34.69 seconds
2025-06-01 02:01:51,043 - INFO - Generated code length: 5 characters
2025-06-01 02:01:51,043 - INFO - Generated proof length: 5 characters
2025-06-01 02:01:51,043 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:01:51,043 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:01:56,317 - INFO - Implementation test result: FAIL
2025-06-01 02:01:56,318 - ERROR - Implementation error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:18:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:01:56,318 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:02:01,707 - INFO - Full solution test result: FAIL
2025-06-01 02:02:01,707 - ERROR - Proof error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:18:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:02:01,707 - ERROR - ❌ Implementation fails unit tests
2025-06-01 02:02:01,708 - ERROR - ❌ Proof has errors
2025-06-01 02:02:01,708 - INFO - 
==================================================
2025-06-01 02:02:01,708 - INFO - Processing task task_id_431...
2025-06-01 02:02:01,708 - INFO - Reading problem description and code template from tasks/task_id_431...
2025-06-01 02:02:01,708 - INFO - Problem description length: 597 characters
2025-06-01 02:02:01,708 - INFO - Reading unit tests from tasks/task_id_431...
2025-06-01 02:02:01,713 - INFO - Unit tests length: 465 characters
2025-06-01 02:02:01,713 - INFO - Running main workflow to generate solution...
2025-06-01 02:02:01,713 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.

-----Input-----
The input consists of:
a: An array of integers.
b: An array of integers.

-----Output-----
The output is a Boolean value:
Returns true if there is at least one common element between the two arrays.
Returns false if there are no common elements shared by the arrays or at least one array is empty.
2025-06-01 02:02:01,713 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def hasCommonElement (a : Array Int) (b : Array Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: If the method returns true, there exists at least one common element between the two arrays; If the method returns false, there are no common elements between the two arrays
def hasCommonElement_spec (a : Array Int) (b : Array Int) (result : Bool) : Prop :=
  -- << SPEC START >>
  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ result
  -- << SPEC END >>

theorem hasCommonElement_spec_satisfied (a : Array Int) (b : Array Int) :
  hasCommonElement_spec a b (hasCommonElement a b) := by
  -- << PROOF START >>
  unfold hasCommonElement hasCommonElement_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:02:01,746 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7159b5eca5c0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:02:01,746 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:02:01,746 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:02:01,752 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eb5340>
2025-06-01 02:02:01,752 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7159b62aa250> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:02:01,759 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b5220>
2025-06-01 02:02:01,760 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:02:01,760 - DEBUG - send_request_headers.complete
2025-06-01 02:02:01,760 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:02:01,760 - DEBUG - send_request_body.complete
2025-06-01 02:02:01,760 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:02:02,136 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:02:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'69'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-canary-656df74c88-zhbgc'), (b'x-envoy-upstream-service-time', b'72'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999851'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_b2c118d9dbf5b2e5c178dcb5958de91a'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=GIjT0yYve2MpUSVbZE5kXaecx5G.KdoKzUlnzZi.sBk-1748743322-1.0.1.1-RvhoNJ0q2tAvmchuMTLrC9wfuea4iPDfwx1Sb7bSxGVXL0bHWL32KpAOoT9L483mTgJvcfZLZ9b9kSgYA0.Ack2Ljhzy0muG4n3JG_JtCZE; path=/; expires=Sun, 01-Jun-25 02:32:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Nm1fUdJGgpt6MYRXbjk7qbYhK6dZd4pB_qd48gQ8IAY-1748743322134-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b20610f053bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:02:02,136 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:02:02,136 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:02:02,137 - DEBUG - receive_response_body.complete
2025-06-01 02:02:02,137 - DEBUG - response_closed.started
2025-06-01 02:02:02,137 - DEBUG - response_closed.complete
2025-06-01 02:02:02,137 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:02:02 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '69'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-canary-656df74c88-zhbgc'), ('x-envoy-upstream-service-time', '72'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999851'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_b2c118d9dbf5b2e5c178dcb5958de91a'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=GIjT0yYve2MpUSVbZE5kXaecx5G.KdoKzUlnzZi.sBk-1748743322-1.0.1.1-RvhoNJ0q2tAvmchuMTLrC9wfuea4iPDfwx1Sb7bSxGVXL0bHWL32KpAOoT9L483mTgJvcfZLZ9b9kSgYA0.Ack2Ljhzy0muG4n3JG_JtCZE; path=/; expires=Sun, 01-Jun-25 02:32:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Nm1fUdJGgpt6MYRXbjk7qbYhK6dZd4pB_qd48gQ8IAY-1748743322134-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b20610f053bfe-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:02:02,137 - DEBUG - request_id: req_b2c118d9dbf5b2e5c178dcb5958de91a
2025-06-01 02:02:02,142 - INFO - Retrieved context:  the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Propositions and Proofs

By now, you have seen some ways of defining objects and functions in Lean. In
this chapter, we will begin to explain how to write mathematical assertions
and proofs in the language of dependent type theory as well.

## Propositions as Types

One strategy for proving assertions about objects defined in the language of
dependent type theory is to layer an assertion language and a proof language
on top of the definition language. But there is no reason to multiply
languages in this way: dependent type theory is flexible and expressive, and
there is no reason we cannot represent assertions and proofs in the same
general framework.

For example, we could introduce a new type, `Prop`, to represent propositions,
and introduce constructors to build new propositions from others.

    
    
    def Implies (p q : Prop) : Prop := p → q
    #check And     -- Prop → Prop → Prop
    #check Or      -- Prop → Prop → Prop
    #check Not     -- Prop → Prop
    #check Implies -- Prop → Prop → Prop
    
    variable (p q r : Prop)
    #check And p q                      -- Prop
    #check Or (And p q) r               -- Prop
    #check Implies (And p q) (And q p)  -- Prop
    

We could then introduce, for each element `p : Prop`, another type `Proof p`,
for the type of proofs of `p`. An "axiom" would be a constant of such a type.

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    #check Proof   -- Proof : Prop → Type
    
    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))
    
    variable (p q : Prop)
    #check and_comm p q     -- Proof (Implies (And p q) (And q p))
    

In addition to axioms, however, we would also need rules to build new proofs
from old ones. For example, in many proof systems for propositional logic, we
have the rule of _modus ponens_ :

> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.

We could represent this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q
    

Systems of natural deduction for propositional logic also typically rely on
the following rule:

> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we
> can "cancel" the hypothesis and obtain a proof of `Implies p q`.

We could render this as follows:

    
    
    def Implies (p q : Prop) : Prop := p → q
    structure Proof (p : Prop) : Type where
      proof : p
    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)
    

This approach would provide us with a reasonable way of building assertions
and proofs. Determining that an expression `t` is a correct proof of assertion
`p` would then simply be a matter of checking that `t` has type `Proof p`.

Some simplifications are possible, however. To start with, we can avoid
writing the term `Proof` repeatedly by conflating `Proof p` with `p` itself.
In other words, whenever we have `p : Prop`, we can interpret `p` as a type,
namely, the type of its proofs. We can then read `t : p` as the assertion that
`t` is a proof of `p`.

Moreover, once we make this identification, the rules for implication show
that we can pass back and forth between `Implies p q` and `p → q`. In other
words, implication between propositions `p` and `q` corresponds to having a
function that takes any element of `p` to an element of `q`. As a result, the
introduction of the connective `Implies` is entirely redundant: we can use the
usual function space constructor `p → q` from dependent type theory as our
notion of implication.

This is the approach followed in the Calculus of Constructions, and hence in
Lean as well. The fact that the rules for implication in a proof system for
natural deduction correspond exactly to the rules governing abstraction and
application for functions is an instance of the _Curry-Howard isomorphism_ ,
sometimes known as the _propositions-as-types_ paradigm. In fact, the type
`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy
described in the last chapter. Moreover, `Type u` is also just syntactic sugar
for `Sort (u+1)`. `Prop` has some special features, but like the other type
universes, it is closed under the arrow constructor: if we have `p q : Prop`,
then `p → q : Prop`.

There are at least two ways of thinking about propositions as types. To some
who take a constructive view of logic and mathematics, this is a faithful
rendering of what it means to be a proposition: a proposition `p` represents a
sort of data type, namely, a specification of the type of data that
constitutes a proof. A proof of `p` is then simply an object `t : p` of the
right type.

Those not inclined to this ideology can view it, rather, as a simple coding
trick. To each proposition `p` we associate a type that is empty if `p` is
false and has a single element, say `*`, if `p` is true. In the latter case,
let us say that (the type associated with) `p` is _inhabited_. It just so
happens that the rules for function application and abstraction can
conveniently help us keep track of which elements of `Prop` are inhabited. So
constructing an element `t : p` tells us that `p` is indeed true. You can
think of the inhabitant of `p` as being the "fact that `p` is true." A proof
of `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is
true."

Indeed, if `p : Prop` is any proposition, Lean's kernel treats any two
elements `t1 t2 : p` as being definitionally equal, much the same way as it
treats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as
_proof irrelevance,_ and is consistent with the interpretation in the last
paragraph. It means that even though we can treat proofs `t : p` as ordinary
objects in the language of dependent type theory, they carry no information
beyond the fact that `p` is true.

The two ways we have suggested thinking about the propositions-as-types
paradigm differ in a fundamental way. From the constructive point of view,
proofs are abstract mathematical objects that are _denoted_ by suitable
expressions in dependent type theory. In contrast, if we think in terms of the
coding trick described above, then the expressions themselves do not denote
anything interesting. Rather, it is the fact that we can write them down and
check that they are well-typed that ensures that the proposition in question
is true. In other words, the expressions _themselves_ are the proofs.

In the exposition below, we will slip back and forth between these two ways of
talking, at times saying that an expression "constructs" or "produces" or
"returns" a proof of a proposition, and at other times simply saying that it
"is" such a proof. This is similar to the way that computer scientists
occasionally blur the distinction between syntax and semantics by saying, at
times, that a program "computes" a certain function, and at other times
speaking as though the program "is" the function in question.

In any case, all that really matters is the bottom line. To formally express a
mathematical assertion in the language of dependent type theory, we need to
exhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a
term `t : p`. Lean's task, as a proof assistant, is to help us to construct
such a term, `t`, and to verify that it is well-formed and has the correct
type.

## Working with Propositions as Types

In the propositions-as-types paradigm, theorems involving only `→` can be
proved using lambda abstraction and application. In Lean, the `theorem`
command introduces a new theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    

Compare this proof to the expression `fun x : α => fun y : β => x` of type `α
→ β → α`, where `α` and `β` are data types. This describes the function that
takes arguments `x` and `y` of type `α` and `β`, respectively, and returns
`x`. The proof of `t1` has the same form, the only difference being that `p`
and `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of
`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis
(trivially) to establish that the conclusion, `p`, is true.

Note that the `theorem` command is really a version of the `def` command:
under the propositions and types correspondence, proving the theorem `p → q →
p` is really the same as defining an element of the associated type. To the
kernel type checker, there is no difference between the two.

There are a few pragmatic differences between definitions and theorems,
however. In normal circumstances, it is never necessary to unfold the
"definition" of a theorem; by proof irrelevance, any two proofs of that
theorem are definitionally equal. Once the proof of a theorem is complete,
typically we only need to know that the proof exists; it doesn't matter what
the proof is. In light of that fact, Lean tags proofs as _irreducible_ , which
serves as a hint to the parser (more precisely, the _elaborator_) that there
is generally no need to unfold them when processing a file. In fact, Lean is
generally able to process and check proofs in parallel, since assessing the
correctness of one proof does not require knowing the details of another.

As with definitions, the `#print` command will show you the proof of a
theorem:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp
    
    #print t1
    

Notice that the lambda abstractions `hp : p` and `hq : q` can be viewed as
temporary assumptions in the proof of `t1`. Lean also allows us to specify the
type of the final term `hp`, explicitly, with a `show` statement:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 : p → q → p :=
      fun hp : p =>
      fun hq : q =>
      show p from hp
    

Adding such extra information can improve the clarity of a proof and help
detect errors when writing a proof. The `show` command does nothing more than
annotate the type, and, internally, all the presentations of `t1` that we have
seen produce the same term.

As with ordinary definitions, we can move the lambda-abstracted variables to
the left of the colon:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    #print t1    -- p → q → p
    

We can use the theorem `t1` just as a function application:

    
    
    variable {p : Prop}
    variable {q : Prop}
    theorem t1 (hp : p) (hq : q) : p := hp
    
    axiom hp : p
    
    theorem t2 : q → p := t1 hp
    

The `axiom` declaration postulates the existence of an element of the given
type and may compromise logical consistency. For example, we can use it to
postulate that the empty type `False` has an element:

    
    
    axiom unsound : False
    -- Everything follows from false
    theorem ex : 1 = 0 :=
      False.elim unsound
    

Declaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as
witnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`
that `p` is true yields the theorem `t1 hp : q → p`.

Recall that we can also write theorem `t1` as follows:

    
    
    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp
    
    #print t1
    

The type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the
assertion "for every pair of propositions `p q`, we have `p → q → p`." For
example, we can move all parameters to the right of the colon:

    
    
    theorem t1 : ∀ {p q : Prop}, p → q → p :=
      fun {p q : Prop} (hp : p) (hq : q) => hp
    

If `p` and `q` have been declared as variables, Lean will generalize them for
us automatically:

    
    
    variable {p q : Prop}
    
    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp
    

In fact, by the propositions-as-types correspondence, we can declare the
assumption `hp` that `p` holds, as another variable:

    
    
    variable {p q : Prop}
    variable (hp : p)
    
    theorem t1 : q → p := fun (hq : q) => hp
    

Lean detects that the proof uses `hp` and automatically adds `hp : p` as a
premise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →
q → p`. Remember that this type can just as well be written `∀ (p q : Prop)
(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type
in which the target does not depend on the bound variable.

When we generalize `t1` in such a way, we can then apply it to different pairs
of propositions, to obtain different instances of the general theorem.

    
    
    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp
    
    variable (p q r s : Prop)
    
    #check t1 p q                -- p → q → p
    #check t1 r s                -- r → s → r
    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s
    
    variable (h : r → s)
    #check t1 (r → s) (s → r) h  -- (s → r) → r → s
    

Once again, using the propositions-as-types correspondence, the variable `h`
of type `r → s` can be viewed as the hypothesis, or premise, that `r → s`
holds.

As another example, let us consider the composition function discussed in the
last chapter, now with propositions instead of types.

    
    
    variable (p q r s : Prop)
    
    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=
      fun h₃ : p =>
      show r from h₁ (h₂ h₃)
    

As a theorem of propositional logic, what does `t2` say?

Note that it is often useful to use numeric unicode subscripts, entered as
`\0`, `\1`, `\2`, ..., for hypotheses, as we did in this example.

## Propositional Logic

Lean defines all the standard logical connectives and notation. The
propositional connectives come with the following notation:

Ascii| Unicode| Editor shortcut| Definition  
---|---|---|---  
True| | | True  
False| | | False  
Not| ¬| `\not`, `\neg`| Not  
/\| ∧| `\and`| And  
\/| ∨| `\or`| Or  
->| →| `\to`, `\r`, `\imp`|   
<->| ↔| `\iff`, `\lr`| Iff  
  
They all take values in `Prop`.

    
    
    variable (p q : Prop)
    
    #check p → q → p ∧ q
    #check ¬p → p ↔ False
    #check p ∨ q → q ∨ p
    

The order of operations is as follows: unary negation `¬` binds most strongly,
then `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧
e` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right
(nothing changes now that the arguments are elements of `Prop`, instead of
some other `Type`), as do the other binary connectives. So if we have `p q r :
Prop`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This
is just the "curried" form of `p ∧ q → r`.

In the last chapter we observed that lambda abstraction can be viewed as an
"introduction rule" for `→`. In the current setting, it shows how to
"introduce" or establish an implication. Application can be viewed as an
"elimination rule," showing how to "eliminate" or use an implication in a
proof. The other propositional connectives are defined in Lean's library in
the file `Prelude.core` (see [importing
files](./interacting_with_lean.html#importing-files) for more information on
the library hierarchy), and each connective comes with its canonical
introduction and elimination rules.

### Conjunction

The expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :
p` and `h2 : q`. It is common to describe `And.intro` as the _and-
introduction_ rule. In the next example we use `And.intro` to create a proof
of `p → q → p ∧ q`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq
    
    #check fun (hp : p) (hq : q) => And.intro hp hq
    

The `example` command states a theorem without naming it or storing it in the
permanent context. Essentially, it just checks that the given term has the
indicated type. It is convenient for illustration, and we will use it often.

The expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.
Similarly, `And.right h` is a proof of `q`. They are commonly known as the
left and right _and-elimination_ rules.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : p := And.left h
    example (h : p ∧ q) : q := And.right h
    

We can now prove `p ∧ q → q ∧ p` with the following proof term.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      And.intro (And.right h) (And.left h)
    

Notice that and-introduction and and-elimination are similar to the pairing
and projection operations for the Cartesian product. The difference is that
given `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while
`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is
another instance of the Curry-Howard isomorphism, but in contrast to
implication and the function space constructor, `∧` and `×` are treated
separately in Lean. With the analogy, however, the proof we have just
constructed is similar to a function that swaps the elements of a pair.

We will see in [Chapter Structures and Records](./structures_and_records.html)
that certain types in Lean are _structures_ , which is to say, the type is
defined with a single canonical _constructor_ which builds an element of the
type from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is
an example: the canonical way to construct an element is to apply `And.intro`
to suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous
constructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the
relevant type is an inductive type and can be inferred from the context. In
particular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:

    
    
    variable (p q : Prop)
    variable (hp : p) (hq : q)
    
    #check (⟨hp, hq⟩ : p ∧ q)
    

These angle brackets are obtained by typing `\<` and `\>`, respectively.

Lean provides another useful syntactic gadget. Given an expression `e` of an
inductive type `Foo` (possibly applied to some arguments), the notation
`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of
accessing functions without opening a namespace. For example, the following
two expressions mean the same thing:

    
    
    variable (xs : List Nat)
    
    #check List.length xs
    #check xs.length
    

As a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and
`h.right` for `And.right h`. We can therefore rewrite the sample proof above
conveniently as follows:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      ⟨h.right, h.left⟩
    

There is a fine line between brevity and obfuscation, and omitting information
in this way can sometimes make a proof harder to read. But for straightforward
constructions like the one above, when the type of `h` and the goal of the
construction are salient, the notation is clean and effective.

It is common to iterate constructions like "And." Lean also allows you to
flatten nested constructors that associate to the right, so that these two
proofs are equivalent:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, ⟨h.left, h.right⟩⟩
    
    example (h : p ∧ q) : q ∧ p ∧ q :=
      ⟨h.right, h.left, h.right⟩
    

This is often useful as well.

### Disjunction

The expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof
`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a
proof `hq : q`. These are the left and right _or-introduction_ rules.

    
    
    variable (p q : Prop)
    example (hp : p) : p ∨ q := Or.intro_left q hp
    example (hq : q) : p ∨ q := Or.intro_right p hq
    

The _or-elimination_ rule is slightly more complicated. The idea is that we
can prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`
follows from `q`. In other words, it is a proof by cases. In the expression
`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :
p → r` and `hqr : q → r`, and produces a proof of `r`. In the following
example, we use `Or.elim` to prove `p ∨ q → q ∨ p`.

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h
        (fun hp : p =>
          show q ∨ p from Or.intro_right q hp)
        (fun hq : q =>
          show q ∨ p from Or.intro_left p hq)
    

In most cases, the first argument of `Or.intro_right` and `Or.intro_left` can
be inferred automatically by Lean. Lean therefore provides `Or.inr` and
`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and
`Or.intro_left _`. Thus the proof term above could be written more concisely:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Notice that there is enough information in the full expression for Lean to
infer the types of `hp` and `hq` as well. But using the type annotations in
the longer version makes the proof more readable, and can help catch and debug
errors.

Because `Or` has two constructors, we cannot use anonymous constructor
notation. But we can still write `h.elim` instead of `Or.elim h`:

    
    
    variable (p q r : Prop)
    
    example (h : p ∨ q) : q ∨ p :=
      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)
    

Once again, you should exercise judgment as to whether such abbreviations
enhance or diminish readability.

### Negation and Falsity

Negation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by
deriving a contradiction from `p`. Similarly, the expression `hnp hp` produces
a proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both
these rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is
produced by typing `\not` or `\neg`.)

    
    
    variable (p q : Prop)
    
    example (hpq : p → q) (hnq : ¬q) : ¬p :=
      fun hp : p =>
      show False from hnq (hpq hp)
    

The connective `False` has a single elimination rule, `False.elim`, which
expresses the fact that anything follows from a contradiction. This rule is
sometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the
_principle of explosion_.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)
    

The arbitrary fact, `q`, that follows from falsity is an implicit argument in
`False.elim` and is inferred automatically. This pattern, deriving an
arbitrary fact from contradictory hypotheses, is quite common, and is
represented by `absurd`.

    
    
    variable (p q : Prop)
    
    example (hp : p) (hnp : ¬p) : q := absurd hp hnp
    

Here, for example, is a proof of `¬p → q → (q → p) → r`:

    
    
    variable (p q r : Prop)
    
    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=
      absurd (hqp hq) hnp
    

Incidentally, just as `False` has only an elimination rule, `True` has only an
introduction rule, `True.intro : true`. In other words, `True` is simply true,
and has a canonical proof, `True.intro`.

### Logical Equivalence

The expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`
and `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from
`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔
q`. Here is a proof of `p ∧ q ↔ q ∧ p`:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      Iff.intro
        (fun h : p ∧ q =>
         show q ∧ p from And.intro (And.right h) (And.left h))
        (fun h : q ∧ p =>
         show p ∧ q from And.intro (And.right h) (And.left h))
    
    #check and_swap p q    -- p ∧ q ↔ q ∧ p
    
    variable (h : p ∧ q)
    example : q ∧ p := Iff.mp (and_swap p q) h
    

We can use the anonymous constructor notation to construct a proof of `p ↔ q`
from proofs of the forward and backward directions, and we can also use `.`
notation with `mp` and `mpr`. The previous examples can therefore be written
concisely as follows:

    
    
    variable (p q : Prop)
    
    theorem and_swap : p ∧ q ↔ q ∧ p :=
      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩
    
    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h
    

## Introducing Auxiliary Subgoals

This is a good place to introduce another device Lean offers to help structure
long proofs, namely, the `have` construct, which introduces an auxiliary
subgoal in a proof. Here is a small example, adapted from the last section:

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      have hq : q := h.right
      show q ∧ p from And.intro hq hp
    

Internally, the expression `have h : p := s; t` produces the term `(fun (h :
p) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the
desired conclusion assuming `h : p`, and the two are combined by a lambda
abstraction and application. This simple device is extremely useful when it
comes to structuring long proofs, since we can use intermediate `have`'s as
stepping stones leading to the final goal.

Lean also supports a structured way of reasoning backwards from a goal, which
models the "suffices to show" construction in ordinary mathematics. The next
example simply permutes the last two lines in the previous proof.

    
    
    variable (p q : Prop)
    
    example (h : p ∧ q) : q ∧ p :=
      have hp : p := h.left
      suffices hq : q from And.intro hq hp
      show q from And.right h
    

Writing `suffices hq : q` leaves us with two goals. First, we have to show
that it indeed suffices to show `q`, by proving the original goal of `q ∧ p`
with the additional hypothesis `hq : q`. Finally, we have to show `q`.

## Classical Logic

The introduction and elimination rules we have seen so far are all
constructive, which is to say, they reflect a computational understanding of
the logical connectives based on the propositions-as-types correspondence.
Ordinary classical logic adds to this the law of the excluded middle, `p ∨
¬p`. To use this principle, you have to open the classical namespace.

    
    
    open Classical
    
    variable (p : Prop)
    #check em p
    

Intuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts
to knowing which is the case. If `RH` represents the Riemann hypothesis, a
classical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot
yet assert either disjunct.

One consequence of the law of the excluded middle is the principle of double-
negation elimination:

    
    
    open Classical
    
    theorem dne {p : Prop} (h : ¬¬p) : p :=
      Or.elim (em p)
        (fun hp : p => hp)
        (fun hnp : ¬p => absurd hnp h)
    

Double-negation elimination allows one to prove any proposition, `p`, by
assuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In
other words, double-negation elimination allows one to carry out a proof by
contradiction, something which is not generally possible in constructive
logic. As an exercise, you might try proving the converse, that is, showing
that `em` can be proved from `dne`.

The classical axioms also give you access to additional patterns of proof that
can be justified by appeal to `em`. For example, one can carry out a proof by
cases:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byCases
        (fun h1 : p => h1)
        (fun h1 : ¬p => absurd h1 h)
    

Or you can carry out a proof by contradiction:

    
    
    open Classical
    variable (p : Prop)
    
    example (h : ¬¬p) : p :=
      byContradiction
        (fun h1 : ¬p =>
         show False from h h1)
    

If you are not used to thinking constructively, it may take some time for you
to get a sense of where classical reasoning is used. It is needed in the
following example because, from a constructive standpoint, knowing that `p`
and `q` are not both true does not necessarily tell you which one is false:

    
    
    open Classical
    variable (p q : Prop)
    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=
      Or.elim (em p)
        (fun hp : p =>
          Or.inr
            (show ¬q from
              fun hq : q =>
              h ⟨hp, hq⟩))
        (fun hp : ¬p =>
          Or.inl hp)
    

We will see later that there _are_ situations in constructive logic where
principles like excluded middle and double-negation elimination are
permissible, and Lean supports the use of classical reasoning in such contexts
without relying on excluded middle.

The full list of axioms that are used in Lean to support classical reasoning
are discussed in [Axioms and Computation](./axioms_and_computation.html).

## Examples of Propositional Validities

Lean's standard library contains proofs of many valid statements of
propositional logic, all of which you are free to use in proofs of your own.
The following list includes a number of common identities.

Commutativity:

  1. `p ∧ q ↔ q ∧ p`
  2. `p ∨ q ↔ q ∨ p`

Associativity:

  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`
  4. `(p ∨ q) ∨ r ↔ p ∨ (q �
2025-06-01 02:02:02,145 - DEBUG - close.started
2025-06-01 02:02:02,145 - DEBUG - close.complete
2025-06-01 02:02:02,155 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.'}], 'model': 'o3-mini'}}
2025-06-01 02:02:02,156 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:02:02,156 - DEBUG - close.started
2025-06-01 02:02:02,156 - DEBUG - close.complete
2025-06-01 02:02:02,156 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:02:02,164 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eae1e0>
2025-06-01 02:02:02,164 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:02:02,174 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eaf470>
2025-06-01 02:02:02,174 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:02:02,174 - DEBUG - send_request_headers.complete
2025-06-01 02:02:02,174 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:02:02,174 - DEBUG - send_request_body.complete
2025-06-01 02:02:02,174 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:02:08,412 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:02:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6003'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6007'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199550'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'135ms'), (b'x-request-id', b'req_973844e3c16e152671ab2d6ad44bb62d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b2063abc046f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:02:08,413 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:02:08,413 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:02:08,413 - DEBUG - receive_response_body.complete
2025-06-01 02:02:08,413 - DEBUG - response_closed.started
2025-06-01 02:02:08,413 - DEBUG - response_closed.complete
2025-06-01 02:02:08,413 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:02:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6003', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6007', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199550', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '135ms', 'x-request-id': 'req_973844e3c16e152671ab2d6ad44bb62d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b2063abc046f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:02:08,413 - DEBUG - request_id: req_973844e3c16e152671ab2d6ad44bb62d
2025-06-01 02:02:08,414 - INFO - Attempt 1/3
2025-06-01 02:02:08,414 - INFO - Current plan: {
  "plan_summary": "The plan is to implement a Lean 4 function that takes two arrays of integers and checks for at least one common element between them. The function first checks if either array is empty, returning false immediately if that is the case. Otherwise, it iterates through one array and for each element checks if it exists in the other array. If a common element is found, the function returns true; otherwise, it returns false after completing the iteration.",
  "steps": [
    "Check if either array 'a' or 'b' is empty. If yes, return false.",
    "Iterate through each element in the first array.",
    "For each element in the first array, check if it is a member of the second array.",
    "Return true immediately when a common element is found.",
    "If the iteration completes without finding any common element, return false."
  ],
  "code_keywords": [
    "Lean 4",
    "Array",
    "membership check",
    "exists",
    "iteration",
    "functional style"
  ],
  "proof_keywords": [
    "induction",
    "structural recursion",
    "case analysis",
    "verification of termination"
  ],
  "assumptions": [
    "Both inputs are of type 'Array Int'.",
    "An empty array should lead to an immediate false return, as specified.",
    "Standard library functions for checking membership (e.g., exists) are available."
  ],
  "retry_guidance": "If the initial approach fails, verify that the membership checking function is correctly implemented and that the empty array condition is handled before iteration. Additionally, ensure that the iteration does not go out of bounds and that the function terminates as expected."
}
2025-06-01 02:02:08,415 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "The plan is to implement a Lean 4 function that takes two arrays of integers and checks for at least one common element between them. The function first checks if either array is empty, returning false immediately if that is the case. Otherwise, it iterates through one array and for each element checks if it exists in the other array. If a common element is found, the function returns true; otherwise, it returns false after completing the iteration.",\n  "steps": [\n    "Check if either array \'a\' or \'b\' is empty. If yes, return false.",\n    "Iterate through each element in the first array.",\n    "For each element in the first array, check if it is a member of the second array.",\n    "Return true immediately when a common element is found.",\n    "If the iteration completes without finding any common element, return false."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array",\n    "membership check",\n    "exists",\n    "iteration",\n    "functional style"\n  ],\n  "proof_keywords": [\n    "induction",\n    "structural recursion",\n    "case analysis",\n    "verification of termination"\n  ],\n  "assumptions": [\n    "Both inputs are of type \'Array Int\'.",\n    "An empty array should lead to an immediate false return, as specified.",\n    "Standard library functions for checking membership (e.g., exists) are available."\n  ],\n  "retry_guidance": "If the initial approach fails, verify that the membership checking function is correctly implemented and that the empty array condition is handled before iteration. Additionally, ensure that the iteration does not go out of bounds and that the function terminates as expected."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasCommonElement (a : Array Int) (b : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the method returns true, there exists at least one common element between the two arrays; If the method returns false, there are no common elements between the two arrays\ndef hasCommonElement_spec (a : Array Int) (b : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ result\n  -- << SPEC END >>\n\ntheorem hasCommonElement_spec_satisfied (a : Array Int) (b : Array Int) :\n  hasCommonElement_spec a b (hasCommonElement a b) := by\n  -- << PROOF START >>\n  unfold hasCommonElement hasCommonElement_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Propositions and Proofs\n\nBy now, you have seen some ways of defining objects and functions in Lean. In\nthis chapter, we will begin to explain how to write mathematical assertions\nand proofs in the language of dependent type theory as well.\n\n## Propositions as Types\n\nOne strategy for proving assertions about objects defined in the language of\ndependent type theory is to layer an assertion language and a proof language\non top of the definition language. But there is no reason to multiply\nlanguages in this way: dependent type theory is flexible and expressive, and\nthere is no reason we cannot represent assertions and proofs in the same\ngeneral framework.\n\nFor example, we could introduce a new type, `Prop`, to represent propositions,\nand introduce constructors to build new propositions from others.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    #check And     -- Prop → Prop → Prop\n    #check Or      -- Prop → Prop → Prop\n    #check Not     -- Prop → Prop\n    #check Implies -- Prop → Prop → Prop\n    \n    variable (p q r : Prop)\n    #check And p q                      -- Prop\n    #check Or (And p q) r               -- Prop\n    #check Implies (And p q) (And q p)  -- Prop\n    \n\nWe could then introduce, for each element `p : Prop`, another type `Proof p`,\nfor the type of proofs of `p`. An "axiom" would be a constant of such a type.\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    #check Proof   -- Proof : Prop → Type\n    \n    axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))\n    \n    variable (p q : Prop)\n    #check and_comm p q     -- Proof (Implies (And p q) (And q p))\n    \n\nIn addition to axioms, however, we would also need rules to build new proofs\nfrom old ones. For example, in many proof systems for propositional logic, we\nhave the rule of _modus ponens_ :\n\n> From a proof of `Implies p q` and a proof of `p`, we obtain a proof of `q`.\n\nWe could represent this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q\n    \n\nSystems of natural deduction for propositional logic also typically rely on\nthe following rule:\n\n> Suppose that, assuming `p` as a hypothesis, we have a proof of `q`. Then we\n> can "cancel" the hypothesis and obtain a proof of `Implies p q`.\n\nWe could render this as follows:\n\n    \n    \n    def Implies (p q : Prop) : Prop := p → q\n    structure Proof (p : Prop) : Type where\n      proof : p\n    axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)\n    \n\nThis approach would provide us with a reasonable way of building assertions\nand proofs. Determining that an expression `t` is a correct proof of assertion\n`p` would then simply be a matter of checking that `t` has type `Proof p`.\n\nSome simplifications are possible, however. To start with, we can avoid\nwriting the term `Proof` repeatedly by conflating `Proof p` with `p` itself.\nIn other words, whenever we have `p : Prop`, we can interpret `p` as a type,\nnamely, the type of its proofs. We can then read `t : p` as the assertion that\n`t` is a proof of `p`.\n\nMoreover, once we make this identification, the rules for implication show\nthat we can pass back and forth between `Implies p q` and `p → q`. In other\nwords, implication between propositions `p` and `q` corresponds to having a\nfunction that takes any element of `p` to an element of `q`. As a result, the\nintroduction of the connective `Implies` is entirely redundant: we can use the\nusual function space constructor `p → q` from dependent type theory as our\nnotion of implication.\n\nThis is the approach followed in the Calculus of Constructions, and hence in\nLean as well. The fact that the rules for implication in a proof system for\nnatural deduction correspond exactly to the rules governing abstraction and\napplication for functions is an instance of the _Curry-Howard isomorphism_ ,\nsometimes known as the _propositions-as-types_ paradigm. In fact, the type\n`Prop` is syntactic sugar for `Sort 0`, the very bottom of the type hierarchy\ndescribed in the last chapter. Moreover, `Type u` is also just syntactic sugar\nfor `Sort (u+1)`. `Prop` has some special features, but like the other type\nuniverses, it is closed under the arrow constructor: if we have `p q : Prop`,\nthen `p → q : Prop`.\n\nThere are at least two ways of thinking about propositions as types. To some\nwho take a constructive view of logic and mathematics, this is a faithful\nrendering of what it means to be a proposition: a proposition `p` represents a\nsort of data type, namely, a specification of the type of data that\nconstitutes a proof. A proof of `p` is then simply an object `t : p` of the\nright type.\n\nThose not inclined to this ideology can view it, rather, as a simple coding\ntrick. To each proposition `p` we associate a type that is empty if `p` is\nfalse and has a single element, say `*`, if `p` is true. In the latter case,\nlet us say that (the type associated with) `p` is _inhabited_. It just so\nhappens that the rules for function application and abstraction can\nconveniently help us keep track of which elements of `Prop` are inhabited. So\nconstructing an element `t : p` tells us that `p` is indeed true. You can\nthink of the inhabitant of `p` as being the "fact that `p` is true." A proof\nof `p → q` uses "the fact that `p` is true" to obtain "the fact that `q` is\ntrue."\n\nIndeed, if `p : Prop` is any proposition, Lean\'s kernel treats any two\nelements `t1 t2 : p` as being definitionally equal, much the same way as it\ntreats `(fun x => t) s` and `t[s/x]` as definitionally equal. This is known as\n_proof irrelevance,_ and is consistent with the interpretation in the last\nparagraph. It means that even though we can treat proofs `t : p` as ordinary\nobjects in the language of dependent type theory, they carry no information\nbeyond the fact that `p` is true.\n\nThe two ways we have suggested thinking about the propositions-as-types\nparadigm differ in a fundamental way. From the constructive point of view,\nproofs are abstract mathematical objects that are _denoted_ by suitable\nexpressions in dependent type theory. In contrast, if we think in terms of the\ncoding trick described above, then the expressions themselves do not denote\nanything interesting. Rather, it is the fact that we can write them down and\ncheck that they are well-typed that ensures that the proposition in question\nis true. In other words, the expressions _themselves_ are the proofs.\n\nIn the exposition below, we will slip back and forth between these two ways of\ntalking, at times saying that an expression "constructs" or "produces" or\n"returns" a proof of a proposition, and at other times simply saying that it\n"is" such a proof. This is similar to the way that computer scientists\noccasionally blur the distinction between syntax and semantics by saying, at\ntimes, that a program "computes" a certain function, and at other times\nspeaking as though the program "is" the function in question.\n\nIn any case, all that really matters is the bottom line. To formally express a\nmathematical assertion in the language of dependent type theory, we need to\nexhibit a term `p : Prop`. To _prove_ that assertion, we need to exhibit a\nterm `t : p`. Lean\'s task, as a proof assistant, is to help us to construct\nsuch a term, `t`, and to verify that it is well-formed and has the correct\ntype.\n\n## Working with Propositions as Types\n\nIn the propositions-as-types paradigm, theorems involving only `→` can be\nproved using lambda abstraction and application. In Lean, the `theorem`\ncommand introduces a new theorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    \n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n\nCompare this proof to the expression `fun x : α => fun y : β => x` of type `α\n→ β → α`, where `α` and `β` are data types. This describes the function that\ntakes arguments `x` and `y` of type `α` and `β`, respectively, and returns\n`x`. The proof of `t1` has the same form, the only difference being that `p`\nand `q` are elements of `Prop` rather than `Type`. Intuitively, our proof of\n`p → q → p` assumes `p` and `q` are true, and uses the first hypothesis\n(trivially) to establish that the conclusion, `p`, is true.\n\nNote that the `theorem` command is really a version of the `def` command:\nunder the propositions and types correspondence, proving the theorem `p → q →\np` is really the same as defining an element of the associated type. To the\nkernel type checker, there is no difference between the two.\n\nThere are a few pragmatic differences between definitions and theorems,\nhowever. In normal circumstances, it is never necessary to unfold the\n"definition" of a theorem; by proof irrelevance, any two proofs of that\ntheorem are definitionally equal. Once the proof of a theorem is complete,\ntypically we only need to know that the proof exists; it doesn\'t matter what\nthe proof is. In light of that fact, Lean tags proofs as _irreducible_ , which\nserves as a hint to the parser (more precisely, the _elaborator_) that there\nis generally no need to unfold them when processing a file. In fact, Lean is\ngenerally able to process and check proofs in parallel, since assessing the\ncorrectness of one proof does not require knowing the details of another.\n\nAs with definitions, the `#print` command will show you the proof of a\ntheorem:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p := fun hp : p => fun hq : q => hp\n    \n    #print t1\n    \n\nNotice that the lambda abstractions `hp : p` and `hq : q` can be viewed as\ntemporary assumptions in the proof of `t1`. Lean also allows us to specify the\ntype of the final term `hp`, explicitly, with a `show` statement:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 : p → q → p :=\n      fun hp : p =>\n      fun hq : q =>\n      show p from hp\n    \n\nAdding such extra information can improve the clarity of a proof and help\ndetect errors when writing a proof. The `show` command does nothing more than\nannotate the type, and, internally, all the presentations of `t1` that we have\nseen produce the same term.\n\nAs with ordinary definitions, we can move the lambda-abstracted variables to\nthe left of the colon:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    #print t1    -- p → q → p\n    \n\nWe can use the theorem `t1` just as a function application:\n\n    \n    \n    variable {p : Prop}\n    variable {q : Prop}\n    theorem t1 (hp : p) (hq : q) : p := hp\n    \n    axiom hp : p\n    \n    theorem t2 : q → p := t1 hp\n    \n\nThe `axiom` declaration postulates the existence of an element of the given\ntype and may compromise logical consistency. For example, we can use it to\npostulate that the empty type `False` has an element:\n\n    \n    \n    axiom unsound : False\n    -- Everything follows from false\n    theorem ex : 1 = 0 :=\n      False.elim unsound\n    \n\nDeclaring an "axiom" `hp : p` is tantamount to declaring that `p` is true, as\nwitnessed by `hp`. Applying the theorem `t1 : p → q → p` to the fact `hp : p`\nthat `p` is true yields the theorem `t1 hp : q → p`.\n\nRecall that we can also write theorem `t1` as follows:\n\n    \n    \n    theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp\n    \n    #print t1\n    \n\nThe type of `t1` is now `∀ {p q : Prop}, p → q → p`. We can read this as the\nassertion "for every pair of propositions `p q`, we have `p → q → p`." For\nexample, we can move all parameters to the right of the colon:\n\n    \n    \n    theorem t1 : ∀ {p q : Prop}, p → q → p :=\n      fun {p q : Prop} (hp : p) (hq : q) => hp\n    \n\nIf `p` and `q` have been declared as variables, Lean will generalize them for\nus automatically:\n\n    \n    \n    variable {p q : Prop}\n    \n    theorem t1 : p → q → p := fun (hp : p) (hq : q) => hp\n    \n\nIn fact, by the propositions-as-types correspondence, we can declare the\nassumption `hp` that `p` holds, as another variable:\n\n    \n    \n    variable {p q : Prop}\n    variable (hp : p)\n    \n    theorem t1 : q → p := fun (hq : q) => hp\n    \n\nLean detects that the proof uses `hp` and automatically adds `hp : p` as a\npremise. In all cases, the command `#print t1` still yields `∀ p q : Prop, p →\nq → p`. Remember that this type can just as well be written `∀ (p q : Prop)\n(hp : p) (hq : q), p`, since the arrow denotes nothing more than an arrow type\nin which the target does not depend on the bound variable.\n\nWhen we generalize `t1` in such a way, we can then apply it to different pairs\nof propositions, to obtain different instances of the general theorem.\n\n    \n    \n    theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp\n    \n    variable (p q r s : Prop)\n    \n    #check t1 p q                -- p → q → p\n    #check t1 r s                -- r → s → r\n    #check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s\n    \n    variable (h : r → s)\n    #check t1 (r → s) (s → r) h  -- (s → r) → r → s\n    \n\nOnce again, using the propositions-as-types correspondence, the variable `h`\nof type `r → s` can be viewed as the hypothesis, or premise, that `r → s`\nholds.\n\nAs another example, let us consider the composition function discussed in the\nlast chapter, now with propositions instead of types.\n\n    \n    \n    variable (p q r s : Prop)\n    \n    theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=\n      fun h₃ : p =>\n      show r from h₁ (h₂ h₃)\n    \n\nAs a theorem of propositional logic, what does `t2` say?\n\nNote that it is often useful to use numeric unicode subscripts, entered as\n`\\0`, `\\1`, `\\2`, ..., for hypotheses, as we did in this example.\n\n## Propositional Logic\n\nLean defines all the standard logical connectives and notation. The\npropositional connectives come with the following notation:\n\nAscii| Unicode| Editor shortcut| Definition  \n---|---|---|---  \nTrue| | | True  \nFalse| | | False  \nNot| ¬| `\\not`, `\\neg`| Not  \n/\\| ∧| `\\and`| And  \n\\/| ∨| `\\or`| Or  \n->| →| `\\to`, `\\r`, `\\imp`|   \n<->| ↔| `\\iff`, `\\lr`| Iff  \n  \nThey all take values in `Prop`.\n\n    \n    \n    variable (p q : Prop)\n    \n    #check p → q → p ∧ q\n    #check ¬p → p ↔ False\n    #check p ∨ q → q ∨ p\n    \n\nThe order of operations is as follows: unary negation `¬` binds most strongly,\nthen `∧`, then `∨`, then `→`, and finally `↔`. For example, `a ∧ b → c ∨ d ∧\ne` means `(a ∧ b) → (c ∨ (d ∧ e))`. Remember that `→` associates to the right\n(nothing changes now that the arguments are elements of `Prop`, instead of\nsome other `Type`), as do the other binary connectives. So if we have `p q r :\nProp`, the expression `p → q → r` reads "if `p`, then if `q`, then `r`." This\nis just the "curried" form of `p ∧ q → r`.\n\nIn the last chapter we observed that lambda abstraction can be viewed as an\n"introduction rule" for `→`. In the current setting, it shows how to\n"introduce" or establish an implication. Application can be viewed as an\n"elimination rule," showing how to "eliminate" or use an implication in a\nproof. The other propositional connectives are defined in Lean\'s library in\nthe file `Prelude.core` (see [importing\nfiles](./interacting_with_lean.html#importing-files) for more information on\nthe library hierarchy), and each connective comes with its canonical\nintroduction and elimination rules.\n\n### Conjunction\n\nThe expression `And.intro h1 h2` builds a proof of `p ∧ q` using proofs `h1 :\np` and `h2 : q`. It is common to describe `And.intro` as the _and-\nintroduction_ rule. In the next example we use `And.intro` to create a proof\nof `p → q → p ∧ q`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hq : q) : p ∧ q := And.intro hp hq\n    \n    #check fun (hp : p) (hq : q) => And.intro hp hq\n    \n\nThe `example` command states a theorem without naming it or storing it in the\npermanent context. Essentially, it just checks that the given term has the\nindicated type. It is convenient for illustration, and we will use it often.\n\nThe expression `And.left h` creates a proof of `p` from a proof `h : p ∧ q`.\nSimilarly, `And.right h` is a proof of `q`. They are commonly known as the\nleft and right _and-elimination_ rules.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : p := And.left h\n    example (h : p ∧ q) : q := And.right h\n    \n\nWe can now prove `p ∧ q → q ∧ p` with the following proof term.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      And.intro (And.right h) (And.left h)\n    \n\nNotice that and-introduction and and-elimination are similar to the pairing\nand projection operations for the Cartesian product. The difference is that\ngiven `hp : p` and `hq : q`, `And.intro hp hq` has type `p ∧ q : Prop`, while\n`Prod hp hq` has type `p × q : Type`. The similarity between `∧` and `×` is\nanother instance of the Curry-Howard isomorphism, but in contrast to\nimplication and the function space constructor, `∧` and `×` are treated\nseparately in Lean. With the analogy, however, the proof we have just\nconstructed is similar to a function that swaps the elements of a pair.\n\nWe will see in [Chapter Structures and Records](./structures_and_records.html)\nthat certain types in Lean are _structures_ , which is to say, the type is\ndefined with a single canonical _constructor_ which builds an element of the\ntype from a sequence of suitable arguments. For every `p q : Prop`, `p ∧ q` is\nan example: the canonical way to construct an element is to apply `And.intro`\nto suitable arguments `hp : p` and `hq : q`. Lean allows us to use _anonymous\nconstructor_ notation `⟨arg1, arg2, ...⟩` in situations like these, when the\nrelevant type is an inductive type and can be inferred from the context. In\nparticular, we can often write `⟨hp, hq⟩` instead of `And.intro hp hq`:\n\n    \n    \n    variable (p q : Prop)\n    variable (hp : p) (hq : q)\n    \n    #check (⟨hp, hq⟩ : p ∧ q)\n    \n\nThese angle brackets are obtained by typing `\\<` and `\\>`, respectively.\n\nLean provides another useful syntactic gadget. Given an expression `e` of an\ninductive type `Foo` (possibly applied to some arguments), the notation\n`e.bar` is shorthand for `Foo.bar e`. This provides a convenient way of\naccessing functions without opening a namespace. For example, the following\ntwo expressions mean the same thing:\n\n    \n    \n    variable (xs : List Nat)\n    \n    #check List.length xs\n    #check xs.length\n    \n\nAs a result, given `h : p ∧ q`, we can write `h.left` for `And.left h` and\n`h.right` for `And.right h`. We can therefore rewrite the sample proof above\nconveniently as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      ⟨h.right, h.left⟩\n    \n\nThere is a fine line between brevity and obfuscation, and omitting information\nin this way can sometimes make a proof harder to read. But for straightforward\nconstructions like the one above, when the type of `h` and the goal of the\nconstruction are salient, the notation is clean and effective.\n\nIt is common to iterate constructions like "And." Lean also allows you to\nflatten nested constructors that associate to the right, so that these two\nproofs are equivalent:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, ⟨h.left, h.right⟩⟩\n    \n    example (h : p ∧ q) : q ∧ p ∧ q :=\n      ⟨h.right, h.left, h.right⟩\n    \n\nThis is often useful as well.\n\n### Disjunction\n\nThe expression `Or.intro_left q hp` creates a proof of `p ∨ q` from a proof\n`hp : p`. Similarly, `Or.intro_right p hq` creates a proof for `p ∨ q` using a\nproof `hq : q`. These are the left and right _or-introduction_ rules.\n\n    \n    \n    variable (p q : Prop)\n    example (hp : p) : p ∨ q := Or.intro_left q hp\n    example (hq : q) : p ∨ q := Or.intro_right p hq\n    \n\nThe _or-elimination_ rule is slightly more complicated. The idea is that we\ncan prove `r` from `p ∨ q`, by showing that `r` follows from `p` and that `r`\nfollows from `q`. In other words, it is a proof by cases. In the expression\n`Or.elim hpq hpr hqr`, `Or.elim` takes three arguments, `hpq : p ∨ q`, `hpr :\np → r` and `hqr : q → r`, and produces a proof of `r`. In the following\nexample, we use `Or.elim` to prove `p ∨ q → q ∨ p`.\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h\n        (fun hp : p =>\n          show q ∨ p from Or.intro_right q hp)\n        (fun hq : q =>\n          show q ∨ p from Or.intro_left p hq)\n    \n\nIn most cases, the first argument of `Or.intro_right` and `Or.intro_left` can\nbe inferred automatically by Lean. Lean therefore provides `Or.inr` and\n`Or.inl` which can be viewed as shorthand for `Or.intro_right _` and\n`Or.intro_left _`. Thus the proof term above could be written more concisely:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      Or.elim h (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nNotice that there is enough information in the full expression for Lean to\ninfer the types of `hp` and `hq` as well. But using the type annotations in\nthe longer version makes the proof more readable, and can help catch and debug\nerrors.\n\nBecause `Or` has two constructors, we cannot use anonymous constructor\nnotation. But we can still write `h.elim` instead of `Or.elim h`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (h : p ∨ q) : q ∨ p :=\n      h.elim (fun hp => Or.inr hp) (fun hq => Or.inl hq)\n    \n\nOnce again, you should exercise judgment as to whether such abbreviations\nenhance or diminish readability.\n\n### Negation and Falsity\n\nNegation, `¬p`, is actually defined to be `p → False`, so we obtain `¬p` by\nderiving a contradiction from `p`. Similarly, the expression `hnp hp` produces\na proof of `False` from `hp : p` and `hnp : ¬p`. The next example uses both\nthese rules to produce a proof of `(p → q) → ¬q → ¬p`. (The symbol `¬` is\nproduced by typing `\\not` or `\\neg`.)\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hpq : p → q) (hnq : ¬q) : ¬p :=\n      fun hp : p =>\n      show False from hnq (hpq hp)\n    \n\nThe connective `False` has a single elimination rule, `False.elim`, which\nexpresses the fact that anything follows from a contradiction. This rule is\nsometimes called _ex falso_ (short for _ex falso sequitur quodlibet_), or the\n_principle of explosion_.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)\n    \n\nThe arbitrary fact, `q`, that follows from falsity is an implicit argument in\n`False.elim` and is inferred automatically. This pattern, deriving an\narbitrary fact from contradictory hypotheses, is quite common, and is\nrepresented by `absurd`.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (hp : p) (hnp : ¬p) : q := absurd hp hnp\n    \n\nHere, for example, is a proof of `¬p → q → (q → p) → r`:\n\n    \n    \n    variable (p q r : Prop)\n    \n    example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=\n      absurd (hqp hq) hnp\n    \n\nIncidentally, just as `False` has only an elimination rule, `True` has only an\nintroduction rule, `True.intro : true`. In other words, `True` is simply true,\nand has a canonical proof, `True.intro`.\n\n### Logical Equivalence\n\nThe expression `Iff.intro h1 h2` produces a proof of `p ↔ q` from `h1 : p → q`\nand `h2 : q → p`. The expression `Iff.mp h` produces a proof of `p → q` from\n`h : p ↔ q`. Similarly, `Iff.mpr h` produces a proof of `q → p` from `h : p ↔\nq`. Here is a proof of `p ∧ q ↔ q ∧ p`:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      Iff.intro\n        (fun h : p ∧ q =>\n         show q ∧ p from And.intro (And.right h) (And.left h))\n        (fun h : q ∧ p =>\n         show p ∧ q from And.intro (And.right h) (And.left h))\n    \n    #check and_swap p q    -- p ∧ q ↔ q ∧ p\n    \n    variable (h : p ∧ q)\n    example : q ∧ p := Iff.mp (and_swap p q) h\n    \n\nWe can use the anonymous constructor notation to construct a proof of `p ↔ q`\nfrom proofs of the forward and backward directions, and we can also use `.`\nnotation with `mp` and `mpr`. The previous examples can therefore be written\nconcisely as follows:\n\n    \n    \n    variable (p q : Prop)\n    \n    theorem and_swap : p ∧ q ↔ q ∧ p :=\n      ⟨ fun h => ⟨h.right, h.left⟩, fun h => ⟨h.right, h.left⟩ ⟩\n    \n    example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h\n    \n\n## Introducing Auxiliary Subgoals\n\nThis is a good place to introduce another device Lean offers to help structure\nlong proofs, namely, the `have` construct, which introduces an auxiliary\nsubgoal in a proof. Here is a small example, adapted from the last section:\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      have hq : q := h.right\n      show q ∧ p from And.intro hq hp\n    \n\nInternally, the expression `have h : p := s; t` produces the term `(fun (h :\np) => t) s`. In other words, `s` is a proof of `p`, `t` is a proof of the\ndesired conclusion assuming `h : p`, and the two are combined by a lambda\nabstraction and application. This simple device is extremely useful when it\ncomes to structuring long proofs, since we can use intermediate `have`\'s as\nstepping stones leading to the final goal.\n\nLean also supports a structured way of reasoning backwards from a goal, which\nmodels the "suffices to show" construction in ordinary mathematics. The next\nexample simply permutes the last two lines in the previous proof.\n\n    \n    \n    variable (p q : Prop)\n    \n    example (h : p ∧ q) : q ∧ p :=\n      have hp : p := h.left\n      suffices hq : q from And.intro hq hp\n      show q from And.right h\n    \n\nWriting `suffices hq : q` leaves us with two goals. First, we have to show\nthat it indeed suffices to show `q`, by proving the original goal of `q ∧ p`\nwith the additional hypothesis `hq : q`. Finally, we have to show `q`.\n\n## Classical Logic\n\nThe introduction and elimination rules we have seen so far are all\nconstructive, which is to say, they reflect a computational understanding of\nthe logical connectives based on the propositions-as-types correspondence.\nOrdinary classical logic adds to this the law of the excluded middle, `p ∨\n¬p`. To use this principle, you have to open the classical namespace.\n\n    \n    \n    open Classical\n    \n    variable (p : Prop)\n    #check em p\n    \n\nIntuitively, the constructive "Or" is very strong: asserting `p ∨ q` amounts\nto knowing which is the case. If `RH` represents the Riemann hypothesis, a\nclassical mathematician is willing to assert `RH ∨ ¬RH`, even though we cannot\nyet assert either disjunct.\n\nOne consequence of the law of the excluded middle is the principle of double-\nnegation elimination:\n\n    \n    \n    open Classical\n    \n    theorem dne {p : Prop} (h : ¬¬p) : p :=\n      Or.elim (em p)\n        (fun hp : p => hp)\n        (fun hnp : ¬p => absurd hnp h)\n    \n\nDouble-negation elimination allows one to prove any proposition, `p`, by\nassuming `¬p` and deriving `false`, because that amounts to proving `¬¬p`. In\nother words, double-negation elimination allows one to carry out a proof by\ncontradiction, something which is not generally possible in constructive\nlogic. As an exercise, you might try proving the converse, that is, showing\nthat `em` can be proved from `dne`.\n\nThe classical axioms also give you access to additional patterns of proof that\ncan be justified by appeal to `em`. For example, one can carry out a proof by\ncases:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byCases\n        (fun h1 : p => h1)\n        (fun h1 : ¬p => absurd h1 h)\n    \n\nOr you can carry out a proof by contradiction:\n\n    \n    \n    open Classical\n    variable (p : Prop)\n    \n    example (h : ¬¬p) : p :=\n      byContradiction\n        (fun h1 : ¬p =>\n         show False from h h1)\n    \n\nIf you are not used to thinking constructively, it may take some time for you\nto get a sense of where classical reasoning is used. It is needed in the\nfollowing example because, from a constructive standpoint, knowing that `p`\nand `q` are not both true does not necessarily tell you which one is false:\n\n    \n    \n    open Classical\n    variable (p q : Prop)\n    example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=\n      Or.elim (em p)\n        (fun hp : p =>\n          Or.inr\n            (show ¬q from\n              fun hq : q =>\n              h ⟨hp, hq⟩))\n        (fun hp : ¬p =>\n          Or.inl hp)\n    \n\nWe will see later that there _are_ situations in constructive logic where\nprinciples like excluded middle and double-negation elimination are\npermissible, and Lean supports the use of classical reasoning in such contexts\nwithout relying on excluded middle.\n\nThe full list of axioms that are used in Lean to support classical reasoning\nare discussed in [Axioms and Computation](./axioms_and_computation.html).\n\n## Examples of Propositional Validities\n\nLean\'s standard library contains proofs of many valid statements of\npropositional logic, all of which you are free to use in proofs of your own.\nThe following list includes a number of common identities.\n\nCommutativity:\n\n  1. `p ∧ q ↔ q ∧ p`\n  2. `p ∨ q ↔ q ∨ p`\n\nAssociativity:\n\n  3. `(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)`\n  4. `(p ∨ q) ∨ r ↔ p ∨ (q �'}], 'model': 'gpt-4o'}}
2025-06-01 02:02:08,416 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:02:08,416 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:02:08,416 - DEBUG - send_request_headers.complete
2025-06-01 02:02:08,416 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:02:08,422 - DEBUG - send_request_body.complete
2025-06-01 02:02:08,422 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:02:13,335 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:02:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4607'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4610'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'16002'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'27.996s'), (b'x-request-id', b'req_0d2fc9fd1545799155cd5e168b334ebb'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b208aa81c46f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:02:13,335 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:02:13,336 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:02:13,337 - DEBUG - receive_response_body.complete
2025-06-01 02:02:13,337 - DEBUG - response_closed.started
2025-06-01 02:02:13,337 - DEBUG - response_closed.complete
2025-06-01 02:02:13,337 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:02:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4607', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4610', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '16002', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '27.996s', 'x-request-id': 'req_0d2fc9fd1545799155cd5e168b334ebb', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b208aa81c46f0-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:02:13,337 - DEBUG - request_id: req_0d2fc9fd1545799155cd5e168b334ebb
2025-06-01 02:02:13,337 - INFO - Raw solution received: ```json
{
  "code": "if a.isEmpty || b.isEmpty then\n    false\n  else\n    a.any fun x => b.contains x",
  "proof": "unfold hasCommonElement hasCommonElement_spec\n\n  by_cases h₁ : a.isEmpty || b.isEmpty\n  simp [h₁, hasCommonElement_spec]\n  \n  intro h₂\n  simp [h₁] at h₂\n  \n  apply Exists.elim h₂\n  \n  intro x hx\n  have h_in_a : ∃ i, i < a.size ∧ a[i]! = x := by\n    simp [Array.exists_at] at hx\n    exact hx.left\n  \n  have h_in_b : ∃ j, j < b.size ∧ b[j]! = x := by\n    simp [Array.exists_at] at hx\n    exact hx.right.decidable_elim\n  \n  apply And.intro h_in_a h_in_b\n"
}
```
2025-06-01 02:02:13,337 - INFO - <class 'str'>
2025-06-01 02:02:13,337 - INFO - Generated solution: {'code': 'if a.isEmpty || b.isEmpty then\n    false\n  else\n    a.any fun x => b.contains x', 'proof': 'unfold hasCommonElement hasCommonElement_spec\n\n  by_cases h₁ : a.isEmpty || b.isEmpty\n  simp [h₁, hasCommonElement_spec]\n  \n  intro h₂\n  simp [h₁] at h₂\n  \n  apply Exists.elim h₂\n  \n  intro x hx\n  have h_in_a : ∃ i, i < a.size ∧ a[i]! = x := by\n    simp [Array.exists_at] at hx\n    exact hx.left\n  \n  have h_in_b : ∃ j, j < b.size ∧ b[j]! = x := by\n    simp [Array.exists_at] at hx\n    exact hx.right.decidable_elim\n  \n  apply And.intro h_in_a h_in_b\n'}
2025-06-01 02:02:18,561 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:24:9: error: tactic 'unfold' failed to unfold 'hasCommonElement' at
  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔
    (if (a.isEmpty || b.isEmpty) = true then false else a.any fun x => b.contains x) = true
2025-06-01 02:02:18,562 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that checks whether two arrays of integers have any elements in common. In other words, the method should return true if there is at least one element that appears in both arrays, and false if no such element exists.\n\n-----Input-----\nThe input consists of:\na: An array of integers.\nb: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if there is at least one common element between the two arrays.\nReturns false if there are no common elements shared by the arrays or at least one array is empty.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef hasCommonElement (a : Array Int) (b : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the method returns true, there exists at least one common element between the two arrays; If the method returns false, there are no common elements between the two arrays\ndef hasCommonElement_spec (a : Array Int) (b : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔ result\n  -- << SPEC END >>\n\ntheorem hasCommonElement_spec_satisfied (a : Array Int) (b : Array Int) :\n  hasCommonElement_spec a b (hasCommonElement a b) := by\n  -- << PROOF START >>\n  unfold hasCommonElement hasCommonElement_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nif a.isEmpty || b.isEmpty then\n    false\n  else\n    a.any fun x => b.contains x\n\nGenerated Proof:\nunfold hasCommonElement hasCommonElement_spec\n\n  by_cases h₁ : a.isEmpty || b.isEmpty\n  simp [h₁, hasCommonElement_spec]\n  \n  intro h₂\n  simp [h₁] at h₂\n  \n  apply Exists.elim h₂\n  \n  intro x hx\n  have h_in_a : ∃ i, i < a.size ∧ a[i]! = x := by\n    simp [Array.exists_at] at hx\n    exact hx.left\n  \n  have h_in_b : ∃ j, j < b.size ∧ b[j]! = x := by\n    simp [Array.exists_at] at hx\n    exact hx.right.decidable_elim\n  \n  apply And.intro h_in_a h_in_b\n\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:24:9: error: tactic 'unfold' failed to unfold 'hasCommonElement' at\n  (∃ i j, i < a.size ∧ j < b.size ∧ a[i]! = b[j]!) ↔\n    (if (a.isEmpty || b.isEmpty) = true then false else a.any fun x => b.contains x) = true"}], 'model': 'o3-mini'}}
2025-06-01 02:02:18,563 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:02:18,563 - DEBUG - close.started
2025-06-01 02:02:18,563 - DEBUG - close.complete
2025-06-01 02:02:18,563 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:02:18,573 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62debd0>
2025-06-01 02:02:18,573 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:02:18,584 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62de3c0>
2025-06-01 02:02:18,584 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:02:18,584 - DEBUG - send_request_headers.complete
2025-06-01 02:02:18,584 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:02:18,584 - DEBUG - send_request_body.complete
2025-06-01 02:02:18,584 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:02:27,329 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:02:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8512'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8520'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199061'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'281ms'), (b'x-request-id', b'req_f43d3f27d14deb49269bc2ae971ea2a7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b20ca3c5d8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:02:27,330 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:02:27,330 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:02:27,331 - DEBUG - receive_response_body.complete
2025-06-01 02:02:27,331 - DEBUG - response_closed.started
2025-06-01 02:02:27,331 - DEBUG - response_closed.complete
2025-06-01 02:02:27,331 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:02:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8512', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8520', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199061', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '281ms', 'x-request-id': 'req_f43d3f27d14deb49269bc2ae971ea2a7', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b20ca3c5d8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:02:27,331 - DEBUG - request_id: req_f43d3f27d14deb49269bc2ae971ea2a7
2025-06-01 02:02:27,332 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails because the 'unfold' tactic does not successfully expand the definition of hasCommonElement due to the if-then-else structure. In this context, using 'unfold' on definitions that involve conditionals may not simplify the goal as expected.", 'error_type': 'proof', 'suggested_fix': "Replace the 'unfold' tactic with 'split_ifs' or perform a case analysis on the condition (a.isEmpty || b.isEmpty). For example, you can use 'by_cases' or 'split_ifs' to distinguish the cases where either array is empty or not, and then handle each case separately to prove the equivalence in hasCommonElement_spec. Ensure that for the non-empty arrays case, you prove both directions of the equivalence (i.e., if there exists a common element then a.any (λ x, b.contains x) is true, and vice versa).", 'retry_strategy': "Revise the proof by explicitly handling the if statement in hasCommonElement. Use tactics like 'split_ifs' to desugar the definition, then apply appropriate case analysis and reasoning to complete the proof. Check that each branch of the if correctly corresponds to the specification."}
2025-06-01 02:02:27,332 - INFO - Solution generated in 25.62 seconds
2025-06-01 02:02:27,332 - INFO - Generated code length: 5 characters
2025-06-01 02:02:27,332 - INFO - Generated proof length: 5 characters
2025-06-01 02:02:27,332 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:02:27,332 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:02:32,617 - INFO - Implementation test result: FAIL
2025-06-01 02:02:32,617 - ERROR - Implementation error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:17:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:02:32,617 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:02:37,791 - INFO - Full solution test result: FAIL
2025-06-01 02:02:37,791 - ERROR - Proof error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:17:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:02:37,791 - ERROR - ❌ Implementation fails unit tests
2025-06-01 02:02:37,791 - ERROR - ❌ Proof has errors
2025-06-01 02:02:37,791 - INFO - 
==================================================
2025-06-01 02:02:37,791 - INFO - Processing task task_id_433...
2025-06-01 02:02:37,792 - INFO - Reading problem description and code template from tasks/task_id_433...
2025-06-01 02:02:37,792 - INFO - Problem description length: 646 characters
2025-06-01 02:02:37,792 - INFO - Reading unit tests from tasks/task_id_433...
2025-06-01 02:02:37,792 - INFO - Unit tests length: 367 characters
2025-06-01 02:02:37,792 - INFO - Running main workflow to generate solution...
2025-06-01 02:02:37,792 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.

-----Input-----
The input consists of:
n: An integer.
a: An array of integers.

-----Output-----
The output is a Boolean value:
Returns true if the integer is greater than all elements in the array.
Returns false if there is at least one element in the array that is greater than or equal to the integer.

-----Note-----
The array is assumed to be non-null.
2025-06-01 02:02:37,792 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def isGreater (n : Int) (a : Array Int) : Bool :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: If the result is true, then n is greater than all elements in the array; If the result is false, then there exists at least one element in the array that is greater than or equal to n
def isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=
  -- << SPEC START >>
  (∀ i, i < a.size → n > a[i]!) ↔ result
  -- << SPEC END >>

theorem isGreater_spec_satisfied (n : Int) (a : Array Int) :
  isGreater_spec n a (isGreater n a) := by
  -- << PROOF START >>
  unfold isGreater isGreater_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:02:37,821 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7159b5eca200>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:02:37,821 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:02:37,821 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:02:37,832 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eb7950>
2025-06-01 02:02:37,832 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7159b6503950> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:02:37,843 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eb7800>
2025-06-01 02:02:37,843 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:02:37,843 - DEBUG - send_request_headers.complete
2025-06-01 02:02:37,843 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:02:37,843 - DEBUG - send_request_body.complete
2025-06-01 02:02:37,843 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:02:38,203 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:02:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'43'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5c589d798-mxjnj'), (b'x-envoy-upstream-service-time', b'47'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999839'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'9ms'), (b'x-request-id', b'req_7bd7d52a78f7688a3a6d2e81e0349ce2'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=w_lL1pSOuRbeC1cnREi9A0rsUN25gbDFg4iJ.1gAOfw-1748743358-1.0.1.1-gH.5lc2eTTIYH262a8sQdCiy2w4UyY4jIRsboB_8mX1cAOe6LF.dH1J_H5dARGiybtyzuN0eAO2eEy9DJ01pUPYmfzD.u2VFRqZPIX.Eaho; path=/; expires=Sun, 01-Jun-25 02:32:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=TuDoY5.LcPSxwCCbbDtP9CA.eFKPUMo9vmwbIBRwjVY-1748743358206-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b2142996246f0-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:02:38,203 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:02:38,203 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:02:38,204 - DEBUG - receive_response_body.complete
2025-06-01 02:02:38,204 - DEBUG - response_closed.started
2025-06-01 02:02:38,204 - DEBUG - response_closed.complete
2025-06-01 02:02:38,204 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:02:38 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '43'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-5c589d798-mxjnj'), ('x-envoy-upstream-service-time', '47'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999839'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '9ms'), ('x-request-id', 'req_7bd7d52a78f7688a3a6d2e81e0349ce2'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=w_lL1pSOuRbeC1cnREi9A0rsUN25gbDFg4iJ.1gAOfw-1748743358-1.0.1.1-gH.5lc2eTTIYH262a8sQdCiy2w4UyY4jIRsboB_8mX1cAOe6LF.dH1J_H5dARGiybtyzuN0eAO2eEy9DJ01pUPYmfzD.u2VFRqZPIX.Eaho; path=/; expires=Sun, 01-Jun-25 02:32:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=TuDoY5.LcPSxwCCbbDtP9CA.eFKPUMo9vmwbIBRwjVY-1748743358206-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b2142996246f0-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:02:38,204 - DEBUG - request_id: req_7bd7d52a78f7688a3a6d2e81e0349ce2
2025-06-01 02:02:38,209 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
 the same
time:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      match h with
      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

Lean also provides a pattern-matching `let` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
      let ⟨w, hpw, hqw⟩ := h
      ⟨w, hqw, hpw⟩
    

This is essentially just alternative notation for the `match` construct above.
Lean will even allow us to use an implicit `match` in the `fun` expression:

    
    
    variable (α : Type) (p q : α → Prop)
    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩
    

We will see in [Chapter Induction and
Recursion](./induction_and_recursion.html) that all these variations are
instances of a more general pattern-matching construct.

In the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then
we show that the sum of two even numbers is an even number.

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>
      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>
        Exists.intro (w1 + w2)
          (calc a + b
            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]
            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))
    

Using the various gadgets described in this chapter --- the match statement,
anonymous constructors, and the `rewrite` tactic, we can write this proof
concisely as follows:

    
    
    def is_even (a : Nat) := ∃ b, a = 2 * b
    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
      match h1, h2 with
      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
    

Just as the constructive "or" is stronger than the classical "or," so, too, is
the constructive "exists" stronger than the classical "exists". For example,
the following implication requires classical reasoning because, from a
constructive standpoint, knowing that it is not the case that every `x`
satisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.

    
    
    open Classical
    variable (p : α → Prop)
    
    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
      byContradiction
        (fun h1 : ¬ ∃ x, p x =>
          have h2 : ∀ x, ¬ p x :=
            fun x =>
            fun h3 : p x =>
            have h4 : ∃ x, p x := ⟨x, h3⟩
            show False from h1 h4
          show False from h h2)
    

What follows are some common identities involving the existential quantifier.
In the exercises below, we encourage you to prove as many as you can. We also
leave it to you to determine which are nonconstructive, and hence require some
form of classical reasoning.

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : (∃ x : α, r) → r := sorry
    example (a : α) : r → (∃ x : α, r) := sorry
    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry
    
    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry
    
    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
    

Notice that the second example and the last two examples require the
assumption that there is at least one element `a` of type `α`.

Here are solutions to two of the more difficult ones:

    
    
    open Classical
    
    variable (α : Type) (p q : α → Prop)
    variable (a : α)
    variable (r : Prop)
    
    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
      Iff.intro
        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>
          Or.elim h1
            (fun hpa : p a => Or.inl ⟨a, hpa⟩)
            (fun hqa : q a => Or.inr ⟨a, hqa⟩))
        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>
          Or.elim h
            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)
            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))
    
    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
      Iff.intro
        (fun ⟨b, (hb : p b → r)⟩ =>
         fun h2 : ∀ x, p x =>
         show r from hb (h2 b))
        (fun h1 : (∀ x, p x) → r =>
         show ∃ x, p x → r from
           byCases
             (fun hap : ∀ x, p x => ⟨a, λ h' => h1 hap⟩)
             (fun hnap : ¬ ∀ x, p x =>
              byContradiction
                (fun hnex : ¬ ∃ x, p x → r =>
                  have hap : ∀ x, p x :=
                    fun x =>
                    byContradiction
                      (fun hnp : ¬ p x =>
                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩
                        show False from hnex hex)
                  show False from hnap hap)))
    

## More on the Proof Language

We have seen that keywords like `fun`, `have`, and `show` make it possible to
write formal proof terms that mirror the structure of informal mathematical
proofs. In this section, we discuss some additional features of the proof
language that are often convenient.

To start with, we can use anonymous "have" expressions to introduce an
auxiliary goal without having to label it. We can refer to the last expression
introduced in this way using the keyword `this`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
      show f 0 ≤ f 3 from Nat.le_trans this (h 2)
    

Often proofs move from one fact to the next, so this can be effective in
eliminating the clutter of lots of labels.

When the goal can be inferred, we can also ask Lean instead to fill in the
proof by writing `by assumption`:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    example : f 0 ≤ f 3 :=
      have : f 0 ≤ f 1 := h 0
      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
    

This tells Lean to use the `assumption` tactic, which, in turn, proves the
goal by finding a suitable hypothesis in the local context. We will learn more
about the `assumption` tactic in the next chapter.

We can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the
proposition whose proof we want Lean to find in the context. You can type
these corner quotes using `\f<` and `\f>`, respectively. The letter "f" is for
"French," since the unicode symbols can also be used as French quotation
marks. In fact, the notation is defined in Lean as follows:

    
    
    notation "‹" p "›" => show p by assumption
    

This approach is more robust than using `by assumption`, because the type of
the assumption that needs to be inferred is given explicitly. It also makes
proofs more readable. Here is a more elaborate example:

    
    
    variable (f : Nat → Nat)
    variable (h : ∀ x : Nat, f x ≤ f (x + 1))
    
    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
      fun _ : f 0 ≥ f 1 =>
      fun _ : f 1 ≥ f 2 =>
      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
    

Keep in mind that you can use the French quotation marks in this way to refer
to _anything_ in the context, not just things that were introduced
anonymously. Its use is also not limited to propositions, though using it for
data is somewhat odd:

    
    
    example (n : Nat) : Nat := ‹Nat›
    

Later, we show how you can extend the proof language using the Lean macro
system.

## Exercises

  1. Prove these equivalences:

    
    
    variable (α : Type) (p q : α → Prop)
    
    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
    

You should also try to understand why the reverse implication is not derivable
in the last example.

  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):

    
    
    variable (α : Type) (p q : α → Prop)
    variable (r : Prop)
    
    example : α → ((∀ x : α, r) ↔ r) := sorry
    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
    

  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:

    
    
    variable (men : Type) (barber : men)
    variable (shaves : men → men → Prop)
    
    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry
    

  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach's weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.

    
    
    def even (n : Nat) : Prop := sorry
    
    def prime (n : Nat) : Prop := sorry
    
    def infinitely_many_primes : Prop := sorry
    
    def Fermat_prime (n : Nat) : Prop := sorry
    
    def infinitely_many_Fermat_primes : Prop := sorry
    
    def goldbach_conjecture : Prop := sorry
    
    def Goldbach's_weak_conjecture : Prop := sorry
    
    def Fermat's_last_theorem : Prop := sorry
    

  5. Prove as many of the identities listed in the Existential Quantifier section as you can.

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")

[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
2025-06-01 02:02:38,212 - DEBUG - close.started
2025-06-01 02:02:38,212 - DEBUG - close.complete
2025-06-01 02:02:38,225 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.'}], 'model': 'o3-mini'}}
2025-06-01 02:02:38,226 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:02:38,226 - DEBUG - close.started
2025-06-01 02:02:38,226 - DEBUG - close.complete
2025-06-01 02:02:38,226 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:02:38,232 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eb5010>
2025-06-01 02:02:38,232 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:02:38,239 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eb50a0>
2025-06-01 02:02:38,239 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:02:38,239 - DEBUG - send_request_headers.complete
2025-06-01 02:02:38,239 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:02:38,239 - DEBUG - send_request_body.complete
2025-06-01 02:02:38,239 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:02:44,570 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:02:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'6097'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'6100'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199537'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'138ms'), (b'x-request-id', b'req_4b5a783b45baa863c2840956803ef4ab'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b21450c823bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:02:44,571 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:02:44,571 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:02:44,571 - DEBUG - receive_response_body.complete
2025-06-01 02:02:44,571 - DEBUG - response_closed.started
2025-06-01 02:02:44,571 - DEBUG - response_closed.complete
2025-06-01 02:02:44,571 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:02:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '6097', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '6100', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199537', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '138ms', 'x-request-id': 'req_4b5a783b45baa863c2840956803ef4ab', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b21450c823bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:02:44,571 - DEBUG - request_id: req_4b5a783b45baa863c2840956803ef4ab
2025-06-01 02:02:44,572 - INFO - Attempt 1/3
2025-06-01 02:02:44,572 - INFO - Current plan: {
  "plan_summary": "The plan is to create a Lean 4 function that takes an integer and an array of integers, then checks if the integer is strictly greater than every element in the array. This involves iterating over the array (or using a built-in predicate) and ensuring that for each element the condition n > element holds. Special attention is given to an empty array case, which by definition should result in true since no counter-example exists.",
  "steps": [
    "Define the function signature accepting an integer and an array of integers, returning a Boolean.",
    "Determine the method for iterating over the array, for example using an 'all' predicate that checks if the given property holds for all elements.",
    "Implement the predicate to check that the provided integer is greater than each element of the array.",
    "Handle the empty array case, noting that if the array is empty, the result should be true.",
    "Provide a straightforward justification via case analysis: one case when the array is empty (return true), and one case when the array is non-empty (ensure all elements satisfy n > element)."
  ],
  "code_keywords": [
    "Lean 4 function",
    "array",
    "all predicate",
    "iteration",
    "Boolean"
  ],
  "proof_keywords": [
    "induction",
    "case analysis",
    "empty array corner case",
    "correctness"
  ],
  "assumptions": [
    "The input array is non-null as noted in the task.",
    "The array might be empty, so the function should correctly return true in that case.",
    "Standard Lean 4 array functions (e.g., array.all or equivalent constructs) are available."
  ],
  "retry_guidance": "If any errors related to array manipulation or function signature definition occur, review Lean 4's array library and ensure that the predicate is applied correctly. Also, check that edge cases (like the empty array) are handled explicitly."
}
2025-06-01 02:02:44,573 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "The plan is to create a Lean 4 function that takes an integer and an array of integers, then checks if the integer is strictly greater than every element in the array. This involves iterating over the array (or using a built-in predicate) and ensuring that for each element the condition n > element holds. Special attention is given to an empty array case, which by definition should result in true since no counter-example exists.",\n  "steps": [\n    "Define the function signature accepting an integer and an array of integers, returning a Boolean.",\n    "Determine the method for iterating over the array, for example using an \'all\' predicate that checks if the given property holds for all elements.",\n    "Implement the predicate to check that the provided integer is greater than each element of the array.",\n    "Handle the empty array case, noting that if the array is empty, the result should be true.",\n    "Provide a straightforward justification via case analysis: one case when the array is empty (return true), and one case when the array is non-empty (ensure all elements satisfy n > element)."\n  ],\n  "code_keywords": [\n    "Lean 4 function",\n    "array",\n    "all predicate",\n    "iteration",\n    "Boolean"\n  ],\n  "proof_keywords": [\n    "induction",\n    "case analysis",\n    "empty array corner case",\n    "correctness"\n  ],\n  "assumptions": [\n    "The input array is non-null as noted in the task.",\n    "The array might be empty, so the function should correctly return true in that case.",\n    "Standard Lean 4 array functions (e.g., array.all or equivalent constructs) are available."\n  ],\n  "retry_guidance": "If any errors related to array manipulation or function signature definition occur, review Lean 4\'s array library and ensure that the predicate is applied correctly. Also, check that edge cases (like the empty array) are handled explicitly."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isGreater (n : Int) (a : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the result is true, then n is greater than all elements in the array; If the result is false, then there exists at least one element in the array that is greater than or equal to n\ndef isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∀ i, i < a.size → n > a[i]!) ↔ result\n  -- << SPEC END >>\n\ntheorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n  isGreater_spec n a (isGreater n a) := by\n  -- << PROOF START >>\n  unfold isGreater isGreater_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n the same\ntime:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      match h with\n      | ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nLean also provides a pattern-matching `let` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=\n      let ⟨w, hpw, hqw⟩ := h\n      ⟨w, hqw, hpw⟩\n    \n\nThis is essentially just alternative notation for the `match` construct above.\nLean will even allow us to use an implicit `match` in the `fun` expression:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=\n      fun ⟨w, hpw, hqw⟩ => ⟨w, hqw, hpw⟩\n    \n\nWe will see in [Chapter Induction and\nRecursion](./induction_and_recursion.html) that all these variations are\ninstances of a more general pattern-matching construct.\n\nIn the following example, we define `is_even a` as `∃ b, a = 2 * b`, and then\nwe show that the sum of two even numbers is an even number.\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    \n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =>\n      Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =>\n        Exists.intro (w1 + w2)\n          (calc a + b\n            _ = 2 * w1 + 2 * w2 := by rw [hw1, hw2]\n            _ = 2 * (w1 + w2)   := by rw [Nat.mul_add])))\n    \n\nUsing the various gadgets described in this chapter --- the match statement,\nanonymous constructors, and the `rewrite` tactic, we can write this proof\nconcisely as follows:\n\n    \n    \n    def is_even (a : Nat) := ∃ b, a = 2 * b\n    theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=\n      match h1, h2 with\n      | ⟨w1, hw1⟩, ⟨w2, hw2⟩ => ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩\n    \n\nJust as the constructive "or" is stronger than the classical "or," so, too, is\nthe constructive "exists" stronger than the classical "exists". For example,\nthe following implication requires classical reasoning because, from a\nconstructive standpoint, knowing that it is not the case that every `x`\nsatisfies `¬ p` is not the same as having a particular `x` that satisfies `p`.\n\n    \n    \n    open Classical\n    variable (p : α → Prop)\n    \n    example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=\n      byContradiction\n        (fun h1 : ¬ ∃ x, p x =>\n          have h2 : ∀ x, ¬ p x :=\n            fun x =>\n            fun h3 : p x =>\n            have h4 : ∃ x, p x := ⟨x, h3⟩\n            show False from h1 h4\n          show False from h h2)\n    \n\nWhat follows are some common identities involving the existential quantifier.\nIn the exercises below, we encourage you to prove as many as you can. We also\nleave it to you to determine which are nonconstructive, and hence require some\nform of classical reasoning.\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : (∃ x : α, r) → r := sorry\n    example (a : α) : r → (∃ x : α, r) := sorry\n    example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry\n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry\n    \n    example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry\n    example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry\n    example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry\n    example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry\n    \n    example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry\n    example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry\n    example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry\n    \n\nNotice that the second example and the last two examples require the\nassumption that there is at least one element `a` of type `α`.\n\nHere are solutions to two of the more difficult ones:\n\n    \n    \n    open Classical\n    \n    variable (α : Type) (p q : α → Prop)\n    variable (a : α)\n    variable (r : Prop)\n    \n    example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=\n      Iff.intro\n        (fun ⟨a, (h1 : p a ∨ q a)⟩ =>\n          Or.elim h1\n            (fun hpa : p a => Or.inl ⟨a, hpa⟩)\n            (fun hqa : q a => Or.inr ⟨a, hqa⟩))\n        (fun h : (∃ x, p x) ∨ (∃ x, q x) =>\n          Or.elim h\n            (fun ⟨a, hpa⟩ => ⟨a, (Or.inl hpa)⟩)\n            (fun ⟨a, hqa⟩ => ⟨a, (Or.inr hqa)⟩))\n    \n    example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=\n      Iff.intro\n        (fun ⟨b, (hb : p b → r)⟩ =>\n         fun h2 : ∀ x, p x =>\n         show r from hb (h2 b))\n        (fun h1 : (∀ x, p x) → r =>\n         show ∃ x, p x → r from\n           byCases\n             (fun hap : ∀ x, p x => ⟨a, λ h\' => h1 hap⟩)\n             (fun hnap : ¬ ∀ x, p x =>\n              byContradiction\n                (fun hnex : ¬ ∃ x, p x → r =>\n                  have hap : ∀ x, p x :=\n                    fun x =>\n                    byContradiction\n                      (fun hnp : ¬ p x =>\n                        have hex : ∃ x, p x → r := ⟨x, (fun hp => absurd hp hnp)⟩\n                        show False from hnex hex)\n                  show False from hnap hap)))\n    \n\n## More on the Proof Language\n\nWe have seen that keywords like `fun`, `have`, and `show` make it possible to\nwrite formal proof terms that mirror the structure of informal mathematical\nproofs. In this section, we discuss some additional features of the proof\nlanguage that are often convenient.\n\nTo start with, we can use anonymous "have" expressions to introduce an\nauxiliary goal without having to label it. We can refer to the last expression\nintroduced in this way using the keyword `this`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans this (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans this (h 2)\n    \n\nOften proofs move from one fact to the next, so this can be effective in\neliminating the clutter of lots of labels.\n\nWhen the goal can be inferred, we can also ask Lean instead to fill in the\nproof by writing `by assumption`:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    example : f 0 ≤ f 3 :=\n      have : f 0 ≤ f 1 := h 0\n      have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)\n      show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)\n    \n\nThis tells Lean to use the `assumption` tactic, which, in turn, proves the\ngoal by finding a suitable hypothesis in the local context. We will learn more\nabout the `assumption` tactic in the next chapter.\n\nWe can also ask Lean to fill in the proof by writing `‹p›`, where `p` is the\nproposition whose proof we want Lean to find in the context. You can type\nthese corner quotes using `\\f<` and `\\f>`, respectively. The letter "f" is for\n"French," since the unicode symbols can also be used as French quotation\nmarks. In fact, the notation is defined in Lean as follows:\n\n    \n    \n    notation "‹" p "›" => show p by assumption\n    \n\nThis approach is more robust than using `by assumption`, because the type of\nthe assumption that needs to be inferred is given explicitly. It also makes\nproofs more readable. Here is a more elaborate example:\n\n    \n    \n    variable (f : Nat → Nat)\n    variable (h : ∀ x : Nat, f x ≤ f (x + 1))\n    \n    example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=\n      fun _ : f 0 ≥ f 1 =>\n      fun _ : f 1 ≥ f 2 =>\n      have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›\n      have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)\n      show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›\n    \n\nKeep in mind that you can use the French quotation marks in this way to refer\nto _anything_ in the context, not just things that were introduced\nanonymously. Its use is also not limited to propositions, though using it for\ndata is somewhat odd:\n\n    \n    \n    example (n : Nat) : Nat := ‹Nat›\n    \n\nLater, we show how you can extend the proof language using the Lean macro\nsystem.\n\n## Exercises\n\n  1. Prove these equivalences:\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    \n    example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry\n    example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry\n    example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry\n    \n\nYou should also try to understand why the reverse implication is not derivable\nin the last example.\n\n  2. It is often possible to bring a component of a formula outside a universal quantifier, when it does not depend on the quantified variable. Try proving these (one direction of the second of these requires classical logic):\n\n    \n    \n    variable (α : Type) (p q : α → Prop)\n    variable (r : Prop)\n    \n    example : α → ((∀ x : α, r) ↔ r) := sorry\n    example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry\n    example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry\n    \n\n  3. Consider the "barber paradox," that is, the claim that in a certain town there is a (male) barber that shaves all and only the men who do not shave themselves. Prove that this is a contradiction:\n\n    \n    \n    variable (men : Type) (barber : men)\n    variable (shaves : men → men → Prop)\n    \n    example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : False := sorry\n    \n\n  4. Remember that, without any parameters, an expression of type `Prop` is just an assertion. Fill in the definitions of `prime` and `Fermat_prime` below, and construct each of the given assertions. For example, you can say that there are infinitely many primes by asserting that for every natural number `n`, there is a prime number greater than `n`. Goldbach\'s weak conjecture states that every odd number greater than 5 is the sum of three primes. Look up the definition of a Fermat prime or any of the other statements, if necessary.\n\n    \n    \n    def even (n : Nat) : Prop := sorry\n    \n    def prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_primes : Prop := sorry\n    \n    def Fermat_prime (n : Nat) : Prop := sorry\n    \n    def infinitely_many_Fermat_primes : Prop := sorry\n    \n    def goldbach_conjecture : Prop := sorry\n    \n    def Goldbach\'s_weak_conjecture : Prop := sorry\n    \n    def Fermat\'s_last_theorem : Prop := sorry\n    \n\n  5. Prove as many of the identities listed in the Existential Quantifier section as you can.\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n\n[ __](propositions_and_proofs.html "Previous chapter") [ __](tactics.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The'}], 'model': 'gpt-4o'}}
2025-06-01 02:02:44,574 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:02:44,574 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:02:44,574 - DEBUG - send_request_headers.complete
2025-06-01 02:02:44,574 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:02:44,578 - DEBUG - send_request_body.complete
2025-06-01 02:02:44,578 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:02:48,048 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:02:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'3237'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'3241'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'16067'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'27.866s'), (b'x-request-id', b'req_5f1911c45378b11e545a451f13bc036c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b216c98a33bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:02:48,048 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:02:48,049 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:02:48,055 - DEBUG - receive_response_body.complete
2025-06-01 02:02:48,055 - DEBUG - response_closed.started
2025-06-01 02:02:48,056 - DEBUG - response_closed.complete
2025-06-01 02:02:48,056 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:02:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '3237', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '3241', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '16067', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '27.866s', 'x-request-id': 'req_5f1911c45378b11e545a451f13bc036c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b216c98a33bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:02:48,056 - DEBUG - request_id: req_5f1911c45378b11e545a451f13bc036c
2025-06-01 02:02:48,056 - INFO - Raw solution received: ```json
{
  "code": "a.all (fun x => n > x)",
  "proof": "by\n  unfold isGreater isGreater_spec\n  by_cases h : a = #[]\n  case pos =>\n    simp [Array.size, h]\n  case neg =>\n    simp at h\n    apply Array.size_pos_iff.2 h\n    apply Array.all_iff_forall.2\n    simp\n    intro i hi\n    exact (Array.getElem_eq_nthLe_iff _ _ i.hi).symm ▸ a.getElem i hi\n"
}
```
2025-06-01 02:02:48,056 - INFO - <class 'str'>
2025-06-01 02:02:48,056 - INFO - Generated solution: {'code': 'a.all (fun x => n > x)', 'proof': 'by\n  unfold isGreater isGreater_spec\n  by_cases h : a = #[]\n  case pos =>\n    simp [Array.size, h]\n  case neg =>\n    simp at h\n    apply Array.size_pos_iff.2 h\n    apply Array.all_iff_forall.2\n    simp\n    intro i hi\n    exact (Array.getElem_eq_nthLe_iff _ _ i.hi).symm ▸ a.getElem i hi\n'}
2025-06-01 02:02:53,245 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:18:40: error: unsolved goals
n : ℤ
a : Array ℤ
⊢ (∀ i < a.size, n > a[i]!) ↔ (a.all fun x => decide (n > x)) = true
lean_playground/TempTest.lean:21:2: error: unexpected token 'by'; expected command
2025-06-01 02:02:53,245 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that determines if a given integer is strictly greater than every element in a provided array. The method should return true only if the integer is larger than each element in the array; otherwise, it should return false.\n\n-----Input-----\nThe input consists of:\nn: An integer.\na: An array of integers.\n\n-----Output-----\nThe output is a Boolean value:\nReturns true if the integer is greater than all elements in the array.\nReturns false if there is at least one element in the array that is greater than or equal to the integer.\n\n-----Note-----\nThe array is assumed to be non-null.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef isGreater (n : Int) (a : Array Int) : Bool :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: If the result is true, then n is greater than all elements in the array; If the result is false, then there exists at least one element in the array that is greater than or equal to n\ndef isGreater_spec (n : Int) (a : Array Int) (result : Bool) : Prop :=\n  -- << SPEC START >>\n  (∀ i, i < a.size → n > a[i]!) ↔ result\n  -- << SPEC END >>\n\ntheorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n  isGreater_spec n a (isGreater n a) := by\n  -- << PROOF START >>\n  unfold isGreater isGreater_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na.all (fun x => n > x)\n\nGenerated Proof:\nby\n  unfold isGreater isGreater_spec\n  by_cases h : a = #[]\n  case pos =>\n    simp [Array.size, h]\n  case neg =>\n    simp at h\n    apply Array.size_pos_iff.2 h\n    apply Array.all_iff_forall.2\n    simp\n    intro i hi\n    exact (Array.getElem_eq_nthLe_iff _ _ i.hi).symm ▸ a.getElem i hi\n\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:18:40: error: unsolved goals\nn : ℤ\na : Array ℤ\n⊢ (∀ i < a.size, n > a[i]!) ↔ (a.all fun x => decide (n > x)) = true\nlean_playground/TempTest.lean:21:2: error: unexpected token 'by'; expected command"}], 'model': 'o3-mini'}}
2025-06-01 02:02:53,246 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:02:53,246 - DEBUG - close.started
2025-06-01 02:02:53,246 - DEBUG - close.complete
2025-06-01 02:02:53,246 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:02:53,253 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b677b290>
2025-06-01 02:02:53,253 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:02:53,261 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b6de0>
2025-06-01 02:02:53,261 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:02:53,261 - DEBUG - send_request_headers.complete
2025-06-01 02:02:53,261 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:02:53,261 - DEBUG - send_request_body.complete
2025-06-01 02:02:53,261 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:03:03,566 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:03:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'9614'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'9620'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199131'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'260ms'), (b'x-request-id', b'req_508b5c1bcbaa042111f1ae22b54d7fba'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b21a2fa348fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:03:03,566 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:03:03,566 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:03:03,567 - DEBUG - receive_response_body.complete
2025-06-01 02:03:03,567 - DEBUG - response_closed.started
2025-06-01 02:03:03,567 - DEBUG - response_closed.complete
2025-06-01 02:03:03,567 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:03:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '9614', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '9620', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199131', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '260ms', 'x-request-id': 'req_508b5c1bcbaa042111f1ae22b54d7fba', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b21a2fa348fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:03:03,567 - DEBUG - request_id: req_508b5c1bcbaa042111f1ae22b54d7fba
2025-06-01 02:03:03,567 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof script fails because the equivalence between the property (a proposition) and the implementation (a Boolean check) was not fully bridged. The error message 'unsolved goals' indicates that Lean could not conclude the desired equivalence. Moreover, the use of by_cases on the array being empty and non‐empty seems misplaced, and there is an unexpected token 'by' after the proof block hinting at a malformed proof structure.", 'error_type': 'proof', 'suggested_fix': "Modify the implementation of isGreater to explicitly use the 'decide' mechanism so that its result is a Boolean reflecting the proposition, and then use an appropriate lemma (e.g., Array.all_iff_forall) to bridge the gap. For example, you can define isGreater as follows:\n\n  def isGreater (n : Int) (a : Array Int) : Bool :=\n    a.all (fun x => decide (n > x))\n\nThen, update the proof as:\n\n  theorem isGreater_spec_satisfied (n : Int) (a : Array Int) :\n    isGreater_spec n a (isGreater n a) := by\n      simp [isGreater, isGreater_spec, Array.all_iff_forall]\n\nThis setup uses simp to replace both sides with the same proposition, and thus resolves the unsolved goals.", 'retry_strategy': 'Revise the code with the above fixes and re-run the Lean file. Ensure that the proof script uses proper simp tactics to normalize the boolean and proposition equivalence. If further issues arise, confirm the existence and form of lemmas like Array.all_iff_forall for the version of Lean you are using.'}
2025-06-01 02:03:03,567 - INFO - Solution generated in 25.78 seconds
2025-06-01 02:03:03,567 - INFO - Generated code length: 5 characters
2025-06-01 02:03:03,568 - INFO - Generated proof length: 5 characters
2025-06-01 02:03:03,568 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:03:03,568 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:03:08,673 - INFO - Implementation test result: FAIL
2025-06-01 02:03:08,674 - ERROR - Implementation error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:17:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:03:08,674 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:03:13,956 - INFO - Full solution test result: FAIL
2025-06-01 02:03:13,956 - ERROR - Proof error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:17:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:03:13,956 - ERROR - ❌ Implementation fails unit tests
2025-06-01 02:03:13,956 - ERROR - ❌ Proof has errors
2025-06-01 02:03:13,956 - INFO - 
==================================================
2025-06-01 02:03:13,956 - INFO - Processing task task_id_435...
2025-06-01 02:03:13,956 - INFO - Reading problem description and code template from tasks/task_id_435...
2025-06-01 02:03:13,957 - INFO - Problem description length: 596 characters
2025-06-01 02:03:13,957 - INFO - Reading unit tests from tasks/task_id_435...
2025-06-01 02:03:13,957 - INFO - Unit tests length: 231 characters
2025-06-01 02:03:13,957 - INFO - Running main workflow to generate solution...
2025-06-01 02:03:13,957 - INFO - Problem description: -----Description-----  
This task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.

-----Input-----  
The input consists of a single value:  
n: A non-negative integer.

-----Output-----  
The output is an integer:  
Returns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.

-----Note-----  
It is assumed that the input number n is non-negative.
2025-06-01 02:03:13,957 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def lastDigit (n : Nat) : Nat :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The returned digit d should be between 0 and 9; d should be the last digit of the input number n
def lastDigit_spec (n : Nat) (result : Nat) : Prop :=
  -- << SPEC START >>
  (0 ≤ result ∧ result < 10) ∧
  (n % 10 = result)
  -- << SPEC END >>

theorem lastDigit_spec_satisfied (n : Nat) :
  lastDigit_spec n (lastDigit n) := by
  -- << PROOF START >>
  unfold lastDigit lastDigit_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:03:13,986 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7159b5eca160>, 'json_data': {'input': '-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:03:13,986 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:03:13,986 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:03:13,993 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62dd520>
2025-06-01 02:03:13,993 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7159b62ab2d0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:03:14,000 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62dc560>
2025-06-01 02:03:14,000 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:03:14,000 - DEBUG - send_request_headers.complete
2025-06-01 02:03:14,000 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:03:14,001 - DEBUG - send_request_body.complete
2025-06-01 02:03:14,001 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:03:14,356 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:03:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'44'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-55694c5655-d4njj'), (b'x-envoy-upstream-service-time', b'51'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999851'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_8e028e43c23cd4fa96cb10ef9e5b93c7'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=j9.2qUsOIk616Wlxs7G8otJ75TiObhp.JOYfeWYqvr0-1748743394-1.0.1.1-8A6yAhSCwru0db2qLCj_jPQfjzcPPrwbWhNOXxw3AtPd.m8EP7SrAX8M1wJs1HMyo0MTyun.dBswdRilPh6AA8Ooj1cA3viqYPAEMjUVg7E; path=/; expires=Sun, 01-Jun-25 02:33:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=yLWFUzDv3wX3BoGLPsuHlaSu5YCPR_jumAShcnW8_VE-1748743394355-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b22248be73bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:03:14,357 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:03:14,357 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:03:14,357 - DEBUG - receive_response_body.complete
2025-06-01 02:03:14,357 - DEBUG - response_closed.started
2025-06-01 02:03:14,357 - DEBUG - response_closed.complete
2025-06-01 02:03:14,357 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:03:14 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '44'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-55694c5655-d4njj'), ('x-envoy-upstream-service-time', '51'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999851'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '8ms'), ('x-request-id', 'req_8e028e43c23cd4fa96cb10ef9e5b93c7'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=j9.2qUsOIk616Wlxs7G8otJ75TiObhp.JOYfeWYqvr0-1748743394-1.0.1.1-8A6yAhSCwru0db2qLCj_jPQfjzcPPrwbWhNOXxw3AtPd.m8EP7SrAX8M1wJs1HMyo0MTyun.dBswdRilPh6AA8Ooj1cA3viqYPAEMjUVg7E; path=/; expires=Sun, 01-Jun-25 02:33:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=yLWFUzDv3wX3BoGLPsuHlaSu5YCPR_jumAShcnW8_VE-1748743394355-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b22248be73bfe-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:03:14,357 - DEBUG - request_id: req_8e028e43c23cd4fa96cb10ef9e5b93c7
2025-06-01 02:03:14,362 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Induction and Recursion

In the previous chapter, we saw that inductive definitions provide a powerful
means of introducing new types in Lean. Moreover, the constructors and the
recursors provide the only means of defining functions on these types. By the
propositions-as-types correspondence, this means that induction is the
fundamental method of proof.

Lean provides natural ways of defining recursive functions, performing pattern
matching, and writing inductive proofs. It allows you to define a function by
specifying equations that it should satisfy, and it allows you to prove a
theorem by specifying how to handle various cases that can arise. Behind the
scenes, these descriptions are "compiled" down to primitive recursors, using a
procedure that we refer to as the "equation compiler." The equation compiler
is not part of the trusted code base; its output consists of terms that are
checked independently by the kernel.

## Pattern Matching

The interpretation of schematic patterns is the first step of the compilation
process. We have seen that the `casesOn` recursor can be used to define
functions and prove theorems by cases, according to the constructors involved
in an inductively defined type. But complicated definitions may use several
nested `casesOn` applications, and may be hard to read and understand. Pattern
matching provides an approach that is more convenient, and familiar to users
of functional programming languages.

Consider the inductively defined type of natural numbers. Every natural number
is either `zero` or `succ x`, and so you can define a function from the
natural numbers to an arbitrary type by specifying a value in each of those
cases:

    
    
    open Nat
    
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    

The equations used to define these functions hold definitionally:

    
    
    open Nat
    def sub1 : Nat → Nat
      | zero   => zero
      | succ x => x
    def isZero : Nat → Bool
      | zero   => true
      | succ x => false
    example : sub1 0 = 0 := rfl
    example (x : Nat) : sub1 (succ x) = x := rfl
    
    example : isZero 0 = true := rfl
    example (x : Nat) : isZero (succ x) = false := rfl
    
    example : sub1 7 = 6 := rfl
    example (x : Nat) : isZero (x + 3) = false := rfl
    

Instead of `zero` and `succ`, we can use more familiar notation:

    
    
    def sub1 : Nat → Nat
      | 0   => 0
      | x+1 => x
    
    def isZero : Nat → Bool
      | 0   => true
      | x+1 => false
    

Because addition and the zero notation have been assigned the
`[match_pattern]` attribute, they can be used in pattern matching. Lean simply
normalizes these expressions until the constructors `zero` and `succ` are
exposed.

Pattern matching works with any inductive type, such as products and option
types:

    
    
    def swap : α × β → β × α
      | (a, b) => (b, a)
    
    def foo : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar : Option Nat → Nat
      | some n => n + 1
      | none   => 0
    

Here we use it not only to define a function, but also to carry out a proof by
cases:

    
    
    namespace Hidden
    def not : Bool → Bool
      | true  => false
      | false => true
    
    theorem not_not : ∀ (b : Bool), not (not b) = b
      | true  => rfl  -- proof that not (not true) = true
      | false => rfl  -- proof that not (not false) = false
    end Hidden
    

Pattern matching can also be used to destruct inductively defined
propositions:

    
    
    example (p q : Prop) : p ∧ q → q ∧ p
      | And.intro h₁ h₂ => And.intro h₂ h₁
    
    example (p q : Prop) : p ∨ q → q ∨ p
      | Or.inl hp => Or.inr hp
      | Or.inr hq => Or.inl hq
    

This provides a compact way of unpacking hypotheses that make use of logical
connectives.

In all these examples, pattern matching was used to carry out a single case
distinction. More interestingly, patterns can involve nested constructors, as
in the following examples.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    

The equation compiler first splits on cases as to whether the input is `zero`
or of the form `succ x`. It then does a case split on whether `x` is of the
form `zero` or `succ x`. It determines the necessary case splits from the
patterns that are presented to it, and raises an error if the patterns fail to
exhaust the cases. Once again, we can use arithmetic notation, as in the
version below. In either case, the defining equations hold definitionally.

    
    
    def sub2 : Nat → Nat
      | 0   => 0
      | 1   => 0
      | x+2 => x
    example : sub2 0 = 0 := rfl
    example : sub2 1 = 0 := rfl
    example : sub2 (x+2) = x := rfl
    
    example : sub2 5 = 3 := rfl
    

You can write `#print sub2` to see how the function was compiled to recursors.
(Lean will tell you that `sub2` has been defined in terms of an internal
auxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses
these auxiliary functions to compile `match` expressions. Actually, the
definition above is expanded to

    
    
    def sub2 : Nat → Nat :=
      fun x =>
        match x with
        | 0   => 0
        | 1   => 0
        | x+2 => x
    

Here are some more examples of nested pattern matching:

    
    
    example (p q : α → Prop)
            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)
      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)
    
    def foo : Nat × Nat → Nat
      | (0, n)     => 0
      | (m+1, 0)   => 1
      | (m+1, n+1) => 2
    

The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a function
of two arguments:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

Here is another example:

    
    
    def bar : List Nat → List Nat → Nat
      | [],      []      => 0
      | a :: as, []      => a
      | [],      b :: bs => b
      | a :: as, b :: bs => a + b
    

Note that the patterns are separated by commas.

In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of patterns.

    
    
    namespace Hidden
    def and : Bool → Bool → Bool
      | true,  a => a
      | false, _ => false
    
    def or : Bool → Bool → Bool
      | true,  _ => true
      | false, a => a
    
    def cond : Bool → α → α → α
      | true,  x, y => x
      | false, x, y => y
    end Hidden
    

Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is known as a
_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside
the equation compiler, here the underscore does _not_ indicate an implicit
argument. The use of underscores for wildcards is common in functional
programming languages, and so Lean adopts that notation. Section Wildcards and
Overlapping Patterns expands on the notion of a wildcard, and Section
Inaccessible Patterns explains how you can use implicit arguments in patterns
as well.

As described in [Chapter Inductive Types](./inductive_types.html), inductive
data types can depend on parameters. The following example defines the `tail`
function using pattern matching. The argument `α : Type u` is a parameter and
occurs before the colon to indicate it does not participate in the pattern
matching. Lean also allows parameters to occur after `:`, but it cannot
pattern match on them.

    
    
    def tail1 {α : Type u} : List α → List α
      | []      => []
      | a :: as => as
    
    def tail2 : {α : Type u} → List α → List α
      | α, []      => []
      | α, a :: as => as
    

Despite the different placement of the parameter `α` in these two examples, in
both cases it is treated in the same way, in that it does not participate in a
case split.

Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the various cases.
Such examples of _dependent pattern matching_ are considered in the Section
Dependent Pattern Matching.

## Wildcards and Overlapping Patterns

Consider one of the examples from the last section:

    
    
    def foo : Nat → Nat → Nat
      | 0,   n   => 0
      | m+1, 0   => 1
      | m+1, n+1 => 2
    

An alternative presentation is:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    

In the second presentation, the patterns overlap; for example, the pair of
arguments `0 0` matches all three cases. But Lean handles the ambiguity by
using the first applicable equation, so in this example the net result is the
same. In particular, the following equations hold definitionally:

    
    
    def foo : Nat → Nat → Nat
      | 0, n => 0
      | m, 0 => 1
      | m, n => 2
    example : foo 0     0     = 0 := rfl
    example : foo 0     (n+1) = 0 := rfl
    example : foo (m+1) 0     = 1 := rfl
    example : foo (m+1) (n+1) = 2 := rfl
    

Since the values of `m` and `n` are not needed, we can just as well use
wildcard patterns instead.

    
    
    def foo : Nat → Nat → Nat
      | 0, _ => 0
      | _, 0 => 1
      | _, _ => 2
    

You can check that this definition of `foo` satisfies the same definitional
identities as before.

Some functional programming languages support _incomplete patterns_. In these
languages, the interpreter produces an exception or returns an arbitrary value
for incomplete cases. We can simulate the arbitrary value approach using the
`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to
the fact that there is an element of `α`; in the [Chapter Type
Classes](./type_classes.html) we will see that Lean can be instructed that
suitable base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the standard library provides
a default element, `default`, of any inhabited type.

We can also use the type `Option α` to simulate incomplete patterns. The idea
is to return `some a` for the provided patterns, and use `none` for the
incomplete cases. The following example demonstrates both approaches.

    
    
    def f1 : Nat → Nat → Nat
      | 0, _  => 1
      | _, 0  => 2
      | _, _  => default  -- the "incomplete" case
    
    example : f1 0     0     = 1       := rfl
    example : f1 0     (a+1) = 1       := rfl
    example : f1 (a+1) 0     = 2       := rfl
    example : f1 (a+1) (b+1) = default := rfl
    
    def f2 : Nat → Nat → Option Nat
      | 0, _  => some 1
      | _, 0  => some 2
      | _, _  => none     -- the "incomplete" case
    
    example : f2 0     0     = some 1 := rfl
    example : f2 0     (a+1) = some 1 := rfl
    example : f2 (a+1) 0     = some 2 := rfl
    example : f2 (a+1) (b+1) = none   := rfl
    

The equation compiler is clever. If you leave out any of the cases in the
following definition, the error message will let you know what has not been
covered.

    
    
    def bar : Nat → List Nat → Bool → Nat
      | 0,   _,      false => 0
      | 0,   b :: _, _     => b
      | 0,   [],     true  => 7
      | a+1, [],     false => a
      | a+1, [],     true  => a + 1
      | a+1, b :: _, _     => a + b
    

It will also use an "if ... then ... else" instead of a `casesOn` in
appropriate situations.

    
    
    def foo : Char → Nat
      | 'A' => 1
      | 'B' => 2
      | _   => 3
    
    #print foo.match_1
    

## Structural Recursion and Induction

What makes the equation compiler powerful is that it also supports recursive
definitions. In the next three sections, we will describe, respectively:

  * structurally recursive definitions
  * well-founded recursive definitions
  * mutually recursive definitions

Generally speaking, the equation compiler processes input of the following
form:

    
    
    def foo (a : α) : (b : β) → γ
      | [patterns₁] => t₁
      ...
      | [patternsₙ] => tₙ
    

Here `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of
arguments on which pattern matching takes place, and `γ` is any type, which
can depend on `a` and `b`. Each line should contain the same number of
patterns, one for each element of `β`. As we have seen, a pattern is either a
variable, a constructor applied to other patterns, or an expression that
normalizes to something of that form (where the non-constructors are marked
with the `[match_pattern]` attribute). The appearances of constructors prompt
case splits, with the arguments to the constructors represented by the given
variables. In Section Dependent Pattern Matching, we will see that it is
sometimes necessary to include explicit terms in patterns that are needed to
make an expression type check, though they do not play a role in pattern
matching. These are called "inaccessible patterns" for that reason. But we
will not need to use such inaccessible patterns before Section Dependent
Pattern Matching.

As we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of
the parameters `a`, as well as any of the variables that are introduced in the
corresponding patterns. What makes recursion and induction possible is that
they can also involve recursive calls to `foo`. In this section, we will deal
with _structural recursion_ , in which the arguments to `foo` occurring on the
right-hand side of the `=>` are subterms of the patterns on the left-hand
side. The idea is that they are structurally smaller, and hence appear in the
inductive type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation compiler:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    
    theorem add_zero (m : Nat)   : add m zero = m := rfl
    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl
    
    theorem zero_add : ∀ n, add zero n = n
      | zero   => rfl
      | succ n => congrArg succ (zero_add n)
    
    def mul : Nat → Nat → Nat
      | n, zero   => zero
      | n, succ m => add (mul n m) n
    

The proof of `zero_add` makes it clear that proof by induction is really a
form of recursion in Lean.

The example above shows that the defining equations for `add` hold
definitionally, and the same is true of `mul`. The equation compiler tries to
ensure that this holds whenever possible, as is the case with straightforward
structural induction. In other situations, however, reductions hold only
_propositionally_ , which is to say, they are equational theorems that must be
applied explicitly. The equation compiler generates such theorems internally.
They are not meant to be used directly by the user; rather, the `simp` tactic
is configured to use them when necessary. Thus both of the following proofs of
`zero_add` work:

    
    
    open Nat
    def add : Nat → Nat → Nat
      | m, zero   => m
      | m, succ n => succ (add m n)
    theorem zero_add : ∀ n, add zero n = n
      | zero   => by simp [add]
      | succ n => by simp [add, zero_add]
    

As with definition by pattern matching, parameters to a structural recursion
or induction may appear before the colon. Such parameters are simply added to
the local context before the definition is processed. For example, the
definition of addition may also be written as follows:

    
    
    open Nat
    def add (m : Nat) : Nat → Nat
      | zero   => m
      | succ n => succ (add m n)
    

You can also write the example above using `match`.

    
    
    open Nat
    def add (m n : Nat) : Nat :=
      match n with
      | zero   => m
      | succ n => succ (add m n)
    

A more interesting example of structural recursion is given by the Fibonacci
function `fib`.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    example : fib 0 = 1 := rfl
    example : fib 1 = 1 := rfl
    example : fib (n + 2) = fib (n + 1) + fib n := rfl
    
    example : fib 7 = 21 := rfl
    

Here, the value of the `fib` function at `n + 2` (which is definitionally
equal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which
is definitionally equivalent to `succ n`) and the value at `n`. This is a
notoriously inefficient way of computing the Fibonacci function, however, with
an execution time that is exponential in `n`. Here is a better way:

    
    
    def fibFast (n : Nat) : Nat :=
      (loop n).2
    where
      loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
    
    #eval fibFast 100
    

Here is the same definition using a `let rec` instead of a `where`.

    
    
    def fibFast (n : Nat) : Nat :=
      let rec loop : Nat → Nat × Nat
        | 0   => (0, 1)
        | n+1 => let p := loop n; (p.2, p.1 + p.2)
      (loop n).2
    

In both cases, Lean generates the auxiliary function `fibFast.loop`.

To handle structural recursion, the equation compiler uses _course-of-values_
recursion, using constants `below` and `brecOn` that are automatically
generated with each inductively defined type. You can get a sense of how it
works by looking at the types of `Nat.below` and `Nat.brecOn`:

    
    
    variable (C : Nat → Type u)
    
    #check (@Nat.below C : Nat → Type u)
    
    #reduce @Nat.below C (3 : Nat)
    
    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
    

The type `@Nat.below C (3 : nat)` is a data structure that stores elements of
`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by
`Nat.brecOn`. It enables us to define the value of a dependent function of
type `(n : Nat) → C n` at a particular input `n` in terms of all the previous
values of the function, presented as an element of `@Nat.below C n`.

The use of course-of-values recursion is one of the techniques the equation
compiler uses to justify to the Lean kernel that a function terminates. It
does not affect the code generator which compiles recursive functions as other
functional programming language compilers. Recall that `#eval fib <n>` is
exponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient
because it uses the definition sent to the kernel that is based on the
`brecOn` construction.

    
    
    def fib : Nat → Nat
      | 0   => 1
      | 1   => 1
      | n+2 => fib (n+1) + fib n
    
    -- #eval fib 50 -- slow
    #reduce fib 50  -- fast
    
    #print fib
    

Another good example of a recursive definition is the list `append` function.

    
    
    def append : List α → List α → List α
      | [],    bs => bs
      | a::as, bs => a :: append as bs
    
    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
    

Here is another: it adds elements of the first list to elements of the second
list, until one of the two lists runs out.

    
    
    def listAdd [Add α] : List α → List α → List α
      | [],      _       => []
      | _,       []      => []
      | a :: as, b :: bs => (a + b) :: listAdd as bs
    
    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
    -- [5, 7, 9]
    

You are encouraged to experiment with similar examples in the exercises below.

## Local recursive declarations

You can define local recursive declarations using the `let rec` keyword.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction.

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using `where` clause
after your definition. Lean converts them into a `let rec`.

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Well-Founded Recursion and Induction

When structural recursion cannot be used, we can prove termination using well-
founded recursion. We need a well-founded relation and a proof that each
recursive application is decreasing with respect to this relation. Dependent
type theory is powerful enough to encode and justify well-founded recursion.
Let us start with the logical background that is needed to understand how it
works.

Lean's standard library defines two predicates, `Acc r a` and `WellFounded r`,
where `r` is a binary relation on a type `α`, and `a` is an element of type
`α`.

    
    
    variable (α : Sort u)
    variable (r : α → α → Prop)
    
    #check (Acc r : α → Prop)
    #check (WellFounded r : Prop)
    

The first, `Acc`, is an inductively defined predicate. According to its
definition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of
`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that
`x` is accessible from below, in the sense that all its predecessors are
accessible. In particular, if `x` has no predecessors, it is accessible. Given
any type `α`, we should be able to assign a value to each accessible element
of `α`, recursively, by assigning values to all its predecessors first.

The statement that `r` is well-founded, denoted `WellFounded r`, is exactly
the statement that every element of the type is accessible. By the above
considerations, if `r` is a well-founded relation on a type `α`, we should
have a principle of well-founded recursion on `α`, with respect to the
relation `r`. And, indeed, we do: the standard library defines
`WellFounded.fix`, which serves exactly that purpose.

    
    
    noncomputable def f {α : Sort u}
          (r : α → α → Prop)
          (h : WellFounded r)
          (C : α → Sort v)
          (F : (x : α) → ((y : α) → r y x → C y) → C x)
          : (x : α) → C x := WellFounded.fix h F
    

There is a long cast of characters here, but the first block we have already
seen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is
well-founded. The variable `C` represents the motive of the recursive
definition: for each element `x : α`, we would like to construct an element of
`C x`. The function `F` provides the inductive recipe for doing that: it tells
us how to construct an element `C x`, given elements of `C y` for each
predecessor `y` of `x`.

Note that `WellFounded.fix` works equally well as an induction principle. It
says that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices
to show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C
x`.

In the example above we use the modifier `noncomputable` because the code
generator currently does not support `WellFounded.fix`. The function
`WellFounded.fix` is another tool Lean uses to justify that a function
terminates.

Lean knows that the usual order `<` on the natural numbers is well founded. It
also knows a number of ways of constructing new well founded orders from
others, for example, using lexicographic order.

Here is essentially the definition of division on the natural numbers that is
found in the standard library.

    
    
    open Nat
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left
    
    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        f (x - y) (div_lemma h) y + 1
      else
        zero
    
    noncomputable def div := WellFounded.fix (measure id).wf div.F
    
    #reduce div 8 2 -- 4
    

The definition is somewhat inscrutable. Here the recursion is on `x`, and
`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed
`x`. You have to remember that the second argument to `div.F`, the recipe for
the recursion, is a function that is supposed to return the divide by `y`
function for all values `x₁` smaller than `x`.

The elaborator is designed to make definitions like this more convenient. It
accepts the following:

    
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
        div (x - y) y + 1
      else
        0
    

When Lean encounters a recursive definition, it first tries structural
recursion, and only when that fails, does it fall back on well-founded
recursion. Lean uses the tactic `decreasing_tactic` to show that the recursive
applications are smaller. The auxiliary proposition `x - y < x` in the example
above should be viewed as a hint for this tactic.

The defining equation for `div` does _not_ hold definitionally, but we can
unfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select
which `div` application we want to unfold.

    
    
    def div (x y : Nat) : Nat :=
     if h : 0 < y ∧ y ≤ x then
       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1
       div (x - y) y + 1
     else
       0
    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by
      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation
    
    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by
      conv => lhs; unfold div
      simp [h]
    

The following example is similar: it converts any natural number to a binary
expression, represented as a list of 0's and 1's. We have to provide evidence
that the recursive call is decreasing, which we do here with a `sorry`. The
`sorry` does not prevent the interpreter from evaluating the function
successfully.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 =>
        have : (n + 2) / 2 < n + 2 := sorry
        natToBin ((n + 2) / 2) ++ [n % 2]
    
    #eval natToBin 1234567
    

As a final example, we observe that Ackermann's function can be defined
directly, because it is justified by the well-foundedness of the lexicographic
order on the natural numbers. The `termination_by` clause instructs Lean to
use a lexicographic order. This clause is actually mapping the function
arguments to elements of type `Nat × Nat`. Then, Lean uses typeclass
resolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    

Note that a lexicographic order is used in the example above because the
instance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also
defines the instance

    
    
    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=
      sizeOfWFRel
    

In the following example, we prove termination by showing that `as.size - i`
is decreasing in the recursive application.

    
    
    def takeWhile (p : α → Bool) (as : Array α) : Array α :=
      go 0 #[]
    where
      go (i : Nat) (r : Array α) : Array α :=
        if h : i < as.size then
          let a := as.get ⟨i, h⟩
          if p a then
            go (i+1) (r.push a)
          else
            r
        else
          r
      termination_by as.size - i
    

Note that, auxiliary function `go` is recursive in this example, but
`takeWhile` is not.

By default, Lean uses the tactic `decreasing_tactic` to prove recursive
applications are decreasing. The
 modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
2025-06-01 02:03:14,366 - DEBUG - close.started
2025-06-01 02:03:14,366 - DEBUG - close.complete
2025-06-01 02:03:14,378 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.'}], 'model': 'o3-mini'}}
2025-06-01 02:03:14,379 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:03:14,379 - DEBUG - close.started
2025-06-01 02:03:14,379 - DEBUG - close.complete
2025-06-01 02:03:14,379 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:03:14,387 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62de9c0>
2025-06-01 02:03:14,387 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:03:14,397 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62dd5e0>
2025-06-01 02:03:14,397 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:03:14,398 - DEBUG - send_request_headers.complete
2025-06-01 02:03:14,398 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:03:14,398 - DEBUG - send_request_body.complete
2025-06-01 02:03:14,398 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:03:19,311 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:03:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4652'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4655'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199550'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'135ms'), (b'x-request-id', b'req_71f251d2a55bb7c33a0d0850d3efbade'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b22270def4278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:03:19,312 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:03:19,312 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:03:19,312 - DEBUG - receive_response_body.complete
2025-06-01 02:03:19,312 - DEBUG - response_closed.started
2025-06-01 02:03:19,312 - DEBUG - response_closed.complete
2025-06-01 02:03:19,312 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:03:19 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4652', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4655', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199550', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '135ms', 'x-request-id': 'req_71f251d2a55bb7c33a0d0850d3efbade', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b22270def4278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:03:19,312 - DEBUG - request_id: req_71f251d2a55bb7c33a0d0850d3efbade
2025-06-01 02:03:19,313 - INFO - Attempt 1/3
2025-06-01 02:03:19,313 - INFO - Current plan: {
  "plan_summary": "The plan is to implement a Lean 4 function that computes the last digit of a given non-negative integer by computing n mod 10. This modular arithmetic operation ensures the output is between 0 and 9. The strategy involves defining a function with the appropriate type signature, performing a modulo operation, and verifying that the result meets the necessary condition.",
  "steps": [
    "Define a Lean function with the appropriate signature to accept a non-negative integer.",
    "Implement the function by computing the modulo of the input with 10.",
    "Ensure that the function returns the result directly, satisfying the range guarantee (0 to 9).",
    "Optionally include basic proofs or comments to document why the modulo operation produces the correct result given the assumption that the number is non-negative."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "modulo",
    "non-negative integer",
    "n % 10"
  ],
  "proof_keywords": [
    "modulo arithmetic",
    "non-negative property",
    "range verification",
    "simple arithmetic"
  ],
  "assumptions": [
    "The input integer n is non-negative",
    "Standard modulo operation in Lean 4 yields results in the expected range for non-negative numbers"
  ],
  "retry_guidance": "If there are compilation or type errors, check that the function's type signature correctly uses Lean's integer type (or natural numbers), and verify that the operator for modulo arithmetic is properly imported and used. If range properties need proof, consider an inductive proof or a simple arithmetic argument."
}
2025-06-01 02:03:19,314 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "The plan is to implement a Lean 4 function that computes the last digit of a given non-negative integer by computing n mod 10. This modular arithmetic operation ensures the output is between 0 and 9. The strategy involves defining a function with the appropriate type signature, performing a modulo operation, and verifying that the result meets the necessary condition.",\n  "steps": [\n    "Define a Lean function with the appropriate signature to accept a non-negative integer.",\n    "Implement the function by computing the modulo of the input with 10.",\n    "Ensure that the function returns the result directly, satisfying the range guarantee (0 to 9).",\n    "Optionally include basic proofs or comments to document why the modulo operation produces the correct result given the assumption that the number is non-negative."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "modulo",\n    "non-negative integer",\n    "n % 10"\n  ],\n  "proof_keywords": [\n    "modulo arithmetic",\n    "non-negative property",\n    "range verification",\n    "simple arithmetic"\n  ],\n  "assumptions": [\n    "The input integer n is non-negative",\n    "Standard modulo operation in Lean 4 yields results in the expected range for non-negative numbers"\n  ],\n  "retry_guidance": "If there are compilation or type errors, check that the function\'s type signature correctly uses Lean\'s integer type (or natural numbers), and verify that the operator for modulo arithmetic is properly imported and used. If range properties need proof, consider an inductive proof or a simple arithmetic argument."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef lastDigit (n : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned digit d should be between 0 and 9; d should be the last digit of the input number n\ndef lastDigit_spec (n : Nat) (result : Nat) : Prop :=\n  -- << SPEC START >>\n  (0 ≤ result ∧ result < 10) ∧\n  (n % 10 = result)\n  -- << SPEC END >>\n\ntheorem lastDigit_spec_satisfied (n : Nat) :\n  lastDigit_spec n (lastDigit n) := by\n  -- << PROOF START >>\n  unfold lastDigit lastDigit_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Induction and Recursion\n\nIn the previous chapter, we saw that inductive definitions provide a powerful\nmeans of introducing new types in Lean. Moreover, the constructors and the\nrecursors provide the only means of defining functions on these types. By the\npropositions-as-types correspondence, this means that induction is the\nfundamental method of proof.\n\nLean provides natural ways of defining recursive functions, performing pattern\nmatching, and writing inductive proofs. It allows you to define a function by\nspecifying equations that it should satisfy, and it allows you to prove a\ntheorem by specifying how to handle various cases that can arise. Behind the\nscenes, these descriptions are "compiled" down to primitive recursors, using a\nprocedure that we refer to as the "equation compiler." The equation compiler\nis not part of the trusted code base; its output consists of terms that are\nchecked independently by the kernel.\n\n## Pattern Matching\n\nThe interpretation of schematic patterns is the first step of the compilation\nprocess. We have seen that the `casesOn` recursor can be used to define\nfunctions and prove theorems by cases, according to the constructors involved\nin an inductively defined type. But complicated definitions may use several\nnested `casesOn` applications, and may be hard to read and understand. Pattern\nmatching provides an approach that is more convenient, and familiar to users\nof functional programming languages.\n\nConsider the inductively defined type of natural numbers. Every natural number\nis either `zero` or `succ x`, and so you can define a function from the\nnatural numbers to an arbitrary type by specifying a value in each of those\ncases:\n\n    \n    \n    open Nat\n    \n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    \n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    \n\nThe equations used to define these functions hold definitionally:\n\n    \n    \n    open Nat\n    def sub1 : Nat → Nat\n      | zero   => zero\n      | succ x => x\n    def isZero : Nat → Bool\n      | zero   => true\n      | succ x => false\n    example : sub1 0 = 0 := rfl\n    example (x : Nat) : sub1 (succ x) = x := rfl\n    \n    example : isZero 0 = true := rfl\n    example (x : Nat) : isZero (succ x) = false := rfl\n    \n    example : sub1 7 = 6 := rfl\n    example (x : Nat) : isZero (x + 3) = false := rfl\n    \n\nInstead of `zero` and `succ`, we can use more familiar notation:\n\n    \n    \n    def sub1 : Nat → Nat\n      | 0   => 0\n      | x+1 => x\n    \n    def isZero : Nat → Bool\n      | 0   => true\n      | x+1 => false\n    \n\nBecause addition and the zero notation have been assigned the\n`[match_pattern]` attribute, they can be used in pattern matching. Lean simply\nnormalizes these expressions until the constructors `zero` and `succ` are\nexposed.\n\nPattern matching works with any inductive type, such as products and option\ntypes:\n\n    \n    \n    def swap : α × β → β × α\n      | (a, b) => (b, a)\n    \n    def foo : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar : Option Nat → Nat\n      | some n => n + 1\n      | none   => 0\n    \n\nHere we use it not only to define a function, but also to carry out a proof by\ncases:\n\n    \n    \n    namespace Hidden\n    def not : Bool → Bool\n      | true  => false\n      | false => true\n    \n    theorem not_not : ∀ (b : Bool), not (not b) = b\n      | true  => rfl  -- proof that not (not true) = true\n      | false => rfl  -- proof that not (not false) = false\n    end Hidden\n    \n\nPattern matching can also be used to destruct inductively defined\npropositions:\n\n    \n    \n    example (p q : Prop) : p ∧ q → q ∧ p\n      | And.intro h₁ h₂ => And.intro h₂ h₁\n    \n    example (p q : Prop) : p ∨ q → q ∨ p\n      | Or.inl hp => Or.inr hp\n      | Or.inr hq => Or.inl hq\n    \n\nThis provides a compact way of unpacking hypotheses that make use of logical\nconnectives.\n\nIn all these examples, pattern matching was used to carry out a single case\ndistinction. More interestingly, patterns can involve nested constructors, as\nin the following examples.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    \n\nThe equation compiler first splits on cases as to whether the input is `zero`\nor of the form `succ x`. It then does a case split on whether `x` is of the\nform `zero` or `succ x`. It determines the necessary case splits from the\npatterns that are presented to it, and raises an error if the patterns fail to\nexhaust the cases. Once again, we can use arithmetic notation, as in the\nversion below. In either case, the defining equations hold definitionally.\n\n    \n    \n    def sub2 : Nat → Nat\n      | 0   => 0\n      | 1   => 0\n      | x+2 => x\n    example : sub2 0 = 0 := rfl\n    example : sub2 1 = 0 := rfl\n    example : sub2 (x+2) = x := rfl\n    \n    example : sub2 5 = 3 := rfl\n    \n\nYou can write `#print sub2` to see how the function was compiled to recursors.\n(Lean will tell you that `sub2` has been defined in terms of an internal\nauxiliary function, `sub2.match_1`, but you can print that out too.) Lean uses\nthese auxiliary functions to compile `match` expressions. Actually, the\ndefinition above is expanded to\n\n    \n    \n    def sub2 : Nat → Nat :=\n      fun x =>\n        match x with\n        | 0   => 0\n        | 1   => 0\n        | x+2 => x\n    \n\nHere are some more examples of nested pattern matching:\n\n    \n    \n    example (p q : α → Prop)\n            : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)\n      | Exists.intro x (Or.inl px) => Or.inl (Exists.intro x px)\n      | Exists.intro x (Or.inr qx) => Or.inr (Exists.intro x qx)\n    \n    def foo : Nat × Nat → Nat\n      | (0, n)     => 0\n      | (m+1, 0)   => 1\n      | (m+1, n+1) => 2\n    \n\nThe equation compiler can process multiple arguments sequentially. For\nexample, it would be more natural to define the previous example as a function\nof two arguments:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nHere is another example:\n\n    \n    \n    def bar : List Nat → List Nat → Nat\n      | [],      []      => 0\n      | a :: as, []      => a\n      | [],      b :: bs => b\n      | a :: as, b :: bs => a + b\n    \n\nNote that the patterns are separated by commas.\n\nIn each of the following examples, splitting occurs on only the first\nargument, even though the others are included among the list of patterns.\n\n    \n    \n    namespace Hidden\n    def and : Bool → Bool → Bool\n      | true,  a => a\n      | false, _ => false\n    \n    def or : Bool → Bool → Bool\n      | true,  _ => true\n      | false, a => a\n    \n    def cond : Bool → α → α → α\n      | true,  x, y => x\n      | false, x, y => y\n    end Hidden\n    \n\nNotice also that, when the value of an argument is not needed in the\ndefinition, you can use an underscore instead. This underscore is known as a\n_wildcard pattern_ , or an _anonymous variable_. In contrast to usage outside\nthe equation compiler, here the underscore does _not_ indicate an implicit\nargument. The use of underscores for wildcards is common in functional\nprogramming languages, and so Lean adopts that notation. Section Wildcards and\nOverlapping Patterns expands on the notion of a wildcard, and Section\nInaccessible Patterns explains how you can use implicit arguments in patterns\nas well.\n\nAs described in [Chapter Inductive Types](./inductive_types.html), inductive\ndata types can depend on parameters. The following example defines the `tail`\nfunction using pattern matching. The argument `α : Type u` is a parameter and\noccurs before the colon to indicate it does not participate in the pattern\nmatching. Lean also allows parameters to occur after `:`, but it cannot\npattern match on them.\n\n    \n    \n    def tail1 {α : Type u} : List α → List α\n      | []      => []\n      | a :: as => as\n    \n    def tail2 : {α : Type u} → List α → List α\n      | α, []      => []\n      | α, a :: as => as\n    \n\nDespite the different placement of the parameter `α` in these two examples, in\nboth cases it is treated in the same way, in that it does not participate in a\ncase split.\n\nLean can also handle more complex forms of pattern matching, in which\narguments to dependent types pose additional constraints on the various cases.\nSuch examples of _dependent pattern matching_ are considered in the Section\nDependent Pattern Matching.\n\n## Wildcards and Overlapping Patterns\n\nConsider one of the examples from the last section:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0,   n   => 0\n      | m+1, 0   => 1\n      | m+1, n+1 => 2\n    \n\nAn alternative presentation is:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    \n\nIn the second presentation, the patterns overlap; for example, the pair of\narguments `0 0` matches all three cases. But Lean handles the ambiguity by\nusing the first applicable equation, so in this example the net result is the\nsame. In particular, the following equations hold definitionally:\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, n => 0\n      | m, 0 => 1\n      | m, n => 2\n    example : foo 0     0     = 0 := rfl\n    example : foo 0     (n+1) = 0 := rfl\n    example : foo (m+1) 0     = 1 := rfl\n    example : foo (m+1) (n+1) = 2 := rfl\n    \n\nSince the values of `m` and `n` are not needed, we can just as well use\nwildcard patterns instead.\n\n    \n    \n    def foo : Nat → Nat → Nat\n      | 0, _ => 0\n      | _, 0 => 1\n      | _, _ => 2\n    \n\nYou can check that this definition of `foo` satisfies the same definitional\nidentities as before.\n\nSome functional programming languages support _incomplete patterns_. In these\nlanguages, the interpreter produces an exception or returns an arbitrary value\nfor incomplete cases. We can simulate the arbitrary value approach using the\n`Inhabited` type class. Roughly, an element of `Inhabited α` is a witness to\nthe fact that there is an element of `α`; in the [Chapter Type\nClasses](./type_classes.html) we will see that Lean can be instructed that\nsuitable base types are inhabited, and can automatically infer that other\nconstructed types are inhabited. On this basis, the standard library provides\na default element, `default`, of any inhabited type.\n\nWe can also use the type `Option α` to simulate incomplete patterns. The idea\nis to return `some a` for the provided patterns, and use `none` for the\nincomplete cases. The following example demonstrates both approaches.\n\n    \n    \n    def f1 : Nat → Nat → Nat\n      | 0, _  => 1\n      | _, 0  => 2\n      | _, _  => default  -- the "incomplete" case\n    \n    example : f1 0     0     = 1       := rfl\n    example : f1 0     (a+1) = 1       := rfl\n    example : f1 (a+1) 0     = 2       := rfl\n    example : f1 (a+1) (b+1) = default := rfl\n    \n    def f2 : Nat → Nat → Option Nat\n      | 0, _  => some 1\n      | _, 0  => some 2\n      | _, _  => none     -- the "incomplete" case\n    \n    example : f2 0     0     = some 1 := rfl\n    example : f2 0     (a+1) = some 1 := rfl\n    example : f2 (a+1) 0     = some 2 := rfl\n    example : f2 (a+1) (b+1) = none   := rfl\n    \n\nThe equation compiler is clever. If you leave out any of the cases in the\nfollowing definition, the error message will let you know what has not been\ncovered.\n\n    \n    \n    def bar : Nat → List Nat → Bool → Nat\n      | 0,   _,      false => 0\n      | 0,   b :: _, _     => b\n      | 0,   [],     true  => 7\n      | a+1, [],     false => a\n      | a+1, [],     true  => a + 1\n      | a+1, b :: _, _     => a + b\n    \n\nIt will also use an "if ... then ... else" instead of a `casesOn` in\nappropriate situations.\n\n    \n    \n    def foo : Char → Nat\n      | \'A\' => 1\n      | \'B\' => 2\n      | _   => 3\n    \n    #print foo.match_1\n    \n\n## Structural Recursion and Induction\n\nWhat makes the equation compiler powerful is that it also supports recursive\ndefinitions. In the next three sections, we will describe, respectively:\n\n  * structurally recursive definitions\n  * well-founded recursive definitions\n  * mutually recursive definitions\n\nGenerally speaking, the equation compiler processes input of the following\nform:\n\n    \n    \n    def foo (a : α) : (b : β) → γ\n      | [patterns₁] => t₁\n      ...\n      | [patternsₙ] => tₙ\n    \n\nHere `(a : α)` is a sequence of parameters, `(b : β)` is the sequence of\narguments on which pattern matching takes place, and `γ` is any type, which\ncan depend on `a` and `b`. Each line should contain the same number of\npatterns, one for each element of `β`. As we have seen, a pattern is either a\nvariable, a constructor applied to other patterns, or an expression that\nnormalizes to something of that form (where the non-constructors are marked\nwith the `[match_pattern]` attribute). The appearances of constructors prompt\ncase splits, with the arguments to the constructors represented by the given\nvariables. In Section Dependent Pattern Matching, we will see that it is\nsometimes necessary to include explicit terms in patterns that are needed to\nmake an expression type check, though they do not play a role in pattern\nmatching. These are called "inaccessible patterns" for that reason. But we\nwill not need to use such inaccessible patterns before Section Dependent\nPattern Matching.\n\nAs we saw in the last section, the terms `t₁, ..., tₙ` can make use of any of\nthe parameters `a`, as well as any of the variables that are introduced in the\ncorresponding patterns. What makes recursion and induction possible is that\nthey can also involve recursive calls to `foo`. In this section, we will deal\nwith _structural recursion_ , in which the arguments to `foo` occurring on the\nright-hand side of the `=>` are subterms of the patterns on the left-hand\nside. The idea is that they are structurally smaller, and hence appear in the\ninductive type at an earlier stage. Here are some examples of structural\nrecursion from the last chapter, now defined using the equation compiler:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    \n    theorem add_zero (m : Nat)   : add m zero = m := rfl\n    theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl\n    \n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => rfl\n      | succ n => congrArg succ (zero_add n)\n    \n    def mul : Nat → Nat → Nat\n      | n, zero   => zero\n      | n, succ m => add (mul n m) n\n    \n\nThe proof of `zero_add` makes it clear that proof by induction is really a\nform of recursion in Lean.\n\nThe example above shows that the defining equations for `add` hold\ndefinitionally, and the same is true of `mul`. The equation compiler tries to\nensure that this holds whenever possible, as is the case with straightforward\nstructural induction. In other situations, however, reductions hold only\n_propositionally_ , which is to say, they are equational theorems that must be\napplied explicitly. The equation compiler generates such theorems internally.\nThey are not meant to be used directly by the user; rather, the `simp` tactic\nis configured to use them when necessary. Thus both of the following proofs of\n`zero_add` work:\n\n    \n    \n    open Nat\n    def add : Nat → Nat → Nat\n      | m, zero   => m\n      | m, succ n => succ (add m n)\n    theorem zero_add : ∀ n, add zero n = n\n      | zero   => by simp [add]\n      | succ n => by simp [add, zero_add]\n    \n\nAs with definition by pattern matching, parameters to a structural recursion\nor induction may appear before the colon. Such parameters are simply added to\nthe local context before the definition is processed. For example, the\ndefinition of addition may also be written as follows:\n\n    \n    \n    open Nat\n    def add (m : Nat) : Nat → Nat\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nYou can also write the example above using `match`.\n\n    \n    \n    open Nat\n    def add (m n : Nat) : Nat :=\n      match n with\n      | zero   => m\n      | succ n => succ (add m n)\n    \n\nA more interesting example of structural recursion is given by the Fibonacci\nfunction `fib`.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    example : fib 0 = 1 := rfl\n    example : fib 1 = 1 := rfl\n    example : fib (n + 2) = fib (n + 1) + fib n := rfl\n    \n    example : fib 7 = 21 := rfl\n    \n\nHere, the value of the `fib` function at `n + 2` (which is definitionally\nequal to `succ (succ n)`) is defined in terms of the values at `n + 1` (which\nis definitionally equivalent to `succ n`) and the value at `n`. This is a\nnotoriously inefficient way of computing the Fibonacci function, however, with\nan execution time that is exponential in `n`. Here is a better way:\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      (loop n).2\n    where\n      loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n    \n    #eval fibFast 100\n    \n\nHere is the same definition using a `let rec` instead of a `where`.\n\n    \n    \n    def fibFast (n : Nat) : Nat :=\n      let rec loop : Nat → Nat × Nat\n        | 0   => (0, 1)\n        | n+1 => let p := loop n; (p.2, p.1 + p.2)\n      (loop n).2\n    \n\nIn both cases, Lean generates the auxiliary function `fibFast.loop`.\n\nTo handle structural recursion, the equation compiler uses _course-of-values_\nrecursion, using constants `below` and `brecOn` that are automatically\ngenerated with each inductively defined type. You can get a sense of how it\nworks by looking at the types of `Nat.below` and `Nat.brecOn`:\n\n    \n    \n    variable (C : Nat → Type u)\n    \n    #check (@Nat.below C : Nat → Type u)\n    \n    #reduce @Nat.below C (3 : Nat)\n    \n    #check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)\n    \n\nThe type `@Nat.below C (3 : nat)` is a data structure that stores elements of\n`C 0`, `C 1`, and `C 2`. The course-of-values recursion is implemented by\n`Nat.brecOn`. It enables us to define the value of a dependent function of\ntype `(n : Nat) → C n` at a particular input `n` in terms of all the previous\nvalues of the function, presented as an element of `@Nat.below C n`.\n\nThe use of course-of-values recursion is one of the techniques the equation\ncompiler uses to justify to the Lean kernel that a function terminates. It\ndoes not affect the code generator which compiles recursive functions as other\nfunctional programming language compilers. Recall that `#eval fib <n>` is\nexponential on `<n>`. On the other hand, `#reduce fib <n>` is efficient\nbecause it uses the definition sent to the kernel that is based on the\n`brecOn` construction.\n\n    \n    \n    def fib : Nat → Nat\n      | 0   => 1\n      | 1   => 1\n      | n+2 => fib (n+1) + fib n\n    \n    -- #eval fib 50 -- slow\n    #reduce fib 50  -- fast\n    \n    #print fib\n    \n\nAnother good example of a recursive definition is the list `append` function.\n\n    \n    \n    def append : List α → List α → List α\n      | [],    bs => bs\n      | a::as, bs => a :: append as bs\n    \n    example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl\n    \n\nHere is another: it adds elements of the first list to elements of the second\nlist, until one of the two lists runs out.\n\n    \n    \n    def listAdd [Add α] : List α → List α → List α\n      | [],      _       => []\n      | _,       []      => []\n      | a :: as, b :: bs => (a + b) :: listAdd as bs\n    \n    #eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]\n    -- [5, 7, 9]\n    \n\nYou are encouraged to experiment with similar examples in the exercises below.\n\n## Local recursive declarations\n\nYou can define local recursive declarations using the `let rec` keyword.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using `where` clause\nafter your definition. Lean converts them into a `let rec`.\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Well-Founded Recursion and Induction\n\nWhen structural recursion cannot be used, we can prove termination using well-\nfounded recursion. We need a well-founded relation and a proof that each\nrecursive application is decreasing with respect to this relation. Dependent\ntype theory is powerful enough to encode and justify well-founded recursion.\nLet us start with the logical background that is needed to understand how it\nworks.\n\nLean\'s standard library defines two predicates, `Acc r a` and `WellFounded r`,\nwhere `r` is a binary relation on a type `α`, and `a` is an element of type\n`α`.\n\n    \n    \n    variable (α : Sort u)\n    variable (r : α → α → Prop)\n    \n    #check (Acc r : α → Prop)\n    #check (WellFounded r : Prop)\n    \n\nThe first, `Acc`, is an inductively defined predicate. According to its\ndefinition, `Acc r x` is equivalent to `∀ y, r y x → Acc r y`. If you think of\n`r y x` as denoting a kind of order relation `y ≺ x`, then `Acc r x` says that\n`x` is accessible from below, in the sense that all its predecessors are\naccessible. In particular, if `x` has no predecessors, it is accessible. Given\nany type `α`, we should be able to assign a value to each accessible element\nof `α`, recursively, by assigning values to all its predecessors first.\n\nThe statement that `r` is well-founded, denoted `WellFounded r`, is exactly\nthe statement that every element of the type is accessible. By the above\nconsiderations, if `r` is a well-founded relation on a type `α`, we should\nhave a principle of well-founded recursion on `α`, with respect to the\nrelation `r`. And, indeed, we do: the standard library defines\n`WellFounded.fix`, which serves exactly that purpose.\n\n    \n    \n    noncomputable def f {α : Sort u}\n          (r : α → α → Prop)\n          (h : WellFounded r)\n          (C : α → Sort v)\n          (F : (x : α) → ((y : α) → r y x → C y) → C x)\n          : (x : α) → C x := WellFounded.fix h F\n    \n\nThere is a long cast of characters here, but the first block we have already\nseen: the type, `α`, the relation, `r`, and the assumption, `h`, that `r` is\nwell-founded. The variable `C` represents the motive of the recursive\ndefinition: for each element `x : α`, we would like to construct an element of\n`C x`. The function `F` provides the inductive recipe for doing that: it tells\nus how to construct an element `C x`, given elements of `C y` for each\npredecessor `y` of `x`.\n\nNote that `WellFounded.fix` works equally well as an induction principle. It\nsays that if `≺` is well-founded and you want to prove `∀ x, C x`, it suffices\nto show that for an arbitrary `x`, if we have `∀ y ≺ x, C y`, then we have `C\nx`.\n\nIn the example above we use the modifier `noncomputable` because the code\ngenerator currently does not support `WellFounded.fix`. The function\n`WellFounded.fix` is another tool Lean uses to justify that a function\nterminates.\n\nLean knows that the usual order `<` on the natural numbers is well founded. It\nalso knows a number of ways of constructing new well founded orders from\nothers, for example, using lexicographic order.\n\nHere is essentially the definition of division on the natural numbers that is\nfound in the standard library.\n\n    \n    \n    open Nat\n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun h => sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left\n    \n    def div.F (x : Nat) (f : (x₁ : Nat) → x₁ < x → Nat → Nat) (y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        f (x - y) (div_lemma h) y + 1\n      else\n        zero\n    \n    noncomputable def div := WellFounded.fix (measure id).wf div.F\n    \n    #reduce div 8 2 -- 4\n    \n\nThe definition is somewhat inscrutable. Here the recursion is on `x`, and\n`div.F x f : Nat → Nat` returns the "divide by `y`" function for that fixed\n`x`. You have to remember that the second argument to `div.F`, the recipe for\nthe recursion, is a function that is supposed to return the divide by `y`\nfunction for all values `x₁` smaller than `x`.\n\nThe elaborator is designed to make definitions like this more convenient. It\naccepts the following:\n\n    \n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n        div (x - y) y + 1\n      else\n        0\n    \n\nWhen Lean encounters a recursive definition, it first tries structural\nrecursion, and only when that fails, does it fall back on well-founded\nrecursion. Lean uses the tactic `decreasing_tactic` to show that the recursive\napplications are smaller. The auxiliary proposition `x - y < x` in the example\nabove should be viewed as a hint for this tactic.\n\nThe defining equation for `div` does _not_ hold definitionally, but we can\nunfold `div` using the `unfold` tactic. We use [`conv`](./conv.html) to select\nwhich `div` application we want to unfold.\n\n    \n    \n    def div (x y : Nat) : Nat :=\n     if h : 0 < y ∧ y ≤ x then\n       have : x - y < x := Nat.sub_lt (Nat.lt_of_lt_of_le h.1 h.2) h.1\n       div (x - y) y + 1\n     else\n       0\n    example (x y : Nat) : div x y = if 0 < y ∧ y ≤ x then div (x - y) y + 1 else 0 := by\n      conv => lhs; unfold div -- unfold occurrence in the left-hand-side of the equation\n    \n    example (x y : Nat) (h : 0 < y ∧ y ≤ x) : div x y = div (x - y) y + 1 := by\n      conv => lhs; unfold div\n      simp [h]\n    \n\nThe following example is similar: it converts any natural number to a binary\nexpression, represented as a list of 0\'s and 1\'s. We have to provide evidence\nthat the recursive call is decreasing, which we do here with a `sorry`. The\n`sorry` does not prevent the interpreter from evaluating the function\nsuccessfully.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 =>\n        have : (n + 2) / 2 < n + 2 := sorry\n        natToBin ((n + 2) / 2) ++ [n % 2]\n    \n    #eval natToBin 1234567\n    \n\nAs a final example, we observe that Ackermann\'s function can be defined\ndirectly, because it is justified by the well-foundedness of the lexicographic\norder on the natural numbers. The `termination_by` clause instructs Lean to\nuse a lexicographic order. This clause is actually mapping the function\narguments to elements of type `Nat × Nat`. Then, Lean uses typeclass\nresolution to synthesize an element of type `WellFoundedRelation (Nat × Nat)`.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    \n\nNote that a lexicographic order is used in the example above because the\ninstance `WellFoundedRelation (α × β)` uses a lexicographic order. Lean also\ndefines the instance\n\n    \n    \n    instance (priority := low) [SizeOf α] : WellFoundedRelation α :=\n      sizeOfWFRel\n    \n\nIn the following example, we prove termination by showing that `as.size - i`\nis decreasing in the recursive application.\n\n    \n    \n    def takeWhile (p : α → Bool) (as : Array α) : Array α :=\n      go 0 #[]\n    where\n      go (i : Nat) (r : Array α) : Array α :=\n        if h : i < as.size then\n          let a := as.get ⟨i, h⟩\n          if p a then\n            go (i+1) (r.push a)\n          else\n            r\n        else\n          r\n      termination_by as.size - i\n    \n\nNote that, auxiliary function `go` is recursive in this example, but\n`takeWhile` is not.\n\nBy default, Lean uses the tactic `decreasing_tactic` to prove recursive\napplications are decreasing. The\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 02:03:19,315 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:03:19,315 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:03:19,315 - DEBUG - send_request_headers.complete
2025-06-01 02:03:19,316 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:03:19,321 - DEBUG - send_request_body.complete
2025-06-01 02:03:19,321 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:03:24,057 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:03:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4512'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4514'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'12108'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'35.784s'), (b'x-request-id', b'req_70d5a82cdb2071aeb4b2d485df2b20e4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b2245cf1e4278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:03:24,057 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:03:24,058 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:03:24,058 - DEBUG - receive_response_body.complete
2025-06-01 02:03:24,058 - DEBUG - response_closed.started
2025-06-01 02:03:24,058 - DEBUG - response_closed.complete
2025-06-01 02:03:24,058 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:03:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4512', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4514', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '12108', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '35.784s', 'x-request-id': 'req_70d5a82cdb2071aeb4b2d485df2b20e4', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b2245cf1e4278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:03:24,058 - DEBUG - request_id: req_70d5a82cdb2071aeb4b2d485df2b20e4
2025-06-01 02:03:24,059 - INFO - Raw solution received: ```json
{
  "code": "n % 10",
  "proof": "\n  by_cases h : n < 10\n  \n  case inl =>\n    -- n < 10, therefore n % 10 should be n itself\n    simp [h]\n    exact ⟨Nat.zero_le n, h, rfl⟩\n  \n  case inr h' =>\n    -- n >= 10\n    have : 0 ≤ n % 10 := Nat.mod_lt n (by decide)\n    simp [h']\n    cases (Nat.exists_eq_add_of_le (Nat.le_of_not_lt h)).mp with\n    | ⟨q, hq⟩ =>\n      simp [Nat.mod_eq] at hq\n      rw [hq] at *\n      simp [Nat.add_mul_mod_self_left, Nat.mul_comm]\n      exact ⟨this, hq.symm ▸ Nat.mod_lt _ (by decide), by simp⟩\n  "
}
```
2025-06-01 02:03:24,059 - INFO - <class 'str'>
2025-06-01 02:03:24,059 - INFO - Generated solution: {'code': 'n % 10', 'proof': "\n  by_cases h : n < 10\n  \n  case inl =>\n    -- n < 10, therefore n % 10 should be n itself\n    simp [h]\n    exact ⟨Nat.zero_le n, h, rfl⟩\n  \n  case inr h' =>\n    -- n >= 10\n    have : 0 ≤ n % 10 := Nat.mod_lt n (by decide)\n    simp [h']\n    cases (Nat.exists_eq_add_of_le (Nat.le_of_not_lt h)).mp with\n    | ⟨q, hq⟩ =>\n      simp [Nat.mod_eq] at hq\n      rw [hq] at *\n      simp [Nat.add_mul_mod_self_left, Nat.mul_comm]\n      exact ⟨this, hq.symm ▸ Nat.mod_lt _ (by decide), by simp⟩\n  "}
2025-06-01 02:03:29,285 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:35:5: error: unexpected token '⟨'; expected '_' or identifier
2025-06-01 02:03:29,286 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description-----  \nThis task requires writing a Lean 4 method that extracts the last digit of a given non-negative integer. The method should return the last digit, which is obtained by computing the remainder when the number is divided by 10. The result must always be between 0 and 9.\n\n-----Input-----  \nThe input consists of a single value:  \nn: A non-negative integer.\n\n-----Output-----  \nThe output is an integer:  \nReturns the last digit of the input number, ensuring that the digit lies within the range 0 to 9.\n\n-----Note-----  \nIt is assumed that the input number n is non-negative.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef lastDigit (n : Nat) : Nat :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The returned digit d should be between 0 and 9; d should be the last digit of the input number n\ndef lastDigit_spec (n : Nat) (result : Nat) : Prop :=\n  -- << SPEC START >>\n  (0 ≤ result ∧ result < 10) ∧\n  (n % 10 = result)\n  -- << SPEC END >>\n\ntheorem lastDigit_spec_satisfied (n : Nat) :\n  lastDigit_spec n (lastDigit n) := by\n  -- << PROOF START >>\n  unfold lastDigit lastDigit_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\nn % 10\n\nGenerated Proof:\n\n  by_cases h : n < 10\n  \n  case inl =>\n    -- n < 10, therefore n % 10 should be n itself\n    simp [h]\n    exact ⟨Nat.zero_le n, h, rfl⟩\n  \n  case inr h' =>\n    -- n >= 10\n    have : 0 ≤ n % 10 := Nat.mod_lt n (by decide)\n    simp [h']\n    cases (Nat.exists_eq_add_of_le (Nat.le_of_not_lt h)).mp with\n    | ⟨q, hq⟩ =>\n      simp [Nat.mod_eq] at hq\n      rw [hq] at *\n      simp [Nat.add_mul_mod_self_left, Nat.mul_comm]\n      exact ⟨this, hq.symm ▸ Nat.mod_lt _ (by decide), by simp⟩\n  \n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:35:5: error: unexpected token '⟨'; expected '_' or identifier"}], 'model': 'o3-mini'}}
2025-06-01 02:03:29,287 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:03:29,287 - DEBUG - close.started
2025-06-01 02:03:29,287 - DEBUG - close.complete
2025-06-01 02:03:29,287 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:03:29,293 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b76b0>
2025-06-01 02:03:29,293 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:03:29,302 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b7bc0>
2025-06-01 02:03:29,302 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:03:29,303 - DEBUG - send_request_headers.complete
2025-06-01 02:03:29,303 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:03:29,303 - DEBUG - send_request_body.complete
2025-06-01 02:03:29,303 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:03:42,295 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:03:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'12744'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'12751'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199163'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'251ms'), (b'x-request-id', b'req_ec1504251569117e19219e1d4c5c4819'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b228439e18fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:03:42,295 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:03:42,295 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:03:42,295 - DEBUG - receive_response_body.complete
2025-06-01 02:03:42,295 - DEBUG - response_closed.started
2025-06-01 02:03:42,295 - DEBUG - response_closed.complete
2025-06-01 02:03:42,296 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:03:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '12744', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '12751', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199163', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '251ms', 'x-request-id': 'req_ec1504251569117e19219e1d4c5c4819', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b228439e18fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:03:42,296 - DEBUG - request_id: req_ec1504251569117e19219e1d4c5c4819
2025-06-01 02:03:42,296 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The proof fails due to a syntax error: Lean complains about the unexpected token '⟨'. This error occurs because the proof uses tuple notation (the angle-bracket syntax) in a context where Lean expects an identifier or an underscore. Moreover, breaking the proof into by_cases is unnecessary for this simple modulus computation.", 'error_type': 'syntax', 'suggested_fix': "Rewrite the proof in a simpler way. Instead of using by_cases and tuple destructuring with ⟨...⟩, unfold the definitions and use the 'constructor' tactic to split the conjunction. For example:\n\n  theorem lastDigit_spec_satisfied (n : Nat) : lastDigit_spec n (lastDigit n) := by\n    unfold lastDigit lastDigit_spec\n    constructor\n    · constructor\n      · exact Nat.zero_le (n % 10)\n      · exact Nat.mod_lt n (by decide)\n    · rfl\n\nThis directly proves that 0 ≤ n % 10 < 10 and that n % 10 equals itself.", 'retry_strategy': "Replace the by_cases proof with the simplified 'constructor' based proof as suggested; then re-run the proof checking to ensure all errors are resolved."}
2025-06-01 02:03:42,296 - INFO - Solution generated in 28.34 seconds
2025-06-01 02:03:42,296 - INFO - Generated code length: 5 characters
2025-06-01 02:03:42,296 - INFO - Generated proof length: 5 characters
2025-06-01 02:03:42,296 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:03:42,297 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:03:47,569 - INFO - Implementation test result: FAIL
2025-06-01 02:03:47,569 - ERROR - Implementation error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:18:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:03:47,569 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:03:52,790 - INFO - Full solution test result: FAIL
2025-06-01 02:03:52,790 - ERROR - Proof error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:18:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:03:52,790 - ERROR - ❌ Implementation fails unit tests
2025-06-01 02:03:52,790 - ERROR - ❌ Proof has errors
2025-06-01 02:03:52,790 - INFO - 
==================================================
2025-06-01 02:03:52,790 - INFO - Processing task task_id_441...
2025-06-01 02:03:52,790 - INFO - Reading problem description and code template from tasks/task_id_441...
2025-06-01 02:03:52,792 - INFO - Problem description length: 489 characters
2025-06-01 02:03:52,792 - INFO - Reading unit tests from tasks/task_id_441...
2025-06-01 02:03:52,792 - INFO - Unit tests length: 171 characters
2025-06-01 02:03:52,792 - INFO - Running main workflow to generate solution...
2025-06-01 02:03:52,792 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.

-----Input-----
The input consists of:
size: An integer representing the length of an edge of the cube.

-----Output-----
The output is an integer:
Returns the surface area of the cube.

-----Note-----
The input edge length is assumed to be greater than 0.
2025-06-01 02:03:52,792 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def cubeSurfaceArea (size : Int) : Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The surface area of the cube is calculated correctly
def cubeSurfaceArea_spec (size : Int) (result : Int) : Prop :=
  -- << SPEC START >>
  result = 6 * size * size
  -- << SPEC END >>

theorem cubeSurfaceArea_spec_satisfied (size : Int):
  cubeSurfaceArea_spec size (cubeSurfaceArea size) := by
  -- << PROOF START >>
  unfold cubeSurfaceArea cubeSurfaceArea_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:03:52,821 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7159b5ecb600>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.\n\n-----Input-----\nThe input consists of:\nsize: An integer representing the length of an edge of the cube.\n\n-----Output-----\nThe output is an integer:\nReturns the surface area of the cube.\n\n-----Note-----\nThe input edge length is assumed to be greater than 0.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:03:52,822 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:03:52,822 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:03:52,828 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62de630>
2025-06-01 02:03:52,828 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7159b65030d0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:03:52,835 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eb7860>
2025-06-01 02:03:52,835 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:03:52,835 - DEBUG - send_request_headers.complete
2025-06-01 02:03:52,835 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:03:52,835 - DEBUG - send_request_body.complete
2025-06-01 02:03:52,835 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:03:53,299 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:03:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'66'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-6b84dbcf9f-wfb5s'), (b'x-envoy-upstream-service-time', b'70'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999877'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_1823790bb68acef65c1e6f540a72778d'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zITwc2paoVXWSXLt6xK5crVjQdmMCuqFl05kfG_XVa8-1748743433-1.0.1.1-3hLQwD68Rm7oZGVSjRgwBUuB_nT_f_Edt0PdHVc0wXR4DmQTzbofFeMUYjveyxWeFPOkn5pXjBRd7Zp0FfNwfq90eerUbLIQsY947zWdT2o; path=/; expires=Sun, 01-Jun-25 02:33:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=flI948xg5DhBD3CaZbEJjVOEnGqm0ACIrA_rJC.u0Fs-1748743433298-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b231739b73bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:03:53,300 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:03:53,300 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:03:53,300 - DEBUG - receive_response_body.complete
2025-06-01 02:03:53,300 - DEBUG - response_closed.started
2025-06-01 02:03:53,301 - DEBUG - response_closed.complete
2025-06-01 02:03:53,301 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:03:53 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '66'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-6b84dbcf9f-wfb5s'), ('x-envoy-upstream-service-time', '70'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999877'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '7ms'), ('x-request-id', 'req_1823790bb68acef65c1e6f540a72778d'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=zITwc2paoVXWSXLt6xK5crVjQdmMCuqFl05kfG_XVa8-1748743433-1.0.1.1-3hLQwD68Rm7oZGVSjRgwBUuB_nT_f_Edt0PdHVc0wXR4DmQTzbofFeMUYjveyxWeFPOkn5pXjBRd7Zp0FfNwfq90eerUbLIQsY947zWdT2o; path=/; expires=Sun, 01-Jun-25 02:33:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=flI948xg5DhBD3CaZbEJjVOEnGqm0ACIrA_rJC.u0Fs-1748743433298-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b231739b73bfe-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:03:53,301 - DEBUG - request_id: req_1823790bb68acef65c1e6f540a72778d
2025-06-01 02:03:53,306 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
 modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
 m by rw [Nat.zero_add, Nat.add_zero])
       (fun (n : Nat) (ih : m + n = n + m) =>
        show m + succ n = succ n + m from
        calc m + succ n
          _ = succ (m + n) := rfl
          _ = succ (n + m) := by rw [ih]
          _ = succ n + m   := sorry)
    

At this point, we see that we need another supporting fact, namely, that `succ
(n + m) = succ n + m`. You can prove this by induction on `m`:

    
    
    open Nat
    
    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m
        (show succ n + 0 = succ (n + 0) from rfl)
        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>
         show succ n + succ m = succ (n + succ m) from
         calc succ n + succ m
           _ = succ (succ n + m)   := rfl
           _ = succ (succ (n + m)) := by rw [ih]
           _ = succ (n + succ m)   := rfl)
    

You can then replace the `sorry` in the previous proof with `succ_add`. Yet
again, the proofs can be compressed:

    
    
    namespace Hidden
    open Nat
    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m
        rfl
        (fun m ih => by simp only [add_succ, ih])
    
    theorem add_comm (m n : Nat) : m + n = n + m :=
      Nat.recOn (motive := fun x => m + x = x + m) n
        (by simp)
        (fun m ih => by simp [add_succ, succ_add, ih])
    end Hidden
    

## Other Recursive Data Types

Let us consider some more examples of inductively defined types. For any type,
`α`, the type `List α` of lists of elements of `α` is defined in the library.

    
    
    namespace Hidden
    inductive List (α : Type u) where
      | nil  : List α
      | cons : α → List α → List α
    
    namespace List
    
    def append (as bs : List α) : List α :=
      match as with
      | nil       => bs
      | cons a as => cons a (append as bs)
    
    theorem nil_append (as : List α) : append nil as = as :=
      rfl
    
    theorem cons_append (a : α) (as bs : List α)
                        : append (cons a as) bs = cons a (append as bs) :=
      rfl
    
    end List
    end Hidden
    

A list of elements of type `α` is either the empty list, `nil`, or an element
`h : α` followed by a list `t : List α`. The first element, `h`, is commonly
known as the "head" of the list, and the remainder, `t`, is known as the
"tail."

As an exercise, prove the following:

    
    
    namespace Hidden
    inductive List (α : Type u) where
    | nil  : List α
    | cons : α → List α → List α
    namespace List
    def append (as bs : List α) : List α :=
     match as with
     | nil       => bs
     | cons a as => cons a (append as bs)
    theorem nil_append (as : List α) : append nil as = as :=
     rfl
    theorem cons_append (a : α) (as bs : List α)
                        : append (cons a as) bs = cons a (append as bs) :=
     rfl
    theorem append_nil (as : List α) : append as nil = as :=
      sorry
    
    theorem append_assoc (as bs cs : List α)
            : append (append as bs) cs = append as (append bs cs) :=
      sorry
    end List
    end Hidden
    

Try also defining the function `length : {α : Type u} → List α → Nat` that
returns the length of a list, and prove that it behaves as expected (for
example, `length (append as bs) = length as + length bs`).

For another example, we can define the type of binary trees:

    
    
    inductive BinaryTree where
      | leaf : BinaryTree
      | node : BinaryTree → BinaryTree → BinaryTree
    

In fact, we can even define the type of countably branching trees:

    
    
    inductive CBTree where
      | leaf : CBTree
      | sup : (Nat → CBTree) → CBTree
    
    namespace CBTree
    
    def succ (t : CBTree) : CBTree :=
      sup (fun _ => t)
    
    def toCBTree : Nat → CBTree
      | 0 => leaf
      | n+1 => succ (toCBTree n)
    
    def omega : CBTree :=
      sup toCBTree
    
    end CBTree
    

## Tactics for Inductive Types

Given the fundamental importance of inductive types in Lean, it should not be
surprising that there are a number of tactics designed to work with them
effectively. We describe some of them here.

The `cases` tactic works on elements of an inductively defined type, and does
what the name suggests: it decomposes the element according to each of the
possible constructors. In its most basic form, it is applied to an element `x`
in the local context. It then reduces the goal to cases in which `x` is
replaced by each of the constructions.

    
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by
      intro n
      cases n
      . exact hz  -- goal is p 0
      . apply hs  -- goal is a : Nat ⊢ p (succ a)
    

There are extra bells and whistles. For one thing, `cases` allows you to
choose the names for each alternative using a `with` clause. In the next
example, for example, we choose the name `m` for the argument to `succ`, so
that the second case refers to `succ m`. More importantly, the cases tactic
will detect any items in the local context that depend on the target variable.
It reverts these elements, does the split, and reintroduces them. In the
example below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in
the first branch, and `h : succ m ≠ 0` in the second.

    
    
    open Nat
    
    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by
      cases n with
      | zero =>
        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0
        apply absurd rfl h
      | succ m =>
        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m
        rfl
    

Notice that `cases` can be used to produce data as well as prove propositions.

    
    
    def f (n : Nat) : Nat := by
      cases n; exact 3; exact 7
    
    example : f 0 = 3 := rfl
    example : f 5 = 7 := rfl
    

Once again, cases will revert, split, and then reintroduce dependencies in the
context.

    
    
    def Tuple (α : Type) (n : Nat) :=
      { as : List α // as.length = n }
    
    def f {n : Nat} (t : Tuple α n) : Nat := by
      cases n; exact 3; exact 7
    
    def myTuple : Tuple Nat 3 :=
      ⟨[0, 1, 2], rfl⟩
    
    example : f myTuple = 7 :=
      rfl
    

Here is an example of multiple constructors with arguments.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    
    def silly (x : Foo) : Nat := by
      cases x with
      | bar1 a b => exact b
      | bar2 c d e => exact e
    

The alternatives for each constructor don't need to be solved in the order the
constructors were declared.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x with
      | bar2 c d e => exact e
      | bar1 a b => exact b
    

The syntax of the `with` is convenient for writing structured proofs. Lean
also provides a complementary `case` tactic, which allows you to focus on goal
assign variable names.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x
      case bar1 a b => exact b
      case bar2 c d e => exact e
    

The `case` tactic is clever, in that it will match the constructor to the
appropriate goal. For example, we can fill the goals above in the opposite
order:

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x
      case bar2 c d e => exact e
      case bar1 a b => exact b
    

You can also use `cases` with an arbitrary expression. Assuming that
expression occurs in the goal, the cases tactic will generalize over the
expression, introduce the resulting universally quantified variable, and case
on that.

    
    
    open Nat
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
            : p (m + 3 * k) := by
      cases m + 3 * k
      exact hz   -- goal is p 0
      apply hs   -- goal is a : Nat ⊢ p (succ a)
    

Think of this as saying "split on cases as to whether `m + 3 * k` is zero or
the successor of some number." The result is functionally equivalent to the
following:

    
    
    open Nat
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
            : p (m + 3 * k) := by
      generalize m + 3 * k = n
      cases n
      exact hz   -- goal is p 0
      apply hs   -- goal is a : Nat ⊢ p (succ a)
    

Notice that the expression `m + 3 * k` is erased by `generalize`; all that
matters is whether it is of the form `0` or `succ a`. This form of `cases`
will _not_ revert any hypotheses that also mention the expression in the
equation (in this case, `m + 3 * k`). If such a term appears in a hypothesis
and you want to generalize over that as well, you need to `revert` it
explicitly.

If the expression you case on does not appear in the goal, the `cases` tactic
uses `have` to put the type of the expression into the context. Here is an
example:

    
    
    example (p : Prop) (m n : Nat)
            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by
      cases Nat.lt_or_ge m n
      case inl hlt => exact h₁ hlt
      case inr hge => exact h₂ hge
    

The theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to
think of the proof above as splitting on these two cases. In the first branch,
we have the hypothesis `hlt : m < n`, and in the second we have the hypothesis
`hge : m ≥ n`. The proof above is functionally equivalent to the following:

    
    
    example (p : Prop) (m n : Nat)
            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by
      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n
      cases h
      case inl hlt => exact h₁ hlt
      case inr hge => exact h₂ hge
    

After the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we
simply do cases on that.

Here is another example, where we use the decidability of equality on the
natural numbers to split on the cases `m = n` and `m ≠ n`.

    
    
    #check Nat.sub_self
    
    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by
      cases Decidable.em (m = n) with
      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n
      | inr hne => apply Or.inr; exact hne
    

Remember that if you `open Classical`, you can use the law of the excluded
middle for any proposition at all. But using type class inference (see
[Chapter Type Classes](./type_classes.html)), Lean can actually find the
relevant decision procedure, which means that you can use the case split in a
computable function.

Just as the `cases` tactic can be used to carry out proof by cases, the
`induction` tactic can be used to carry out proofs by induction. The syntax is
similar to that of `cases`, except that the argument can only be a term in the
local context. Here is an example:

    
    
    namespace Hidden
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n with
      | zero => rfl
      | succ n ih => rw [Nat.add_succ, ih]
    end Hidden
    

As with `cases`, we can use the `case` tactic instead of `with`.

    
    
    namespace Hidden
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n
      case zero => rfl
      case succ n ih => rw [Nat.add_succ, ih]
    end Hidden
    

Here are some additional examples:

    
    
    namespace Hidden
    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n
    open Nat
    
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n <;> simp [*, add_zero, add_succ]
    
    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by
      induction n <;> simp [*, add_zero, add_succ]
    
    theorem add_comm (m n : Nat) : m + n = n + m := by
      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]
    
    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by
      induction k <;> simp [*, add_zero, add_succ]
    end Hidden
    

The `induction` tactic also supports user-defined induction principles with
multiple targets (aka major premises).

    
    
    /-
    theorem Nat.mod.inductionOn
          {motive : Nat → Nat → Sort u}
          (x y  : Nat)
          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)
          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)
          : motive x y :=
    -/
    
    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by
      induction x, y using Nat.mod.inductionOn with
      | ind x y h₁ ih =>
        rw [Nat.mod_eq_sub_mod h₁.2]
        exact ih h
      | base x y h₁ =>
        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁
        match this with
        | Or.inl h₁ => exact absurd h h₁
        | Or.inr h₁ =>
          have hgt : y > x := Nat.gt_of_not_le h₁
          rw [← Nat.mod_eq_of_lt hgt] at hgt
          assumption
    

You can use the `match` notation in tactics too:

    
    
    example : p ∨ q → q ∨ p := by
      intro h
      match h with
      | Or.inl _  => apply Or.inr; assumption
      | Or.inr h2 => apply Or.inl; exact h2
    

As a convenience, pattern-matching has been integrated into tactics such as
`intro` and `funext`.

    
    
    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by
      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩
      exact ⟨hq, hp⟩
    
    example :
        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)
        =
        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by
      funext (a, b) (c, d)
      show a + d = d + a
      rw [Nat.add_comm]
    

We close this section with one last tactic that is designed to facilitate
working with inductive types, namely, the `injection` tactic. By design, the
elements of an inductive type are freely generated, which is to say, the
constructors are injective and have disjoint ranges. The `injection` tactic is
designed to make use of this fact:

    
    
    open Nat
    
    example (m n k : Nat) (h : succ (succ m) = succ (succ n))
            : n + k = m + k := by
      injection h with h'
      injection h' with h''
      rw [h'']
    

The first instance of the tactic adds `h' : succ m = succ n` to the context,
and the second adds `h'' : m = n`.

The `injection` tactic also detects contradictions that arise when different
constructors are set equal to one another, and uses them to close the goal.

    
    
    open Nat
    
    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
      injection h
    
    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
      contradiction
    
    example (h : 7 = 4) : False := by
      contradiction
    

As the second example shows, the `contradiction` tactic also detects
contradictions of this form.

## Inductive Families

We are almost done describing the full range of inductive definitions accepted
by Lean. So far, you have seen that Lean allows you to introduce inductive
types with any number of recursive constructors. In fact, a single inductive
definition can introduce an indexed _family_ of inductive types, in a manner
we now describe.

An inductive family is an indexed family of types defined by a simultaneous
induction of the following form:

    
    
    inductive foo : ... → Sort u where
      | constructor₁ : ... → foo ...
      | constructor₂ : ... → foo ...
      ...
      | constructorₙ : ... → foo ...
    

In contrast to an ordinary inductive definition, which constructs an element
of some `Sort u`, the more general version constructs a function `... → Sort
u`, where "`...`" denotes a sequence of argument types, also known as
_indices_. Each constructor then constructs an element of some member of the
family. One example is the definition of `Vector α n`, the type of vectors of
elements of `α` of length `n`:

    
    
    namespace Hidden
    inductive Vector (α : Type u) : Nat → Type u where
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    end Hidden
    

Notice that the `cons` constructor takes an element of `Vector α n` and
returns an element of `Vector α (n+1)`, thereby using an element of one member
of the family to build an element of another.

A more exotic example is given by the definition of the equality type in Lean:

    
    
    namespace Hidden
    inductive Eq {α : Sort u} (a : α) : α → Prop where
      | refl : Eq a a
    end Hidden
    

For each fixed `α : Sort u` and `a : α`, this definition constructs a family
of types `Eq a x`, indexed by `x : α`. Notably, however, there is only one
constructor, `refl`, which is an element of `Eq a a`. Intuitively, the only
way to construct a proof of `Eq a x` is to use reflexivity, in the case where
`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of
types `Eq a x`. The elimination principle generated by Lean is as follows:

    
    
    universe u v
    
    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}
                      → motive a rfl → {b : α} → (h : a = b) → motive b h)
    

It is a remarkable fact that all the basic axioms for equality follow from the
constructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality
is atypical, however; see the discussion in Section Axiomatic Details.

The recursor `Eq.rec` is also used to define substitution:

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      Eq.rec (motive := fun x _ => p x) h₂ h₁
    end Hidden
    

You can also define `subst` using `match`.

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      match h₁ with
      | rfl => h₂
    end Hidden
    

Actually, Lean compiles the `match` expressions using a definition based on
`Eq.rec`.

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      match h₁ with
      | rfl => h₂
    
    set_option pp.all true
    #print subst
      -- ... subst.match_1 ...
    #print subst.match_1
      -- ... Eq.casesOn ...
    #print Eq.casesOn
      -- ... Eq.rec ...
    end Hidden
    

Using the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are
the same, in which case, `p b` and `p a` are the same.

It is not hard to prove that `Eq` is symmetric and transitive. In the
following example, we prove `symm` and leave as exercises the theorems `trans`
and `congr` (congruence).

    
    
    namespace Hidden
    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=
      match h with
      | rfl => rfl
    
    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=
      sorry
    
    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=
      sorry
    end Hidden
    

In the type theory literature, there are further generalizations of inductive
definitions, for example, the principles of _induction-recursion_ and
_induction-induction_. These are not supported by Lean.

## Axiomatic Details

We have described inductive types and their syntax through examples. This
section provides additional information for those interested in the axiomatic
foundations.

We have seen that the constructor to an inductive type takes _parameters_ \---
intuitively, the arguments that remain fixed throughout the inductive
construction --- and _indices_ , the arguments parameterizing the family of
types that is simultaneously under construction. Each constructor should have
a type, where the argument types are built up from previously defined types,
the parameter and index types, and the inductive family currently being
defined. The requirement is that if the latter is present at all, it occurs
only _strictly positively_. This means simply that any argument to the
constructor in which it occurs is a dependent arrow type in which the
inductive type under definition occurs only as the resulting type, where the
indices are given in terms of constants and previous arguments.

Since an inductive type lives in `Sort u` for some `u`, it is reasonable to
ask _which_ universe levels `u` can be instantiated to. Each constructor `c`
in the definition of a family `C` of inductive types is of the form

    
    
      c : (a : α) → (b : β[a]) → C a p[a,b]
    

where `a` is a sequence of data type parameters, `b` is the sequence of
arguments to the constructors, and `p[a, b]` are the indices, which determine
which element of the inductive family the construction inhabits. (Note that
this description is somewhat misleading, in that the arguments to the
constructor can appear in any order as long as the dependencies make sense.)
The constraints on the universe level of `C` fall into two cases, depending on
whether or not the inductive type is specified to land in `Prop` (that is,
`Sort 0`).

Let us first consider the case where the inductive type is _not_ specified to
land in `Prop`. Then the universe level `u` is constrained to satisfy the
following:

> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,
> if `βk[a] : Sort v`, we have `u` ≥ `v`.

In other words, the universe level `u` is required to be at least as large as
the universe level of each type that represents an argument to a constructor.

When the inductive type is specified to land in `Prop`, there are no
constraints on the universe levels of the constructor arguments. But these
universe levels do have a bearing on the elimination rule. Generally speaking,
for an inductive type in `Prop`, the motive of the elimination rule is
required to be in `Prop`.

There is an exception to this last rule: we are allowed to eliminate from an
inductively defined `Prop` to an arbitrary `Sort` when there is only one
constructor and each constructor argument is either in `Prop` or an index. The
intuition is that in this case the elimination does not make use of any
information that is not already given by the mere fact that the type of
argument is inhabited. This special case is known as _singleton elimination_.

We have already seen singleton elimination at play in applications of
`Eq.rec`, the eliminator for the inductively defined equality type. We can use
an element `h : Eq a b` to cast an element `t' : p a` to `p b` even when `p a`
and `p b` are arbitrary types, because the cast does not produce new data; it
only reinterprets the data we already have. Singleton elimination is also used
with heterogeneous equality and well-founded recursion, which will be
discussed in a [Chapter Induction and
Recursion](./induction_and_recursion.html#well-founded-recursion-and-
induction).

## Mutual and Nested Inductive Types

We now consider two generalizations of inductive types that are often useful,
which Lean supports by "compiling" them down to the more primitive kinds of
inductive types described above. In other words, Lean parses the more general
definitions, defines auxiliary inductive types based on them, and then uses
the auxiliary types to define the ones we really want. Lean's equation
compiler, described in the next chapter, is needed to make use of these types
effectively. Nonetheless, it makes sense to describe the declarations here,
because they are straightforward variations on ordinary inductive definitions.

First, Lean supports _mutually defined_ inductive types. The idea is that we
can define two (or more) inductive types at the same time, where each one
refers to the other(s).

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : (n : Nat) → Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : (n : Nat) → Even n → Odd (n + 1)
    end
    

In this example, two types are defined simultaneously: a natural number `n` is
`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one
more than an `Even` number. In the exercises below, you are asked to spell out
the details.

A mutual inductive definition can also be used to define the notation of a
finite tree with nodes labelled by elements of `α`:

    
    
    mutual
        inductive Tree (α : Type u) where
          | node : α → TreeList α → Tree α
    
        inductive TreeList (α : Type u) where
          | nil  : TreeList α
          | cons : Tree α → TreeList α → TreeList α
    end
    

With this definition, one can construct an element of `Tree α` by giving an
element of `α` together with a list of subtrees, possibly empty. The list of
subtrees is represented by the type `TreeList α`, which is defined to be
either the empty list, `nil`, or the `cons` of a tree and an element of
`TreeList α`.

This definition is inconvenient to work with, however. It would be much nicer
if the list of subtrees were given by the type `List (Tree α)`, especially
since Lean's library contains a number of functions and theorems for working
with lists. One can show that the type `TreeList α` is _isomorphic_ to `List
(Tree α)`, but translating results back and forth along this isomorphism is
tedious.

In fact, Lean allows us to define the inductive type we really want:

    
    
    inductive Tree (α : Type u) where
      | mk : α → List (Tree α) → Tree α
    

This is known as a _nested_ inductive type. It falls outside the strict
specification of an inductive type given in the last section because `Tree`
does not occur strictly positively among the arguments to `mk`, but, rather,
nested inside the `List` type constructor. Lean then automatically builds the
isomorphism between `TreeList α` and `List (Tree α)` in its kernel, and
defines the constructors for `Tree` in terms of the isomorphism.

## Exercises

  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.

Since many of these are already defined in Lean's core library, you should
work within a namespace named `Hidden`, or something like that, in order to
avoid name clashes.

  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:

a. `length (s ++ t) = length s + length t`

b. `length (reverse t) = length t`

c. `reverse (reverse t) = t`

  3. Define an inductive data type consisting of terms built up from the following constructors:

     * `const n`, a constant denoting the natural number `n`
     * `var n`, a variable, numbered `n`
     * `plus s t`, denoting the sum of `s` and `t`
     * `times s t`, denoting the product of `s` and `t`

Recursively define a function that evaluates any such term with respect to an
assignment of values to the variables.

  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.

[ __](interacting_with_lean.html "Previous chapter") [
__](induction_and_recursion.html "Next chapter")

[ __](interacting_with_lean.html "Previous chapter") [
__](induction_and_recursion.html "Next chapter")
2025-06-01 02:03:53,309 - DEBUG - close.started
2025-06-01 02:03:53,310 - DEBUG - close.complete
2025-06-01 02:03:53,323 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.\n\n-----Input-----\nThe input consists of:\nsize: An integer representing the length of an edge of the cube.\n\n-----Output-----\nThe output is an integer:\nReturns the surface area of the cube.\n\n-----Note-----\nThe input edge length is assumed to be greater than 0.'}], 'model': 'o3-mini'}}
2025-06-01 02:03:53,323 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:03:53,323 - DEBUG - close.started
2025-06-01 02:03:53,323 - DEBUG - close.complete
2025-06-01 02:03:53,324 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:03:53,331 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eb7b60>
2025-06-01 02:03:53,331 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:03:53,339 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b5eb4650>
2025-06-01 02:03:53,339 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:03:53,340 - DEBUG - send_request_headers.complete
2025-06-01 02:03:53,340 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:03:53,340 - DEBUG - send_request_body.complete
2025-06-01 02:03:53,340 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:03:57,684 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:03:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'4106'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4110'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199577'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'126ms'), (b'x-request-id', b'req_7526c75ae1fccdcd688d4d753aac06af'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b231a7d6e4278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:03:57,685 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:03:57,685 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:03:57,685 - DEBUG - receive_response_body.complete
2025-06-01 02:03:57,685 - DEBUG - response_closed.started
2025-06-01 02:03:57,685 - DEBUG - response_closed.complete
2025-06-01 02:03:57,685 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:03:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '4106', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4110', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199577', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '126ms', 'x-request-id': 'req_7526c75ae1fccdcd688d4d753aac06af', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b231a7d6e4278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:03:57,685 - DEBUG - request_id: req_7526c75ae1fccdcd688d4d753aac06af
2025-06-01 02:03:57,686 - INFO - Attempt 1/3
2025-06-01 02:03:57,686 - INFO - Current plan: {
  "plan_summary": "Implement a function in Lean 4 that takes an integer edge length and returns the surface area of the cube using the formula 6 * (edge^2). The function assumes the input is a positive integer.",
  "steps": [
    "Define a function with an appropriate signature (taking an integer as input and returning an integer).",
    "Inside the function, compute the square of the input edge length (size * size).",
    "Multiply the squared value by 6 to obtain the cube's surface area.",
    "Return the computed surface area."
  ],
  "code_keywords": [
    "Lean 4",
    "function definition",
    "integer multiplication",
    "cube surface area",
    "edge length"
  ],
  "proof_keywords": [
    "computational function",
    "arithmetic operations",
    "formula derivation"
  ],
  "assumptions": [
    "Input edge length is a positive integer.",
    "Standard arithmetic operations (multiplication and exponentiation) are available."
  ],
  "retry_guidance": "Ensure the arithmetic operations correctly follow Lean 4 syntax for multiplication and exponentiation. Re-check function signature compatibility."
}
2025-06-01 02:03:57,686 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "Implement a function in Lean 4 that takes an integer edge length and returns the surface area of the cube using the formula 6 * (edge^2). The function assumes the input is a positive integer.",\n  "steps": [\n    "Define a function with an appropriate signature (taking an integer as input and returning an integer).",\n    "Inside the function, compute the square of the input edge length (size * size).",\n    "Multiply the squared value by 6 to obtain the cube\'s surface area.",\n    "Return the computed surface area."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "function definition",\n    "integer multiplication",\n    "cube surface area",\n    "edge length"\n  ],\n  "proof_keywords": [\n    "computational function",\n    "arithmetic operations",\n    "formula derivation"\n  ],\n  "assumptions": [\n    "Input edge length is a positive integer.",\n    "Standard arithmetic operations (multiplication and exponentiation) are available."\n  ],\n  "retry_guidance": "Ensure the arithmetic operations correctly follow Lean 4 syntax for multiplication and exponentiation. Re-check function signature compatibility."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeSurfaceArea (size : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The surface area of the cube is calculated correctly\ndef cubeSurfaceArea_spec (size : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = 6 * size * size\n  -- << SPEC END >>\n\ntheorem cubeSurfaceArea_spec_satisfied (size : Int):\n  cubeSurfaceArea_spec size (cubeSurfaceArea size) := by\n  -- << PROOF START >>\n  unfold cubeSurfaceArea cubeSurfaceArea_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 02:03:57,688 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:03:57,688 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:03:57,688 - DEBUG - send_request_headers.complete
2025-06-01 02:03:57,688 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:03:57,694 - DEBUG - send_request_body.complete
2025-06-01 02:03:57,694 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:03:59,232 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:03:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'1304'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1306'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'12755'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'34.488s'), (b'x-request-id', b'req_9e3cb2b9b1e217bd3418c0be3dc18b6b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b23359c894278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:03:59,232 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:03:59,232 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:03:59,233 - DEBUG - receive_response_body.complete
2025-06-01 02:03:59,233 - DEBUG - response_closed.started
2025-06-01 02:03:59,233 - DEBUG - response_closed.complete
2025-06-01 02:03:59,233 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:03:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '1304', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1306', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '12755', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '34.488s', 'x-request-id': 'req_9e3cb2b9b1e217bd3418c0be3dc18b6b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b23359c894278-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:03:59,233 - DEBUG - request_id: req_9e3cb2b9b1e217bd3418c0be3dc18b6b
2025-06-01 02:03:59,234 - INFO - Raw solution received: ```json
{
  "code": "6 * size * size",
  "proof": "simp"
}
```
2025-06-01 02:03:59,234 - INFO - <class 'str'>
2025-06-01 02:03:59,234 - INFO - Generated solution: {'code': '6 * size * size', 'proof': 'simp'}
2025-06-01 02:04:04,681 - INFO - Lean execution result: Lean code executed successfully.
2025-06-01 02:04:04,682 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that calculates the surface area of a cube based on the length of one of its edges. The method should compute the surface area using the standard formula for a cube.\n\n-----Input-----\nThe input consists of:\nsize: An integer representing the length of an edge of the cube.\n\n-----Output-----\nThe output is an integer:\nReturns the surface area of the cube.\n\n-----Note-----\nThe input edge length is assumed to be greater than 0.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeSurfaceArea (size : Int) : Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The surface area of the cube is calculated correctly\ndef cubeSurfaceArea_spec (size : Int) (result : Int) : Prop :=\n  -- << SPEC START >>\n  result = 6 * size * size\n  -- << SPEC END >>\n\ntheorem cubeSurfaceArea_spec_satisfied (size : Int):\n  cubeSurfaceArea_spec size (cubeSurfaceArea size) := by\n  -- << PROOF START >>\n  unfold cubeSurfaceArea cubeSurfaceArea_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\n6 * size * size\n\nGenerated Proof:\nsimp\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean code executed successfully.'}], 'model': 'o3-mini'}}
2025-06-01 02:04:04,683 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:04:04,683 - DEBUG - close.started
2025-06-01 02:04:04,683 - DEBUG - close.complete
2025-06-01 02:04:04,683 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:04:04,689 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b677af00>
2025-06-01 02:04:04,689 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:04:04,697 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b677bd10>
2025-06-01 02:04:04,697 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:04:04,697 - DEBUG - send_request_headers.complete
2025-06-01 02:04:04,697 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:04:04,697 - DEBUG - send_request_body.complete
2025-06-01 02:04:04,697 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:04:07,673 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:04:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2748'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2750'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199335'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'199ms'), (b'x-request-id', b'req_44bce4e5415383609d14c754300ae70b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b23616c583bfe-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:04:07,673 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:04:07,673 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:04:07,674 - DEBUG - receive_response_body.complete
2025-06-01 02:04:07,674 - DEBUG - response_closed.started
2025-06-01 02:04:07,674 - DEBUG - response_closed.complete
2025-06-01 02:04:07,674 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:04:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2748', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2750', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199335', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '199ms', 'x-request-id': 'req_44bce4e5415383609d14c754300ae70b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b23616c583bfe-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:04:07,674 - DEBUG - request_id: req_44bce4e5415383609d14c754300ae70b
2025-06-01 02:04:07,674 - INFO - Feedback received: {'verdict': 'pass', 'error_summary': 'The code compiled and executed without errors. The implementation correctly computes the surface area of a cube, and the proof is verified by simp.', 'error_type': 'unknown', 'suggested_fix': 'No fix required.', 'retry_strategy': 'None'}
2025-06-01 02:04:07,675 - INFO - Solution generated in 14.88 seconds
2025-06-01 02:04:07,675 - INFO - Generated code length: 15 characters
2025-06-01 02:04:07,675 - INFO - Generated proof length: 4 characters
2025-06-01 02:04:07,675 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:04:07,675 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:04:13,024 - INFO - Implementation test result: PASS
2025-06-01 02:04:13,024 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:04:18,407 - INFO - Full solution test result: PASS
2025-06-01 02:04:18,407 - INFO - ✅ Implementation passes unit tests
2025-06-01 02:04:18,407 - INFO - ✅ Proof is correct
2025-06-01 02:04:18,407 - INFO - 
==================================================
2025-06-01 02:04:18,407 - INFO - Processing task task_id_447...
2025-06-01 02:04:18,407 - INFO - Reading problem description and code template from tasks/task_id_447...
2025-06-01 02:04:18,407 - INFO - Problem description length: 691 characters
2025-06-01 02:04:18,408 - INFO - Reading unit tests from tasks/task_id_447...
2025-06-01 02:04:18,408 - INFO - Unit tests length: 234 characters
2025-06-01 02:04:18,408 - INFO - Running main workflow to generate solution...
2025-06-01 02:04:18,408 - INFO - Problem description: -----Description----- 
This task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.

-----Input-----
The input consists of:
a: An array of integers (which may be empty or non-empty).

-----Output-----
The output is an array of integers:
Returns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.

-----Note-----
There are no additional preconditions; the method should work correctly for any array of integers.
2025-06-01 02:04:18,408 - INFO - Task Lean code: import Mathlib
import Aesop

-- Implementation
def cubeElements (a : Array Int) : Array Int :=
  -- << CODE START >>
  {{code}}
  -- << CODE END >>


-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array
def cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=
  -- << SPEC START >>
  (result.size = a.size) ∧
  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)
  -- << SPEC END >>

theorem cubeElements_spec_satisfied (a : Array Int) :
  cubeElements_spec a (cubeElements a) := by
  -- << PROOF START >>
  unfold cubeElements cubeElements_spec
  {{proof}}
  -- << PROOF END >>

2025-06-01 02:04:18,436 - DEBUG - Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x7159b5eca8e0>, 'json_data': {'input': '-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.', 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}
2025-06-01 02:04:18,437 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/embeddings
2025-06-01 02:04:18,437 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:04:18,444 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62dd8e0>
2025-06-01 02:04:18,444 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7159b62ab350> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:04:18,456 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b4500>
2025-06-01 02:04:18,456 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:04:18,456 - DEBUG - send_request_headers.complete
2025-06-01 02:04:18,456 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:04:18,456 - DEBUG - send_request_body.complete
2025-06-01 02:04:18,456 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:04:18,882 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:04:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-6d88f968d4-jr9v5'), (b'x-envoy-upstream-service-time', b'125'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999827'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_4ac8baa3a7f083d8688818502ecbb4bc'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WEfL4Bb7VhunU6evEo84836Q71NhVO4ILzklXu7wYuE-1748743458-1.0.1.1-F7uVlgzvvIbf8vI0S9wS_eshqY3BzNIWDFPUlhSqv92Bx0gXNmxoXIjDuFrse4rpQyWEbq8YSz9Rb8pReAaH2IN03Pj9v0E99Cs8aRCyWIo; path=/; expires=Sun, 01-Jun-25 02:34:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=dlboo6mvCa2WCxaFdqwLaX63sIs3Eyt8cP92StFMZ2Y-1748743458886-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b23b76e1f4278-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:04:18,882 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-06-01 02:04:18,883 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:04:18,883 - DEBUG - receive_response_body.complete
2025-06-01 02:04:18,883 - DEBUG - response_closed.started
2025-06-01 02:04:18,883 - DEBUG - response_closed.complete
2025-06-01 02:04:18,883 - DEBUG - HTTP Response: POST https://api.openai.com/v1/embeddings "200 OK" Headers([('date', 'Sun, 01 Jun 2025 02:04:18 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-2ubqdehd3txfzsucvalz9yzg'), ('openai-processing-ms', '121'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-6d88f968d4-jr9v5'), ('x-envoy-upstream-service-time', '125'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999827'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '10ms'), ('x-request-id', 'req_4ac8baa3a7f083d8688818502ecbb4bc'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=WEfL4Bb7VhunU6evEo84836Q71NhVO4ILzklXu7wYuE-1748743458-1.0.1.1-F7uVlgzvvIbf8vI0S9wS_eshqY3BzNIWDFPUlhSqv92Bx0gXNmxoXIjDuFrse4rpQyWEbq8YSz9Rb8pReAaH2IN03Pj9v0E99Cs8aRCyWIo; path=/; expires=Sun, 01-Jun-25 02:34:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=dlboo6mvCa2WCxaFdqwLaX63sIs3Eyt8cP92StFMZ2Y-1748743458886-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '948b23b76e1f4278-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-01 02:04:18,883 - DEBUG - request_id: req_4ac8baa3a7f083d8688818502ecbb4bc
2025-06-01 02:04:18,888 - INFO - Retrieved context: 1. [Theorem Proving in Lean 4](title_page.html)
  2. [**1.** Introduction](introduction.html)
  3. [**2.** Dependent Type Theory](dependent_type_theory.html)
  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)
  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)
  6. [**5.** Tactics](tactics.html)
  7. [**6.** Interacting with Lean](interacting_with_lean.html)
  8. [**7.** Inductive Types](inductive_types.html)
  9. [**8.** Induction and Recursion](induction_and_recursion.html)
  10. [**9.** Structures and Records](structures_and_records.html)
  11. [**10.** Type Classes](type_classes.html)
  12. [**11.** The Conversion Tactic Mode](conv.html)
  13. [**12.** Axioms and Computation](axioms_and_computation.html)

__ __

  * Light (default)
  * Rust
  * Coal
  * Navy
  * Ayu

__

# Theorem Proving in Lean 4

[ __](print.html "Print this book") [
__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")

# Introduction

## Computers and Theorem Proving

_Formal verification_ involves the use of logical and computational methods to
establish claims that are expressed in precise mathematical terms. These can
include ordinary mathematical theorems, as well as claims that pieces of
hardware or software, network protocols, and mechanical and hybrid systems
meet their specifications. In practice, there is not a sharp distinction
between verifying a piece of mathematics and verifying the correctness of a
system: formal verification requires describing hardware and software systems
in mathematical terms, at which point establishing claims as to their
correctness becomes a form of theorem proving. Conversely, the proof of a
mathematical theorem may require a lengthy computation, in which case
verifying the truth of the theorem requires verifying that the computation
does what it is supposed to do.

The gold standard for supporting a mathematical claim is to provide a proof,
and twentieth-century developments in logic show most if not all conventional
proof methods can be reduced to a small set of axioms and rules in any of a
number of foundational systems. With this reduction, there are two ways that a
computer can help establish a claim: it can help find a proof in the first
place, and it can help verify that a purported proof is correct.

_Automated theorem proving_ focuses on the "finding" aspect. Resolution
theorem provers, tableau theorem provers, fast satisfiability solvers, and so
on provide means of establishing the validity of formulas in propositional and
first-order logic. Other systems provide search procedures and decision
procedures for specific languages and domains, such as linear or nonlinear
expressions over the integers or the real numbers. Architectures like SMT
("satisfiability modulo theories") combine domain-general search methods with
domain-specific procedures. Computer algebra systems and specialized
mathematical software packages provide means of carrying out mathematical
computations, establishing mathematical bounds, or finding mathematical
objects. A calculation can be viewed as a proof as well, and these systems,
too, help establish mathematical claims.

Automated reasoning systems strive for power and efficiency, often at the
expense of guaranteed soundness. Such systems can have bugs, and it can be
difficult to ensure that the results they deliver are correct. In contrast,
_interactive theorem proving_ focuses on the "verification" aspect of theorem
proving, requiring that every claim is supported by a proof in a suitable
axiomatic foundation. This sets a very high standard: every rule of inference
and every step of a calculation has to be justified by appealing to prior
definitions and theorems, all the way down to basic axioms and rules. In fact,
most such systems provide fully elaborated "proof objects" that can be
communicated to other systems and checked independently. Constructing such
proofs typically requires much more input and interaction from users, but it
allows you to obtain deeper and more complex proofs.

The _Lean Theorem Prover_ aims to bridge the gap between interactive and
automated theorem proving, by situating automated tools and methods in a
framework that supports user interaction and the construction of fully
specified axiomatic proofs. The goal is to support both mathematical reasoning
and reasoning about complex systems, and to verify claims in both domains.

Lean's underlying logic has a computational interpretation, and Lean can be
viewed equally well as a programming language. More to the point, it can be
viewed as a system for writing programs with a precise semantics, as well as
reasoning about the functions that the programs compute. Lean also has
mechanisms to serve as its own _metaprogramming language_ , which means that
you can implement automation and extend the functionality of Lean using Lean
itself. These aspects of Lean are described in the free online book,
[Functional Programming in Lean](https://lean-
lang.org/functional_programming_in_lean/), though computational aspects of the
system will make an appearance here.

## About Lean

The _Lean_ project was launched by Leonardo de Moura at Microsoft Research
Redmond in 2013. It is an ongoing, long-term effort, and much of the potential
for automation will be realized only gradually over time. Lean is released
under the [Apache 2.0 license](LICENSE), a permissive open source license that
permits others to use and extend the code and mathematical libraries freely.

To install Lean in your computer consider using the
[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)
instructions. The Lean source code, and instructions for building Lean, are
available at <https://github.com/leanprover/lean4/>.

This tutorial describes the current version of Lean, known as Lean 4.

## About this Book

This book is designed to teach you to develop and verify proofs in Lean. Much
of the background information you will need in order to do this is not
specific to Lean at all. To start with, you will learn the logical system that
Lean is based on, a version of _dependent type theory_ that is powerful enough
to prove almost any conventional mathematical theorem, and expressive enough
to do it in a natural way. More specifically, Lean is based on a version of a
system known as the Calculus of Constructions with inductive types. Lean can
not only define mathematical objects and express mathematical assertions in
dependent type theory, but it also can be used as a language for writing
proofs.

Because fully detailed axiomatic proofs are so complicated, the challenge of
theorem proving is to have the computer fill in as many of the details as
possible. You will learn various methods to support this in [dependent type
theory](dependent_type_theory.html). For example, term rewriting, and Lean's
automated methods for simplifying terms and expressions automatically.
Similarly, methods of _elaboration_ and _type inference_ , which can be used
to support flexible forms of algebraic reasoning.

Finally, you will learn about features that are specific to Lean, including
the language you use to communicate with the system, and the mechanisms Lean
offers for managing complex theories and data.

Throughout the text you will find examples of Lean code like the one below:

    
    
    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
      fun hpq : p ∧ q =>
      have hp : p := And.left hpq
      have hq : q := And.right hpq
      show q ∧ p from And.intro hq hp
    

Next to every code example in this book, you will see a button that reads
"Copy to clipboard". Pressing the button copies the example with enough
surrounding context to make the code compile correctly. You can paste the
example code into [VS Code](https://code.visualstudio.com/) and modify the
examples, and Lean will check the results and provide feedback continuously as
you type. We recommend running the examples and experimenting with the code on
your own as you work through the chapters that follow. You can open this book
in VS Code by using the command "Lean 4: Docs: Show Documentation Resources"
and selecting "Theorem Proving in Lean 4" in the tab that opens.

## Acknowledgments

This tutorial is an open access project maintained on Github. Many people have
contributed to the effort, providing corrections, suggestions, examples, and
text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus
Klaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean
Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John
Mazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,
Paul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.
Please see [lean prover](https://github.com/leanprover/) and [lean
community](https://github.com/leanprover-community/) for an up to date list of
our amazing contributors.

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")

[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html
"Next chapter")
 m by rw [Nat.zero_add, Nat.add_zero])
       (fun (n : Nat) (ih : m + n = n + m) =>
        show m + succ n = succ n + m from
        calc m + succ n
          _ = succ (m + n) := rfl
          _ = succ (n + m) := by rw [ih]
          _ = succ n + m   := sorry)
    

At this point, we see that we need another supporting fact, namely, that `succ
(n + m) = succ n + m`. You can prove this by induction on `m`:

    
    
    open Nat
    
    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m
        (show succ n + 0 = succ (n + 0) from rfl)
        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>
         show succ n + succ m = succ (n + succ m) from
         calc succ n + succ m
           _ = succ (succ n + m)   := rfl
           _ = succ (succ (n + m)) := by rw [ih]
           _ = succ (n + succ m)   := rfl)
    

You can then replace the `sorry` in the previous proof with `succ_add`. Yet
again, the proofs can be compressed:

    
    
    namespace Hidden
    open Nat
    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m
        rfl
        (fun m ih => by simp only [add_succ, ih])
    
    theorem add_comm (m n : Nat) : m + n = n + m :=
      Nat.recOn (motive := fun x => m + x = x + m) n
        (by simp)
        (fun m ih => by simp [add_succ, succ_add, ih])
    end Hidden
    

## Other Recursive Data Types

Let us consider some more examples of inductively defined types. For any type,
`α`, the type `List α` of lists of elements of `α` is defined in the library.

    
    
    namespace Hidden
    inductive List (α : Type u) where
      | nil  : List α
      | cons : α → List α → List α
    
    namespace List
    
    def append (as bs : List α) : List α :=
      match as with
      | nil       => bs
      | cons a as => cons a (append as bs)
    
    theorem nil_append (as : List α) : append nil as = as :=
      rfl
    
    theorem cons_append (a : α) (as bs : List α)
                        : append (cons a as) bs = cons a (append as bs) :=
      rfl
    
    end List
    end Hidden
    

A list of elements of type `α` is either the empty list, `nil`, or an element
`h : α` followed by a list `t : List α`. The first element, `h`, is commonly
known as the "head" of the list, and the remainder, `t`, is known as the
"tail."

As an exercise, prove the following:

    
    
    namespace Hidden
    inductive List (α : Type u) where
    | nil  : List α
    | cons : α → List α → List α
    namespace List
    def append (as bs : List α) : List α :=
     match as with
     | nil       => bs
     | cons a as => cons a (append as bs)
    theorem nil_append (as : List α) : append nil as = as :=
     rfl
    theorem cons_append (a : α) (as bs : List α)
                        : append (cons a as) bs = cons a (append as bs) :=
     rfl
    theorem append_nil (as : List α) : append as nil = as :=
      sorry
    
    theorem append_assoc (as bs cs : List α)
            : append (append as bs) cs = append as (append bs cs) :=
      sorry
    end List
    end Hidden
    

Try also defining the function `length : {α : Type u} → List α → Nat` that
returns the length of a list, and prove that it behaves as expected (for
example, `length (append as bs) = length as + length bs`).

For another example, we can define the type of binary trees:

    
    
    inductive BinaryTree where
      | leaf : BinaryTree
      | node : BinaryTree → BinaryTree → BinaryTree
    

In fact, we can even define the type of countably branching trees:

    
    
    inductive CBTree where
      | leaf : CBTree
      | sup : (Nat → CBTree) → CBTree
    
    namespace CBTree
    
    def succ (t : CBTree) : CBTree :=
      sup (fun _ => t)
    
    def toCBTree : Nat → CBTree
      | 0 => leaf
      | n+1 => succ (toCBTree n)
    
    def omega : CBTree :=
      sup toCBTree
    
    end CBTree
    

## Tactics for Inductive Types

Given the fundamental importance of inductive types in Lean, it should not be
surprising that there are a number of tactics designed to work with them
effectively. We describe some of them here.

The `cases` tactic works on elements of an inductively defined type, and does
what the name suggests: it decomposes the element according to each of the
possible constructors. In its most basic form, it is applied to an element `x`
in the local context. It then reduces the goal to cases in which `x` is
replaced by each of the constructions.

    
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by
      intro n
      cases n
      . exact hz  -- goal is p 0
      . apply hs  -- goal is a : Nat ⊢ p (succ a)
    

There are extra bells and whistles. For one thing, `cases` allows you to
choose the names for each alternative using a `with` clause. In the next
example, for example, we choose the name `m` for the argument to `succ`, so
that the second case refers to `succ m`. More importantly, the cases tactic
will detect any items in the local context that depend on the target variable.
It reverts these elements, does the split, and reintroduces them. In the
example below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in
the first branch, and `h : succ m ≠ 0` in the second.

    
    
    open Nat
    
    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by
      cases n with
      | zero =>
        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0
        apply absurd rfl h
      | succ m =>
        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m
        rfl
    

Notice that `cases` can be used to produce data as well as prove propositions.

    
    
    def f (n : Nat) : Nat := by
      cases n; exact 3; exact 7
    
    example : f 0 = 3 := rfl
    example : f 5 = 7 := rfl
    

Once again, cases will revert, split, and then reintroduce dependencies in the
context.

    
    
    def Tuple (α : Type) (n : Nat) :=
      { as : List α // as.length = n }
    
    def f {n : Nat} (t : Tuple α n) : Nat := by
      cases n; exact 3; exact 7
    
    def myTuple : Tuple Nat 3 :=
      ⟨[0, 1, 2], rfl⟩
    
    example : f myTuple = 7 :=
      rfl
    

Here is an example of multiple constructors with arguments.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    
    def silly (x : Foo) : Nat := by
      cases x with
      | bar1 a b => exact b
      | bar2 c d e => exact e
    

The alternatives for each constructor don't need to be solved in the order the
constructors were declared.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x with
      | bar2 c d e => exact e
      | bar1 a b => exact b
    

The syntax of the `with` is convenient for writing structured proofs. Lean
also provides a complementary `case` tactic, which allows you to focus on goal
assign variable names.

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x
      case bar1 a b => exact b
      case bar2 c d e => exact e
    

The `case` tactic is clever, in that it will match the constructor to the
appropriate goal. For example, we can fill the goals above in the opposite
order:

    
    
    inductive Foo where
      | bar1 : Nat → Nat → Foo
      | bar2 : Nat → Nat → Nat → Foo
    def silly (x : Foo) : Nat := by
      cases x
      case bar2 c d e => exact e
      case bar1 a b => exact b
    

You can also use `cases` with an arbitrary expression. Assuming that
expression occurs in the goal, the cases tactic will generalize over the
expression, introduce the resulting universally quantified variable, and case
on that.

    
    
    open Nat
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
            : p (m + 3 * k) := by
      cases m + 3 * k
      exact hz   -- goal is p 0
      apply hs   -- goal is a : Nat ⊢ p (succ a)
    

Think of this as saying "split on cases as to whether `m + 3 * k` is zero or
the successor of some number." The result is functionally equivalent to the
following:

    
    
    open Nat
    
    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
            : p (m + 3 * k) := by
      generalize m + 3 * k = n
      cases n
      exact hz   -- goal is p 0
      apply hs   -- goal is a : Nat ⊢ p (succ a)
    

Notice that the expression `m + 3 * k` is erased by `generalize`; all that
matters is whether it is of the form `0` or `succ a`. This form of `cases`
will _not_ revert any hypotheses that also mention the expression in the
equation (in this case, `m + 3 * k`). If such a term appears in a hypothesis
and you want to generalize over that as well, you need to `revert` it
explicitly.

If the expression you case on does not appear in the goal, the `cases` tactic
uses `have` to put the type of the expression into the context. Here is an
example:

    
    
    example (p : Prop) (m n : Nat)
            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by
      cases Nat.lt_or_ge m n
      case inl hlt => exact h₁ hlt
      case inr hge => exact h₂ hge
    

The theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to
think of the proof above as splitting on these two cases. In the first branch,
we have the hypothesis `hlt : m < n`, and in the second we have the hypothesis
`hge : m ≥ n`. The proof above is functionally equivalent to the following:

    
    
    example (p : Prop) (m n : Nat)
            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by
      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n
      cases h
      case inl hlt => exact h₁ hlt
      case inr hge => exact h₂ hge
    

After the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we
simply do cases on that.

Here is another example, where we use the decidability of equality on the
natural numbers to split on the cases `m = n` and `m ≠ n`.

    
    
    #check Nat.sub_self
    
    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by
      cases Decidable.em (m = n) with
      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n
      | inr hne => apply Or.inr; exact hne
    

Remember that if you `open Classical`, you can use the law of the excluded
middle for any proposition at all. But using type class inference (see
[Chapter Type Classes](./type_classes.html)), Lean can actually find the
relevant decision procedure, which means that you can use the case split in a
computable function.

Just as the `cases` tactic can be used to carry out proof by cases, the
`induction` tactic can be used to carry out proofs by induction. The syntax is
similar to that of `cases`, except that the argument can only be a term in the
local context. Here is an example:

    
    
    namespace Hidden
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n with
      | zero => rfl
      | succ n ih => rw [Nat.add_succ, ih]
    end Hidden
    

As with `cases`, we can use the `case` tactic instead of `with`.

    
    
    namespace Hidden
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n
      case zero => rfl
      case succ n ih => rw [Nat.add_succ, ih]
    end Hidden
    

Here are some additional examples:

    
    
    namespace Hidden
    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n
    open Nat
    
    theorem zero_add (n : Nat) : 0 + n = n := by
      induction n <;> simp [*, add_zero, add_succ]
    
    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by
      induction n <;> simp [*, add_zero, add_succ]
    
    theorem add_comm (m n : Nat) : m + n = n + m := by
      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]
    
    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by
      induction k <;> simp [*, add_zero, add_succ]
    end Hidden
    

The `induction` tactic also supports user-defined induction principles with
multiple targets (aka major premises).

    
    
    /-
    theorem Nat.mod.inductionOn
          {motive : Nat → Nat → Sort u}
          (x y  : Nat)
          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)
          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)
          : motive x y :=
    -/
    
    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by
      induction x, y using Nat.mod.inductionOn with
      | ind x y h₁ ih =>
        rw [Nat.mod_eq_sub_mod h₁.2]
        exact ih h
      | base x y h₁ =>
        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁
        match this with
        | Or.inl h₁ => exact absurd h h₁
        | Or.inr h₁ =>
          have hgt : y > x := Nat.gt_of_not_le h₁
          rw [← Nat.mod_eq_of_lt hgt] at hgt
          assumption
    

You can use the `match` notation in tactics too:

    
    
    example : p ∨ q → q ∨ p := by
      intro h
      match h with
      | Or.inl _  => apply Or.inr; assumption
      | Or.inr h2 => apply Or.inl; exact h2
    

As a convenience, pattern-matching has been integrated into tactics such as
`intro` and `funext`.

    
    
    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by
      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩
      exact ⟨hq, hp⟩
    
    example :
        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)
        =
        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by
      funext (a, b) (c, d)
      show a + d = d + a
      rw [Nat.add_comm]
    

We close this section with one last tactic that is designed to facilitate
working with inductive types, namely, the `injection` tactic. By design, the
elements of an inductive type are freely generated, which is to say, the
constructors are injective and have disjoint ranges. The `injection` tactic is
designed to make use of this fact:

    
    
    open Nat
    
    example (m n k : Nat) (h : succ (succ m) = succ (succ n))
            : n + k = m + k := by
      injection h with h'
      injection h' with h''
      rw [h'']
    

The first instance of the tactic adds `h' : succ m = succ n` to the context,
and the second adds `h'' : m = n`.

The `injection` tactic also detects contradictions that arise when different
constructors are set equal to one another, and uses them to close the goal.

    
    
    open Nat
    
    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
      injection h
    
    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
      contradiction
    
    example (h : 7 = 4) : False := by
      contradiction
    

As the second example shows, the `contradiction` tactic also detects
contradictions of this form.

## Inductive Families

We are almost done describing the full range of inductive definitions accepted
by Lean. So far, you have seen that Lean allows you to introduce inductive
types with any number of recursive constructors. In fact, a single inductive
definition can introduce an indexed _family_ of inductive types, in a manner
we now describe.

An inductive family is an indexed family of types defined by a simultaneous
induction of the following form:

    
    
    inductive foo : ... → Sort u where
      | constructor₁ : ... → foo ...
      | constructor₂ : ... → foo ...
      ...
      | constructorₙ : ... → foo ...
    

In contrast to an ordinary inductive definition, which constructs an element
of some `Sort u`, the more general version constructs a function `... → Sort
u`, where "`...`" denotes a sequence of argument types, also known as
_indices_. Each constructor then constructs an element of some member of the
family. One example is the definition of `Vector α n`, the type of vectors of
elements of `α` of length `n`:

    
    
    namespace Hidden
    inductive Vector (α : Type u) : Nat → Type u where
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    end Hidden
    

Notice that the `cons` constructor takes an element of `Vector α n` and
returns an element of `Vector α (n+1)`, thereby using an element of one member
of the family to build an element of another.

A more exotic example is given by the definition of the equality type in Lean:

    
    
    namespace Hidden
    inductive Eq {α : Sort u} (a : α) : α → Prop where
      | refl : Eq a a
    end Hidden
    

For each fixed `α : Sort u` and `a : α`, this definition constructs a family
of types `Eq a x`, indexed by `x : α`. Notably, however, there is only one
constructor, `refl`, which is an element of `Eq a a`. Intuitively, the only
way to construct a proof of `Eq a x` is to use reflexivity, in the case where
`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of
types `Eq a x`. The elimination principle generated by Lean is as follows:

    
    
    universe u v
    
    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}
                      → motive a rfl → {b : α} → (h : a = b) → motive b h)
    

It is a remarkable fact that all the basic axioms for equality follow from the
constructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality
is atypical, however; see the discussion in Section Axiomatic Details.

The recursor `Eq.rec` is also used to define substitution:

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      Eq.rec (motive := fun x _ => p x) h₂ h₁
    end Hidden
    

You can also define `subst` using `match`.

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      match h₁ with
      | rfl => h₂
    end Hidden
    

Actually, Lean compiles the `match` expressions using a definition based on
`Eq.rec`.

    
    
    namespace Hidden
    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
      match h₁ with
      | rfl => h₂
    
    set_option pp.all true
    #print subst
      -- ... subst.match_1 ...
    #print subst.match_1
      -- ... Eq.casesOn ...
    #print Eq.casesOn
      -- ... Eq.rec ...
    end Hidden
    

Using the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are
the same, in which case, `p b` and `p a` are the same.

It is not hard to prove that `Eq` is symmetric and transitive. In the
following example, we prove `symm` and leave as exercises the theorems `trans`
and `congr` (congruence).

    
    
    namespace Hidden
    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=
      match h with
      | rfl => rfl
    
    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=
      sorry
    
    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=
      sorry
    end Hidden
    

In the type theory literature, there are further generalizations of inductive
definitions, for example, the principles of _induction-recursion_ and
_induction-induction_. These are not supported by Lean.

## Axiomatic Details

We have described inductive types and their syntax through examples. This
section provides additional information for those interested in the axiomatic
foundations.

We have seen that the constructor to an inductive type takes _parameters_ \---
intuitively, the arguments that remain fixed throughout the inductive
construction --- and _indices_ , the arguments parameterizing the family of
types that is simultaneously under construction. Each constructor should have
a type, where the argument types are built up from previously defined types,
the parameter and index types, and the inductive family currently being
defined. The requirement is that if the latter is present at all, it occurs
only _strictly positively_. This means simply that any argument to the
constructor in which it occurs is a dependent arrow type in which the
inductive type under definition occurs only as the resulting type, where the
indices are given in terms of constants and previous arguments.

Since an inductive type lives in `Sort u` for some `u`, it is reasonable to
ask _which_ universe levels `u` can be instantiated to. Each constructor `c`
in the definition of a family `C` of inductive types is of the form

    
    
      c : (a : α) → (b : β[a]) → C a p[a,b]
    

where `a` is a sequence of data type parameters, `b` is the sequence of
arguments to the constructors, and `p[a, b]` are the indices, which determine
which element of the inductive family the construction inhabits. (Note that
this description is somewhat misleading, in that the arguments to the
constructor can appear in any order as long as the dependencies make sense.)
The constraints on the universe level of `C` fall into two cases, depending on
whether or not the inductive type is specified to land in `Prop` (that is,
`Sort 0`).

Let us first consider the case where the inductive type is _not_ specified to
land in `Prop`. Then the universe level `u` is constrained to satisfy the
following:

> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,
> if `βk[a] : Sort v`, we have `u` ≥ `v`.

In other words, the universe level `u` is required to be at least as large as
the universe level of each type that represents an argument to a constructor.

When the inductive type is specified to land in `Prop`, there are no
constraints on the universe levels of the constructor arguments. But these
universe levels do have a bearing on the elimination rule. Generally speaking,
for an inductive type in `Prop`, the motive of the elimination rule is
required to be in `Prop`.

There is an exception to this last rule: we are allowed to eliminate from an
inductively defined `Prop` to an arbitrary `Sort` when there is only one
constructor and each constructor argument is either in `Prop` or an index. The
intuition is that in this case the elimination does not make use of any
information that is not already given by the mere fact that the type of
argument is inhabited. This special case is known as _singleton elimination_.

We have already seen singleton elimination at play in applications of
`Eq.rec`, the eliminator for the inductively defined equality type. We can use
an element `h : Eq a b` to cast an element `t' : p a` to `p b` even when `p a`
and `p b` are arbitrary types, because the cast does not produce new data; it
only reinterprets the data we already have. Singleton elimination is also used
with heterogeneous equality and well-founded recursion, which will be
discussed in a [Chapter Induction and
Recursion](./induction_and_recursion.html#well-founded-recursion-and-
induction).

## Mutual and Nested Inductive Types

We now consider two generalizations of inductive types that are often useful,
which Lean supports by "compiling" them down to the more primitive kinds of
inductive types described above. In other words, Lean parses the more general
definitions, defines auxiliary inductive types based on them, and then uses
the auxiliary types to define the ones we really want. Lean's equation
compiler, described in the next chapter, is needed to make use of these types
effectively. Nonetheless, it makes sense to describe the declarations here,
because they are straightforward variations on ordinary inductive definitions.

First, Lean supports _mutually defined_ inductive types. The idea is that we
can define two (or more) inductive types at the same time, where each one
refers to the other(s).

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : (n : Nat) → Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : (n : Nat) → Even n → Odd (n + 1)
    end
    

In this example, two types are defined simultaneously: a natural number `n` is
`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one
more than an `Even` number. In the exercises below, you are asked to spell out
the details.

A mutual inductive definition can also be used to define the notation of a
finite tree with nodes labelled by elements of `α`:

    
    
    mutual
        inductive Tree (α : Type u) where
          | node : α → TreeList α → Tree α
    
        inductive TreeList (α : Type u) where
          | nil  : TreeList α
          | cons : Tree α → TreeList α → TreeList α
    end
    

With this definition, one can construct an element of `Tree α` by giving an
element of `α` together with a list of subtrees, possibly empty. The list of
subtrees is represented by the type `TreeList α`, which is defined to be
either the empty list, `nil`, or the `cons` of a tree and an element of
`TreeList α`.

This definition is inconvenient to work with, however. It would be much nicer
if the list of subtrees were given by the type `List (Tree α)`, especially
since Lean's library contains a number of functions and theorems for working
with lists. One can show that the type `TreeList α` is _isomorphic_ to `List
(Tree α)`, but translating results back and forth along this isomorphism is
tedious.

In fact, Lean allows us to define the inductive type we really want:

    
    
    inductive Tree (α : Type u) where
      | mk : α → List (Tree α) → Tree α
    

This is known as a _nested_ inductive type. It falls outside the strict
specification of an inductive type given in the last section because `Tree`
does not occur strictly positively among the arguments to `mk`, but, rather,
nested inside the `List` type constructor. Lean then automatically builds the
isomorphism between `TreeList α` and `List (Tree α)` in its kernel, and
defines the constructors for `Tree` in terms of the isomorphism.

## Exercises

  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.

Since many of these are already defined in Lean's core library, you should
work within a namespace named `Hidden`, or something like that, in order to
avoid name clashes.

  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:

a. `length (s ++ t) = length s + length t`

b. `length (reverse t) = length t`

c. `reverse (reverse t) = t`

  3. Define an inductive data type consisting of terms built up from the following constructors:

     * `const n`, a constant denoting the natural number `n`
     * `var n`, a variable, numbered `n`
     * `plus s t`, denoting the sum of `s` and `t`
     * `times s t`, denoting the product of `s` and `t`

Recursively define a function that evaluates any such term with respect to an
assignment of values to the variables.

  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.

[ __](interacting_with_lean.html "Previous chapter") [
__](induction_and_recursion.html "Next chapter")

[ __](interacting_with_lean.html "Previous chapter") [
__](induction_and_recursion.html "Next chapter")
 modifier `decreasing_by` allows us to provide
our own tactic. Here is an example.

    
    
    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=
      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos
    
    def div (x y : Nat) : Nat :=
      if h : 0 < y ∧ y ≤ x then
        div (x - y) y + 1
      else
        0
    decreasing_by apply div_lemma; assumption
    

Note that `decreasing_by` is not replacement for `termination_by`, they
complement each other. `termination_by` is used to specify a well-founded
relation, and `decreasing_by` for providing our own tactic for showing
recursive applications are decreasing. In the following example, we use both
of them.

    
    
    def ack : Nat → Nat → Nat
      | 0,   y   => y+1
      | x+1, 0   => ack x 1
      | x+1, y+1 => ack x (ack (x+1) y)
    termination_by x y => (x, y)
    decreasing_by
      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions
      · apply Prod.Lex.left; simp_arith
      · apply Prod.Lex.right; simp_arith
      · apply Prod.Lex.left; simp_arith
    

We can use `decreasing_by sorry` to instruct Lean to "trust" us that the
function terminates.

    
    
    def natToBin : Nat → List Nat
      | 0     => [0]
      | 1     => [1]
      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]
    decreasing_by sorry
    
    #eval natToBin 1234567
    

Recall that using `sorry` is equivalent to using a new axiom, and should be
avoided. In the following example, we used the `sorry` to prove `False`. The
command `#print axioms unsound` shows that `unsound` depends on the unsound
axiom `sorryAx` used to implement `sorry`.

    
    
    def unsound (x : Nat) : False :=
      unsound (x + 1)
    decreasing_by sorry
    
    #check unsound 0
    -- `unsound 0` is a proof of `False`
    
    #print axioms unsound
    -- 'unsound' depends on axioms: [sorryAx]
    

Summary:

  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument's type.

  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.

  * The default well-founded relation instance for `Nat` is `<`.

  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.

## Mutual Recursion

Lean also supports mutual recursive definitions. The syntax is similar to that
for mutual inductive types. Here is an example:

    
    
    mutual
      def even : Nat → Bool
        | 0   => true
        | n+1 => odd n
    
      def odd : Nat → Bool
        | 0   => false
        | n+1 => even n
    end
    
    example : even (a + 1) = odd a := by
      simp [even]
    
    example : odd (a + 1) = even a := by
      simp [odd]
    
    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by
      intro a; induction a
      . simp [even, odd]
      . simp [even, odd, *]
    

What makes this a mutual definition is that `even` is defined recursively in
terms of `odd`, while `odd` is defined recursively in terms of `even`. Under
the hood, this is compiled as a single recursive definition. The internally
defined function takes, as argument, an element of a sum type, either an input
to `even`, or an input to `odd`. It then returns an output appropriate to the
input. To define that function, Lean uses a suitable well-founded measure. The
internals are meant to be hidden from users; the canonical way to make use of
such definitions is to use `simp` (or `unfold`), as we did above.

Mutual recursive definitions also provide natural ways of working with mutual
and nested inductive types. Recall the definition of `Even` and `Odd` as
mutual inductive predicates as presented before.

    
    
    mutual
      inductive Even : Nat → Prop where
        | even_zero : Even 0
        | even_succ : ∀ n, Odd n → Even (n + 1)
    
      inductive Odd : Nat → Prop where
        | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    

The constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive
means for showing that a number is even or odd. We need to use the fact that
the inductive type is generated by these constructors to know that zero is not
odd, and that the latter two implications reverse. As usual, the constructors
are kept in a namespace that is named after the type being defined, and the
command `open Even Odd` allows us to access them more conveniently.

    
    
    mutual
     inductive Even : Nat → Prop where
       | even_zero : Even 0
       | even_succ : ∀ n, Odd n → Even (n + 1)
     inductive Odd : Nat → Prop where
       | odd_succ : ∀ n, Even n → Odd (n + 1)
    end
    open Even Odd
    
    theorem not_odd_zero : ¬ Odd 0 :=
      fun h => nomatch h
    
    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n
      | _, odd_succ n h => h
    
    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n
      | _, even_succ n h => h
    

For another example, suppose we use a nested inductive type to define a set of
terms inductively, so that a term is either a constant (with a name given by a
string), or the result of applying a constant to a list of constants.

    
    
    inductive Term where
      | const : String → Term
      | app   : String → List Term → Term
    

We can then use a mutual recursive definition to count the number of constants
occurring in a term, as well as the number occurring in a list of terms.

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    
    mutual
      def numConsts : Term → Nat
        | const _ => 1
        | app _ cs => numConstsLst cs
    
      def numConstsLst : List Term → Nat
        | [] => 0
        | c :: cs => numConsts c + numConstsLst cs
    end
    
    def sample := app "f" [app "g" [const "x"], const "y"]
    
    #eval numConsts sample
    
    end Term
    

As a final example, we define a function `replaceConst a b e` that replaces a
constant `a` with `b` in a term `e`, and then prove the number of constants is
the same. Note that, our proof uses mutual recursion (aka induction).

    
    
    inductive Term where
     | const : String → Term
     | app   : String → List Term → Term
    namespace Term
    mutual
     def numConsts : Term → Nat
       | const _ => 1
       | app _ cs => numConstsLst cs
      def numConstsLst : List Term → Nat
       | [] => 0
       | c :: cs => numConsts c + numConstsLst cs
    end
    mutual
      def replaceConst (a b : String) : Term → Term
        | const c => if a == c then const b else const c
        | app f cs => app f (replaceConstLst a b cs)
    
      def replaceConstLst (a b : String) : List Term → List Term
        | [] => []
        | c :: cs => replaceConst a b c :: replaceConstLst a b cs
    end
    
    mutual
      theorem numConsts_replaceConst (a b : String) (e : Term)
                : numConsts (replaceConst a b e) = numConsts e := by
        match e with
        | const c => simp [replaceConst]; split <;> simp [numConsts]
        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]
    
      theorem numConsts_replaceConstLst (a b : String) (es : List Term)
                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by
        match es with
        | [] => simp [replaceConstLst, numConstsLst]
        | c :: cs =>
          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,
                numConsts_replaceConstLst a b cs]
    end
    

## Dependent Pattern Matching

All the examples of pattern matching we considered in Section Pattern Matching
can easily be written using `casesOn` and `recOn`. However, this is often not
the case with indexed inductive families such as `Vector α n`, since case
splits impose constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very simple
functions such as `map`, `zip`, and `unzip` using recursors. To understand the
difficulty, consider what it would take to define a function `tail` which
takes a vector `v : Vector α (succ n)` and deletes the first element. A first
thought might be to use the `casesOn` function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    #check @Vector.casesOn
    /-
      {α : Type u}
      → {motive : (a : Nat) → Vector α a → Sort v} →
      → {a : Nat} → (t : Vector α a)
      → motive 0 nil
      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
      → motive a t
    -/
    
    end Vector
    

But what value should we return in the `nil` case? Something funny is going
on: if `v` has type `Vector α (succ n)`, it _can't_ be nil, but it is not
clear how to tell that to `casesOn`.

One solution is to define an auxiliary function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v
        (fun h : 0 = n + 1 => Nat.noConfusion h)
        (fun (a : α) (m : Nat) (as : Vector α m) =>
         fun (h : m + 1 = n + 1) =>
           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))
    
    def tail (v : Vector α (n+1)) : Vector α n :=
      tailAux v rfl
    end Vector
    

In the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of
the fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::
w`, and we can simply return `w`, after casting it from a vector of length `m`
to a vector of length `n`.

The difficulty in defining `tail` is to maintain the relationships between the
indices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate
the relationship between `n` and the index associated with the minor premise.
Moreover, the `zero = n + 1` case is unreachable, and the canonical way to
discard such a case is to use `noConfusion`.

The `tail` function is, however, easy to define using recursive equations, and
the equation compiler generates all the boilerplate code automatically for us.
Here are a number of similar examples:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : {n : Nat} → Vector α (n+1) → α
      | n, cons a as => a
    
    def tail : {n : Nat} → Vector α (n+1) → Vector α n
      | n, cons a as => as
    
    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
      | n, cons a as => rfl
    
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

Note that we can omit recursive equations for "unreachable" cases such as
`head nil`. The automatically generated definitions for indexed families are
far from straightforward. For example:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)
    
    #print map
    #print map.match_1
    end Vector
    

The `map` function is even more tedious to define by hand than the `tail`
function. We encourage you to try it, using `recOn`, `casesOn` and
`noConfusion`.

## Inaccessible Patterns

Sometimes an argument in a dependent matching pattern is not essential to the
definition, but nonetheless has to be included to specialize the type of the
expression appropriately. Lean allows users to mark such subterms as
_inaccessible_ for pattern matching. These annotations are essential, for
example, when a term occurring in the left-hand side is neither a variable nor
a constructor application, because these are not suitable targets for pattern
matching. We can view such inaccessible patterns as "don't care" components of
the patterns. You can declare a subterm inaccessible by writing `.(t)`. If the
inaccessible pattern can be inferred, you can also write `_`.

The following example, we declare an inductive type that defines the property
of "being in the image of `f`". You can view an element of the type `ImageOf f
b` as evidence that `b` is in the image of `f`, whereby the constructor `imf`
is used to build such evidence. We can then define any function `f` with an
"inverse" which takes anything in the image of `f` to an element that is
mapped to it. The typing rules forces us to write `f a` for the first
argument, but this term is neither a variable nor a constructor application,
and plays no role in the pattern-matching definition. To define the function
`inverse` below, we _have to_ mark `f a` inaccessible.

    
    
    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
      | imf : (a : α) → ImageOf f (f a)
    
    open ImageOf
    
    def inverse {f : α → β} : (b : β) → ImageOf f b → α
      | .(f a), imf a => a
    
    def inverse' {f : α → β} : (b : β) → ImageOf f b → α
      | _, imf a => a
    

In the example above, the inaccessible annotation makes it clear that `f` is
_not_ a pattern matching variable.

Inaccessible patterns can be used to clarify and control definitions that make
use of dependent pattern matching. Consider the following definition of the
function `Vector.add`, which adds two vectors of elements of a type, assuming
that type has an associated addition function:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    
    namespace Vector
    
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | 0,   nil,       nil       => nil
      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)
    
    end Vector
    

The argument `{n : Nat}` appear after the colon, because it cannot be held
fixed throughout the definition. When implementing this definition, the
equation compiler starts with a case distinction as to whether the first
argument is `0` or of the form `n+1`. This is followed by nested case splits
on the next two arguments, and in each case the equation compiler rules out
the cases are not compatible with the first pattern.

But, in fact, a case split is not required on the first argument; the
`casesOn` eliminator for `Vector` automatically abstracts this argument and
replaces it by `0` and `n + 1` when we do a case split on the second argument.
Using inaccessible patterns, we can prompt the equation compiler to avoid the
case split on `n`

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | .(_), nil,       nil       => nil
      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Marking the position as an inaccessible pattern tells the equation compiler
first, that the form of the argument should be inferred from the constraints
posed by the other arguments, and, second, that the first argument should
_not_ participate in pattern matching.

The inaccessible pattern `.(_)` can be written as `_` for convenience.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
      | _, nil,       nil       => nil
      | _, cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

As we mentioned above, the argument `{n : Nat}` is part of the pattern
matching, because it cannot be held fixed throughout the definition. In
previous Lean versions, users often found it cumbersome to have to include
these extra discriminants. Thus, Lean 4 implements a new feature,
_discriminant refinement_ , which includes these extra discriminants
automatically for us.

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

When combined with the _auto bound implicits_ feature, you can simplify the
declare further and write:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def add [Add α] : Vector α n → Vector α n → Vector α n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a + b) (add as bs)
    end Vector
    

Using these new features, you can write the other vector functions defined in
the previous sections more compactly as follows:

    
    
    inductive Vector (α : Type u) : Nat → Type u
      | nil  : Vector α 0
      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
    namespace Vector
    def head : Vector α (n+1) → α
      | cons a as => a
    
    def tail : Vector α (n+1) → Vector α n
      | cons a as => as
    
    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
      | cons a as => rfl
    
    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (f a b) (map f as bs)
    
    def zip : Vector α n → Vector β n → Vector (α × β) n
      | nil,       nil       => nil
      | cons a as, cons b bs => cons (a, b) (zip as bs)
    end Vector
    

## Match Expressions

Lean also provides a compiler for _match-with_ expressions found in many
functional languages:

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    

This does not look very different from an ordinary pattern matching
definition, but the point is that a `match` can be used anywhere in an
expression, and with arbitrary arguments.

    
    
    def isNotZero (m : Nat) : Bool :=
      match m with
      | 0   => false
      | n+1 => true
    
    def filter (p : α → Bool) : List α → List α
      | []      => []
      | a :: as =>
        match p a with
        | true => a :: filter p as
        | false => filter p as
    
    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
    

Here is another example:

    
    
    def foo (n : Nat) (b c : Bool) :=
      5 + match n - 5, b && c with
          | 0,   true  => 0
          | m+1, true  => m + 7
          | 0,   false => 5
          | m+1, false => m + 3
    
    #eval foo 7 true false
    
    example : foo 7 true false = 9 := rfl
    

Lean uses the `match` construct internally to implement pattern-matching in
all parts of the system. Thus, all four of these definitions have the same net
effect:

    
    
    def bar₁ : Nat × Nat → Nat
      | (m, n) => m + n
    
    def bar₂ (p : Nat × Nat) : Nat :=
      match p with
      | (m, n) => m + n
    
    def bar₃ : Nat × Nat → Nat :=
      fun (m, n) => m + n
    
    def bar₄ (p : Nat × Nat) : Nat :=
      let (m, n) := p; m + n
    

These variations are equally useful for destructing propositions:

    
    
    variable (p q : Nat → Prop)
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      match h₀, h₁ with
      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩
    
    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
            : ∃ x y, p x ∧ q y :=
      let ⟨x, px⟩ := h₀
      let ⟨y, qy⟩ := h₁
      ⟨x, y, px, qy⟩
    

## Local Recursive Declarations

You can define local recursive declarations using the `let rec` keyword:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      let rec loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
      loop n []
    
    #check @replicate.loop
    -- {α : Type} → α → Nat → List α → List α
    

Lean creates an auxiliary declaration for each `let rec`. In the example
above, it created the declaration `replicate.loop` for the `let rec loop`
occurring at `replicate`. Note that, Lean "closes" the declaration by adding
any local variable occurring in the `let rec` declaration as additional
parameters. For example, the local variable `a` occurs at `let rec loop`.

You can also use `let rec` in tactic mode and for creating proofs by
induction:

    
    
    def replicate (n : Nat) (a : α) : List α :=
     let rec loop : Nat → List α → List α
       | 0,   as => as
       | n+1, as => loop n (a::as)
     loop n []
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      let rec aux (n : Nat) (as : List α)
                  : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
      exact aux n []
    

You can also introduce auxiliary recursive declarations using a `where` clause
after your definition. Lean converts them into a `let rec`:

    
    
    def replicate (n : Nat) (a : α) : List α :=
      loop n []
    where
      loop : Nat → List α → List α
        | 0,   as => as
        | n+1, as => loop n (a::as)
    
    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
      exact aux n []
    where
      aux (n : Nat) (as : List α)
          : (replicate.loop a n as).length = n + as.length := by
        match n with
        | 0   => simp [replicate.loop]
        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
    

## Exercises

  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.

  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).

  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.

  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.

  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    
    open Expr
    
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    

Here `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.

Write a function that evaluates such an expression, evaluating each `var n` to
`v n`.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def sampleExpr : Expr :=
      plus (times (var 0) (const 7)) (times (const 2) (var 1))
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    
    def sampleVal : Nat → Nat
      | 0 => 5
      | 1 => 6
      | _ => 0
    
    -- Try it out. You should get 47 here.
    -- #eval eval sampleVal sampleExpr
    

Implement "constant fusion," a procedure that simplifies subterms like `5 + 7`
to `12`. Using the auxiliary function `simpConst`, define a function "fuse":
to simplify a plus or a times, first simplify the arguments recursively, and
then apply `simpConst` to try to simplify the result.

    
    
    inductive Expr where
      | const : Nat → Expr
      | var : Nat → Expr
      | plus : Expr → Expr → Expr
      | times : Expr → Expr → Expr
      deriving Repr
    open Expr
    def eval (v : Nat → Nat) : Expr → Nat
      | const n     => sorry
      | var n       => v n
      | plus e₁ e₂  => sorry
      | times e₁ e₂ => sorry
    def simpConst : Expr → Expr
      | plus (const n₁) (const n₂)  => const (n₁ + n₂)
      | times (const n₁) (const n₂) => const (n₁ * n₂)
      | e                           => e
    
    def fuse : Expr → Expr := sorry
    
    theorem simpConst_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (simpConst e) = eval v e :=
      sorry
    
    theorem fuse_eq (v : Nat → Nat)
            : ∀ e : Expr, eval v (fuse e) = eval v e :=
      sorry
    

The last two theorems show that the definitions preserve the value.

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")

[ __](inductive_types.html "Previous chapter") [
__](structures_and_records.html "Next chapter")
2025-06-01 02:04:18,891 - DEBUG - close.started
2025-06-01 02:04:18,891 - DEBUG - close.complete
2025-06-01 02:04:18,901 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Planning Agent.\n\n        You are a PLANNING AGENT responsible for interpreting Lean 4 programming tasks \ndescribed in natural language and generating a structured, high-level plan \nfor solving them. You do not write code or proofs.\n\n\n        Goals:\n        - Break down the problem into logical subgoals.\n- Identify required Lean constructs or algorithms.\n- Propose a suitable proof strategy.\n- Generate useful keywords for retrieving examples via RAG.\n- Revise plans based on past errors if provided.\n        \n        Inputs:\n        task_description, function_signature (optional), previous_errors (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {'plan_summary': 'string', 'steps': 'list[string]', 'code_keywords': 'list[string]', 'proof_keywords': 'list[string]', 'assumptions': 'list[string]', 'retry_guidance': 'string'}\n        \n        Notes:\n        Focus on strategy and structure. Do not produce code.\nSuggest inductive or constructive proof strategies when possible.\nIf previous errors are provided, analyze them to refine the plan.\nUse clear, concise language.\n\n        \n        Guidelines:\n        \n        "}, {'role': 'user', 'content': 'Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.'}], 'model': 'o3-mini'}}
2025-06-01 02:04:18,902 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:04:18,902 - DEBUG - close.started
2025-06-01 02:04:18,902 - DEBUG - close.complete
2025-06-01 02:04:18,902 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:04:18,909 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62dd220>
2025-06-01 02:04:18,909 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:04:18,919 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62deab0>
2025-06-01 02:04:18,919 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:04:18,919 - DEBUG - send_request_headers.complete
2025-06-01 02:04:18,919 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:04:18,919 - DEBUG - send_request_body.complete
2025-06-01 02:04:18,919 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:04:24,329 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:04:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'5171'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5173'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199526'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'141ms'), (b'x-request-id', b'req_ef6ab1d009c1b51d79d4268a961f0514'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b23ba4b2a3fe6-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:04:24,329 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:04:24,329 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:04:24,330 - DEBUG - receive_response_body.complete
2025-06-01 02:04:24,330 - DEBUG - response_closed.started
2025-06-01 02:04:24,330 - DEBUG - response_closed.complete
2025-06-01 02:04:24,330 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:04:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '5171', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5173', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199526', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '141ms', 'x-request-id': 'req_ef6ab1d009c1b51d79d4268a961f0514', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b23ba4b2a3fe6-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:04:24,330 - DEBUG - request_id: req_ef6ab1d009c1b51d79d4268a961f0514
2025-06-01 02:04:24,331 - INFO - Attempt 1/3
2025-06-01 02:04:24,331 - INFO - Current plan: {
  "plan_summary": "The goal is to implement a Lean 4 function that maps each integer in the input array to its cube. We will utilize array mapping functions to transform each element by computing its cube (n * n * n) and return the resulting array.",
  "steps": [
    "Define the function signature to take an array of integers and return an array of integers.",
    "Utilize the built-in array.map method to iterate over each element in the array.",
    "For each element, compute the cube by multiplying the element by itself three times.",
    "Return the new array with the cubed values, ensuring it has the same length as the input."
  ],
  "code_keywords": [
    "Lean 4",
    "Array.map",
    "function signature",
    "integer multiplication"
  ],
  "proof_keywords": [
    "inductive reasoning",
    "structural induction",
    "array mapping correctness"
  ],
  "assumptions": [
    "The built-in array.map method is available and can be used to transform the array.",
    "Integer arithmetic is correctly implemented in Lean 4."
  ],
  "retry_guidance": "Review error messages related to array indexing or map function usage if encountered. Verify that the cube computation (multiplying the number three times) is correctly defined and that type coercions are handled if necessary."
}
2025-06-01 02:04:24,331 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You are Lean 4 Code & Proof Generator.\n\n        You are a GENERATION AGENT responsible for producing Lean 4 code and proofs \nbased on a structured plan and relevant context.\n\n\n        Goals:\n        - Implement the required Lean 4 code as per the planning output.\n- Construct a formal proof of correctness (non-trivial, no `sorry`).\n- Incorporate relevant patterns or lemmas from RAG if provided.\n        \n        Inputs:\n        plan, rag_context, function_signature, code_template (with {{code}}, {{proof}} placeholders), task_specification\n        \n        Output Format: json\n        \n        Schema:\n        {'code': 'string', 'proof': 'string'}\n        \n        Notes:\n        \n        \n        Guidelines:\n        Ensure syntactically and type-correct Lean 4 code.\nUse helpful constructs like pattern matching, recursion, and tactics.\nBe logically rigorous and concise.\nYou MUST NOT use `sorry` in code or proofs. If you do, your output will be rejected.\nAlways provide a complete implementation and proof.\nIf RAG context is provided, integrate relevant patterns or lemmas.\nIf the plan is incomplete, request additional details.\nDo not include any `def ...` or `import ...` lines in the generated code or proof fragments; only provide the function body and proof script as required by the template.\nWhen the specification is of the form P ↔ result where result is a Bool computed by an if or Boolean expression, you must use by_cases (or split_ifs) on the Boolean condition(s), and in each branch use simp to reduce the goal, then close the goals with trivial, exact, or exfalso as appropriate.\nDo not use curly-brace tactic blocks { ... }; use Lean's standard tactic indentation and structure.\nDo not attempt to prove P ↔ false or P ↔ true by splitting and leaving goals open; always use simp to reduce the goal to false ↔ false, true ↔ true, or similar, and close with trivial or exact.\nIf the function is defined by if ... then ... else ..., your proof should start with unfold and then by_cases on the same condition(s) as the function, and use simp in each branch.\nDo NOT use Lean 3-style tactic blocks (e.g., `case inl => ... | inr => ...`) or tuple constructors with embedded tactic blocks (e.g., `⟨ha, by simp [hz]⟩`). In Lean 4, all tactic blocks must be at the top level and not inside tuple constructors.\nFor specifications of the form `P ↔ result` where `result` is a Bool, after `unfold`, use `by_cases` on the main Boolean condition(s) and use `simp` in each branch. Do not introduce unnecessary intermediate variables or subcases.\nDo NOT use `⟨..., by ...⟩` or similar constructs. All tactic blocks must be at the top level.\nPrefer the simplest possible proof that closes all goals. Avoid introducing unnecessary variables, cases, or tactics.\n\n        "}, {'role': 'user', 'content': 'Plan:\n{\n  "plan_summary": "The goal is to implement a Lean 4 function that maps each integer in the input array to its cube. We will utilize array mapping functions to transform each element by computing its cube (n * n * n) and return the resulting array.",\n  "steps": [\n    "Define the function signature to take an array of integers and return an array of integers.",\n    "Utilize the built-in array.map method to iterate over each element in the array.",\n    "For each element, compute the cube by multiplying the element by itself three times.",\n    "Return the new array with the cubed values, ensuring it has the same length as the input."\n  ],\n  "code_keywords": [\n    "Lean 4",\n    "Array.map",\n    "function signature",\n    "integer multiplication"\n  ],\n  "proof_keywords": [\n    "inductive reasoning",\n    "structural induction",\n    "array mapping correctness"\n  ],\n  "assumptions": [\n    "The built-in array.map method is available and can be used to transform the array.",\n    "Integer arithmetic is correctly implemented in Lean 4."\n  ],\n  "retry_guidance": "Review error messages related to array indexing or map function usage if encountered. Verify that the cube computation (multiplying the number three times) is correctly defined and that type coercions are handled if necessary."\n}\n\nTemplate:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  -- << SPEC START >>\n  (result.size = a.size) ∧\n  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n  -- << SPEC END >>\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  -- << PROOF START >>\n  unfold cubeElements cubeElements_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nRetrieved Context:\n1. [Theorem Proving in Lean 4](title_page.html)\n  2. [**1.** Introduction](introduction.html)\n  3. [**2.** Dependent Type Theory](dependent_type_theory.html)\n  4. [**3.** Propositions and Proofs](propositions_and_proofs.html)\n  5. [**4.** Quantifiers and Equality](quantifiers_and_equality.html)\n  6. [**5.** Tactics](tactics.html)\n  7. [**6.** Interacting with Lean](interacting_with_lean.html)\n  8. [**7.** Inductive Types](inductive_types.html)\n  9. [**8.** Induction and Recursion](induction_and_recursion.html)\n  10. [**9.** Structures and Records](structures_and_records.html)\n  11. [**10.** Type Classes](type_classes.html)\n  12. [**11.** The Conversion Tactic Mode](conv.html)\n  13. [**12.** Axioms and Computation](axioms_and_computation.html)\n\n__ __\n\n  * Light (default)\n  * Rust\n  * Coal\n  * Navy\n  * Ayu\n\n__\n\n# Theorem Proving in Lean 4\n\n[ __](print.html "Print this book") [\n__](https://github.com/leanprover/theorem_proving_in_lean4 "Git repository")\n\n# Introduction\n\n## Computers and Theorem Proving\n\n_Formal verification_ involves the use of logical and computational methods to\nestablish claims that are expressed in precise mathematical terms. These can\ninclude ordinary mathematical theorems, as well as claims that pieces of\nhardware or software, network protocols, and mechanical and hybrid systems\nmeet their specifications. In practice, there is not a sharp distinction\nbetween verifying a piece of mathematics and verifying the correctness of a\nsystem: formal verification requires describing hardware and software systems\nin mathematical terms, at which point establishing claims as to their\ncorrectness becomes a form of theorem proving. Conversely, the proof of a\nmathematical theorem may require a lengthy computation, in which case\nverifying the truth of the theorem requires verifying that the computation\ndoes what it is supposed to do.\n\nThe gold standard for supporting a mathematical claim is to provide a proof,\nand twentieth-century developments in logic show most if not all conventional\nproof methods can be reduced to a small set of axioms and rules in any of a\nnumber of foundational systems. With this reduction, there are two ways that a\ncomputer can help establish a claim: it can help find a proof in the first\nplace, and it can help verify that a purported proof is correct.\n\n_Automated theorem proving_ focuses on the "finding" aspect. Resolution\ntheorem provers, tableau theorem provers, fast satisfiability solvers, and so\non provide means of establishing the validity of formulas in propositional and\nfirst-order logic. Other systems provide search procedures and decision\nprocedures for specific languages and domains, such as linear or nonlinear\nexpressions over the integers or the real numbers. Architectures like SMT\n("satisfiability modulo theories") combine domain-general search methods with\ndomain-specific procedures. Computer algebra systems and specialized\nmathematical software packages provide means of carrying out mathematical\ncomputations, establishing mathematical bounds, or finding mathematical\nobjects. A calculation can be viewed as a proof as well, and these systems,\ntoo, help establish mathematical claims.\n\nAutomated reasoning systems strive for power and efficiency, often at the\nexpense of guaranteed soundness. Such systems can have bugs, and it can be\ndifficult to ensure that the results they deliver are correct. In contrast,\n_interactive theorem proving_ focuses on the "verification" aspect of theorem\nproving, requiring that every claim is supported by a proof in a suitable\naxiomatic foundation. This sets a very high standard: every rule of inference\nand every step of a calculation has to be justified by appealing to prior\ndefinitions and theorems, all the way down to basic axioms and rules. In fact,\nmost such systems provide fully elaborated "proof objects" that can be\ncommunicated to other systems and checked independently. Constructing such\nproofs typically requires much more input and interaction from users, but it\nallows you to obtain deeper and more complex proofs.\n\nThe _Lean Theorem Prover_ aims to bridge the gap between interactive and\nautomated theorem proving, by situating automated tools and methods in a\nframework that supports user interaction and the construction of fully\nspecified axiomatic proofs. The goal is to support both mathematical reasoning\nand reasoning about complex systems, and to verify claims in both domains.\n\nLean\'s underlying logic has a computational interpretation, and Lean can be\nviewed equally well as a programming language. More to the point, it can be\nviewed as a system for writing programs with a precise semantics, as well as\nreasoning about the functions that the programs compute. Lean also has\nmechanisms to serve as its own _metaprogramming language_ , which means that\nyou can implement automation and extend the functionality of Lean using Lean\nitself. These aspects of Lean are described in the free online book,\n[Functional Programming in Lean](https://lean-\nlang.org/functional_programming_in_lean/), though computational aspects of the\nsystem will make an appearance here.\n\n## About Lean\n\nThe _Lean_ project was launched by Leonardo de Moura at Microsoft Research\nRedmond in 2013. It is an ongoing, long-term effort, and much of the potential\nfor automation will be realized only gradually over time. Lean is released\nunder the [Apache 2.0 license](LICENSE), a permissive open source license that\npermits others to use and extend the code and mathematical libraries freely.\n\nTo install Lean in your computer consider using the\n[Quickstart](https://github.com/leanprover/lean4/blob/master/doc/quickstart.md)\ninstructions. The Lean source code, and instructions for building Lean, are\navailable at <https://github.com/leanprover/lean4/>.\n\nThis tutorial describes the current version of Lean, known as Lean 4.\n\n## About this Book\n\nThis book is designed to teach you to develop and verify proofs in Lean. Much\nof the background information you will need in order to do this is not\nspecific to Lean at all. To start with, you will learn the logical system that\nLean is based on, a version of _dependent type theory_ that is powerful enough\nto prove almost any conventional mathematical theorem, and expressive enough\nto do it in a natural way. More specifically, Lean is based on a version of a\nsystem known as the Calculus of Constructions with inductive types. Lean can\nnot only define mathematical objects and express mathematical assertions in\ndependent type theory, but it also can be used as a language for writing\nproofs.\n\nBecause fully detailed axiomatic proofs are so complicated, the challenge of\ntheorem proving is to have the computer fill in as many of the details as\npossible. You will learn various methods to support this in [dependent type\ntheory](dependent_type_theory.html). For example, term rewriting, and Lean\'s\nautomated methods for simplifying terms and expressions automatically.\nSimilarly, methods of _elaboration_ and _type inference_ , which can be used\nto support flexible forms of algebraic reasoning.\n\nFinally, you will learn about features that are specific to Lean, including\nthe language you use to communicate with the system, and the mechanisms Lean\noffers for managing complex theories and data.\n\nThroughout the text you will find examples of Lean code like the one below:\n\n    \n    \n    theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=\n      fun hpq : p ∧ q =>\n      have hp : p := And.left hpq\n      have hq : q := And.right hpq\n      show q ∧ p from And.intro hq hp\n    \n\nNext to every code example in this book, you will see a button that reads\n"Copy to clipboard". Pressing the button copies the example with enough\nsurrounding context to make the code compile correctly. You can paste the\nexample code into [VS Code](https://code.visualstudio.com/) and modify the\nexamples, and Lean will check the results and provide feedback continuously as\nyou type. We recommend running the examples and experimenting with the code on\nyour own as you work through the chapters that follow. You can open this book\nin VS Code by using the command "Lean 4: Docs: Show Documentation Resources"\nand selecting "Theorem Proving in Lean 4" in the tab that opens.\n\n## Acknowledgments\n\nThis tutorial is an open access project maintained on Github. Many people have\ncontributed to the effort, providing corrections, suggestions, examples, and\ntext. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan\nCarter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus\nKlaas de Vries, Ben Dyer, Gabriel Ebner, Anthony Hart, Simon Hudon, Sean\nLeather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John\nMazey, Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman,\nPaul Chisholm, Chris Lovett, and Siddhartha Gadgil for their contributions.\nPlease see [lean prover](https://github.com/leanprover/) and [lean\ncommunity](https://github.com/leanprover-community/) for an up to date list of\nour amazing contributors.\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n\n[ __](title_page.html "Previous chapter") [ __](dependent_type_theory.html\n"Next chapter")\n m by rw [Nat.zero_add, Nat.add_zero])\n       (fun (n : Nat) (ih : m + n = n + m) =>\n        show m + succ n = succ n + m from\n        calc m + succ n\n          _ = succ (m + n) := rfl\n          _ = succ (n + m) := by rw [ih]\n          _ = succ n + m   := sorry)\n    \n\nAt this point, we see that we need another supporting fact, namely, that `succ\n(n + m) = succ n + m`. You can prove this by induction on `m`:\n\n    \n    \n    open Nat\n    \n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        (show succ n + 0 = succ (n + 0) from rfl)\n        (fun (m : Nat) (ih : succ n + m = succ (n + m)) =>\n         show succ n + succ m = succ (n + succ m) from\n         calc succ n + succ m\n           _ = succ (succ n + m)   := rfl\n           _ = succ (succ (n + m)) := by rw [ih]\n           _ = succ (n + succ m)   := rfl)\n    \n\nYou can then replace the `sorry` in the previous proof with `succ_add`. Yet\nagain, the proofs can be compressed:\n\n    \n    \n    namespace Hidden\n    open Nat\n    theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=\n      Nat.recOn (motive := fun x => succ n + x = succ (n + x)) m\n        rfl\n        (fun m ih => by simp only [add_succ, ih])\n    \n    theorem add_comm (m n : Nat) : m + n = n + m :=\n      Nat.recOn (motive := fun x => m + x = x + m) n\n        (by simp)\n        (fun m ih => by simp [add_succ, succ_add, ih])\n    end Hidden\n    \n\n## Other Recursive Data Types\n\nLet us consider some more examples of inductively defined types. For any type,\n`α`, the type `List α` of lists of elements of `α` is defined in the library.\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n      | nil  : List α\n      | cons : α → List α → List α\n    \n    namespace List\n    \n    def append (as bs : List α) : List α :=\n      match as with\n      | nil       => bs\n      | cons a as => cons a (append as bs)\n    \n    theorem nil_append (as : List α) : append nil as = as :=\n      rfl\n    \n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n      rfl\n    \n    end List\n    end Hidden\n    \n\nA list of elements of type `α` is either the empty list, `nil`, or an element\n`h : α` followed by a list `t : List α`. The first element, `h`, is commonly\nknown as the "head" of the list, and the remainder, `t`, is known as the\n"tail."\n\nAs an exercise, prove the following:\n\n    \n    \n    namespace Hidden\n    inductive List (α : Type u) where\n    | nil  : List α\n    | cons : α → List α → List α\n    namespace List\n    def append (as bs : List α) : List α :=\n     match as with\n     | nil       => bs\n     | cons a as => cons a (append as bs)\n    theorem nil_append (as : List α) : append nil as = as :=\n     rfl\n    theorem cons_append (a : α) (as bs : List α)\n                        : append (cons a as) bs = cons a (append as bs) :=\n     rfl\n    theorem append_nil (as : List α) : append as nil = as :=\n      sorry\n    \n    theorem append_assoc (as bs cs : List α)\n            : append (append as bs) cs = append as (append bs cs) :=\n      sorry\n    end List\n    end Hidden\n    \n\nTry also defining the function `length : {α : Type u} → List α → Nat` that\nreturns the length of a list, and prove that it behaves as expected (for\nexample, `length (append as bs) = length as + length bs`).\n\nFor another example, we can define the type of binary trees:\n\n    \n    \n    inductive BinaryTree where\n      | leaf : BinaryTree\n      | node : BinaryTree → BinaryTree → BinaryTree\n    \n\nIn fact, we can even define the type of countably branching trees:\n\n    \n    \n    inductive CBTree where\n      | leaf : CBTree\n      | sup : (Nat → CBTree) → CBTree\n    \n    namespace CBTree\n    \n    def succ (t : CBTree) : CBTree :=\n      sup (fun _ => t)\n    \n    def toCBTree : Nat → CBTree\n      | 0 => leaf\n      | n+1 => succ (toCBTree n)\n    \n    def omega : CBTree :=\n      sup toCBTree\n    \n    end CBTree\n    \n\n## Tactics for Inductive Types\n\nGiven the fundamental importance of inductive types in Lean, it should not be\nsurprising that there are a number of tactics designed to work with them\neffectively. We describe some of them here.\n\nThe `cases` tactic works on elements of an inductively defined type, and does\nwhat the name suggests: it decomposes the element according to each of the\npossible constructors. In its most basic form, it is applied to an element `x`\nin the local context. It then reduces the goal to cases in which `x` is\nreplaced by each of the constructions.\n\n    \n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by\n      intro n\n      cases n\n      . exact hz  -- goal is p 0\n      . apply hs  -- goal is a : Nat ⊢ p (succ a)\n    \n\nThere are extra bells and whistles. For one thing, `cases` allows you to\nchoose the names for each alternative using a `with` clause. In the next\nexample, for example, we choose the name `m` for the argument to `succ`, so\nthat the second case refers to `succ m`. More importantly, the cases tactic\nwill detect any items in the local context that depend on the target variable.\nIt reverts these elements, does the split, and reintroduces them. In the\nexample below, notice that the hypothesis `h : n ≠ 0` becomes `h : 0 ≠ 0` in\nthe first branch, and `h : succ m ≠ 0` in the second.\n\n    \n    \n    open Nat\n    \n    example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by\n      cases n with\n      | zero =>\n        -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0\n        apply absurd rfl h\n      | succ m =>\n        -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m\n        rfl\n    \n\nNotice that `cases` can be used to produce data as well as prove propositions.\n\n    \n    \n    def f (n : Nat) : Nat := by\n      cases n; exact 3; exact 7\n    \n    example : f 0 = 3 := rfl\n    example : f 5 = 7 := rfl\n    \n\nOnce again, cases will revert, split, and then reintroduce dependencies in the\ncontext.\n\n    \n    \n    def Tuple (α : Type) (n : Nat) :=\n      { as : List α // as.length = n }\n    \n    def f {n : Nat} (t : Tuple α n) : Nat := by\n      cases n; exact 3; exact 7\n    \n    def myTuple : Tuple Nat 3 :=\n      ⟨[0, 1, 2], rfl⟩\n    \n    example : f myTuple = 7 :=\n      rfl\n    \n\nHere is an example of multiple constructors with arguments.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    \n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar1 a b => exact b\n      | bar2 c d e => exact e\n    \n\nThe alternatives for each constructor don\'t need to be solved in the order the\nconstructors were declared.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x with\n      | bar2 c d e => exact e\n      | bar1 a b => exact b\n    \n\nThe syntax of the `with` is convenient for writing structured proofs. Lean\nalso provides a complementary `case` tactic, which allows you to focus on goal\nassign variable names.\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar1 a b => exact b\n      case bar2 c d e => exact e\n    \n\nThe `case` tactic is clever, in that it will match the constructor to the\nappropriate goal. For example, we can fill the goals above in the opposite\norder:\n\n    \n    \n    inductive Foo where\n      | bar1 : Nat → Nat → Foo\n      | bar2 : Nat → Nat → Nat → Foo\n    def silly (x : Foo) : Nat := by\n      cases x\n      case bar2 c d e => exact e\n      case bar1 a b => exact b\n    \n\nYou can also use `cases` with an arbitrary expression. Assuming that\nexpression occurs in the goal, the cases tactic will generalize over the\nexpression, introduce the resulting universally quantified variable, and case\non that.\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      cases m + 3 * k\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nThink of this as saying "split on cases as to whether `m + 3 * k` is zero or\nthe successor of some number." The result is functionally equivalent to the\nfollowing:\n\n    \n    \n    open Nat\n    \n    example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)\n            : p (m + 3 * k) := by\n      generalize m + 3 * k = n\n      cases n\n      exact hz   -- goal is p 0\n      apply hs   -- goal is a : Nat ⊢ p (succ a)\n    \n\nNotice that the expression `m + 3 * k` is erased by `generalize`; all that\nmatters is whether it is of the form `0` or `succ a`. This form of `cases`\nwill _not_ revert any hypotheses that also mention the expression in the\nequation (in this case, `m + 3 * k`). If such a term appears in a hypothesis\nand you want to generalize over that as well, you need to `revert` it\nexplicitly.\n\nIf the expression you case on does not appear in the goal, the `cases` tactic\nuses `have` to put the type of the expression into the context. Here is an\nexample:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      cases Nat.lt_or_ge m n\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nThe theorem `Nat.lt_or_ge m n` says `m < n ∨ m ≥ n`, and it is natural to\nthink of the proof above as splitting on these two cases. In the first branch,\nwe have the hypothesis `hlt : m < n`, and in the second we have the hypothesis\n`hge : m ≥ n`. The proof above is functionally equivalent to the following:\n\n    \n    \n    example (p : Prop) (m n : Nat)\n            (h₁ : m < n → p) (h₂ : m ≥ n → p) : p := by\n      have h : m < n ∨ m ≥ n := Nat.lt_or_ge m n\n      cases h\n      case inl hlt => exact h₁ hlt\n      case inr hge => exact h₂ hge\n    \n\nAfter the first two lines, we have `h : m < n ∨ m ≥ n` as a hypothesis, and we\nsimply do cases on that.\n\nHere is another example, where we use the decidability of equality on the\nnatural numbers to split on the cases `m = n` and `m ≠ n`.\n\n    \n    \n    #check Nat.sub_self\n    \n    example (m n : Nat) : m - n = 0 ∨ m ≠ n := by\n      cases Decidable.em (m = n) with\n      | inl heq => rw [heq]; apply Or.inl; exact Nat.sub_self n\n      | inr hne => apply Or.inr; exact hne\n    \n\nRemember that if you `open Classical`, you can use the law of the excluded\nmiddle for any proposition at all. But using type class inference (see\n[Chapter Type Classes](./type_classes.html)), Lean can actually find the\nrelevant decision procedure, which means that you can use the case split in a\ncomputable function.\n\nJust as the `cases` tactic can be used to carry out proof by cases, the\n`induction` tactic can be used to carry out proofs by induction. The syntax is\nsimilar to that of `cases`, except that the argument can only be a term in the\nlocal context. Here is an example:\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n with\n      | zero => rfl\n      | succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nAs with `cases`, we can use the `case` tactic instead of `with`.\n\n    \n    \n    namespace Hidden\n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n\n      case zero => rfl\n      case succ n ih => rw [Nat.add_succ, ih]\n    end Hidden\n    \n\nHere are some additional examples:\n\n    \n    \n    namespace Hidden\n    theorem add_zero (n : Nat) : n + 0 = n := Nat.add_zero n\n    open Nat\n    \n    theorem zero_add (n : Nat) : 0 + n = n := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by\n      induction n <;> simp [*, add_zero, add_succ]\n    \n    theorem add_comm (m n : Nat) : m + n = n + m := by\n      induction n <;> simp [*, add_zero, add_succ, succ_add, zero_add]\n    \n    theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by\n      induction k <;> simp [*, add_zero, add_succ]\n    end Hidden\n    \n\nThe `induction` tactic also supports user-defined induction principles with\nmultiple targets (aka major premises).\n\n    \n    \n    /-\n    theorem Nat.mod.inductionOn\n          {motive : Nat → Nat → Sort u}\n          (x y  : Nat)\n          (ind  : ∀ x y, 0 < y ∧ y ≤ x → motive (x - y) y → motive x y)\n          (base : ∀ x y, ¬(0 < y ∧ y ≤ x) → motive x y)\n          : motive x y :=\n    -/\n    \n    example (x : Nat) {y : Nat} (h : y > 0) : x % y < y := by\n      induction x, y using Nat.mod.inductionOn with\n      | ind x y h₁ ih =>\n        rw [Nat.mod_eq_sub_mod h₁.2]\n        exact ih h\n      | base x y h₁ =>\n        have : ¬ 0 < y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁\n        match this with\n        | Or.inl h₁ => exact absurd h h₁\n        | Or.inr h₁ =>\n          have hgt : y > x := Nat.gt_of_not_le h₁\n          rw [← Nat.mod_eq_of_lt hgt] at hgt\n          assumption\n    \n\nYou can use the `match` notation in tactics too:\n\n    \n    \n    example : p ∨ q → q ∨ p := by\n      intro h\n      match h with\n      | Or.inl _  => apply Or.inr; assumption\n      | Or.inr h2 => apply Or.inl; exact h2\n    \n\nAs a convenience, pattern-matching has been integrated into tactics such as\n`intro` and `funext`.\n\n    \n    \n    example : s ∧ q ∧ r → p ∧ r → q ∧ p := by\n      intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩\n      exact ⟨hq, hp⟩\n    \n    example :\n        (fun (x : Nat × Nat) (y : Nat × Nat) => x.1 + y.2)\n        =\n        (fun (x : Nat × Nat) (z : Nat × Nat) => z.2 + x.1) := by\n      funext (a, b) (c, d)\n      show a + d = d + a\n      rw [Nat.add_comm]\n    \n\nWe close this section with one last tactic that is designed to facilitate\nworking with inductive types, namely, the `injection` tactic. By design, the\nelements of an inductive type are freely generated, which is to say, the\nconstructors are injective and have disjoint ranges. The `injection` tactic is\ndesigned to make use of this fact:\n\n    \n    \n    open Nat\n    \n    example (m n k : Nat) (h : succ (succ m) = succ (succ n))\n            : n + k = m + k := by\n      injection h with h\'\n      injection h\' with h\'\'\n      rw [h\'\']\n    \n\nThe first instance of the tactic adds `h\' : succ m = succ n` to the context,\nand the second adds `h\'\' : m = n`.\n\nThe `injection` tactic also detects contradictions that arise when different\nconstructors are set equal to one another, and uses them to close the goal.\n\n    \n    \n    open Nat\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      injection h\n    \n    example (m n : Nat) (h : succ m = 0) : n = n + 7 := by\n      contradiction\n    \n    example (h : 7 = 4) : False := by\n      contradiction\n    \n\nAs the second example shows, the `contradiction` tactic also detects\ncontradictions of this form.\n\n## Inductive Families\n\nWe are almost done describing the full range of inductive definitions accepted\nby Lean. So far, you have seen that Lean allows you to introduce inductive\ntypes with any number of recursive constructors. In fact, a single inductive\ndefinition can introduce an indexed _family_ of inductive types, in a manner\nwe now describe.\n\nAn inductive family is an indexed family of types defined by a simultaneous\ninduction of the following form:\n\n    \n    \n    inductive foo : ... → Sort u where\n      | constructor₁ : ... → foo ...\n      | constructor₂ : ... → foo ...\n      ...\n      | constructorₙ : ... → foo ...\n    \n\nIn contrast to an ordinary inductive definition, which constructs an element\nof some `Sort u`, the more general version constructs a function `... → Sort\nu`, where "`...`" denotes a sequence of argument types, also known as\n_indices_. Each constructor then constructs an element of some member of the\nfamily. One example is the definition of `Vector α n`, the type of vectors of\nelements of `α` of length `n`:\n\n    \n    \n    namespace Hidden\n    inductive Vector (α : Type u) : Nat → Type u where\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    end Hidden\n    \n\nNotice that the `cons` constructor takes an element of `Vector α n` and\nreturns an element of `Vector α (n+1)`, thereby using an element of one member\nof the family to build an element of another.\n\nA more exotic example is given by the definition of the equality type in Lean:\n\n    \n    \n    namespace Hidden\n    inductive Eq {α : Sort u} (a : α) : α → Prop where\n      | refl : Eq a a\n    end Hidden\n    \n\nFor each fixed `α : Sort u` and `a : α`, this definition constructs a family\nof types `Eq a x`, indexed by `x : α`. Notably, however, there is only one\nconstructor, `refl`, which is an element of `Eq a a`. Intuitively, the only\nway to construct a proof of `Eq a x` is to use reflexivity, in the case where\n`x` is `a`. Note that `Eq a a` is the only inhabited type in the family of\ntypes `Eq a x`. The elimination principle generated by Lean is as follows:\n\n    \n    \n    universe u v\n    \n    #check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}\n                      → motive a rfl → {b : α} → (h : a = b) → motive b h)\n    \n\nIt is a remarkable fact that all the basic axioms for equality follow from the\nconstructor, `refl`, and the eliminator, `Eq.rec`. The definition of equality\nis atypical, however; see the discussion in Section Axiomatic Details.\n\nThe recursor `Eq.rec` is also used to define substitution:\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      Eq.rec (motive := fun x _ => p x) h₂ h₁\n    end Hidden\n    \n\nYou can also define `subst` using `match`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    end Hidden\n    \n\nActually, Lean compiles the `match` expressions using a definition based on\n`Eq.rec`.\n\n    \n    \n    namespace Hidden\n    theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=\n      match h₁ with\n      | rfl => h₂\n    \n    set_option pp.all true\n    #print subst\n      -- ... subst.match_1 ...\n    #print subst.match_1\n      -- ... Eq.casesOn ...\n    #print Eq.casesOn\n      -- ... Eq.rec ...\n    end Hidden\n    \n\nUsing the recursor or `match` with `h₁ : a = b`, we may assume `a` and `b` are\nthe same, in which case, `p b` and `p a` are the same.\n\nIt is not hard to prove that `Eq` is symmetric and transitive. In the\nfollowing example, we prove `symm` and leave as exercises the theorems `trans`\nand `congr` (congruence).\n\n    \n    \n    namespace Hidden\n    theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=\n      match h with\n      | rfl => rfl\n    \n    theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=\n      sorry\n    \n    theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=\n      sorry\n    end Hidden\n    \n\nIn the type theory literature, there are further generalizations of inductive\ndefinitions, for example, the principles of _induction-recursion_ and\n_induction-induction_. These are not supported by Lean.\n\n## Axiomatic Details\n\nWe have described inductive types and their syntax through examples. This\nsection provides additional information for those interested in the axiomatic\nfoundations.\n\nWe have seen that the constructor to an inductive type takes _parameters_ \\---\nintuitively, the arguments that remain fixed throughout the inductive\nconstruction --- and _indices_ , the arguments parameterizing the family of\ntypes that is simultaneously under construction. Each constructor should have\na type, where the argument types are built up from previously defined types,\nthe parameter and index types, and the inductive family currently being\ndefined. The requirement is that if the latter is present at all, it occurs\nonly _strictly positively_. This means simply that any argument to the\nconstructor in which it occurs is a dependent arrow type in which the\ninductive type under definition occurs only as the resulting type, where the\nindices are given in terms of constants and previous arguments.\n\nSince an inductive type lives in `Sort u` for some `u`, it is reasonable to\nask _which_ universe levels `u` can be instantiated to. Each constructor `c`\nin the definition of a family `C` of inductive types is of the form\n\n    \n    \n      c : (a : α) → (b : β[a]) → C a p[a,b]\n    \n\nwhere `a` is a sequence of data type parameters, `b` is the sequence of\narguments to the constructors, and `p[a, b]` are the indices, which determine\nwhich element of the inductive family the construction inhabits. (Note that\nthis description is somewhat misleading, in that the arguments to the\nconstructor can appear in any order as long as the dependencies make sense.)\nThe constraints on the universe level of `C` fall into two cases, depending on\nwhether or not the inductive type is specified to land in `Prop` (that is,\n`Sort 0`).\n\nLet us first consider the case where the inductive type is _not_ specified to\nland in `Prop`. Then the universe level `u` is constrained to satisfy the\nfollowing:\n\n> For each constructor `c` as above, and each `βk[a]` in the sequence `β[a]`,\n> if `βk[a] : Sort v`, we have `u` ≥ `v`.\n\nIn other words, the universe level `u` is required to be at least as large as\nthe universe level of each type that represents an argument to a constructor.\n\nWhen the inductive type is specified to land in `Prop`, there are no\nconstraints on the universe levels of the constructor arguments. But these\nuniverse levels do have a bearing on the elimination rule. Generally speaking,\nfor an inductive type in `Prop`, the motive of the elimination rule is\nrequired to be in `Prop`.\n\nThere is an exception to this last rule: we are allowed to eliminate from an\ninductively defined `Prop` to an arbitrary `Sort` when there is only one\nconstructor and each constructor argument is either in `Prop` or an index. The\nintuition is that in this case the elimination does not make use of any\ninformation that is not already given by the mere fact that the type of\nargument is inhabited. This special case is known as _singleton elimination_.\n\nWe have already seen singleton elimination at play in applications of\n`Eq.rec`, the eliminator for the inductively defined equality type. We can use\nan element `h : Eq a b` to cast an element `t\' : p a` to `p b` even when `p a`\nand `p b` are arbitrary types, because the cast does not produce new data; it\nonly reinterprets the data we already have. Singleton elimination is also used\nwith heterogeneous equality and well-founded recursion, which will be\ndiscussed in a [Chapter Induction and\nRecursion](./induction_and_recursion.html#well-founded-recursion-and-\ninduction).\n\n## Mutual and Nested Inductive Types\n\nWe now consider two generalizations of inductive types that are often useful,\nwhich Lean supports by "compiling" them down to the more primitive kinds of\ninductive types described above. In other words, Lean parses the more general\ndefinitions, defines auxiliary inductive types based on them, and then uses\nthe auxiliary types to define the ones we really want. Lean\'s equation\ncompiler, described in the next chapter, is needed to make use of these types\neffectively. Nonetheless, it makes sense to describe the declarations here,\nbecause they are straightforward variations on ordinary inductive definitions.\n\nFirst, Lean supports _mutually defined_ inductive types. The idea is that we\ncan define two (or more) inductive types at the same time, where each one\nrefers to the other(s).\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : (n : Nat) → Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : (n : Nat) → Even n → Odd (n + 1)\n    end\n    \n\nIn this example, two types are defined simultaneously: a natural number `n` is\n`Even` if it is `0` or one more than an `Odd` number, and `Odd` if it is one\nmore than an `Even` number. In the exercises below, you are asked to spell out\nthe details.\n\nA mutual inductive definition can also be used to define the notation of a\nfinite tree with nodes labelled by elements of `α`:\n\n    \n    \n    mutual\n        inductive Tree (α : Type u) where\n          | node : α → TreeList α → Tree α\n    \n        inductive TreeList (α : Type u) where\n          | nil  : TreeList α\n          | cons : Tree α → TreeList α → TreeList α\n    end\n    \n\nWith this definition, one can construct an element of `Tree α` by giving an\nelement of `α` together with a list of subtrees, possibly empty. The list of\nsubtrees is represented by the type `TreeList α`, which is defined to be\neither the empty list, `nil`, or the `cons` of a tree and an element of\n`TreeList α`.\n\nThis definition is inconvenient to work with, however. It would be much nicer\nif the list of subtrees were given by the type `List (Tree α)`, especially\nsince Lean\'s library contains a number of functions and theorems for working\nwith lists. One can show that the type `TreeList α` is _isomorphic_ to `List\n(Tree α)`, but translating results back and forth along this isomorphism is\ntedious.\n\nIn fact, Lean allows us to define the inductive type we really want:\n\n    \n    \n    inductive Tree (α : Type u) where\n      | mk : α → List (Tree α) → Tree α\n    \n\nThis is known as a _nested_ inductive type. It falls outside the strict\nspecification of an inductive type given in the last section because `Tree`\ndoes not occur strictly positively among the arguments to `mk`, but, rather,\nnested inside the `List` type constructor. Lean then automatically builds the\nisomorphism between `TreeList α` and `List (Tree α)` in its kernel, and\ndefines the constructors for `Tree` in terms of the isomorphism.\n\n## Exercises\n\n  1. Try defining other operations on the natural numbers, such as multiplication, the predecessor function (with `pred 0 = 0`), truncated subtraction (with `n - m = 0` when `m` is greater than or equal to `n`), and exponentiation. Then try proving some of their basic properties, building on the theorems we have already proved.\n\nSince many of these are already defined in Lean\'s core library, you should\nwork within a namespace named `Hidden`, or something like that, in order to\navoid name clashes.\n\n  2. Define some operations on lists, like a `length` function or the `reverse` function. Prove some properties, such as the following:\n\na. `length (s ++ t) = length s + length t`\n\nb. `length (reverse t) = length t`\n\nc. `reverse (reverse t) = t`\n\n  3. Define an inductive data type consisting of terms built up from the following constructors:\n\n     * `const n`, a constant denoting the natural number `n`\n     * `var n`, a variable, numbered `n`\n     * `plus s t`, denoting the sum of `s` and `t`\n     * `times s t`, denoting the product of `s` and `t`\n\nRecursively define a function that evaluates any such term with respect to an\nassignment of values to the variables.\n\n  4. Similarly, define the type of propositional formulas, as well as functions on the type of such formulas: an evaluation function, functions that measure the complexity of a formula, and a function that substitutes another formula for a given variable.\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n\n[ __](interacting_with_lean.html "Previous chapter") [\n__](induction_and_recursion.html "Next chapter")\n modifier `decreasing_by` allows us to provide\nour own tactic. Here is an example.\n\n    \n    \n    theorem div_lemma {x y : Nat} : 0 < y ∧ y ≤ x → x - y < x :=\n      fun ⟨ypos, ylex⟩ => Nat.sub_lt (Nat.lt_of_lt_of_le ypos ylex) ypos\n    \n    def div (x y : Nat) : Nat :=\n      if h : 0 < y ∧ y ≤ x then\n        div (x - y) y + 1\n      else\n        0\n    decreasing_by apply div_lemma; assumption\n    \n\nNote that `decreasing_by` is not replacement for `termination_by`, they\ncomplement each other. `termination_by` is used to specify a well-founded\nrelation, and `decreasing_by` for providing our own tactic for showing\nrecursive applications are decreasing. In the following example, we use both\nof them.\n\n    \n    \n    def ack : Nat → Nat → Nat\n      | 0,   y   => y+1\n      | x+1, 0   => ack x 1\n      | x+1, y+1 => ack x (ack (x+1) y)\n    termination_by x y => (x, y)\n    decreasing_by\n      all_goals simp_wf -- unfolds well-founded recursion auxiliary definitions\n      · apply Prod.Lex.left; simp_arith\n      · apply Prod.Lex.right; simp_arith\n      · apply Prod.Lex.left; simp_arith\n    \n\nWe can use `decreasing_by sorry` to instruct Lean to "trust" us that the\nfunction terminates.\n\n    \n    \n    def natToBin : Nat → List Nat\n      | 0     => [0]\n      | 1     => [1]\n      | n + 2 => natToBin ((n + 2) / 2) ++ [n % 2]\n    decreasing_by sorry\n    \n    #eval natToBin 1234567\n    \n\nRecall that using `sorry` is equivalent to using a new axiom, and should be\navoided. In the following example, we used the `sorry` to prove `False`. The\ncommand `#print axioms unsound` shows that `unsound` depends on the unsound\naxiom `sorryAx` used to implement `sorry`.\n\n    \n    \n    def unsound (x : Nat) : False :=\n      unsound (x + 1)\n    decreasing_by sorry\n    \n    #check unsound 0\n    -- `unsound 0` is a proof of `False`\n    \n    #print axioms unsound\n    -- \'unsound\' depends on axioms: [sorryAx]\n    \n\nSummary:\n\n  * If there is no `termination_by`, a well-founded relation is derived (if possible) by selecting an argument and then using typeclass resolution to synthesize a well-founded relation for this argument\'s type.\n\n  * If `termination_by` is specified, it maps the arguments of the function to a type `α` and type class resolution is again used. Recall that, the default instance for `β × γ` is a lexicographic order based on the well-founded relations for `β` and `γ`.\n\n  * The default well-founded relation instance for `Nat` is `<`.\n\n  * By default, the tactic `decreasing_tactic` is used to show that recursive applications are smaller with respect to the selected well-founded relation. If `decreasing_tactic` fails, the error message includes the remaining goal `... |- G`. Note that, the `decreasing_tactic` uses `assumption`. So, you can include a `have`-expression to prove goal `G`. You can also provide your own tactic using `decreasing_by`.\n\n## Mutual Recursion\n\nLean also supports mutual recursive definitions. The syntax is similar to that\nfor mutual inductive types. Here is an example:\n\n    \n    \n    mutual\n      def even : Nat → Bool\n        | 0   => true\n        | n+1 => odd n\n    \n      def odd : Nat → Bool\n        | 0   => false\n        | n+1 => even n\n    end\n    \n    example : even (a + 1) = odd a := by\n      simp [even]\n    \n    example : odd (a + 1) = even a := by\n      simp [odd]\n    \n    theorem even_eq_not_odd : ∀ a, even a = not (odd a) := by\n      intro a; induction a\n      . simp [even, odd]\n      . simp [even, odd, *]\n    \n\nWhat makes this a mutual definition is that `even` is defined recursively in\nterms of `odd`, while `odd` is defined recursively in terms of `even`. Under\nthe hood, this is compiled as a single recursive definition. The internally\ndefined function takes, as argument, an element of a sum type, either an input\nto `even`, or an input to `odd`. It then returns an output appropriate to the\ninput. To define that function, Lean uses a suitable well-founded measure. The\ninternals are meant to be hidden from users; the canonical way to make use of\nsuch definitions is to use `simp` (or `unfold`), as we did above.\n\nMutual recursive definitions also provide natural ways of working with mutual\nand nested inductive types. Recall the definition of `Even` and `Odd` as\nmutual inductive predicates as presented before.\n\n    \n    \n    mutual\n      inductive Even : Nat → Prop where\n        | even_zero : Even 0\n        | even_succ : ∀ n, Odd n → Even (n + 1)\n    \n      inductive Odd : Nat → Prop where\n        | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    \n\nThe constructors, `even_zero`, `even_succ`, and `odd_succ` provide positive\nmeans for showing that a number is even or odd. We need to use the fact that\nthe inductive type is generated by these constructors to know that zero is not\nodd, and that the latter two implications reverse. As usual, the constructors\nare kept in a namespace that is named after the type being defined, and the\ncommand `open Even Odd` allows us to access them more conveniently.\n\n    \n    \n    mutual\n     inductive Even : Nat → Prop where\n       | even_zero : Even 0\n       | even_succ : ∀ n, Odd n → Even (n + 1)\n     inductive Odd : Nat → Prop where\n       | odd_succ : ∀ n, Even n → Odd (n + 1)\n    end\n    open Even Odd\n    \n    theorem not_odd_zero : ¬ Odd 0 :=\n      fun h => nomatch h\n    \n    theorem even_of_odd_succ : ∀ n, Odd (n + 1) → Even n\n      | _, odd_succ n h => h\n    \n    theorem odd_of_even_succ : ∀ n, Even (n + 1) → Odd n\n      | _, even_succ n h => h\n    \n\nFor another example, suppose we use a nested inductive type to define a set of\nterms inductively, so that a term is either a constant (with a name given by a\nstring), or the result of applying a constant to a list of constants.\n\n    \n    \n    inductive Term where\n      | const : String → Term\n      | app   : String → List Term → Term\n    \n\nWe can then use a mutual recursive definition to count the number of constants\noccurring in a term, as well as the number occurring in a list of terms.\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    \n    mutual\n      def numConsts : Term → Nat\n        | const _ => 1\n        | app _ cs => numConstsLst cs\n    \n      def numConstsLst : List Term → Nat\n        | [] => 0\n        | c :: cs => numConsts c + numConstsLst cs\n    end\n    \n    def sample := app "f" [app "g" [const "x"], const "y"]\n    \n    #eval numConsts sample\n    \n    end Term\n    \n\nAs a final example, we define a function `replaceConst a b e` that replaces a\nconstant `a` with `b` in a term `e`, and then prove the number of constants is\nthe same. Note that, our proof uses mutual recursion (aka induction).\n\n    \n    \n    inductive Term where\n     | const : String → Term\n     | app   : String → List Term → Term\n    namespace Term\n    mutual\n     def numConsts : Term → Nat\n       | const _ => 1\n       | app _ cs => numConstsLst cs\n      def numConstsLst : List Term → Nat\n       | [] => 0\n       | c :: cs => numConsts c + numConstsLst cs\n    end\n    mutual\n      def replaceConst (a b : String) : Term → Term\n        | const c => if a == c then const b else const c\n        | app f cs => app f (replaceConstLst a b cs)\n    \n      def replaceConstLst (a b : String) : List Term → List Term\n        | [] => []\n        | c :: cs => replaceConst a b c :: replaceConstLst a b cs\n    end\n    \n    mutual\n      theorem numConsts_replaceConst (a b : String) (e : Term)\n                : numConsts (replaceConst a b e) = numConsts e := by\n        match e with\n        | const c => simp [replaceConst]; split <;> simp [numConsts]\n        | app f cs => simp [replaceConst, numConsts, numConsts_replaceConstLst a b cs]\n    \n      theorem numConsts_replaceConstLst (a b : String) (es : List Term)\n                : numConstsLst (replaceConstLst a b es) = numConstsLst es := by\n        match es with\n        | [] => simp [replaceConstLst, numConstsLst]\n        | c :: cs =>\n          simp [replaceConstLst, numConstsLst, numConsts_replaceConst a b c,\n                numConsts_replaceConstLst a b cs]\n    end\n    \n\n## Dependent Pattern Matching\n\nAll the examples of pattern matching we considered in Section Pattern Matching\ncan easily be written using `casesOn` and `recOn`. However, this is often not\nthe case with indexed inductive families such as `Vector α n`, since case\nsplits impose constraints on the values of the indices. Without the equation\ncompiler, we would need a lot of boilerplate code to define very simple\nfunctions such as `map`, `zip`, and `unzip` using recursors. To understand the\ndifficulty, consider what it would take to define a function `tail` which\ntakes a vector `v : Vector α (succ n)` and deletes the first element. A first\nthought might be to use the `casesOn` function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    #check @Vector.casesOn\n    /-\n      {α : Type u}\n      → {motive : (a : Nat) → Vector α a → Sort v} →\n      → {a : Nat} → (t : Vector α a)\n      → motive 0 nil\n      → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))\n      → motive a t\n    -/\n    \n    end Vector\n    \n\nBut what value should we return in the `nil` case? Something funny is going\non: if `v` has type `Vector α (succ n)`, it _can\'t_ be nil, but it is not\nclear how to tell that to `casesOn`.\n\nOne solution is to define an auxiliary function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=\n      Vector.casesOn (motive := fun x _ => x = n + 1 → Vector α n) v\n        (fun h : 0 = n + 1 => Nat.noConfusion h)\n        (fun (a : α) (m : Nat) (as : Vector α m) =>\n         fun (h : m + 1 = n + 1) =>\n           Nat.noConfusion h (fun h1 : m = n => h1 ▸ as))\n    \n    def tail (v : Vector α (n+1)) : Vector α n :=\n      tailAux v rfl\n    end Vector\n    \n\nIn the `nil` case, `m` is instantiated to `0`, and `noConfusion` makes use of\nthe fact that `0 = succ n` cannot occur. Otherwise, `v` is of the form `a ::\nw`, and we can simply return `w`, after casting it from a vector of length `m`\nto a vector of length `n`.\n\nThe difficulty in defining `tail` is to maintain the relationships between the\nindices. The hypothesis `e : m = n + 1` in `tailAux` is used to communicate\nthe relationship between `n` and the index associated with the minor premise.\nMoreover, the `zero = n + 1` case is unreachable, and the canonical way to\ndiscard such a case is to use `noConfusion`.\n\nThe `tail` function is, however, easy to define using recursive equations, and\nthe equation compiler generates all the boilerplate code automatically for us.\nHere are a number of similar examples:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : {n : Nat} → Vector α (n+1) → α\n      | n, cons a as => a\n    \n    def tail : {n : Nat} → Vector α (n+1) → Vector α n\n      | n, cons a as => as\n    \n    theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v\n      | n, cons a as => rfl\n    \n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\nNote that we can omit recursive equations for "unreachable" cases such as\n`head nil`. The automatically generated definitions for indexed families are\nfar from straightforward. For example:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    #print map\n    #print map.match_1\n    end Vector\n    \n\nThe `map` function is even more tedious to define by hand than the `tail`\nfunction. We encourage you to try it, using `recOn`, `casesOn` and\n`noConfusion`.\n\n## Inaccessible Patterns\n\nSometimes an argument in a dependent matching pattern is not essential to the\ndefinition, but nonetheless has to be included to specialize the type of the\nexpression appropriately. Lean allows users to mark such subterms as\n_inaccessible_ for pattern matching. These annotations are essential, for\nexample, when a term occurring in the left-hand side is neither a variable nor\na constructor application, because these are not suitable targets for pattern\nmatching. We can view such inaccessible patterns as "don\'t care" components of\nthe patterns. You can declare a subterm inaccessible by writing `.(t)`. If the\ninaccessible pattern can be inferred, you can also write `_`.\n\nThe following example, we declare an inductive type that defines the property\nof "being in the image of `f`". You can view an element of the type `ImageOf f\nb` as evidence that `b` is in the image of `f`, whereby the constructor `imf`\nis used to build such evidence. We can then define any function `f` with an\n"inverse" which takes anything in the image of `f` to an element that is\nmapped to it. The typing rules forces us to write `f a` for the first\nargument, but this term is neither a variable nor a constructor application,\nand plays no role in the pattern-matching definition. To define the function\n`inverse` below, we _have to_ mark `f a` inaccessible.\n\n    \n    \n    inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where\n      | imf : (a : α) → ImageOf f (f a)\n    \n    open ImageOf\n    \n    def inverse {f : α → β} : (b : β) → ImageOf f b → α\n      | .(f a), imf a => a\n    \n    def inverse\' {f : α → β} : (b : β) → ImageOf f b → α\n      | _, imf a => a\n    \n\nIn the example above, the inaccessible annotation makes it clear that `f` is\n_not_ a pattern matching variable.\n\nInaccessible patterns can be used to clarify and control definitions that make\nuse of dependent pattern matching. Consider the following definition of the\nfunction `Vector.add`, which adds two vectors of elements of a type, assuming\nthat type has an associated addition function:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    \n    namespace Vector\n    \n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | 0,   nil,       nil       => nil\n      | n+1, cons a as, cons b bs => cons (a + b) (add as bs)\n    \n    end Vector\n    \n\nThe argument `{n : Nat}` appear after the colon, because it cannot be held\nfixed throughout the definition. When implementing this definition, the\nequation compiler starts with a case distinction as to whether the first\nargument is `0` or of the form `n+1`. This is followed by nested case splits\non the next two arguments, and in each case the equation compiler rules out\nthe cases are not compatible with the first pattern.\n\nBut, in fact, a case split is not required on the first argument; the\n`casesOn` eliminator for `Vector` automatically abstracts this argument and\nreplaces it by `0` and `n + 1` when we do a case split on the second argument.\nUsing inaccessible patterns, we can prompt the equation compiler to avoid the\ncase split on `n`\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | .(_), nil,       nil       => nil\n      | .(_), cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nMarking the position as an inaccessible pattern tells the equation compiler\nfirst, that the form of the argument should be inferred from the constraints\nposed by the other arguments, and, second, that the first argument should\n_not_ participate in pattern matching.\n\nThe inaccessible pattern `.(_)` can be written as `_` for convenience.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n\n      | _, nil,       nil       => nil\n      | _, cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nAs we mentioned above, the argument `{n : Nat}` is part of the pattern\nmatching, because it cannot be held fixed throughout the definition. In\nprevious Lean versions, users often found it cumbersome to have to include\nthese extra discriminants. Thus, Lean 4 implements a new feature,\n_discriminant refinement_ , which includes these extra discriminants\nautomatically for us.\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nWhen combined with the _auto bound implicits_ feature, you can simplify the\ndeclare further and write:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def add [Add α] : Vector α n → Vector α n → Vector α n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a + b) (add as bs)\n    end Vector\n    \n\nUsing these new features, you can write the other vector functions defined in\nthe previous sections more compactly as follows:\n\n    \n    \n    inductive Vector (α : Type u) : Nat → Type u\n      | nil  : Vector α 0\n      | cons : α → {n : Nat} → Vector α n → Vector α (n+1)\n    namespace Vector\n    def head : Vector α (n+1) → α\n      | cons a as => a\n    \n    def tail : Vector α (n+1) → Vector α n\n      | cons a as => as\n    \n    theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v\n      | cons a as => rfl\n    \n    def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (f a b) (map f as bs)\n    \n    def zip : Vector α n → Vector β n → Vector (α × β) n\n      | nil,       nil       => nil\n      | cons a as, cons b bs => cons (a, b) (zip as bs)\n    end Vector\n    \n\n## Match Expressions\n\nLean also provides a compiler for _match-with_ expressions found in many\nfunctional languages:\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n\nThis does not look very different from an ordinary pattern matching\ndefinition, but the point is that a `match` can be used anywhere in an\nexpression, and with arbitrary arguments.\n\n    \n    \n    def isNotZero (m : Nat) : Bool :=\n      match m with\n      | 0   => false\n      | n+1 => true\n    \n    def filter (p : α → Bool) : List α → List α\n      | []      => []\n      | a :: as =>\n        match p a with\n        | true => a :: filter p as\n        | false => filter p as\n    \n    example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl\n    \n\nHere is another example:\n\n    \n    \n    def foo (n : Nat) (b c : Bool) :=\n      5 + match n - 5, b && c with\n          | 0,   true  => 0\n          | m+1, true  => m + 7\n          | 0,   false => 5\n          | m+1, false => m + 3\n    \n    #eval foo 7 true false\n    \n    example : foo 7 true false = 9 := rfl\n    \n\nLean uses the `match` construct internally to implement pattern-matching in\nall parts of the system. Thus, all four of these definitions have the same net\neffect:\n\n    \n    \n    def bar₁ : Nat × Nat → Nat\n      | (m, n) => m + n\n    \n    def bar₂ (p : Nat × Nat) : Nat :=\n      match p with\n      | (m, n) => m + n\n    \n    def bar₃ : Nat × Nat → Nat :=\n      fun (m, n) => m + n\n    \n    def bar₄ (p : Nat × Nat) : Nat :=\n      let (m, n) := p; m + n\n    \n\nThese variations are equally useful for destructing propositions:\n\n    \n    \n    variable (p q : Nat → Prop)\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      match h₀, h₁ with\n      | ⟨x, px⟩, ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=\n      fun ⟨x, px⟩ ⟨y, qy⟩ => ⟨x, y, px, qy⟩\n    \n    example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)\n            : ∃ x y, p x ∧ q y :=\n      let ⟨x, px⟩ := h₀\n      let ⟨y, qy⟩ := h₁\n      ⟨x, y, px, qy⟩\n    \n\n## Local Recursive Declarations\n\nYou can define local recursive declarations using the `let rec` keyword:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      let rec loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n      loop n []\n    \n    #check @replicate.loop\n    -- {α : Type} → α → Nat → List α → List α\n    \n\nLean creates an auxiliary declaration for each `let rec`. In the example\nabove, it created the declaration `replicate.loop` for the `let rec loop`\noccurring at `replicate`. Note that, Lean "closes" the declaration by adding\nany local variable occurring in the `let rec` declaration as additional\nparameters. For example, the local variable `a` occurs at `let rec loop`.\n\nYou can also use `let rec` in tactic mode and for creating proofs by\ninduction:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n     let rec loop : Nat → List α → List α\n       | 0,   as => as\n       | n+1, as => loop n (a::as)\n     loop n []\n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      let rec aux (n : Nat) (as : List α)\n                  : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n      exact aux n []\n    \n\nYou can also introduce auxiliary recursive declarations using a `where` clause\nafter your definition. Lean converts them into a `let rec`:\n\n    \n    \n    def replicate (n : Nat) (a : α) : List α :=\n      loop n []\n    where\n      loop : Nat → List α → List α\n        | 0,   as => as\n        | n+1, as => loop n (a::as)\n    \n    theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by\n      exact aux n []\n    where\n      aux (n : Nat) (as : List α)\n          : (replicate.loop a n as).length = n + as.length := by\n        match n with\n        | 0   => simp [replicate.loop]\n        | n+1 => simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]\n    \n\n## Exercises\n\n  1. Open a namespace `Hidden` to avoid naming conflicts, and use the equation compiler to define addition, multiplication, and exponentiation on the natural numbers. Then use the equation compiler to derive some of their basic properties.\n\n  2. Similarly, use the equation compiler to define some basic operations on lists (like the `reverse` function) and prove theorems about lists by induction (such as the fact that `reverse (reverse xs) = xs` for any list `xs`).\n\n  3. Define your own function to carry out course-of-value recursion on the natural numbers. Similarly, see if you can figure out how to define `WellFounded.fix` on your own.\n\n  4. Following the examples in Section Dependent Pattern Matching, define a function that will append two vectors. This is tricky; you will have to define an auxiliary function.\n\n  5. Consider the following type of arithmetic expressions. The idea is that `var n` is a variable, `vₙ`, and `const n` is the constant whose value is `n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    \n    open Expr\n    \n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    \n\nHere `sampleExpr` represents `(v₀ * 7) + (2 * v₁)`.\n\nWrite a function that evaluates such an expression, evaluating each `var n` to\n`v n`.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def sampleExpr : Expr :=\n      plus (times (var 0) (const 7)) (times (const 2) (var 1))\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    \n    def sampleVal : Nat → Nat\n      | 0 => 5\n      | 1 => 6\n      | _ => 0\n    \n    -- Try it out. You should get 47 here.\n    -- #eval eval sampleVal sampleExpr\n    \n\nImplement "constant fusion," a procedure that simplifies subterms like `5 + 7`\nto `12`. Using the auxiliary function `simpConst`, define a function "fuse":\nto simplify a plus or a times, first simplify the arguments recursively, and\nthen apply `simpConst` to try to simplify the result.\n\n    \n    \n    inductive Expr where\n      | const : Nat → Expr\n      | var : Nat → Expr\n      | plus : Expr → Expr → Expr\n      | times : Expr → Expr → Expr\n      deriving Repr\n    open Expr\n    def eval (v : Nat → Nat) : Expr → Nat\n      | const n     => sorry\n      | var n       => v n\n      | plus e₁ e₂  => sorry\n      | times e₁ e₂ => sorry\n    def simpConst : Expr → Expr\n      | plus (const n₁) (const n₂)  => const (n₁ + n₂)\n      | times (const n₁) (const n₂) => const (n₁ * n₂)\n      | e                           => e\n    \n    def fuse : Expr → Expr := sorry\n    \n    theorem simpConst_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (simpConst e) = eval v e :=\n      sorry\n    \n    theorem fuse_eq (v : Nat → Nat)\n            : ∀ e : Expr, eval v (fuse e) = eval v e :=\n      sorry\n    \n\nThe last two theorems show that the definitions preserve the value.\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")\n\n[ __](inductive_types.html "Previous chapter") [\n__](structures_and_records.html "Next chapter")'}], 'model': 'gpt-4o'}}
2025-06-01 02:04:24,333 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:04:24,333 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:04:24,333 - DEBUG - send_request_headers.complete
2025-06-01 02:04:24,333 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:04:24,337 - DEBUG - send_request_body.complete
2025-06-01 02:04:24,338 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:04:26,799 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:04:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'2239'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2242'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'7729'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'44.54s'), (b'x-request-id', b'req_ab46c6fcf1315de7f65a6c85ea35ed2b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b23dc2e8e3fe6-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:04:26,799 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:04:26,800 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:04:26,801 - DEBUG - receive_response_body.complete
2025-06-01 02:04:26,801 - DEBUG - response_closed.started
2025-06-01 02:04:26,801 - DEBUG - response_closed.complete
2025-06-01 02:04:26,801 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:04:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '2239', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2242', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '30000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '7729', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '44.54s', 'x-request-id': 'req_ab46c6fcf1315de7f65a6c85ea35ed2b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b23dc2e8e3fe6-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:04:26,801 - DEBUG - request_id: req_ab46c6fcf1315de7f65a6c85ea35ed2b
2025-06-01 02:04:26,801 - INFO - Raw solution received: ```json
{
  "code": "a.map (fun n => n * n * n)",
  "proof": "\n  intro a\n  apply And.intro\n  . simp\n  . intro i hi\n    simp\n"
}
```
2025-06-01 02:04:26,801 - INFO - <class 'str'>
2025-06-01 02:04:26,801 - INFO - Generated solution: {'code': 'a.map (fun n => n * n * n)', 'proof': '\n  intro a\n  apply And.intro\n  . simp\n  . intro i hi\n    simp\n'}
2025-06-01 02:04:32,218 - INFO - Lean execution result: Lean Error: lean_playground/TempTest.lean:23:8: error: tactic 'introN' failed, insufficient number of binders
a : Array ℤ
⊢ (Array.map (fun n => n * n * n) a).size = a.size ∧
    ∀ i < a.size, (Array.map (fun n => n * n * n) a)[i]! = a[i]! * a[i]! * a[i]!
2025-06-01 02:04:32,219 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are Lean 4 Proof Validator and Feedback Generator.\n\n        You are a VERIFICATION & FEEDBACK AGENT. You validate generated Lean 4 code \nand proofs by executing them and providing structured error feedback.\n\n\n        Goals:\n        - Execute Lean 4 code and parse stdout/stderr.\n- Classify and summarize any errors.\n- Suggest fixes for code or proof generation.\n- Recommend updates to planning when necessary.\n        \n        Inputs:\n        generated_code, generated_proof, lean_output_stdout, lean_output_stderr, previous_plan (optional)\n        \n        Output Format: json\n        \n        Schema:\n        {\'verdict\': \'enum ["pass", "fail"]\', \'error_summary\': \'string\', \'error_type\': \'enum ["syntax", "type", "proof", "timeout", "unknown"]\', \'suggested_fix\': \'string\', \'retry_strategy\': \'string\'}\n        \n        Notes:\n        Avoid vague suggestions—be specific about what needs to be revised.\nOffer fix hints in terms of proof tactics or code constructs.\nMark output as "pass" only if the code and proof execute without errors.\nIf the proof fails, provide a detailed error summary and suggest specific tactics or code changes.\nIf the code fails to compile or run, classify the error type and suggest how to fix it.\nIf the proof times out, suggest strategies to optimize the proof or code.\nIf the output is unknown, request clarification or additional context.\n\n        \n        Guidelines:\n        \n        '}, {'role': 'user', 'content': "Problem Description:\n-----Description----- \nThis task requires writing a Lean 4 method that transforms an array of integers by replacing every element with its cube. In other words, for each element in the input array, the output array should contain the result of multiplying that element by itself three times.\n\n-----Input-----\nThe input consists of:\na: An array of integers (which may be empty or non-empty).\n\n-----Output-----\nThe output is an array of integers:\nReturns an array with the same length as the input, where each element is the cube of the corresponding element in the input array.\n\n-----Note-----\nThere are no additional preconditions; the method should work correctly for any array of integers.\n\nLean Template:\nimport Mathlib\nimport Aesop\n\n-- Implementation\ndef cubeElements (a : Array Int) : Array Int :=\n  -- << CODE START >>\n  {{code}}\n  -- << CODE END >>\n\n\n-- Theorem: The length of the output array must be the same as the length of the input array; Each element in the output array is the cube of the corresponding element in the input array\ndef cubeElements_spec (a : Array Int) (result : Array Int) : Prop :=\n  -- << SPEC START >>\n  (result.size = a.size) ∧\n  (∀ i, i < a.size → result[i]! = a[i]! * a[i]! * a[i]!)\n  -- << SPEC END >>\n\ntheorem cubeElements_spec_satisfied (a : Array Int) :\n  cubeElements_spec a (cubeElements a) := by\n  -- << PROOF START >>\n  unfold cubeElements cubeElements_spec\n  {{proof}}\n  -- << PROOF END >>\n\n\nGenerated Implementation:\na.map (fun n => n * n * n)\n\nGenerated Proof:\n\n  intro a\n  apply And.intro\n  . simp\n  . intro i hi\n    simp\n\n\nLean Output STDOUT:\n\n\nLean Output STDERR:\nLean Error: lean_playground/TempTest.lean:23:8: error: tactic 'introN' failed, insufficient number of binders\na : Array ℤ\n⊢ (Array.map (fun n => n * n * n) a).size = a.size ∧\n    ∀ i < a.size, (Array.map (fun n => n * n * n) a)[i]! = a[i]! * a[i]! * a[i]!"}], 'model': 'o3-mini'}}
2025-06-01 02:04:32,219 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-01 02:04:32,219 - DEBUG - close.started
2025-06-01 02:04:32,219 - DEBUG - close.complete
2025-06-01 02:04:32,220 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-06-01 02:04:32,226 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b5460>
2025-06-01 02:04:32,226 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x715a9e4c3bd0> server_hostname='api.openai.com' timeout=5.0
2025-06-01 02:04:32,235 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7159b62b7920>
2025-06-01 02:04:32,235 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-01 02:04:32,236 - DEBUG - send_request_headers.complete
2025-06-01 02:04:32,236 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-01 02:04:32,236 - DEBUG - send_request_body.complete
2025-06-01 02:04:32,236 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-01 02:04:40,980 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 01 Jun 2025 02:04:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-2ubqdehd3txfzsucvalz9yzg'), (b'openai-processing-ms', b'8085'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'8138'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'199165'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'250ms'), (b'x-request-id', b'req_5bc243e9a9d1c4a6c72b06f846266bc4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'948b240d89df8fcd-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-01 02:04:40,980 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-01 02:04:40,980 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-01 02:04:40,980 - DEBUG - receive_response_body.complete
2025-06-01 02:04:40,980 - DEBUG - response_closed.started
2025-06-01 02:04:40,980 - DEBUG - response_closed.complete
2025-06-01 02:04:40,980 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 01 Jun 2025 02:04:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-2ubqdehd3txfzsucvalz9yzg', 'openai-processing-ms': '8085', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '8138', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '199165', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '250ms', 'x-request-id': 'req_5bc243e9a9d1c4a6c72b06f846266bc4', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '948b240d89df8fcd-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-01 02:04:40,981 - DEBUG - request_id: req_5bc243e9a9d1c4a6c72b06f846266bc4
2025-06-01 02:04:40,981 - INFO - Feedback received: {'verdict': 'fail', 'error_summary': "The error arises because the proof begins with 'intro a', but 'a' is already introduced by the theorem's statement. Lean then complains about an insufficient number of binders when trying to introduce another 'a'.", 'error_type': 'proof', 'suggested_fix': "Remove the 'intro a' tactic. The theorem already has 'a' in its context. The revised proof should start with 'apply And.intro' (or combine the steps) without reintroducing 'a'. For example:\n\n  theorem cubeElements_spec_satisfied (a : Array Int) : cubeElements_spec a (cubeElements a) := by\n    unfold cubeElements cubeElements_spec\n    apply And.intro\n    . simp\n    . intro i hi\n      simp\n\nThis should resolve the error.", 'retry_strategy': "Remove the redundant 'intro a' and re-run the proof. If further errors arise, check the unfolding and simplification steps to ensure they match the desired specification."}
2025-06-01 02:04:40,981 - INFO - Solution generated in 22.57 seconds
2025-06-01 02:04:40,981 - INFO - Generated code length: 5 characters
2025-06-01 02:04:40,981 - INFO - Generated proof length: 5 characters
2025-06-01 02:04:40,981 - INFO - Loading Lean template and inserting generated solution...
2025-06-01 02:04:40,981 - INFO - Executing Lean code with implementation only (proof=sorry)...
2025-06-01 02:04:46,373 - INFO - Implementation test result: FAIL
2025-06-01 02:04:46,373 - ERROR - Implementation error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:18:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:04:46,373 - INFO - Executing Lean code with implementation and proof...
2025-06-01 02:04:51,633 - INFO - Full solution test result: FAIL
2025-06-01 02:04:51,633 - ERROR - Proof error: lean_playground/TempTest.lean:5:4: warning: declaration uses 'sorry'
lean_playground/TempTest.lean:18:8: warning: declaration uses 'sorry'
lean_playgr...
2025-06-01 02:04:51,633 - ERROR - ❌ Implementation fails unit tests
2025-06-01 02:04:51,633 - ERROR - ❌ Proof has errors
2025-06-01 02:04:51,633 - INFO - Testing Summary:
2025-06-01 02:04:51,633 - INFO - Task task_id_0:
2025-06-01 02:04:51,633 - INFO -   Passes Unit Tests: True
2025-06-01 02:04:51,633 - INFO -   Proof is Correct: True
2025-06-01 02:04:51,633 - INFO -   Runtime: 19.42529034614563 seconds
2025-06-01 02:04:51,634 - INFO - Testing completed.
2025-06-01 02:04:51,634 - INFO - Task task_id_58:
2025-06-01 02:04:51,634 - INFO -   Passes Unit Tests: False
2025-06-01 02:04:51,634 - INFO -   Proof is Correct: False
2025-06-01 02:04:51,634 - INFO -   Runtime: 26.108152389526367 seconds
2025-06-01 02:04:51,634 - INFO - Testing completed.
2025-06-01 02:04:51,634 - INFO - Task task_id_77:
2025-06-01 02:04:51,634 - INFO -   Passes Unit Tests: False
2025-06-01 02:04:51,634 - INFO -   Proof is Correct: False
2025-06-01 02:04:51,634 - INFO -   Runtime: 23.245276927947998 seconds
2025-06-01 02:04:51,634 - INFO - Testing completed.
2025-06-01 02:04:51,634 - INFO - Task task_id_127:
2025-06-01 02:04:51,634 - INFO -   Passes Unit Tests: False
2025-06-01 02:04:51,634 - INFO -   Proof is Correct: False
2025-06-01 02:04:51,634 - INFO -   Runtime: 24.97942876815796 seconds
2025-06-01 02:04:51,634 - INFO - Testing completed.
2025-06-01 02:04:51,634 - INFO - Task task_id_227:
2025-06-01 02:04:51,634 - INFO -   Passes Unit Tests: False
2025-06-01 02:04:51,634 - INFO -   Proof is Correct: False
2025-06-01 02:04:51,634 - INFO -   Runtime: 27.29011821746826 seconds
2025-06-01 02:04:51,634 - INFO - Testing completed.
2025-06-01 02:04:51,634 - INFO - Task task_id_404:
2025-06-01 02:04:51,634 - INFO -   Passes Unit Tests: False
2025-06-01 02:04:51,634 - INFO -   Proof is Correct: False
2025-06-01 02:04:51,634 - INFO -   Runtime: 34.69204044342041 seconds
2025-06-01 02:04:51,635 - INFO - Testing completed.
2025-06-01 02:04:51,635 - INFO - Task task_id_431:
2025-06-01 02:04:51,635 - INFO -   Passes Unit Tests: False
2025-06-01 02:04:51,635 - INFO -   Proof is Correct: False
2025-06-01 02:04:51,635 - INFO -   Runtime: 25.61886477470398 seconds
2025-06-01 02:04:51,635 - INFO - Testing completed.
2025-06-01 02:04:51,635 - INFO - Task task_id_433:
2025-06-01 02:04:51,635 - INFO -   Passes Unit Tests: False
2025-06-01 02:04:51,635 - INFO -   Proof is Correct: False
2025-06-01 02:04:51,635 - INFO -   Runtime: 25.77520227432251 seconds
2025-06-01 02:04:51,635 - INFO - Testing completed.
2025-06-01 02:04:51,635 - INFO - Task task_id_435:
2025-06-01 02:04:51,635 - INFO -   Passes Unit Tests: False
2025-06-01 02:04:51,635 - INFO -   Proof is Correct: False
2025-06-01 02:04:51,635 - INFO -   Runtime: 28.339226245880127 seconds
2025-06-01 02:04:51,635 - INFO - Testing completed.
2025-06-01 02:04:51,635 - INFO - Task task_id_441:
2025-06-01 02:04:51,635 - INFO -   Passes Unit Tests: True
2025-06-01 02:04:51,635 - INFO -   Proof is Correct: True
2025-06-01 02:04:51,635 - INFO -   Runtime: 14.882381916046143 seconds
2025-06-01 02:04:51,635 - INFO - Testing completed.
2025-06-01 02:04:51,636 - INFO - Task task_id_447:
2025-06-01 02:04:51,636 - INFO -   Passes Unit Tests: False
2025-06-01 02:04:51,636 - INFO -   Proof is Correct: False
2025-06-01 02:04:51,636 - INFO -   Runtime: 22.573102712631226 seconds
2025-06-01 02:04:51,636 - INFO - Testing completed.
2025-06-01 02:04:51,766 - DEBUG - close.started
2025-06-01 02:04:51,766 - DEBUG - close.complete
2025-06-01 02:04:51,766 - DEBUG - close.started
2025-06-01 02:04:51,767 - DEBUG - close.complete
2025-06-01 02:04:51,956 - DEBUG - close.started
2025-06-01 02:04:51,956 - DEBUG - close.complete
